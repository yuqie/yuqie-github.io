<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Chrome书签同步</title>
    <url>/2020/08/27/Chrome%E4%B9%A6%E7%AD%BE%E5%90%8C%E6%AD%A5/</url>
    <content><![CDATA[<p>最近一直在用自己的笔记本工作，有些书签没有同步到办公室电脑上，今天刚好到办公室了，设置好VPN，点击同步，竟然没有同步，后续删除账号再重新登录也没能解决。</p>
<a id="more"></a>
<p><strong>手动大法</strong>: 将笔记本电脑上的bookmarks（一般在C:\Users\username\AppData\Local\Google\Chrome\User Data\Default）拷贝到台式机相应的文件夹下。</p>
<p><strong>如何恢复书签</strong>： C:\Users\username\AppData\Local\Google\Chrome\User Data\Default 该目录下一般会有几天前的备份文件bookmarks.bak，将其重命名为bookmarks即可。</p>
<p>PS：最后删除账号，重新添加搞定了。</p>
]]></content>
      <categories>
        <category>日常记录</category>
      </categories>
      <tags>
        <tag>Chrome</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown之表格</title>
    <url>/2020/07/25/Markdown%E4%B9%8B%E8%A1%A8%E6%A0%BC/</url>
    <content><![CDATA[<h2 id="1-Markdown自带表格编辑语法"><a href="#1-Markdown自带表格编辑语法" class="headerlink" title="1. Markdown自带表格编辑语法"></a>1. Markdown自带表格编辑语法</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"> |水果        | 价格    |  数量  |</span><br><span class="line"> |:--------   | -----:   | :----: |</span><br><span class="line">|香蕉        | $1      |   5    |</span><br><span class="line"> |苹果        | $1      |   6    |</span><br><span class="line"> |草莓        | $1      |   7    |</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>效果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">水果</th>
<th style="text-align:right">价格</th>
<th style="text-align:center">数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">香蕉</td>
<td style="text-align:right">$1</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:left">苹果</td>
<td style="text-align:right">$1</td>
<td style="text-align:center">6</td>
</tr>
<tr>
<td style="text-align:left">草莓</td>
<td style="text-align:right">$1</td>
<td style="text-align:center">7</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-HTML表格"><a href="#2-HTML表格" class="headerlink" title="2. HTML表格"></a>2. HTML表格</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">table</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">caption</span>&gt;</span>学生成绩表<span class="tag">&lt;/<span class="name">caption</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">th</span>&gt;</span>学号<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">th</span>&gt;</span>期中<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">th</span>&gt;</span>期末<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>001<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>88<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>90<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">tr</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>002<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>96<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>97<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">tr</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br></pre></td></tr></table></figure>
<th>和<td>标签都可以显示表格单元格。不同的是<th>在单元格中加粗显示。

**<th>：定义表格内的表头单元格。此th元素内部的文本通常会呈现为粗体。**



效果：

<table>
<caption>学生成绩表</caption>
<tr>

<th>学号</th>
<th>期中</th>
<th>期末</th>

<p>&lt;/tr&gt;</p>
<tr>

<td>001</td>
<td>88</td>
<td>90</td>

<p>&lt;/tr&gt; </p>
<tr>

<td>002</td>
<td>96</td>
<td>97</td>

<p>&lt;/tr&gt;<br>&lt;/table&gt;</p>
<h2 id="3-Excel表格"><a href="#3-Excel表格" class="headerlink" title="3. Excel表格"></a>3. Excel表格</h2><p>markdown支持html语法，所以可以先使用Excel生成需要的表格，单击另存为，选择导出格式为html，此时可选择所需表格区间。保存后打开生成的html文件，将其中<code>&lt;table&gt;&lt;/table&gt;</code> 间的数据复制到markdown中即可。</p>
<p><strong>此方式可以创建复杂的表格，比如合并单元格等。</strong></p>
<h2 id="4-exceltk工具"><a href="#4-exceltk工具" class="headerlink" title="4. exceltk工具"></a>4. exceltk工具</h2><p><a href="[http://fanfeilong.github.io/](http://fanfeilong.github.io/">范飞龙</a>)开发的<a href="https://github.com/fanfeilong/exceltk" target="_blank" rel="noopener">exceltk工具</a>，通过简单的cmd命令即可把excel表格中的内容转换为Markdown所能识别的格式，直接把转换后的md格式内容复制到简书即可输出期望的表格样式。</p>
<pre><code>exceltk用例
整个表格： exceltk.exe -t md -xls xxx.xls  
          exceltk.exe -t md -xls xxx.xlsx
指定sheet：
          exceltk.exe -t md -xls xx.xls -sheet sheetname   
          exceltk.exe -t md -xls xx.xlsx -sheet sheetnameexceltk
</code></pre><h2 id="5-在线Markdown表格生成"><a href="#5-在线Markdown表格生成" class="headerlink" title="5. 在线Markdown表格生成"></a>5. 在线Markdown表格生成</h2><p>​      <a href="https://tableconvert.com/" target="_blank" rel="noopener">tableconvert</a>可以在线制作表格，并将其转为Markdown，CSV，Excel，XML，HTML等格式。</p>
<hr>
]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown之隐藏内容</title>
    <url>/2020/07/25/Markdown%E4%B9%8B%E9%9A%90%E8%97%8F%E5%86%85%E5%AE%B9/</url>
    <content><![CDATA[<h2 id="1-HTML标签隐藏"><a href="#1-HTML标签隐藏" class="headerlink" title="1. HTML标签隐藏"></a>1. HTML标签隐藏</h2><p>Markdown内嵌html语法，所以可以用隐藏的html标签。</p>
<a id="more"></a>
<p><strong>注意：前面需空一行</strong></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">'display: none'</span>&gt;</span></span><br><span class="line">注释</span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>测试（在浏览器中看不到即为成功）：</p>
<div style='display: none'>
注释
</div>

<h2 id="2-HTML注释隐藏"><a href="#2-HTML注释隐藏" class="headerlink" title="2. HTML注释隐藏"></a>2. HTML注释隐藏</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--注释，不会在浏览器中显示。--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">多段</span></span><br><span class="line"><span class="comment">注释，</span></span><br><span class="line"><span class="comment">不会在浏览器中显示。</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br></pre></td></tr></table></figure>
<p>测试（在浏览器中看不到即为成功）：</p>
<!--注释，不会在浏览器中显示。-->
<!--
多段
注释，
不会在浏览器中显示。
-->
<h2 id="3-hack-方法隐藏"><a href="#3-hack-方法隐藏" class="headerlink" title="3. hack 方法隐藏"></a>3. hack 方法隐藏</h2><p>hack方法利用markdown的解析原理来实现注释。一般有的markdown解析器不支持上面的注释方法，这个时候就可以用hack方法。</p>
<p>hack方法比上面2种方法稳定，但是语义化太差。<br><figure class="highlight html"><table><tr><td class="code"><pre><span class="line">[comment]: <span class="tag">&lt;&gt;</span> (注释，不会在浏览器中显示。)</span><br><span class="line">[//]: <span class="tag">&lt;&gt;</span> (注释，不会在浏览器中显示。)</span><br><span class="line">[//]: # (注释，不会在浏览器中显示。)</span><br></pre></td></tr></table></figure><br>其中，这种方法最稳定，适用性最强：<br><figure class="highlight html"><table><tr><td class="code"><pre><span class="line">[//]: # (注释，不会在浏览器中显示。)</span><br></pre></td></tr></table></figure><br>还可以：<br><figure class="highlight html"><table><tr><td class="code"><pre><span class="line">[^_^]: # (注释，不会在浏览器中显示。)</span><br></pre></td></tr></table></figure><br>测试（在浏览器中看不到即为成功）：</p>
<blockquote id="fn__^">
<sup>_^</sup>. # (注释，不会在浏览器中显示。)<a href="#reffn__^" title="Jump back to footnote [_^] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn__^">
<sup>_^</sup>. # (注释，不会在浏览器中显示。)<a href="#reffn__^" title="Jump back to footnote [_^] in the text."> &#8617;</a>
</blockquote>
<h2 id="4-HTML标签折叠"><a href="#4-HTML标签折叠" class="headerlink" title="4. HTML标签折叠"></a>4. HTML标签折叠</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">details</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">summary</span>&gt;</span><span class="tag">&lt;<span class="name">mark</span>&gt;</span><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">darkred</span>&gt;</span>摘要<span class="tag">&lt;/<span class="name">font</span>&gt;</span><span class="tag">&lt;/<span class="name">mark</span>&gt;</span><span class="tag">&lt;/<span class="name">summary</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span>&gt;</span> -title<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">pre</span>&gt;</span><span class="tag">&lt;<span class="name">code</span>&gt;</span>  </span><br><span class="line">   隐藏代码块</span><br><span class="line">  <span class="tag">&lt;/<span class="name">code</span>&gt;</span><span class="tag">&lt;/<span class="name">pre</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">details</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>summary：折叠语法展示的摘要</p>
<p>details：折叠语法标签</p>
<p>pre：以原有格式显示元素内的文字是已经格式化的文本。</p>
<p>blockcode：表示程序的代码块。</p>
<p>code：指定代码范例。</p>
<p><strong>隐藏内容也可以是markdown格式。</strong></p>
<p><strong><em>效果</em></strong>：</p>
<details>
<summary><mark><font color=darkred>markdown隐藏内容</font></mark></summary>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;details&gt;</span><br><span class="line">&lt;summary&gt;&lt;mark&gt;&lt;font color&#x3D;darkred&gt;摘要&lt;&#x2F;font&gt;&lt;&#x2F;mark&gt;&lt;&#x2F;summary&gt;</span><br><span class="line"></span><br><span class="line">隐藏内容</span><br><span class="line">&lt;&#x2F;details&gt;</span><br></pre></td></tr></table></figure>

</details>

<hr>
<p>来源：<a href="https://www.imooc.com/article/23400" target="_blank" rel="noopener">慕课网CandyBullet</a></p>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2>]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown之字体颜色以及背景色</title>
    <url>/2020/07/26/Markdown%E4%B9%8B%E5%AD%97%E4%BD%93%E9%A2%9C%E8%89%B2%E4%BB%A5%E5%8F%8A%E8%83%8C%E6%99%AF%E8%89%B2/</url>
    <content><![CDATA[<h2 id="字体，大小和颜色"><a href="#字体，大小和颜色" class="headerlink" title="字体，大小和颜色"></a>字体，大小和颜色</h2><a id="more"></a>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">font</span> <span class="attr">face</span>=<span class="string">"黑体"</span>&gt;</span></span>我是黑体字<span class="xml"><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">font</span> <span class="attr">face</span>=<span class="string">"微软雅黑"</span>&gt;</span></span>我是微软雅黑<span class="xml"><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">font</span> <span class="attr">face</span>=<span class="string">"STCAIYUN"</span>&gt;</span></span>我是华文彩云<span class="xml"><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">red</span>&gt;</span></span>我是红色<span class="xml"><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">#008000</span>&gt;</span></span>我是绿色<span class="xml"><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">Blue</span>&gt;</span></span>我是蓝色<span class="xml"><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">font</span> <span class="attr">size</span>=<span class="string">5</span>&gt;</span></span>我是尺寸<span class="xml"><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">font</span> <span class="attr">face</span>=<span class="string">"黑体"</span> <span class="attr">color</span>=<span class="string">green</span> <span class="attr">size</span>=<span class="string">5</span>&gt;</span></span>我是黑体，绿色，尺寸为5<span class="xml"><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span></span><br></pre></td></tr></table></figure>
<p>效果如下： </p>
<font face="黑体">我是黑体字</font>
<font face="微软雅黑">我是微软雅黑</font>
<font face="STCAIYUN">我是华文彩云</font>
<font color="red">我是红色</font>
<font color="#008000">我是绿色</font>
<font color="Blue">我是蓝色</font>
<font size="5">我是尺寸</font>
<font face="黑体" color="green" size="5">我是黑体，绿色，尺寸为5</font>

<h2 id="文字背景色"><a href="#文字背景色" class="headerlink" title="文字背景色"></a>文字背景色</h2><p>由于 Markdown中不支持 style 标签和 style 属性，所以这里只能是通过 table, tr, td 等表格标签的 bgcolor 属性来实现背景色，将一整行看作一个表格，更改单元格的背景色（bgcolor）</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">table</span>&gt;</span></span><span class="xml"><span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><span class="xml"><span class="tag">&lt;<span class="name">td</span> <span class="attr">bgcolor</span>=<span class="string">blue</span>&gt;</span></span>颜色测试<span class="xml"><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><span class="xml"><span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><span class="xml"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></span></span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<table><tr><td bgcolor="blue">颜色测试</td></tr></table>

<h2 id="图片居中"><a href="#图片居中" class="headerlink" title="图片居中"></a>图片居中</h2><p>将文件放在 <em>/source/image</em> 文件夹下,  可以实现图片显示, 但是这种引用在本地markdown 编辑器中会无法预览,因为相对路径不一致,找不到文件。</p>
<p>使用img标签</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">align</span>=<span class="string">right</span>&gt;</span></span><span class="xml"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"image/timg.jfif"</span> <span class="attr">width</span>=<span class="string">"50%"</span> <span class="attr">height</span>=<span class="string">"50%"</span>&gt;</span></span><span class="xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br></pre></td></tr></table></figure>
<div align="right"><img src="/.com//timg.jfif" width="50%" height="50%"></div>

<p>使用div标签+css控制图片显示</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">"width: 200px; margin: auto"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<div style="width: 200px; margin: auto"></div>

<hr>
<p>参考：<a href="https://blog.csdn.net/heimu24/article/details/81189700" target="_blank" rel="noopener">https://blog.csdn.net/heimu24/article/details/81189700</a></p>
]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown文件恢复</title>
    <url>/2020/08/29/Markdown%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D/</url>
    <content><![CDATA[<p>忘了点保存，打开一看文件是空的。</p>
<ol>
<li>打开Typora $\rightarrow $ 文件$\rightarrow $ 偏好设置</li>
<li>向下滚动到 “保存 &amp; 恢复” 区域</li>
<li>点击 “恢复未保存的草稿”</li>
</ol>
<p>方法参考：<a href="https://blog.csdn.net/makesomethings/article/details/90181198" target="_blank" rel="noopener">https://blog.csdn.net/makesomethings/article/details/90181198</a></p>
]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown之表情，删除线和任务列表</title>
    <url>/2020/08/29/Markdown%E4%B9%8B%E8%A1%A8%E6%83%85%EF%BC%8C%E5%88%A0%E9%99%A4%E7%BA%BF%E5%92%8C%E4%BB%BB%E5%8A%A1%E5%88%97%E8%A1%A8/</url>
    <content><![CDATA[<h3 id="表情"><a href="#表情" class="headerlink" title="表情"></a>表情</h3><p><strong>aliases编码：语法：</strong> <code>:&lt;emoji&gt;:</code></p>
<p>🔽 😓😄</p>
<a id="more"></a>
<p>可查表：</p>
<p><a href="https://www.webfx.com/tools/emoji-cheat-sheet/" target="_blank" rel="noopener">https://www.webfx.com/tools/emoji-cheat-sheet/</a></p>
<p><a href="https://www.cnblogs.com/minghaiJ/p/10685965.html" target="_blank" rel="noopener">https://www.cnblogs.com/minghaiJ/p/10685965.html</a></p>
<p><strong>hexdecimal编码：语法：</strong> <code>&amp;#xCODE;</code> </p>
<p>可以从 <a href="https://link.zhihu.com/?target=https%3A//apps.timwhitlock.info/emoji/tables/unicode%23block-4-enclosed-characters">Emoji Unicode Tables</a> 中查到表情的Unicode编码，去掉开头U+即为code。(typora不支持ORZ)</p>
<h3 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h3><p>用HTML的语法<code>&lt;u&gt;Underline&lt;/u&gt;</code>将产生下划线<u>Underline</u>.</p>
<h3 id="任务线"><a href="#任务线" class="headerlink" title="任务线"></a>任务线</h3><p>GFM添加了删除文本的语法，这是标准的Markdown语法木有的。使用<code>~~</code>包裹的文本将会具有删除的样式，例如<code>~删除文本~</code>将产生<del>删除文本</del>的样式。</p>
<h3 id="任务列表"><a href="#任务列表" class="headerlink" title="任务列表"></a>任务列表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- [ ] 吃饭</span><br><span class="line">- [ ] 逛街</span><br><span class="line">- [ ] 看电影</span><br><span class="line">- [ ] 约泡</span><br></pre></td></tr></table></figure>
<ul>
<li>[ ] 吃饭</li>
<li>[ ] 逛街</li>
<li>[ ] 看电影</li>
<li>[ ] 约泡</li>
</ul>
<h3 id="最大化快捷键"><a href="#最大化快捷键" class="headerlink" title="最大化快捷键"></a>最大化快捷键</h3><p>进去退出最大化：F11</p>
<p>参考：<a href="https://www.jianshu.com/p/092de536d948" target="_blank" rel="noopener">https://www.jianshu.com/p/092de536d948</a></p>
]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>python之csv</title>
    <url>/2020/07/25/python%E4%B9%8Bcsv/</url>
    <content><![CDATA[<h2 id="1-什么是csv？"><a href="#1-什么是csv？" class="headerlink" title="1. 什么是csv？"></a>1. 什么是csv？</h2><p><strong>Comma Separated Values</strong> (CSV), also called called <strong>Character Separated Values</strong> or <strong>Comma Delimited files</strong>, is a file format for data storage which looks like a text file, which contains a list of data separated by commas or other characters.</p>
<a id="more"></a>
<details>
<summary><mark><font color=darkred>csv的格式特点</font></mark></summary>

- One line for each record
- Comma separated fields
- Space-characters adjacent to commas are ignored
- Fields with in-built commas are separated by double quote characters
- Fields with double quote characters must be surrounded by double quotes. Each inbuilt double quote must be represented by a pair of consecutive quotes
- Fields that contain inbuilt line-breaks must be surrounded by double quotes

</details>

<h2 id="2-为什么使用csv文件？"><a href="#2-为什么使用csv文件？" class="headerlink" title="2. 为什么使用csv文件？"></a>2. 为什么使用csv文件？</h2><p>CSV结构简单，是纯文本文件，和txt的区别仅在于后缀名不同。用来做数据存储，容量比XML小（其数据由key-value组成），功能比TXT强大，另外Excel也直接支持CSV文件的查看和生成。</p>
<h3 id="Excel-打开-CSV-文件时遇到的问题。"><a href="#Excel-打开-CSV-文件时遇到的问题。" class="headerlink" title="Excel 打开  CSV 文件时遇到的问题。"></a>Excel 打开  CSV 文件时遇到的问题。</h3><p>直接用 Excel 打开 UTF-8 编码的 CSV 文件会导致汉字部分出现乱码，原因是 Excel 以 ANSI 格式打开，不会做编码识别。打开 UTF-8 编码的 CSV 文件的方法：</p>
<h4 id="1-从数据导入文本"><a href="#1-从数据导入文本" class="headerlink" title="1. 从数据导入文本"></a>1. 从数据导入文本</h4><ul>
<li>打开 Excel </li>
<li>执行“数据”-&gt;“自文本”</li>
</ul>
<ul>
<li>选择 CSV 文件，出现文本导入向导</li>
<li>选择“分隔符号”，下一步</li>
<li>勾选“逗号”，去掉“ Tab 键”，下一步，完成</li>
<li>在“导入数据”对话框里，直接点确定</li>
</ul>
<h4 id="2-转存为ANSI格式"><a href="#2-转存为ANSI格式" class="headerlink" title="2. 转存为ANSI格式"></a>2. 转存为ANSI格式</h4><p>用文本编辑器打开CSV文件，另存为ANSI格式，再用Excel打开。</p>
<h2 id="3-python自带模块csv"><a href="#3-python自带模块csv" class="headerlink" title="3. python自带模块csv"></a>3. python自带模块csv</h2><p><a href="https://docs.python.org/zh-cn/3/library/csv.html#module-csv" target="_blank" rel="noopener"><code>csv</code></a> 模块实现了 CSV 格式表单数据的读写。其提供了诸如“以兼容 Excel 的方式输出数据文件”或“读取 Excel 程序输出的数据文件”的功能，</p>
<p><code>csv</code>定义了以下函数：</p>
<blockquote>
<p><code>csv.reader</code>(<em>csvfile</em>, <em>dialect=’excel’</em>, **fmtparams)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'eggs.csv'</span>, newline=<span class="string">''</span>) <span class="keyword">as</span> csvfile:</span><br><span class="line">    spamreader = csv.reader(csvfile, delimiter=<span class="string">' '</span>, quotechar=<span class="string">'|'</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> spamreader:</span><br><span class="line">        print(<span class="string">', '</span>.join(row))</span><br></pre></td></tr></table></figure>
<p><code>csv.writer</code>(<em>csvfile</em>, <em>dialect=’excel’</em>, **fmtparams)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'eggs.csv'</span>, <span class="string">'w'</span>, newline=<span class="string">''</span>) <span class="keyword">as</span> csvfile:</span><br><span class="line">    spamwriter = csv.writer(csvfile, delimiter=<span class="string">' '</span>,</span><br><span class="line">                            quotechar=<span class="string">'|'</span>, quoting=csv.QUOTE_MINIMAL)</span><br><span class="line">    spamwriter.writerow([<span class="string">'Spam'</span>] * <span class="number">5</span> + [<span class="string">'Baked Beans'</span>])</span><br><span class="line">    spamwriter.writerow([<span class="string">'Spam'</span>, <span class="string">'Lovely Spam'</span>, <span class="string">'Wonderful Spam'</span>])</span><br></pre></td></tr></table></figure>
</blockquote>
<p><code>csv</code>定义了以下类：</p>
<blockquote>
<p>class csv.DictReader(<em>f</em>, <em>fieldnames=None</em>, <em>restkey=None</em>, <em>restval=None</em>, <em>dialect=’excel’</em>, <em>args, *</em>kwds) </p>
<p>将csv数据读取为字典</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Name</th>
<th style="text-align:right">Age</th>
<th style="text-align:center">Class</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">A</td>
<td style="text-align:right">20</td>
<td style="text-align:center">two</td>
</tr>
<tr>
<td style="text-align:left">B</td>
<td style="text-align:right">21</td>
<td style="text-align:center">one</td>
</tr>
<tr>
<td style="text-align:left">C</td>
<td style="text-align:right">22</td>
<td style="text-align:center">one</td>
</tr>
<tr>
<td style="text-align:left">D</td>
<td style="text-align:right">23</td>
<td style="text-align:center">three</td>
</tr>
<tr>
<td style="text-align:left">E</td>
<td style="text-align:right">24</td>
<td style="text-align:center">one</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"csv.csv"</span>,<span class="string">'r'</span>,encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line"> reader = csv.reader(f)</span><br><span class="line"> fieldnames = next(reader)<span class="comment">#获取数据的第一列，作为后续要转为字典的键名 生成器，next方法获取</span></span><br><span class="line"> <span class="comment"># print(fieldnames)</span></span><br><span class="line"> csv_reader = csv.DictReader(f,fieldnames=fieldnames) <span class="comment">#self._fieldnames = fieldnames # list of keys for the dict 以list的形式存放键名</span></span><br><span class="line"> <span class="keyword">for</span> row <span class="keyword">in</span> csv_reader:</span><br><span class="line">  d=&#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> k,v <span class="keyword">in</span> row.items():</span><br><span class="line">   d[k]=v</span><br><span class="line">  print(d)</span><br></pre></td></tr></table></figure>
<p>class csv.DictWriter(<em>f</em>, <em>fieldnames=None</em>, <em>extrasaction=’raise’</em>, <em>dialect=’excel’</em>, <em>args, *</em>kwds)</p>
<p>将字典写入csv文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">file_path = <span class="string">r"E:\new.csv"</span></span><br><span class="line"><span class="keyword">with</span> open(file_path, <span class="string">"w"</span>, newline=<span class="string">""</span>, encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    fieldnames = [<span class="string">"书名"</span>, <span class="string">"作者"</span>, <span class="string">"出版时间"</span>, <span class="string">"价格"</span>, <span class="string">"评分"</span>, <span class="string">"评价人数"</span>]</span><br><span class="line">    f_csv = csv.DictWriter(f, fieldnames)</span><br><span class="line">    f_csv.writeheader()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(time_list)):</span><br><span class="line">        f_csv.writerow(</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"书名"</span>: book_name_list[i],</span><br><span class="line">                <span class="string">"作者"</span>: author_list[i],</span><br><span class="line">                <span class="string">"出版时间"</span>: time_list[i],</span><br><span class="line">                <span class="string">"价格"</span>: price_list[i],</span><br><span class="line">                <span class="string">"评分"</span>: score_list[i],</span><br><span class="line">                <span class="string">"评价人数"</span>: evaluator_list[i]</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
</blockquote>
<p>参考资源：</p>
<p><a href="https://docs.python.org/zh-cn/3/library/csv.html#module-csv" target="_blank" rel="noopener">Python中文文档-module csv</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>csv</tag>
        <tag>数据处理</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown数学符号和公式</title>
    <url>/2020/08/29/Markdown%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7%E5%92%8C%E5%85%AC%E5%BC%8F%20193445/</url>
    <content><![CDATA[<p>Markdown中数学符号和公式的书写规则和<code>latex</code>非常像。</p>
<p>行内公式或数学符号使用<code>$</code>符号包裹Tex命令即可。</p>
<p>单独的公式段落可以用$$$$包裹，或者点击“段落” $\rightarrow$ “公式块”，或者使用快捷键Shift+Ctrl+M</p>
<a id="more"></a>
<p>常用的数学符号：</p>
<h3 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h3><p><strong>小写</strong> \alpha \beta \chi \delta \epsilon \eta \gamma \kappa \lambda \mu \nu \omega \tau \theta \xi \zeta </p>
<p>$\alpha \beta \chi \delta \epsilon \eta \gamma \kappa \lambda \mu \nu \omega \tau \theta \xi \zeta $</p>
<p><strong>大写</strong> 将第一个字母大写即可： $\Alpha \Beta \Chi \Delta \Epsilon $</p>
<h3 id="操作符-关系符"><a href="#操作符-关系符" class="headerlink" title="操作符 关系符"></a>操作符 关系符</h3><p>常用的有 ：</p>
<p>\cdot  \pm \leq \geq \gg \ll \times \div \oplus \otimes \equiv \approx \because \therefore</p>
<p>$\cdot  \pm \leq \geq \gg \ll \times \div \oplus \otimes \equiv \approx \because \therefore$</p>
<h3 id="数学着重号"><a href="#数学着重号" class="headerlink" title="数学着重号"></a>数学着重号</h3><p>\ddot{a} \bar{a} \dot{a} \hat{a} \vec{a} \check{a}</p>
<p>$\ddot{a} \bar{a} \dot{a} \hat{a} \vec{a} \check{a}$</p>
<h3 id="各式箭头"><a href="#各式箭头" class="headerlink" title="各式箭头"></a>各式箭头</h3><p>\leftarrow \rightarrow \uparrow \downarrow</p>
<p>$\leftarrow \rightarrow \uparrow \downarrow$</p>
<p>\Leftarrow \Rightarrow \Uparrow \Downarrow</p>
<p>$\Leftarrow \Rightarrow \Uparrow \Downarrow$</p>
<p>\longleftarrow \longrightarrow </p>
<p>$\longleftarrow \longrightarrow $</p>
<p>\leftrightarrow  \updownarrow</p>
<p>$\leftrightarrow  \updownarrow$</p>
<h3 id="其他符号"><a href="#其他符号" class="headerlink" title="其他符号"></a>其他符号</h3><p>\infty  \forall \nabla \partial \varnothing \hbar \exists</p>
<p>$\infty  \forall \nabla \partial \varnothing \hbar \exists$</p>
<p>\sum  \int  \prod \oint  \iint</p>
<p>$\sum  \int  \prod \oint  \iint$</p>
<h3 id="数学结构"><a href="#数学结构" class="headerlink" title="数学结构"></a>数学结构</h3><p>\frac{a}{b} $\frac{a}{b}$</p>
<p>\sqrt[n]{a} $\sqrt[n]{a} $</p>
<p>\overline{abc} $\overline{abc}$</p>
<p>\widehat{abc} $\widehat{abc}$</p>
<p>\overrightarrow{abc} $\overrightarrow{abc}$</p>
<p>\left\{ a b c\}\right</p>
<p>a = \left \{ \begin{array}{c} x^2 \\ 2x \\0 \end{array} \right. \} $a = \left \{ \begin{array}{c} x^2 \\ 2x \\0 \end{array} \right.$</p>
<p>\left ( \begin{array}{cc} a &amp; b \\ c &amp; d\end{array} \right) $\left ( \begin{array}{cc} a &amp; b \\ c &amp; d\end{array} \right)$</p>
<hr>
<p>参考：</p>
<p><a href="https://blog.csdn.net/wait_for_eva/article/details/84307306" target="_blank" rel="noopener">typora-数学符号</a> </p>
<p><a href="https://blog.csdn.net/mingzhuo_126/article/details/82722455" target="_blank" rel="noopener">使用Typora添加数学公式</a></p>
<p><a href="https://www.cnblogs.com/waleswood/p/6401232.html" target="_blank" rel="noopener">希腊字母、拉丁字母、Markdown、拼写与读音中英对照表</a></p>
<p><a href="https://blog.csdn.net/katherine_hsr/article/details/79179622" target="_blank" rel="noopener">Markdown数学符号&amp;公式</a></p>
]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>python之字符串和列表之间的转换</title>
    <url>/2020/07/28/python%E4%B9%8B%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E5%88%97%E8%A1%A8%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<h2 id="str-to-list"><a href="#str-to-list" class="headerlink" title="str to list"></a>str to list</h2><a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">str1 = <span class="string">"12345"</span></span><br><span class="line">list1 = list(str1)</span><br><span class="line">print(list1)  <span class="comment"># ['1', '2', '3', '4', '5']</span></span><br><span class="line"></span><br><span class="line">str2 = <span class="string">"123 sjhid dhi"</span></span><br><span class="line">list2 = str2.split() <span class="comment">#or list2 = str2.split(" ")</span></span><br><span class="line">print(list2)   <span class="comment"># ['123', 'sjhid', 'dhi']</span></span><br><span class="line"> </span><br><span class="line">str3 = <span class="string">"www.google.com"</span></span><br><span class="line">list3 = str3.split(<span class="string">"."</span>)</span><br><span class="line">print(list3)   <span class="comment"># ['www', 'google', 'com']</span></span><br></pre></td></tr></table></figure>
<h2 id="list-to-str"><a href="#list-to-str" class="headerlink" title="list to str"></a>list to str</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">str4 = <span class="string">""</span>.join(list3)</span><br><span class="line">print(str4)    <span class="comment"># wwwgooglecom</span></span><br><span class="line">str5 = <span class="string">"."</span>.join(list3)  <span class="comment"># www.google.com</span></span><br><span class="line">print(str5)</span><br><span class="line">str6 = <span class="string">" "</span>.join(list3)   <span class="comment"># www google com</span></span><br><span class="line"><span class="keyword">print</span> (str6)</span><br></pre></td></tr></table></figure>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://blog.csdn.net/roytao2/article/details/53433373" target="_blank" rel="noopener">https://blog.csdn.net/roytao2/article/details/53433373</a></p>
<p><a href="https://www.jb51.net/article/107092.htm" target="_blank" rel="noopener">https://www.jb51.net/article/107092.htm</a></p>
<div style='display: none'>

尝试爬取博客页面

</div>]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>python字符串过滤仅保留数字</title>
    <url>/2020/07/25/python%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BF%87%E6%BB%A4%E4%BB%85%E4%BF%9D%E7%95%99%E6%95%B0%E5%AD%97/</url>
    <content><![CDATA[<h2 id="1-内置-filter-函数"><a href="#1-内置-filter-函数" class="headerlink" title="1. 内置 filter() 函数"></a>1. 内置 filter() 函数</h2><p><code>filter(function, iterable)</code>函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表，<font face="黑体" color=green > <strong>注意:</strong> Pyhton2.7 返回列表，Python3.x 返回迭代器对象</font>。</p>
<a id="more"></a>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 过滤出列表中的所有奇数：</span></span><br><span class="line">newlist = filter(is_odd, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>])</span><br><span class="line"><span class="comment"># 过滤出1~100中平方根是整数的数：</span></span><br><span class="line">newlist = filter(is_sqr, range(<span class="number">1</span>, <span class="number">101</span>))</span><br><span class="line"><span class="comment"># 字符串过滤仅保留数字和字母</span></span><br><span class="line">string = <span class="string">'abc5fg67.!aa99'</span></span><br><span class="line">string_new = <span class="string">''</span>.join(list(filter(str.isdigit,string))) <span class="comment">#只保留数字</span></span><br><span class="line">string_new = <span class="string">''</span>.join(list(filter(str.isalpha,string))) <span class="comment">#只保留字母</span></span><br><span class="line">string_new = <span class="string">''</span>.join(list(filter(str.isalnum,string))) <span class="comment">#保留数字和字母</span></span><br><span class="line"><span class="comment"># 如果想保留数字0-9和小数点’.’ 则需要自定义函数</span></span><br><span class="line"><span class="string">''</span>.join(list(filter(<span class="keyword">lambda</span> ch: ch <span class="keyword">in</span> <span class="string">'1234567890.'</span>, string)))</span><br></pre></td></tr></table></figure>
<h2 id="2-正则表达式"><a href="#2-正则表达式" class="headerlink" title="2. 正则表达式"></a>2. 正则表达式</h2><p>python自带<code>re</code> 模块，使 Python 语言拥有全部的正则表达式功能。</p>
<p>从字符串中提取数字，一般形式如：—-.—，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">string=<span class="string">"A1.45，b5，6.45，8.82"</span></span><br><span class="line"><span class="keyword">print</span> re.findall(<span class="string">r"\d+.?\d*"</span>,string)</span><br><span class="line"><span class="comment"># \d+匹配1次或者多次数字</span></span><br><span class="line"><span class="comment"># \.?匹配小数点，可能有或者没有</span></span><br><span class="line"><span class="comment"># \d* 匹配小数点之后的数字，零到任意。</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><ol>
<li><p><a href="https://blog.csdn.net/huoyuanshen/article/details/83106608" target="_blank" rel="noopener">https://blog.csdn.net/huoyuanshen/article/details/83106608</a></p>
</li>
<li><p><a href="https://www.runoob.com/python/python-func-filter.html" target="_blank" rel="noopener">https://www.runoob.com/python/python-func-filter.html</a></p>
<p>​</p>
</li>
</ol>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>内置函数</tag>
        <tag>正则表达式</tag>
        <tag>re</tag>
        <tag>filter()</tag>
      </tags>
  </entry>
  <entry>
    <title>python爬虫之实战问题</title>
    <url>/2020/08/03/python%E7%88%AC%E8%99%AB%E4%B9%8B%E5%AE%9E%E6%88%98%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h2 id="1-selenium调用Chrome打开淘宝时需要登录"><a href="#1-selenium调用Chrome打开淘宝时需要登录" class="headerlink" title="1. selenium调用Chrome打开淘宝时需要登录"></a>1. selenium调用Chrome打开淘宝时需要登录</h2><a id="more"></a>
<p>由于需要登录用户信息，导致爬虫程序被打断，可以再使用selenium去模拟人的登录，输入账号和密码以及滑动，但是觉得很麻烦还会有各种各样的bug，所以决定用类似于cookie的方法即利用保存在电脑上的chrome用户信息来登录淘宝。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chrome_options = webdriver.ChromeOptions()        <span class="comment">#初始化</span></span><br><span class="line">chrome_options.add_argument(<span class="string">'--headless'</span>)         <span class="comment">#设置浏览器无头模式</span></span><br><span class="line">chrome_options.add_argument(<span class="string">'--disable-gpu'</span>)      <span class="comment">#避免一些报错</span></span><br><span class="line">chrome_options.add_argument(<span class="string">'--no-sandbox'</span>)       <span class="comment">#避免出错</span></span><br><span class="line">chrome_options.add_argument(<span class="string">r'user-data-dir=C:\Users\username\AppData\Local\Google\Chrome\User Data'</span>)</span><br><span class="line">browser = webdriver.Chrome(options=chrome_options)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>注意：</strong> 为chrome浏览器设置参数,如果使用用户信息，不会调起新的chrome，所以需要将Chrome所有窗口关闭，否则因为占用会出错。</li>
</ul>
<p>另外还可以直接传入cookies。或者，或者使用requests.post() 传入账号，密码。</p>
<h2 id="2-淘宝搜索button，使用click点击无反应"><a href="#2-淘宝搜索button，使用click点击无反应" class="headerlink" title="2. 淘宝搜索button，使用click点击无反应"></a>2. 淘宝搜索button，使用click点击无反应</h2><p>有些需要enter</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">driver.get(url)</span><br><span class="line">input = driver.find_element_by_xpath(<span class="string">'//*[@id="q"]'</span>)</span><br><span class="line">input.clear()  <span class="comment"># 清空搜索框数据</span></span><br><span class="line">input.send_keys(<span class="string">'ipad'</span>)  <span class="comment"># 输入检索词</span></span><br><span class="line">input.send_keys(Keys.ENTER)</span><br></pre></td></tr></table></figure>
<h2 id="3-淘宝搜索结果的下一页点击失败"><a href="#3-淘宝搜索结果的下一页点击失败" class="headerlink" title="3.淘宝搜索结果的下一页点击失败"></a>3.淘宝搜索结果的下一页点击失败</h2><p>解决方法：在页码框输入页码，然后点击确定</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">input = wait.until(EC.presence_of_element_located((By.XPATH, <span class="string">'//*[@id="mainsrp-pager"]/div/div/div/div[2]/input'</span>))) <span class="comment"># 输入框</span></span><br><span class="line">submit = wait.until(EC.element_to_be_clickable((By.XPATH, <span class="string">'//*[@id="mainsrp-pager"]/div/div/div/div[2]/span[3]'</span>))) <span class="comment"># 确定按钮</span></span><br><span class="line">input.clear()</span><br><span class="line">input.send_keys(str(page))</span><br><span class="line">submit.click()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>实战</tag>
      </tags>
  </entry>
  <entry>
    <title>python爬虫学习</title>
    <url>/2020/07/24/python%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E6%9C%AC%E5%BA%93%E5%92%8C%E8%A7%A3%E6%9E%90%E5%BA%93/</url>
    <content><![CDATA[<h2 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1.前期准备"></a>1.前期准备</h2><h3 id="1-anaconda安装"><a href="#1-anaconda安装" class="headerlink" title="1. anaconda安装"></a>1. anaconda安装</h3><ol>
<li><p>配置环境，将python写入环境变量。</p>
<a id="more"></a>
</li>
</ol>
<h3 id="2-IDE：-pycharm安装"><a href="#2-IDE：-pycharm安装" class="headerlink" title="2. IDE： pycharm安装"></a>2. IDE： pycharm安装</h3><ol>
<li>使用虚拟环境（virtual environment）</li>
<li>settings 安装python包，可以直接从anaconda中把安装包直接拷到Lib-site_package下，如果网速限制，可以替换镜像源。</li>
</ol>
<h2 id="2-urllib"><a href="#2-urllib" class="headerlink" title="2. urllib"></a>2. urllib</h2><p><code>urllib</code> 是Python 内置的 HTTP 请求库，包含如4 个模块：<code>request</code>, <code>error</code>, <code>parse</code>, <code>robotparser</code></p>
<h3 id="request"><a href="#request" class="headerlink" title="request"></a>request</h3><p>该模块可以发送请求并得到响应。</p>
<ol>
<li><p><code>urlopen</code></p>
<p>其结果返回一个 HTTPResposne 类型的对象，主要包含 <code>read、getheader、getheaders</code>等方法，以及 <code>msg、version、status、reason</code>等属性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">response = urllib.request.urlopen(url)</span><br><span class="line">data = response.read().decode()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p><code>response.status</code> 1**：信息状态，2**：成功状态，请求成功为200 ，3**：重定向，4**：客户端错误，400代表解析失败，404 代表网页未找到。</p>
<p><code>response.getheaders()</code> 得到headers</p>
</blockquote>
<ol>
<li><p><code>Request</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">req = request.Request(url=url, data=data, headers=headers, method=<span class="string">'POST'</span>)  </span><br><span class="line">response = request.urlopen(req)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>build_opener</code> 和 <code>Handler</code> 可以实现代理，密码登录等复杂请求，例子可<a href="https://python3webspider.cuiqingcai.com/3.1-shi-yong-urllib#2-request" target="_blank" rel="noopener">参考</a></p>
</li>
</ol>
<h3 id="error"><a href="#error" class="headerlink" title="error"></a>error</h3><p>该模块定义了由 request 模块产生的异常。</p>
<ol>
<li><p><code>URLError</code> 有一个属性<code>reason</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    response = request.urlopen(<span class="number">404</span>_url)  </span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:  </span><br><span class="line">    print(e.reason)  <span class="comment">#  Not Found （对应403）</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>HTTPError</code> 专门处理HTTP请求的错误，具有<code>code</code>, <code>reason</code>, <code>headers</code> 三个属性</p>
</li>
</ol>
<h3 id="parse"><a href="#parse" class="headerlink" title="parse"></a>parse</h3><p>该模块定义了处理 URL 的标准接口，例如实现 URL 各部分的抽取、合并以及链接转换。</p>
<ol>
<li><p><code>quote</code> 将内容转化为 URL 编码的格式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">key = <span class="string">"小说"</span></span><br><span class="line">key_ASCII = quote(key)</span><br><span class="line">print(key_ASCII)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>unquote</code> 将 URL 格式内容解码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">key = <span class="string">"%E5%B0%8F%E8%AF%B4"</span></span><br><span class="line">print(unqoute(key))</span><br></pre></td></tr></table></figure>
<p><strong><code>request</code> 中也有qoute</strong></p>
</li>
</ol>
<h3 id="robotparser"><a href="#robotparser" class="headerlink" title="robotparser"></a>robotparser</h3><p>该模块可以实现网站 Robots 协议的分析。</p>
<p>requests是用于爬取网页源码的一个库。</p>
<h2 id="3-requests"><a href="#3-requests" class="headerlink" title="3. requests"></a>3. requests</h2><h3 id="get"><a href="#get" class="headerlink" title="get"></a>get</h3><p><code>get</code> 方法以 GET 方式请求网页，返回得到一个 Response 对象，有<code>status_code，text，cookies</code> 等属性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">response=requests.get(url) </span><br><span class="line">data=response.text</span><br><span class="line">file_path = <span class="string">r"E:\pycharm\test.html"</span>  <span class="comment"># 'r'是防止字符转义,否则\需要变成/</span></span><br><span class="line"><span class="keyword">with</span> open(file_path, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f: </span><br><span class="line">    f.write(data)</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong>因为Windows操作系统默认字符编码为GBK，而Python默认Unicode.utf-8，如果不写“encoding=‘utf-8’ ”就会报错。</p>
<p>对于二进制数据，可以使用<code>content</code> 属性，可以直接写入文件，直接获得图片，音频，视屏。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = requests.get(<span class="string">"https://github.com/favicon.ico"</span>)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'favicon.ico'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f: <span class="comment"># wb 以二进制方式写入</span></span><br><span class="line">    f.write(r.content)</span><br></pre></td></tr></table></figure>
<p>有些网站禁止抓取，如B站，可以使用headers包含 User-Agent 字段信息，也就是浏览器标识信息。<a href="https://www.jianshu.com/p/da6a44d0791e" target="_blank" rel="noopener" title="User-agent大全">User-agent大全</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">"https://www.bilibili.com/"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># urllib.error.HTTPError: HTTP Error 403: Forbidden</span></span><br><span class="line">response = urllib.request.urlopen(url)</span><br><span class="line">data = response.read().decode() </span><br><span class="line"><span class="comment"># 没有问题</span></span><br><span class="line">response=requests.get(url) </span><br><span class="line">data=response.text</span><br></pre></td></tr></table></figure>
<p>在设置 Headers 使用Cookie来维持登录状态：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'Cookie'</span>: <span class="string">'cookie_content'</span>,</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另外，<code>request</code>还有<code>put, post, delete, options</code> 等方法实现 POST、PUT、DELETE、OPTIONS 等请求。</p>
<h3 id="session会话维持"><a href="#session会话维持" class="headerlink" title="session会话维持"></a>session会话维持</h3><p>通过用 get 方法登录某个网站，用 get 方法第二次去请求个人信息页面，并不能成功。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">requests.get(<span class="string">'http://httpbin.org/cookies/set/number/123456789'</span>)</span><br><span class="line">r = requests.get(<span class="string">'http://httpbin.org/cookies'</span>)</span><br><span class="line">print(r.text) <span class="comment"># cookies 是空字典</span></span><br></pre></td></tr></table></figure>
<p>如何设置一次cookies，维持对话，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = requests.Session()</span><br><span class="line">s.get(<span class="string">'http://httpbin.org/cookies/set/number/123456789'</span>)</span><br><span class="line">r = s.get(<span class="string">'http://httpbin.org/cookies'</span>)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<h2 id="4-使用Selenium调用浏览器"><a href="#4-使用Selenium调用浏览器" class="headerlink" title="4. 使用Selenium调用浏览器"></a>4. 使用Selenium调用浏览器</h2><p><a href="[http://www.selenium.org.cn/](http://www.selenium.org.cn/">Selenium</a>)是web自动化测试工具集，包括IDE、Grid、RC（selenium 1.0）、WebDriver（selenium 2.0）等。</p>
<p> <a href="[https://blog.csdn.net/huilan_same/article/details/52615123](https://blog.csdn.net/huilan_same/article/details/52615123">selenium自动化资源整理</a>)</p>
<h3 id="1-调用Chrome浏览器"><a href="#1-调用Chrome浏览器" class="headerlink" title="1. 调用Chrome浏览器"></a>1. 调用Chrome浏览器</h3><ol>
<li><p>查看本地Chrome版本</p>
</li>
<li><p>下载<a href="http://npm.taobao.org/mirrors/chromedriver" target="_blank" rel="noopener">Chromedriver</a></p>
</li>
<li><p>将chromedriver.exe放到python path下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> selenium.webdriver</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www.bilibili.com/"</span></span><br><span class="line"></span><br><span class="line">driver = selenium.webdriver.Chrome()</span><br><span class="line">driver.get(url)</span><br><span class="line">data = driver.page_source</span><br><span class="line"></span><br><span class="line">file_path = <span class="string">r"E:\pycharm-爬虫\bilibili\首页_selenium.html"</span></span><br><span class="line"><span class="keyword">with</span> open(file_path, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(data)</span><br><span class="line"></span><br><span class="line">driver.close()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="2-调用FireFox浏览器"><a href="#2-调用FireFox浏览器" class="headerlink" title="2. 调用FireFox浏览器"></a>2. 调用FireFox浏览器</h3><ol>
<li>下载<a href="https://github.com/mozilla/geckodriver/releases" target="_blank" rel="noopener">geckodriver</a>，并将其放入PATH中。</li>
<li>driver = selenium.webdriver.Firefox()</li>
</ol>
<h2 id="5-bs4-BeautifulSoup解析HTML"><a href="#5-bs4-BeautifulSoup解析HTML" class="headerlink" title="5. bs4.BeautifulSoup解析HTML"></a>5. bs4.BeautifulSoup解析HTML</h2><p>bs4即<a href="http://www.crummy.com/software/BeautifulSoup/" target="_blank" rel="noopener">BeautifulSoup4</a> ，是一个可以从HTML或XML文件中提取数据的Python库。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">data = <span class="string">'&lt;b class="boldest"&gt;Extremely bold&lt;/b&gt;'</span></span><br><span class="line">soup = BeautifulSoup(data, <span class="string">"html.parser"</span>) <span class="comment"># data为html格式的数据</span></span><br></pre></td></tr></table></figure>
<p>Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种: <code>Tag</code>, <code>NavigableString</code> , <code>BeautifulSoup</code> , <code>Comment</code> 。</p>
<h3 id="Tag"><a href="#Tag" class="headerlink" title="Tag"></a>Tag</h3><p><code>tag</code> 的属性有<code>name</code> 和 <code>attributes</code>，方法<code>get()</code> , 如果不确定某个属性是否存在时,用 <code>tag.get(&#39;attr&#39;)</code> 方法去获取它,跟获取Python字典的key一样&gt;</p>
<p>一个<code>tag</code> 可能有很多属性，属性的操作与<strong>字典</strong>相同，可以被添加，删除或修改。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tag = soup.b <span class="comment"># tag b</span></span><br><span class="line">tag.name  <span class="comment"># 'b'</span></span><br><span class="line">tag.name = <span class="string">"blockquote"</span> <span class="comment"># tag &lt;blockquote class="boldest"&gt;Extremely bold&lt;/blockquote&gt;</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">tag[<span class="string">'class'</span>] <span class="comment"># boldest</span></span><br><span class="line">tag.attrs <span class="comment"># &#123;'class': 'boldest'&#125;</span></span><br><span class="line">tag[<span class="string">'class'</span>] = <span class="string">'verybold'</span> <span class="comment"># 修改 &lt;blockquote class="verybold" &gt;Extremely bold&lt;/blockquote&gt;</span></span><br><span class="line">tag[<span class="string">'id'</span>] = <span class="number">1</span>   <span class="comment"># 添加 &lt;blockquote class="verybold" id="1"&gt;Extremely bold&lt;/blockquote&gt;</span></span><br><span class="line"><span class="keyword">del</span> tag[<span class="string">'class'</span>] <span class="comment"># &lt;blockquote id="1"&gt;Extremely bold&lt;/blockquote&gt;</span></span><br><span class="line"><span class="keyword">del</span> tag[<span class="string">'id'</span>]    <span class="comment"># &lt;blockquote&gt;Extremely bold&lt;/blockquote&gt;</span></span><br></pre></td></tr></table></figure>
<p><code>HTML5</code> 中定义了一系列可以包含多个值的属性，<code>class</code> (一个tag可以有多个CSS的class). <code>rel</code>  <code>rev</code> ， <code>accept-charset</code> ， <code>headers</code> ， <code>accesskey</code> 等。</p>
<p>多值属性的返回值为list， 非多值属性的返回值为字符串：</p>
<p><strong>注意：XML格式的tag不包含多值属性。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 多值属性class</span></span><br><span class="line">css_soup = BeautifulSoup(<span class="string">'&lt;p class="body strikeout"&gt;&lt;/p&gt;'</span>)</span><br><span class="line">css_soup.p[<span class="string">'class'</span>]</span><br><span class="line"><span class="comment"># ["body", "strikeout"]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 非多值属性id</span></span><br><span class="line">id_soup = BeautifulSoup(<span class="string">'&lt;p id="my id"&gt;&lt;/p&gt;'</span>)</span><br><span class="line">id_soup.p[<span class="string">'id'</span>]</span><br><span class="line"><span class="comment"># 'my id'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多值属性修改时</span></span><br><span class="line">rel_soup = BeautifulSoup(<span class="string">'&lt;p&gt;Back to the &lt;a rel="index"&gt;homepage&lt;/a&gt;&lt;/p&gt;'</span>)</span><br><span class="line">rel_soup.a[<span class="string">'rel'</span>] = [<span class="string">'index'</span>, <span class="string">'contents'</span>]</span><br><span class="line">print(rel_soup.p)</span><br><span class="line"><span class="comment"># &lt;p&gt;Back to the &lt;a rel="index contents"&gt;homepage&lt;/a&gt;&lt;/p&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="NavigableString"><a href="#NavigableString" class="headerlink" title="NavigableString"></a>NavigableString</h3><p>字符串常被包含在<code>tag</code> 内。Beautiful Soup用<code>NavigableString</code>类来包装tag中的字符串: <code>tag.string</code></p>
<p>tag中包含的字符串不能编辑,但是可以用 <code>replace_with()</code> 方法替换成其它的字符串</p>
<h3 id="BeautifulSoup"><a href="#BeautifulSoup" class="headerlink" title="BeautifulSoup"></a>BeautifulSoup</h3><p><code>BeautifulSoup</code> 对象表示的是一个文档的全部内容.大部分时候,可以把它当作 <code>Tag</code> 对象，它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法。</p>
<h3 id="Comment"><a href="#Comment" class="headerlink" title="Comment"></a>Comment</h3><p>处理HTML和XML中的注释部分，<code>Comment</code> 对象是一个特殊类型的 <code>NavigableString</code> 对象，但是当它出现在HTML文档中时, <code>Comment</code> 对象会使用特殊的格式输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">markup = <span class="string">"&lt;b&gt;&lt;!--Hey, buddy. Want to buy a used parser?--&gt;&lt;/b&gt;"</span></span><br><span class="line">soup = BeautifulSoup(markup)</span><br><span class="line">comment = soup.b.string</span><br><span class="line">type(comment)</span><br><span class="line"><span class="comment"># &lt;class 'bs4.element.Comment'&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="遍历文档树"><a href="#遍历文档树" class="headerlink" title="遍历文档树"></a>遍历文档树</h3><p>一个<code>tag</code> 可能包含多个字符串或其他<code>tag</code> ，这些都是该<code>tag</code> 的子节点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 点取属性的方式只能获得当前名字的第一个tag</span></span><br><span class="line">soup.head</span><br><span class="line">soup.body.b</span><br><span class="line"><span class="comment"># 想要得到所有的&lt;a&gt;标签</span></span><br><span class="line">soup.find_all(<span class="string">'a'</span>) <span class="comment"># 返回list</span></span><br></pre></td></tr></table></figure>
<h4 id="子节点"><a href="#子节点" class="headerlink" title="子节点"></a>子节点</h4><h5 id="contents-和-children"><a href="#contents-和-children" class="headerlink" title=".contents 和 .children"></a>.contents 和 .children</h5><p><code>tag</code> 的 <code>.contents</code> 属性可以将<code>tag</code> 的子节点以列表的方式输出:</p>
<p>通过<code>tag</code> 的 <code>.children</code> 生成器,可以对<code>tag</code> 的子节点进行循环:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">head_tag = soup.head  <span class="comment"># &lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line">title_tag = head_tag.contents[<span class="number">0</span>]  <span class="comment"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></span><br><span class="line">title_tag.contents    <span class="comment"># [u'The Dormouse's story']</span></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> title_tag.children:</span><br><span class="line">    print(child)      <span class="comment"># The Dormouse's story</span></span><br></pre></td></tr></table></figure>
<h5 id="descendants"><a href="#descendants" class="headerlink" title=".descendants"></a>.descendants</h5><p><code>.contents</code> 和 <code>.children</code> 属性仅包含tag的直接子节点.例如,<head>标签只有一个直接子节点<code>&lt;title&gt;</code> 但<code>&lt;title&gt;</code> 标签也包含一个子节点:字符串 “The Dormouse’s story”，这种情况下字符串 “The Dormouse’s story”也属于<code>&lt;head&gt;</code> 标签的子孙节点. <code>.descendants</code> 属性可以对所有tag的子孙节点进行递归循环。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> head_tag.descendants:</span><br><span class="line">    print(child)</span><br><span class="line">    <span class="comment"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></span><br><span class="line">    <span class="comment"># The Dormouse's story</span></span><br></pre></td></tr></table></figure>
<h5 id="string"><a href="#string" class="headerlink" title=".string"></a>.string</h5><p>如果<code>tag</code> 只有一个 <code>NavigableString</code> 类型子节点,那么这个<code>tag</code> 可以使用 <code>.string</code> 得到子节点</p>
<p>否则，<code>.string</code> 的输出结果是 <code>None</code></p>
<p>输出的字符串中可能包含了很多空格或空行,使用 <code>.stripped_strings</code> 可以去除多余空白内容</p>
<h6 id="bs4-element-get-text"><a href="#bs4-element-get-text" class="headerlink" title="bs4.element.get_text()"></a>bs4.element.get_text()</h6><p> Get all child strings, concatenated using the given separator (默认是空格)</p>
<h4 id="父节点"><a href="#父节点" class="headerlink" title="父节点"></a>父节点</h4><h5 id="parent"><a href="#parent" class="headerlink" title=".parent"></a>.parent</h5><h5 id="parents"><a href="#parents" class="headerlink" title=".parents"></a>.parents</h5><p>通过元素的 <code>.parents</code> 属性可以递归得到元素的所有父辈节点</p>
<h5 id="兄弟节点"><a href="#兄弟节点" class="headerlink" title="兄弟节点"></a>兄弟节点</h5><p>同一个元素的子节点</p>
<h5 id="next-sibling-和-previous-sibling"><a href="#next-sibling-和-previous-sibling" class="headerlink" title=".next_sibling 和 .previous_sibling"></a>.next_sibling 和 .previous_sibling</h5><p>在文档树中,使用 <code>.next_sibling</code> 和 <code>.previous_sibling</code> 属性来查询兄弟节点</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sibling_soup = BeautifulSoup(<span class="string">"&lt;a&gt;&lt;b&gt;text1&lt;/b&gt;&lt;c&gt;text2&lt;/c&gt;&lt;/b&gt;&lt;/a&gt;"</span>)</span><br><span class="line">sibling_soup.b.next_sibling  <span class="comment"># &lt;c&gt;text2&lt;/c&gt;</span></span><br><span class="line">sibling_soup.c.previous_sibling <span class="comment"># &lt;b&gt;text1&lt;/b&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="next-siblings-和-previous-siblings"><a href="#next-siblings-和-previous-siblings" class="headerlink" title=".next_siblings 和 .previous_siblings"></a>.next_siblings 和 .previous_siblings</h5><p>对当前节点的兄弟节点迭代输出</p>
<h3 id="搜索文档树"><a href="#搜索文档树" class="headerlink" title="搜索文档树"></a>搜索文档树</h3><p><code>Beautiful Soup</code> 中定义的搜索方法，比如 <code>find()</code> 和 <code>find_all()</code></p>
<h4 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h4><p>find_all()</p>
<p>可以是字符串，正则表达式，列表，True，方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">soup.find_all(<span class="string">'b'</span>) <span class="comment"># b 标签</span></span><br><span class="line">soup.find_all(re.compile(<span class="string">"^b"</span>)) <span class="comment"># 以b开头的标签</span></span><br><span class="line">soup.find_all([<span class="string">"a"</span>, <span class="string">"b"</span>]) <span class="comment"># 含有a或b的标签</span></span><br><span class="line">soup.find_all(<span class="literal">True</span>) <span class="comment"># True 可以匹配任何值,找到所有的tag,但是不会返回字符串节点</span></span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">has_class_but_no_id</span><span class="params">(tag)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tag.has_attr(<span class="string">'class'</span>) <span class="keyword">and</span> <span class="keyword">not</span> tag.has_attr(<span class="string">'id'</span>) <span class="comment"># 有class，无id</span></span><br><span class="line">soup.find_all(has_class_but_no_id)</span><br></pre></td></tr></table></figure>
<h4 id="find-all"><a href="#find-all" class="headerlink" title="find_all())"></a>find_all())</h4><p><code>find_all(name, attrs, recursive , text , **kwargs)</code></p>
<ol>
<li><p>如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字<code>tag</code> 的属性来搜索<code>soup.find_all(id=&#39;link2&#39;)</code> </p>
</li>
<li><p>有些tag属性在搜索不能使用,比如HTML5中的 data-* 属性,但是可以通过 <code>find_all()</code> 方法的 <code>attrs</code> 参数定义一个字典参数来搜索包含特殊属性的tag: <code>data_soup.find_all(attrs={&quot;data-foo&quot;: &quot;value&quot;})</code></p>
</li>
<li><p>按照CSS类名搜索<code>tag</code> , 但标识CSS类名的关键字 <code>class</code> 在Python中是保留字,使用 <code>class</code> 做参数会导致语法错误.从<code>Beautiful Soup</code> 的4.1.1版本开始,可以通过 class_ 参数搜索有指定CSS类名的<code>tag</code> : <code>soup.find_all(&quot;a&quot;, class_=&quot;sister&quot;)</code></p>
</li>
<li><p>通过 <code>text</code> 参数可以搜搜文档中的字符串内容</p>
</li>
<li><p><code>find_all()</code> 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果不需要全部结果,可以使用 <code>limit</code> 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 <code>limit</code> 的限制时,就停止搜索返回结果.  <code>soup.find_all(&quot;a&quot;, limit=2)</code></p>
</li>
<li><p>recursive 默认为True，检索当前tag的所有子孙节点，<code>soup.html.find_all(&quot;title&quot;, recursive=False)</code> 搜索<code>tag</code> 的直接子节点</p>
</li>
<li><p>```python</p>
<h1 id="这两行代码等价"><a href="#这两行代码等价" class="headerlink" title="这两行代码等价"></a>这两行代码等价</h1><p>soup.find_all(“a”)<br>soup(“a”)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#### find()</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line"># 这两行代码几乎等价</span><br><span class="line">soup.find_all(&#39;title&#39;, limit&#x3D;1) # 返回列表</span><br><span class="line">soup.find(&#39;title&#39;) # 返回结果 等价于 soup.title</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="selector-CSS选择器-的用法"><a href="#selector-CSS选择器-的用法" class="headerlink" title="selector (CSS选择器) 的用法"></a>selector (CSS选择器) 的用法</h4><p>Beautiful Soup支持大部分的CSS（CSS，全称叫作 Cascading Style Sheets，即层叠样式表）选择器， 在 Tag 或 BeautifulSoup 对象的 .select() 方法中传入字符串参数, 即可使用CSS选择器的语法找到tag。</p>
<h5 id="CSS样式"><a href="#CSS样式" class="headerlink" title="CSS样式"></a>CSS样式</h5><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-id">#head_wrapper</span><span class="selector-class">.s-ps-islite</span> <span class="selector-class">.s-p-top</span> &#123;   </span><br><span class="line">    <span class="attribute">position</span>: absolute;  </span><br><span class="line">    <span class="attribute">bottom</span>: <span class="number">40px</span>;  </span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;  </span><br><span class="line">    <span class="attribute">height</span>: <span class="number">181px</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>表示 id =head_wrapper 且（没有空格表是&amp;）class 为 s-ps-islite的节点，然后再选中其内部（有空格表示内部）的 class 为 s-p-top 的节点。字典定义了这个元素的布局方式</p>
<p>谷歌浏览器→右键→检查→鼠标放到网页书名上，在检查窗口右键→copy→copy selector，结果如下(&gt; 找到某个tag标签下的子标签)：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-id">#subject_list</span> &gt; <span class="selector-tag">ul</span> &gt; <span class="selector-tag">li</span><span class="selector-pseudo">:nth-child(1)</span> &gt; <span class="selector-tag">div</span><span class="selector-class">.info</span> &gt; <span class="selector-tag">h2</span> &gt; <span class="selector-tag">a</span></span><br></pre></td></tr></table></figure>
<h5 id="CSS选择器"><a href="#CSS选择器" class="headerlink" title="CSS选择器"></a>CSS选择器</h5><ul>
<li>CSS 选择器用来定位节点，根据 <strong>id、class、标签名筛选</strong>是其中最常用的3种表示方式。</li>
<li>CSS 选择器还支持嵌套选择，各个选择器之间<strong>空格分隔</strong>代表<strong>嵌套关系</strong>，如果<strong>不加空格</strong>，代表<strong>并列</strong>关系。</li>
<li><code>ul &gt; li</code>表示选择父节点为 ul 节点的所有 li 节点</li>
<li><code>li:nth-child(n)</code> 表示选择属于其父节点的第n个子节点的所有 li 节点</li>
<li>CSS选择器及其他语法规则参见<a href="https://python3webspider.cuiqingcai.com/2.2web-wang-ye-ji-chu#2-2-4-xuan-ze-qi" target="_blank" rel="noopener">该表格</a></li>
</ul>
<h3 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h3><p>通过get_text()可以通过下面代码得到每一页面的书名：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">book_name_list = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">21</span>): <span class="comment"># 每页20本书</span></span><br><span class="line">        book_name = soup.select(<span class="string">"#subject_list &gt; ul &gt; li:nth-child("</span> + str(j) + <span class="string">") &gt; div.info &gt; h2 &gt; a"</span>)  </span><br><span class="line">        <span class="comment"># 第29页只有19本书</span></span><br><span class="line">        <span class="keyword">for</span> book_name <span class="keyword">in</span> book_name:</span><br><span class="line">            book_name_list.append(book_name.get_text().replace(<span class="string">" "</span>,<span class="string">""</span>).replace(<span class="string">"\r"</span>, <span class="string">""</span>).replace(<span class="string">"\n"</span>, <span class="string">""</span>))</span><br></pre></td></tr></table></figure>
<h3 id="修改文档树"><a href="#修改文档树" class="headerlink" title="修改文档树"></a>修改文档树</h3><h3 id="解析部分文档"><a href="#解析部分文档" class="headerlink" title="解析部分文档"></a>解析部分文档</h3><p>如果仅仅因为想要查找文档中的<a>标签而将整片文档进行解析,实在是浪费内存和时间.最快的方法是从一开始就把<a>标签以外的东西都忽略掉. <code>SoupStrainer</code> 类可以定义文档的某段内容,这样搜索文档时就不必先解析整篇文档,只会解析在 <code>SoupStrainer</code> 中定义过的文档. 创建一个 <code>SoupStrainer</code> 对象并作为 <code>parse_only</code> 参数给 <code>BeautifulSoup</code> 的构造方法即可.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> SoupStrainer</span><br><span class="line">only_a_tags = SoupStrainer(<span class="string">"a"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="6-解析库pyquery"><a href="#6-解析库pyquery" class="headerlink" title="6. 解析库pyquery"></a>6. 解析库pyquery</h2><p>用法和JQuery类似</p>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><h4 id="字符串初始化"><a href="#字符串初始化" class="headerlink" title="字符串初始化"></a>字符串初始化</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">html = <span class="string">" &lt;html blabla"</span></span><br><span class="line">pq(html)</span><br></pre></td></tr></table></figure>
<h4 id="URL初始化"><a href="#URL初始化" class="headerlink" title="URL初始化"></a>URL初始化</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line">doc = pq(url=<span class="string">'http://cuiqingcai.com'</span>)</span><br><span class="line">print(doc(<span class="string">'title'</span>))</span><br></pre></td></tr></table></figure>
<p>PyQuery 对象会首先请求这个 URL，然后用得到的 HTML 内容完成初始化，这其实就相当于用网页的源代码以字符串的形式传递给 PyQuery 类来初始化。</p>
<p>相当于：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">doc = pq(requests.get(<span class="string">'http://cuiqingcai.com'</span>).text)</span><br><span class="line">print(doc(<span class="string">'title'</span>))</span><br></pre></td></tr></table></figure>
<h4 id="文件初始化"><a href="#文件初始化" class="headerlink" title="文件初始化"></a>文件初始化</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pq(filename=<span class="string">'dem.html'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="CSS选择器-1"><a href="#CSS选择器-1" class="headerlink" title="CSS选择器"></a>CSS选择器</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">doc=pq(html)</span><br><span class="line">print(doc(<span class="string">"#content .info name"</span>))</span><br></pre></td></tr></table></figure>
<h3 id="查找节点"><a href="#查找节点" class="headerlink" title="查找节点"></a>查找节点</h3><h4 id="子节点-1"><a href="#子节点-1" class="headerlink" title="子节点"></a>子节点</h4><h5 id="find"><a href="#find" class="headerlink" title="find()"></a>find()</h5><p>查找所有子孙节点</p>
<p>会找到所有符合条件的节点，和BeautifulSoup中的find()不同，类似于BS中的find_all()</p>
<h5 id="children"><a href="#children" class="headerlink" title="children()"></a>children()</h5><p>只查找子节点 ， 支持CSS选择器</p>
<h4 id="父节点-1"><a href="#父节点-1" class="headerlink" title="父节点"></a>父节点</h4><h5 id="parent-1"><a href="#parent-1" class="headerlink" title="parent()"></a>parent()</h5><p>直接父节点</p>
<h5 id="parents-1"><a href="#parents-1" class="headerlink" title="parents()"></a>parents()</h5><p>祖贤父节点</p>
<h4 id="兄弟节点-1"><a href="#兄弟节点-1" class="headerlink" title="兄弟节点"></a>兄弟节点</h4><h5 id="sublings"><a href="#sublings" class="headerlink" title="sublings()"></a>sublings()</h5><h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h3><p>PyQuery的选择结果不会像BeautifulSoup一样返回list，而是直接返回多个或单个节点</p>
<p>返回单个节点可以直接用str()u转化为字符串，</p>
<p>返回多个节点需要遍历，斯奥用items()方法，返回生成器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lis = doc(<span class="string">'li'</span>).items()</span><br><span class="line">print(type(lis)) <span class="comment"># class 'generator'</span></span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> lis:</span><br><span class="line">    print(li, type(li))</span><br></pre></td></tr></table></figure>
<h3 id="获取信息"><a href="#获取信息" class="headerlink" title="获取信息"></a>获取信息</h3><h4 id="获取属性attr"><a href="#获取属性attr" class="headerlink" title="获取属性attr()"></a>获取属性attr()</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = doc(<span class="string">'a'</span>)</span><br><span class="line">a.attr(<span class="string">'href'</span>)  <span class="comment"># 只会返回第一个满足条件的标签（节点）的href属性</span></span><br></pre></td></tr></table></figure>
<p>如果获取所有节点的属性，需要调用items()遍历。</p>
<h4 id="获取文本"><a href="#获取文本" class="headerlink" title="获取文本"></a>获取文本</h4><p>text()方法返回<strong>所有</strong>节点下纯文字内容，即不需要遍历。</p>
<p>html()方法返回HTML文本，多个节点时，需要<strong>遍历</strong>。</p>
<h3 id="节点操作"><a href="#节点操作" class="headerlink" title="节点操作"></a>节点操作</h3><h4 id="addClass-和-removeClass"><a href="#addClass-和-removeClass" class="headerlink" title="addClass 和 removeClass"></a>addClass 和 removeClass</h4><p>添加，删除class这个属性</p>
<h4 id="attr、text、html"><a href="#attr、text、html" class="headerlink" title="attr、text、html"></a>attr、text、html</h4><p>attr操作其他属性，<code>li.attr(&#39;name&#39;, &#39;link&#39;)</code> 将name属性的值修改为link，如果不存在，则创建改属性。</p>
<p>如果 attr 方法只传入第一个参数的属性名，则是获取这个属性值；如果传入第二个参数，可以用来修改属性值。text 和 html 方法如果不传参数，则是获取节点内纯文本和 HTML 文本；如果传入参数，则进行赋值。</p>
<h4 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h4><p><strong>为提取信息带来便利</strong></p>
<h3 id="伪类选择器"><a href="#伪类选择器" class="headerlink" title="伪类选择器"></a>伪类选择器</h3><p>CSS选择器支持各种各样的伪类选择器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">doc = pq(html)</span><br><span class="line">li = doc(<span class="string">'li:first-child'</span>)</span><br><span class="line">print(li)</span><br><span class="line">li = doc(<span class="string">'li:last-child'</span>)</span><br><span class="line">print(li)</span><br><span class="line">li = doc(<span class="string">'li:nth-child(2)'</span>)</span><br><span class="line">print(li)</span><br><span class="line">li = doc(<span class="string">'li:gt(2)'</span>) <span class="comment"># 三个以后的li节点</span></span><br><span class="line">print(li)</span><br><span class="line">li = doc(<span class="string">'li:nth-child(2n)'</span>) <span class="comment"># 偶数位置的li节点</span></span><br><span class="line">print(li)</span><br><span class="line">li = doc(<span class="string">'li:contains(second)'</span>) <span class="comment">#包含second的li节点</span></span><br><span class="line">print(li)</span><br></pre></td></tr></table></figure>
<h2 id="7-使用代理IP"><a href="#7-使用代理IP" class="headerlink" title="7. 使用代理IP"></a>7. 使用代理IP</h2><p>很多网站对于爬虫做了一定限制，IP容易进小黑屋，所以需要采用代理IP。</p>
<h3 id="代理的种类"><a href="#代理的种类" class="headerlink" title="代理的种类"></a>代理的种类</h3><ul>
<li><p><strong>透明代理 (Transparent Proxy)</strong>: 不但改动了数据包，还会告诉服务器客户端的真实IP，约等于没用。</p>
<ul>
<li>REMOTE_ADDR = Proxy IP</li>
<li>HTTP_VIA = Proxy IP</li>
<li>HTTP_X_FORWARDED_FOR = Your IP</li>
</ul>
</li>
<li><p><strong>普通匿名代理 (Anonymous Proxy)</strong>：会在数据包上做一些改动，服务器上发现这是个代理服务器，但是一般不清楚真实IP地址（有一定几率能追查到）。</p>
<ul>
<li>REMOTE_ADDR = proxy IP</li>
<li>HTTP_VIA = proxy IP</li>
<li>HTTP_X_FORWARDED_FOR = proxy IP</li>
</ul>
</li>
<li><p><strong>混淆代理(Distorting Proxies)</strong>：会在数据包上做一些改动，服务器上发现这是个代理服务器，但会得到一个假的IP地址.</p>
<ul>
<li>REMOTE_ADDR = proxy IP</li>
<li>HTTP_VIA = proxy IP</li>
<li>HTTP_X_FORWARDED_FOR = Random IP address</li>
</ul>
</li>
<li><p><strong>高匿代理(Elite proxy或High Anonymity Proxy)</strong>：会将数据包原封不动的转发，在服务端看来就好像真的是一个普通客户端在访问，而记录的IP则是代理服务器的IP。</p>
<ul>
<li>REMOTE_ADDR = Proxy IP</li>
<li>HTTP_VIA = not determined</li>
<li>HTTP_X_FORWARDED_FOR = not determined</li>
</ul>
<p><strong>参考</strong>：<a href="https://blog.csdn.net/a19860903/article/details/47146715" target="_blank" rel="noopener">https://blog.csdn.net/a19860903/article/details/47146715</a></p>
</li>
</ul>
<h3 id="代理IP网站"><a href="#代理IP网站" class="headerlink" title="代理IP网站"></a>代理IP网站</h3><ol>
<li><a href="https://www.kuaidaili.com/ops/proxylist/1/" target="_blank" rel="noopener">快代理</a></li>
<li><a href="http://www.66ip.cn/index.html" target="_blank" rel="noopener">66代理</a></li>
</ol>
<h3 id="建立代理IP池"><a href="#建立代理IP池" class="headerlink" title="建立代理IP池"></a>建立代理IP池</h3><p>以<a href="https://www.kuaidaili.com/ops/proxylist/1/" target="_blank" rel="noopener">快代理</a>为例：</p>
<details>
<summary><mark>查看隐藏代码</mark></summary>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_proxy</span><span class="params">(headers)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    获取代理IP列表</span></span><br><span class="line"><span class="string">    :return: ip_list [&#123;"https": ip&#125;,…]</span></span><br><span class="line"><span class="string">     """</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    ip_list = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">        <span class="comment"># 快代理</span></span><br><span class="line">        base_url = <span class="string">"https://www.kuaidaili.com/ops/proxylist/"</span> + str(i)</span><br><span class="line">        html = requests.get(base_url, headers=headers).text</span><br><span class="line"> </span><br><span class="line">        pattern = <span class="string">'\d+\.\d+\.\d+\.\d+'</span></span><br><span class="line">        re_list = re.findall(pattern, html)</span><br><span class="line">        <span class="keyword">for</span> ip_port <span class="keyword">in</span> re_list:</span><br><span class="line">            ip_list.append(&#123;<span class="string">"https"</span>: ip_port&#125;)</span><br><span class="line">    <span class="keyword">return</span> ip_list</span><br><span class="line"><span class="comment"># 快代理 上有些IP类型仅为http，有些为http，https</span></span><br></pre></td></tr></table></figure>

</details>

<h3 id="测试代理IP"><a href="#测试代理IP" class="headerlink" title="测试代理IP"></a>测试代理IP</h3><p>通过request直接请求一个网址，看是否通过或者看状态码是否为200(<strong><code>request.status_code == 200</code></strong>)</p>
<p><details></p>
<summary><mark>查看隐藏代码</mark></summary>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_proxy</span><span class="params">(ip_list, headers, test_url)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    测试代理IP</span></span><br><span class="line"><span class="string">    :param ip_list:</span></span><br><span class="line"><span class="string">    :return: ip_list [&#123;"https": ip&#125;,…]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> proxy <span class="keyword">in</span> ip_list:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = requests.get(test_url, headers=headers, proxies=proxy, timeout=<span class="number">5</span>)  </span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ConnectTimeout:</span><br><span class="line">            ip_list.pop(i)</span><br><span class="line">        i = i + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> ip_list</span><br></pre></td></tr></table></figure>
<p><details><br><strong>但是上述代码的问题是设置了代理IP，请求网站通过，也不代表IP有效，因为有可能不是用了设置的代理IP而是用了自己公网下的IP（可以用ifconfig查询所在局域网下的IP，及私网IP）</strong><a href="https://blog.csdn.net/Chenftli/article/details/86701563" target="_blank" rel="noopener">参考</a></p>
<p><details></p>
<summary><mark>查看隐藏代码</mark></summary>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_proxy_3</span><span class="params">(ip_list)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    测试是理IP</span></span><br><span class="line"><span class="string">    :param ip_list:</span></span><br><span class="line"><span class="string">    :return ip_valid_list: [&#123;https: ip&#125;,…]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    ip_valid_list = []</span><br><span class="line">    test_url =  <span class="string">"http://httpbin.org/get"</span> <span class="comment"># 改网站可测试目前请求的IP</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> proxy <span class="keyword">in</span> ip_list:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            res = requests.get(test_url, proxies=proxy, headers=headers, timeout=<span class="number">8</span>)</span><br><span class="line">            data = response.text.strip()</span><br><span class="line">            proxyIP = json.loads(data)[<span class="string">'origin'</span>]</span><br><span class="line">            <span class="keyword">if</span> proxyIP != proxy[<span class="string">"https"</span>]:</span><br><span class="line">                ip_list.pop(i)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="comment">#print("proxy invalid")</span></span><br><span class="line">            ip_list.pop(i)</span><br><span class="line">        i = i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ip_valid_list</span><br></pre></td></tr></table></figure>
<details>

<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><p><details></p>
<summary><mark>隐藏</mark></summary>

<p>Max retries exceeded with url</p>
<ol>
<li><p>requests.exceptions.<strong>ProxyError</strong>: HTTPConnectionPool(host=’**<em>‘, port=443): Max retries exceeded with url: \</em>** (Caused by ProxyError(‘Cannot connect to proxy.’, NewConnectionError(‘<urllib3.connection.HTTPConnection object at 0x0000015363189190>: </p>
<blockquote>
<p>IP代理使用的协议不正常，http和https不能写错。</p>
</blockquote>
</li>
<li><p>requests.exceptions.<strong>ConnectionError</strong>: HTTPSConnectionPool(host=<em>**, , port=443): Max retries exceeded with url: \</em>** (Caused by NewConnectionError(‘<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb51433af98>:</p>
<blockquote>
<p>http的连接数超过最大限制，默认的情况下连接是Keep-alive的，所以导致服务器保持了太多连接而不能再新建连接。</p>
</blockquote>
</li>
<li><p>HTTPSConnectionPool(host=’***‘, port=443): Max retries exceeded with url: ***(Caused by SSLError(SSLError(1, u’[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:579)’),))</p>
<blockquote>
<p>Requests 可以为 HTTPS 请求验证 SSL 证书，就像 web 浏览器一样。SSL 验证默认是开启的，如果证书验证失败，Requests 会抛出 SSLError。</p>
<ul>
<li><p>不用ssl证书验证，将verify 设置为 False，<strong>page=requests.get(url，verify=False)</strong></p>
</li>
<li><p>requests默认是keep-alive的，可能没有释放，加参数 headers={‘Connection’:’close’}</p>
</li>
<li><p>增加连接重试次数：<code>requests.adapters.DEFAULT_RETRIES = 5</code> </p>
</li>
<li><p>关闭多余的连接：requests使用了urllib3库，默认的http connection是keep-alive的，requests设置False关闭。<code>s = requests.session()       s.keep_alive = False</code> </p>
<p>参考：<a href="https://blog.csdn.net/wdh315172/article/details/80491668" target="_blank" rel="noopener">https://blog.csdn.net/wdh315172/article/details/80491668</a></p>
</li>
</ul>
</blockquote>
<details>

</li>
</ol>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><ul>
<li><a href="https://github.com/Hopetree/Jobs-search" target="_blank" rel="noopener">招聘网站爬虫</a></li>
<li><a href="https://github.com/Hopetree/E-commerce-crawlers" target="_blank" rel="noopener">电商网站爬虫</a></li>
<li><a href="https://github.com/Hopetree/Spiders100" target="_blank" rel="noopener">Spiders100</a></li>
<li><a href="https://github.com/Hopetree/MyTools" target="_blank" rel="noopener">一些界面化的爬虫小工具</a></li>
</ul>
<hr>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><ol>
<li><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/" target="_blank" rel="noopener">BeautifulSoup4官方中文文档</a></li>
<li><a href="[https://www.jianshu.com/p/2b783f7914c6](https://www.jianshu.com/p/2b783f7914c6">bs4模块使用指南</a>)</li>
<li><a href="https://python3webspider.cuiqingcai.com/" target="_blank" rel="noopener">Python3网络爬虫开发实战</a>​</li>
</ol>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>requests</tag>
        <tag>BeautifulSoup</tag>
      </tags>
  </entry>
  <entry>
    <title>python爬虫学习之Ajax,Selenium,Splash</title>
    <url>/2020/07/29/python%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E4%B9%8BAjax/</url>
    <content><![CDATA[<h2 id="异步数据加载"><a href="#异步数据加载" class="headerlink" title="异步数据加载"></a>异步数据加载</h2><p>向网站进行一次请求，一次只传部分数据。如：有些网页不需要点击下一页，其内容也可以源源不断地加载。</p>
<h2 id="Ajax数据爬取"><a href="#Ajax数据爬取" class="headerlink" title="Ajax数据爬取"></a>Ajax数据爬取</h2><a id="more"></a>
<h3 id="什么是Ajax"><a href="#什么是Ajax" class="headerlink" title="什么是Ajax"></a>什么是Ajax</h3><p>Ajax，全称为 Asynchronous JavaScript and XML，即异步的 JavaScript 和 XML。它不是一门编程语言，而是利用 JavaScript （JavaScript 可以实现页面的各种交互功能）在保证页面不被刷新、页面链接不改变的情况下与服务器交换数据并更新部分网页的技术。</p>
<p>一般出现在页面底部有“加载更多”，这其实就是 JavaScript 向服务器发送了一个 Ajax 请求，然后获取新的微博数据，将其解析，并将其渲染在网页中。</p>
<h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>简单分为以下 3 步：</p>
<ul>
<li><p>发送请求：Ajax 有其特殊的请求类型，叫作 xhr（XMLHttpRequest）</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> xmlhttp;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">window</span>.XMLHttpRequest) &#123;</span><br><span class="line">    <span class="comment">//code for IE7+, Firefox, Chrome, Opera, Safari</span></span><br><span class="line">    xmlhttp=<span class="keyword">new</span> XMLHttpRequest();&#125; <span class="keyword">else</span> &#123;<span class="comment">//code for IE6, IE5</span></span><br><span class="line">    xmlhttp=<span class="keyword">new</span> ActiveXObject(<span class="string">"Microsoft.XMLHTTP"</span>);</span><br><span class="line">&#125;</span><br><span class="line">xmlhttp.onreadystatechange=<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;<span class="keyword">if</span> (xmlhttp.readyState==<span class="number">4</span> &amp;&amp; xmlhttp.status==<span class="number">200</span>) &#123;<span class="built_in">document</span>.getElementById(<span class="string">"myDiv"</span>).innerHTML=xmlhttp.responseText;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">xmlhttp.open(<span class="string">"POST"</span>,<span class="string">"/ajax/"</span>,<span class="literal">true</span>);</span><br><span class="line">xmlhttp.send();</span><br></pre></td></tr></table></figure>
<p>新建了 XMLHttpRequest 对象，然后调用 onreadystatechange 属性设置了监听，然后调用 open() 和 send() 方法向某个链接（也就是服务器）发送了请求。</p>
<p>前面用 Python 实现请求发送之后，可以得到响应结果，但这里请求的发送变成 JavaScript 来完成。由于设置了监听，所以当服务器返回响应时，onreadystatechange 对应的方法便会被触发，然后在这个方法里面解析响应内容即可。</p>
</li>
<li><p>解析内容</p>
<p>得到响应之后，onreadystatechange 属性对应的方法便会被触发，此时利用 xmlhttp 的 responseText 属性便可取到响应内容。这类似于 Python 中利用 requests 向服务器发起请求，然后得到响应的过程。那么返回内容可能是 HTML，可能是 JSON，接下来只需要在方法中用 JavaScript 进一步处理即可。比如，如果是 JSON 的话，可以进行解析和转化。</p>
</li>
<li><p>渲染网页</p>
<p>JavaScript 有改变网页内容的能力，解析完响应内容之后，就可以调用 JavaScript 来针对解析完的内容对网页进行下一步处理了。比如，通过 document.getElementById().innerHTML 这样的操作，便可以对某个元素内的源代码进行更改，这样网页显示的内容就改变了，这样的操作也被称作 DOM 操作，即对 Document 网页文档进行操作，如更改、删除等。</p>
<p><code>document.getElementById(&quot;myDiv&quot;).innerHTML=xmlhttp.responseText</code> 便将 ID 为 myDiv 的节点内部的 HTML 代码更改为服务器返回的内容，这样 myDiv 元素内部便会呈现出服务器返回的新数据，网页的部分内容看上去就更新了。</p>
</li>
</ul>
<h2 id="动态渲染页面抓取"><a href="#动态渲染页面抓取" class="headerlink" title="动态渲染页面抓取"></a>动态渲染页面抓取</h2><p>JavaScript 动态渲染的页面不止 Ajax 这一种，并且淘宝这种页面，它即使是 Ajax 获取的数据，但是其 Ajax 接口含有很多加密参数，我们难以直接找出其规律，也很难直接分析 Ajax 来抓取。</p>
<p>为了解决这些问题，我们可以<strong>直接使用模拟浏览器运行的方式来实现</strong> ，这样就可以做到在浏览器中看到是什么样，抓取的源码就是什么样，也就是可见即可爬。这样我们就不用再去管网页内部的 JavaScript 用了什么算法渲染页面，不用管网页后台的 Ajax 接口到底有哪些参数。</p>
<h3 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h3><p><a href="[http://www.selenium.org.cn/](http://www.selenium.org.cn/">Selenium</a>)是web自动化测试工具集，包括IDE、Grid、RC（selenium 1.0）、WebDriver（selenium 2.0）等。利用它可以驱动浏览器执行特定的动作，如点击、下拉等操作，同时还可以获取浏览器当前呈现的页面的源代码，做到可见即可爬。对于一些 JavaScript 动态渲染的页面来说，此种抓取方式非常有效。</p>
<p> <a href="[https://blog.csdn.net/huilan_same/article/details/52615123](https://blog.csdn.net/huilan_same/article/details/52615123">selenium自动化资源整理</a>)</p>
<p>[][<a href="https://selenium-python.readthedocs.io/][Selenium使用文档](https://selenium-python.readthedocs.io/" target="_blank" rel="noopener">https://selenium-python.readthedocs.io/][Selenium使用文档](https://selenium-python.readthedocs.io/</a>)</p>
<h4 id="声明浏览器对象"><a href="#声明浏览器对象" class="headerlink" title="声明浏览器对象"></a>声明浏览器对象</h4><p>Selenium 支持非常多的浏览器，如 Chrome、Firefox、Edge 等，还有 Android、BlackBerry 等手机端的浏览器。另外，也支持无界面浏览器 PhantomJS。初始化方式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> selenium.webdriver</span><br><span class="line"></span><br><span class="line">driver = selenium.webdriver.Chrome()</span><br><span class="line">browser = webdriver.Firefox()</span><br><span class="line">browser = webdriver.Edge()</span><br><span class="line">browser = webdriver.Safari()</span><br><span class="line"><span class="comment"># 浏览器对象的初始化并将其赋值为 browser 对象，接下来，可以调用 browser 对象，让其执行各个动作以模拟浏览器操作。</span></span><br><span class="line"><span class="comment"># 要下载浏览器相应的驱动，并将其放入PATH中。例如，FireFox需要下载geckodriver</span></span><br></pre></td></tr></table></figure>
<h4 id="PhantomJS"><a href="#PhantomJS" class="headerlink" title="PhantomJS"></a>PhantomJS</h4><p>PhantomJS是一个无界面浏览器。抓取时，不会弹出窗口.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">browser = webdriver.PhantomJS()</span><br></pre></td></tr></table></figure>
<p>另外，它还支持命令行配置。比如，可以设置缓存和禁用图片加载的功能，进一步提高爬取效率：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SERVICE_ARGS &#x3D; [&#39;--load-images&#x3D;false&#39;, &#39;--disk-cache&#x3D;true&#39;]</span><br><span class="line">browser &#x3D; webdriver.PhantomJS(service_args&#x3D;SERVICE_ARGS)</span><br></pre></td></tr></table></figure>
<ul>
<li>需要 “此电脑&gt;属性&gt;高级系统设置&gt;高级&gt;环境变量&gt;系统变量&gt;Path”里添加phantomjs.exe的解压路径</li>
<li>需要将指定参数executable_path=r’D:\software_apk\phantomjs-2.1.1-windows\bin\phantomjs.exe’否则会报错</li>
</ul>
<h4 id="Chrome-Headless-模式"><a href="#Chrome-Headless-模式" class="headerlink" title="Chrome Headless 模式"></a>Chrome Headless 模式</h4><p>从 Chrome 59 版本开始，已经开始支持 Headless 模式，也就是无界面模式，这样爬取的时候就不会弹出浏览器了。如果要使用此模式，请把 Chrome 升级到 59 版本及以上。启用 Headless 模式的方式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chrome_options = webdriver.ChromeOptions()</span><br><span class="line">chrome_options.add_argument(<span class="string">'--headless'</span>)</span><br><span class="line">browser = webdriver.Chrome(chrome_options=chrome_options)</span><br></pre></td></tr></table></figure>
<h4 id="访问页面"><a href="#访问页面" class="headerlink" title="访问页面"></a>访问页面</h4><p>用 get() 方法来请求网页，参数传入链接 URL 即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://www.bilibili.com/"</span></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(url)</span><br><span class="line">print(browser.page_source)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>
<h4 id="查找节点"><a href="#查找节点" class="headerlink" title="查找节点"></a>查找节点</h4><p>Selenium 可以驱动浏览器完成各种操作，比如填充表单、模拟点击等。</p>
<p> Selenium 提供了一系列查找节点的方法，我们可以用这些方法来获取想要的节点，以便下一步执行一些动作或者提取信息。</p>
<h5 id="单个节点：-查找的目标在网页中只有一个"><a href="#单个节点：-查找的目标在网页中只有一个" class="headerlink" title="单个节点： 查找的目标在网页中只有一个"></a>单个节点： 查找的目标在网页中只有一个</h5><p>find_element_by_name() 是根据 name 值获取，find_element_by_id() 是根据 id 获取。另外，还有根据 XPath、CSS 选择器等获取的方式。</p>
<p>例如，从淘宝页面中提取搜索框这个节点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">'https://www.taobao.com'</span>)</span><br><span class="line">input_first = browser.find_element_by_id(<span class="string">'q'</span>)</span><br><span class="line">input_second = browser.find_element_by_css_selector(<span class="string">'#q'</span>)</span><br><span class="line">input_third = browser.find_element_by_xpath(<span class="string">'//*[@id="q"]'</span>)</span><br><span class="line">input_forth = browser.find_element(By.ID, <span class="string">'q'</span>)</span><br><span class="line">print(input_first, input_second, input_third, input_forth)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure>
<h5 id="多个节点"><a href="#多个节点" class="headerlink" title="多个节点"></a>多个节点</h5><p>如果有多个节点，再用 find_element() 方法查找，就只能得到第一个节点了。如果要查找所有满足条件的节点，需要用 find_elements() 这样的方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lis = browser.find_elements_by_css_selector(<span class="string">'.service-bd li'</span>)</span><br></pre></td></tr></table></figure>
<p>结果为列表，每个节点都是WebElement类型。</p>
<p>其他获取多个节点的方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">find_element_by_id</span><br><span class="line">find_element_by_name</span><br><span class="line">find_element_by_xpath</span><br><span class="line">find_element_by_link_text</span><br><span class="line">find_element_by_partial_link_text</span><br><span class="line">find_element_by_tag_name</span><br><span class="line">find_element_by_class_name</span><br><span class="line">find_element_by_css_selector</span><br><span class="line">find_elements(By.CSS_SELECTOR, <span class="string">'.service-bd li'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="节点交互"><a href="#节点交互" class="headerlink" title="节点交互"></a>节点交互</h4><p>Selenium 可以驱动浏览器来执行一些操作。比较常见的用法有：输入文字时用 send_keys 方法，清空文字时用 clear 方法，点击按钮时用 click 方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">'https://www.taobao.com'</span>)</span><br><span class="line">input = browser.find_element_by_id(<span class="string">'q'</span>)</span><br><span class="line">input.send_keys(<span class="string">'iPhone'</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line">input.clear()</span><br><span class="line">input.send_keys(<span class="string">'iPad'</span>)</span><br><span class="line">button = browser.find_element_by_class_name(<span class="string">'btn-search'</span>)</span><br><span class="line">button.click()</span><br></pre></td></tr></table></figure>
<h4 id="动作链"><a href="#动作链" class="headerlink" title="动作链"></a>动作链</h4><p>有一些操作，它们<strong>没有特定的执行对象</strong> ，比如鼠标拖曳、键盘按键等，这些动作用另一种方式来执行，那就是<strong>动作链</strong> 。</p>
<p>比如，实现一个节点的拖曳操作，将某个节点从一处拖曳到另外一处：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ActionChains</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = <span class="string">'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'</span></span><br><span class="line">browser.get(url)</span><br><span class="line">browser.switch_to.frame(<span class="string">'iframeResult'</span>)</span><br><span class="line">source = browser.find_element_by_css_selector(<span class="string">'#draggable'</span>)</span><br><span class="line">target = browser.find_element_by_css_selector(<span class="string">'#droppable'</span>)</span><br><span class="line">actions = ActionChains(browser)</span><br><span class="line">actions.drag_and_drop(source, target)</span><br><span class="line">actions.perform()</span><br></pre></td></tr></table></figure>
<h4 id="执行-JavaScript"><a href="#执行-JavaScript" class="headerlink" title="执行 JavaScript"></a>执行 JavaScript</h4><p>Selenium API 并没有提供<strong>下拉进度条</strong> 等操作，但可以直接模拟运行 JavaScript，此时使用 execute_script() 方法即可实现，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">'https://www.zhihu.com/explore'</span>)</span><br><span class="line">browser.execute_script(<span class="string">'window.scrollTo(0, document.body.scrollHeight)'</span>)</span><br><span class="line">browser.execute_script(<span class="string">'alert("To Bottom")'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="获取节点信息"><a href="#获取节点信息" class="headerlink" title="获取节点信息"></a>获取节点信息</h4><ul>
<li>通过 <code>page_source</code> 属性可以获取网页的源代码，也可以通过Selenium 提供的选择节点的方法，直接提取节点信息。</li>
</ul>
<ul>
<li>先通过查找节点，获取WebElement类型，再通过get_attribute() 方法，.text属性，.id属性，.location属性，.tag_name属性，.size属性，获取属性、文本、 ID、位置、标签名、大小</li>
</ul>
<h4 id="切换-Frame"><a href="#切换-Frame" class="headerlink" title="切换 Frame"></a>切换 Frame</h4><p>网页中有一种节点叫作 <strong>iframe</strong>，也就是<strong>子 Frame</strong>，相当于页面的<strong>子页面</strong>，它的结构和外部网页的结构完全一致。Selenium 打开页面后，它默认是在父级 Frame 里面操作，而此时如果页面中还有子 Frame，它是不能获取到子 Frame 里面的节点的。这时就需要使用 <code>switch_to.frame()</code> 方法来切换 Frame。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> NoSuchElementException</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = <span class="string">'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'</span></span><br><span class="line">browser.get(url)</span><br><span class="line">browser.switch_to.frame(<span class="string">'iframeResult'</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    logo = browser.find_element_by_class_name(<span class="string">'logo'</span>)</span><br><span class="line"><span class="keyword">except</span> NoSuchElementException:</span><br><span class="line">    print(<span class="string">'NO LOGO'</span>)</span><br><span class="line">browser.switch_to.parent_frame()</span><br><span class="line">logo = browser.find_element_by_class_name(<span class="string">'logo'</span>)</span><br><span class="line">print(logo)</span><br><span class="line">print(logo.text)</span><br></pre></td></tr></table></figure>
<h4 id="延时等待"><a href="#延时等待" class="headerlink" title="延时等待"></a>延时等待</h4><p>get() 方法会在网页框架加载结束后结束执行，此时如果获取 page_source，可能并不是浏览器完全加载完成的页面，所以，这里需要延时等待一定时间，确保节点已经加载出来。</p>
<h5 id="隐式等待"><a href="#隐式等待" class="headerlink" title="隐式等待"></a>隐式等待</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.implicitly_wait(<span class="number">10</span>)</span><br><span class="line">browser.get(<span class="string">'https://www.zhihu.com/explore'</span>)</span><br><span class="line">input = browser.find_element_by_class_name(<span class="string">'zu-top-add-question'</span>)</span><br><span class="line">print(input)</span><br></pre></td></tr></table></figure>
<p>当使用隐式等待 (<code>implicitly_wait()</code>) 执行测试时，如果 Selenium 没有在 DOM 中找到节点，将继续等待，超出设定时间后，则抛出找不到节点的异常。换句话说，当查找节点而节点并没有立即出现的时候，隐式等待将等待一段时间再查找 DOM，默认的时间是 0。</p>
<h5 id="显式等待"><a href="#显式等待" class="headerlink" title="显式等待"></a>显式等待</h5><p>显式等待方法，指定要查找的节点，然后<strong>指定一个最长等待时间</strong>。如果在规定时间内加载出来了这个节点，就返回查找的节点；如果到了规定时间依然没有加载出该节点，则抛出超时异常。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">'https://www.taobao.com/'</span>)</span><br><span class="line">wait = WebDriverWait(browser, <span class="number">10</span>)</span><br><span class="line">input = wait.until(EC.presence_of_element_located((By.ID, <span class="string">'q'</span>)))</span><br><span class="line">button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, <span class="string">'.btn-search'</span>)))</span><br><span class="line">print(input, button)</span><br></pre></td></tr></table></figure>
<p>引入 WebDriverWait 对象，指定最长等待时间，调用其 until() 方法，传入要等待条件 expected_conditions。比如，传入 presence_of_element_located ，其参数是节点的定位元组( ID 为 q 的节点搜索框)。10 秒内如果 ID 为 q 的节点（即搜索框）成功加载出来，就返回该节点；否则，抛出异常。</p>
<p>按钮可以使用 element_to_be_clickable，( CSS 选择器为.btn-search 的按钮)，如果 10 秒内成功加载出来，即可点击，就返回该按钮节点；否则，抛出异常。</p>
<h6 id="其他等待条件"><a href="#其他等待条件" class="headerlink" title="其他等待条件"></a>其他等待条件</h6><p><a href="https://python3webspider.cuiqingcai.com/7.1selenium-de-shi-yong#xian-shi-deng-dai" target="_blank" rel="noopener">https://python3webspider.cuiqingcai.com/7.1selenium-de-shi-yong#xian-shi-deng-dai</a></p>
<h4 id="前进后退"><a href="#前进后退" class="headerlink" title="前进后退"></a>前进后退</h4><p>back() 和 forward() 方法 </p>
<h4 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h4><p>get_cookies() 方法获取所有的 Cookies，add_cookies() 添加删除， delete_all_cookies() 方法删除所有的 Cookies。</p>
<h4 id="选项卡管理"><a href="#选项卡管理" class="headerlink" title="选项卡管理"></a>选项卡管理</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(<span class="string">'https://www.baidu.com'</span>)</span><br><span class="line">browser.execute_script(<span class="string">'window.open()'</span>)</span><br><span class="line">print(browser.window_handles)</span><br><span class="line">browser.switch_to_window(browser.window_handles[<span class="number">1</span>])</span><br><span class="line">browser.get(<span class="string">'https://www.taobao.com'</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line">browser.switch_to_window(browser.window_handles[<span class="number">0</span>])</span><br><span class="line">browser.get(<span class="string">'https://python.org'</span>)</span><br></pre></td></tr></table></figure>
<p>调用 execute_script() 方法，传入 window.open() 这个 JavaScript 语句新开启一个选项卡。</p>
<p>调用 window_handles 属性获取当前开启的所有选项卡，调用 switch_to_window() 方法切换到该选项卡。</p>
<h4 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h4><p>使用 try except 语句来捕获各种异常，都在selenium.common.exceptions下。</p>
<p>TimeoutException</p>
<p>NoSuchElementException</p>
<h3 id="Splash"><a href="#Splash" class="headerlink" title="Splash"></a>Splash</h3><p><a href="https://splash.readthedocs.io/en/stable/index.html" target="_blank" rel="noopener">Splash</a> 是一个 JavaScript 渲染服务，是一个带有 HTTP API 的轻量级浏览器，同时它对接了 Python 中的 Twisted 和 QT 库。</p>
<p>可以实现如下功能：</p>
<ul>
<li>异步方式处理多个网页渲染过程</li>
<li>获取渲染后的页面的源代码或截图</li>
<li>通过关闭图片渲染或者使用 Adblock 规则来加快页面渲染速度</li>
<li>可执行特定的 JavaScript 脚本</li>
<li>可通过 Lua 脚本来控制页面渲染过程</li>
<li>获取渲染的详细过程并通过 HAR（HTTP Archive）格式呈现</li>
</ul>
<p><a href="https://www.jianshu.com/p/feeb15f2e49b" target="_blank" rel="noopener">win10家庭版docker安装</a></p>
<ul>
<li>遇到问题，安装过程中将git bash卸载了。</li>
</ul>
<p><a href="https://www.cnblogs.com/samwu/p/10360943.html" target="_blank" rel="noopener">win10家庭版安装docker</a></p>
<ul>
<li>遇到问题，docker desk 无法启动，out of memory。。。</li>
</ul>
<p><a href="https://blog.csdn.net/pp_lan/article/details/90692510" target="_blank" rel="noopener">https://blog.csdn.net/pp_lan/article/details/90692510</a></p>
<h4 id="Splash-Lua-脚本"><a href="#Splash-Lua-脚本" class="headerlink" title="Splash Lua 脚本"></a>Splash Lua 脚本</h4><p>Splash 可以通过 Lua 脚本执行一系列渲染操作，这样我们就可以用 Splash 来模拟类似 Chrome、PhantomJS 的操作了。</p>
<h5 id="入口及返回值"><a href="#入口及返回值" class="headerlink" title="入口及返回值"></a>入口及返回值</h5><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash, args)</span></span></span><br><span class="line">  splash:go(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line">  splash:wait(<span class="number">0.5</span>)</span><br><span class="line">  <span class="keyword">local</span> title = splash:evaljs(<span class="string">"document.title"</span>)</span><br><span class="line">  <span class="keyword">return</span> &#123;title=title&#125;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Splash 会默认调用main 方法。</li>
<li>返回值可以是字典形式，也可以是字符串形式，最后都会转化为 Splash HTTP Response。</li>
</ul>
<h5 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h5><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash, args)</span></span></span><br><span class="line">  <span class="keyword">local</span> example_urls = &#123;<span class="string">"www.baidu.com"</span>, <span class="string">"www.taobao.com"</span>, <span class="string">"www.zhihu.com"</span>&#125;</span><br><span class="line">  <span class="keyword">local</span> urls = args.urls <span class="keyword">or</span> example_urls</span><br><span class="line">  <span class="keyword">local</span> results = &#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> index, url <span class="keyword">in</span> <span class="built_in">ipairs</span>(urls) <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">local</span> ok, reason = splash:go(<span class="string">"http://"</span> .. url)</span><br><span class="line">    <span class="keyword">if</span> ok <span class="keyword">then</span></span><br><span class="line">      splash:wait(<span class="number">2</span>)</span><br><span class="line">      results[url] = splash:png()</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">return</span> results</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>运行后的返回结果是 3 个站点的截图</p>
<ul>
<li>字符串拼接操作符<code>..</code>，而不是python中的<code>+</code></li>
<li>go 方法会返回加载页面的结果状态，如果页面出现 4xx 或 5xx 状态码，ok 变量就为空，就不会返回加载后的图片。</li>
</ul>
<h4 id="Splash-对象属性"><a href="#Splash-对象属性" class="headerlink" title="Splash 对象属性"></a>Splash 对象属性</h4><p>splash类似于 Selenium 中的 WebDriver 对象。</p>
<h5 id="args"><a href="#args" class="headerlink" title="args"></a>args</h5><h5 id="js-enabled"><a href="#js-enabled" class="headerlink" title="js_enabled"></a>js_enabled</h5><p>这个属性是 Splash 的 JavaScript 执行开关，可以将其配置为 true 或 false 来控制是否执行 JavaScript 代码，默认为 true。</p>
<h5 id="resource-timeout"><a href="#resource-timeout" class="headerlink" title="resource_timeout"></a>resource_timeout</h5><p>设置加载的超时时间，单位是秒。如果设置为 0 或 nil（类似 Python 中的 None），代表不检测超时。</p>
<h5 id="images-enabled"><a href="#images-enabled" class="headerlink" title="images_enabled"></a>images_enabled</h5><p>设置图片是否加载，默认情况下是加载的。禁用该属性后，可以节省网络流量并提高网页加载速度。</p>
<ul>
<li>禁用图片加载可能会影响 JavaScript 渲染。因为禁用图片之后，它的外层 DOM 节点的高度会受影响，进而影响 DOM 节点的位置。因此，如果 JavaScript 对图片节点有操作的话，其执行就会受到影响。</li>
<li>Splash 使用了缓存。如果一开始加载出来了网页图片，然后禁用了图片加载，再重新加载页面，之前加载好的图片可能还会显示出来，这时直接重启 Splash 即可。</li>
</ul>
<h5 id="plugins-enabled"><a href="#plugins-enabled" class="headerlink" title="plugins_enabled"></a>plugins_enabled</h5><p>控制浏览器插件（如 Flash 插件）是否开启。默认情况下，此属性是 false。</p>
<h5 id="scroll-position"><a href="#scroll-position" class="headerlink" title="scroll_position"></a>scroll_position</h5><p>控制页面上下或左右滚动</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">splash.scroll_position = &#123;y=<span class="number">400</span>&#125;</span><br><span class="line">splash.scroll_position = &#123;x=<span class="number">100</span>, y=<span class="number">200</span>&#125;</span><br></pre></td></tr></table></figure>
<h4 id="Splash-对象方法"><a href="#Splash-对象方法" class="headerlink" title="Splash 对象方法"></a>Splash 对象方法</h4><h5 id="go"><a href="#go" class="headerlink" title="go"></a>go</h5><p>该方法用来请求某个链接，而且它可以模拟 GET 和 POST 请求，同时支持传入请求头、表单等数据，其用法如下：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">ok, reason = splash:go&#123;url, baseurl=<span class="literal">nil</span>, headers=<span class="literal">nil</span>, http_method=<span class="string">"GET"</span>, body=<span class="literal">nil</span>, formdata=<span class="literal">nil</span>&#125;</span><br></pre></td></tr></table></figure>
<p>返回值为ok和reason，如果 ok 为空，代表网页加载出现了错误，此时 reason 变量中包含了错误的原因，否则证明页面加载成功。</p>
<h5 id="wait"><a href="#wait" class="headerlink" title="wait"></a>wait</h5><p>控制页面等待时间</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ok, reason = splash:wait&#123;time, cancel_on_redirect=false, cancel_on_error=true&#125;</span><br></pre></td></tr></table></figure>
<h5 id="jsfunc"><a href="#jsfunc" class="headerlink" title="jsfunc"></a>jsfunc</h5><p>直接调用 JavaScript 定义的方法，但是所调用的方法需要用双中括号包围，这相当于实现了 JavaScript 方法到 Lua 脚本的转换。</p>
<p>首先，声明了 JavaScript 定义的方法，然后在页面加载成功后调用了此方法计算出了页面中 div 节点的个数。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash, args)</span></span></span><br><span class="line">  <span class="keyword">local</span> get_div_count = splash:jsfunc(<span class="string">[[function () &#123;</span></span><br><span class="line"><span class="string">    var body = document.body;</span></span><br><span class="line"><span class="string">    var divs = body.getElementsByTagName('div');</span></span><br><span class="line"><span class="string">    return divs.length;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">  ]]</span>)</span><br><span class="line">  splash:go(<span class="string">"https://www.baidu.com"</span>)</span><br><span class="line">  <span class="keyword">return</span> (<span class="string">"There are % s DIVs"</span>):<span class="built_in">format</span>(get_div_count())</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h5 id="evaljs"><a href="#evaljs" class="headerlink" title="evaljs"></a>evaljs</h5><p>执行 JavaScript 代码并返回最后一条 JavaScript 语句的返回结果。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">result = splash:evaljs(js)</span><br></pre></td></tr></table></figure>
<h5 id="runjs"><a href="#runjs" class="headerlink" title="runjs"></a>runjs</h5><p>执行 JavaScript 代码，它与 evaljs 方法的功能类似，但是更偏向于<strong>执行某些动作</strong>或<strong>声明某些方法</strong>。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash, args)</span></span></span><br><span class="line">  splash:go(<span class="string">"https://www.baidu.com"</span>)</span><br><span class="line">  splash:runjs(<span class="string">"foo = function() &#123;return 'bar'&#125;"</span>)</span><br><span class="line">  <span class="keyword">local</span> result = splash:evaljs(<span class="string">"foo()"</span>)</span><br><span class="line">  <span class="keyword">return</span> result</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>用 runjs 方法先声明了一个 JavaScript 定义的方法，然后通过 evaljs 方法来调用得到的结果。</p>
<h5 id="autoload"><a href="#autoload" class="headerlink" title="autoload"></a>autoload</h5><p>设置每个页面访问时自动加载的对象。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">ok, reason = splash:autoload&#123;source_or_url, source=<span class="literal">nil</span>, url=<span class="literal">nil</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>方法只负责加载 JavaScript 代码或库，不执行任何操作。如果要执行操作，可以调用 evaljs 或 runjs 方法。</li>
</ul>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash, args)</span></span></span><br><span class="line">  splash:autoload(<span class="string">[[function get_document_title()&#123;return document.title;&#125;</span></span><br><span class="line"><span class="string">  ]]</span>)</span><br><span class="line">  splash:go(<span class="string">"https://www.baidu.com"</span>)</span><br><span class="line">  <span class="keyword">return</span> splash:evaljs(<span class="string">"get_document_title()"</span>)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<ul>
<li>使用 autoload 方法加载某些方法库，如 jQuery，</li>
</ul>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash, args)</span></span></span><br><span class="line">  <span class="built_in">assert</span>(splash:autoload(<span class="string">"https://code.jquery.com/jquery-2.1.3.min.js"</span>))</span><br><span class="line">  <span class="built_in">assert</span>(splash:go(<span class="string">"https://www.taobao.com"</span>))</span><br><span class="line">  <span class="keyword">local</span> version = splash:evaljs(<span class="string">"$.fn.jquery"</span>)</span><br><span class="line">  <span class="keyword">return</span> <span class="string">'JQuery version: '</span> .. version</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h5 id="call-later"><a href="#call-later" class="headerlink" title="call_later"></a>call_later</h5><p>设置定时任务和延迟时间来实现任务延时执行，并且可以在执行前通过 cancel 方法重新执行定时任务。</p>
<h5 id="htttp-get"><a href="#htttp-get" class="headerlink" title="htttp_get"></a>htttp_get</h5><p>拟发送 HTTP 的 GET 请求</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">response = splash:http_get&#123;url, headers=<span class="literal">nil</span>, follow_redirects=<span class="literal">true</span>&#125;</span><br></pre></td></tr></table></figure>
<h5 id="http-post"><a href="#http-post" class="headerlink" title="http_post"></a>http_post</h5><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">response = splash:http_post&#123;url, headers=<span class="literal">nil</span>, follow_redirects=<span class="literal">true</span>, body=<span class="literal">nil</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>body，可选参数，默认为空，即表单数据。</li>
</ul>
<h5 id="set-content"><a href="#set-content" class="headerlink" title="set_content"></a>set_content</h5><p>用来设置页面的内容</p>
<h5 id="html"><a href="#html" class="headerlink" title="html"></a>html</h5><p>用来获取网页的源代码</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash, args)</span></span></span><br><span class="line">  splash:go(<span class="string">"https://httpbin.org/get"</span>)</span><br><span class="line">  <span class="keyword">return</span> splash:html()</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h5 id="png"><a href="#png" class="headerlink" title="png"></a>png</h5><p>获取 PNG 格式的网页截图</p>
<h5 id="jpeg"><a href="#jpeg" class="headerlink" title="jpeg"></a>jpeg</h5><p>用来获取 JPEG 格式的网页截图</p>
<h5 id="har"><a href="#har" class="headerlink" title="har"></a>har</h5><p>用来获取页面加载过程描述</p>
<h5 id="url"><a href="#url" class="headerlink" title="url"></a>url</h5><p>获取当前正在访问的 URL</p>
<h5 id="get-cokies"><a href="#get-cokies" class="headerlink" title="get_cokies"></a>get_cokies</h5><p>获取当前页面的 Cookies</p>
<h5 id="add-cokies"><a href="#add-cokies" class="headerlink" title="add_cokies"></a>add_cokies</h5><p>为当前页面添加 Cookies</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">cookies = splash:add_cookie&#123;name, value, <span class="built_in">path</span>=<span class="literal">nil</span>, domain=<span class="literal">nil</span>, expires=<span class="literal">nil</span>, httpOnly=<span class="literal">nil</span>, secure=<span class="literal">nil</span>&#125;</span><br></pre></td></tr></table></figure>
<h5 id="clear-cookies"><a href="#clear-cookies" class="headerlink" title="clear_cookies"></a>clear_cookies</h5><p>清除所有的 Cookies</p>
<h5 id="get-viewport-size"><a href="#get-viewport-size" class="headerlink" title="get_viewport_size"></a>get_viewport_size</h5><p>获取当前浏览器页面的大小，即宽高</p>
<h5 id="set-viewport-size"><a href="#set-viewport-size" class="headerlink" title="set_viewport_size"></a>set_viewport_size</h5><p>设置当前浏览器页面的大小，即宽高</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">splash:set_viewport_size(width, height)</span><br></pre></td></tr></table></figure>
<h5 id="set-viewport-full"><a href="#set-viewport-full" class="headerlink" title="set_viewport_full"></a>set_viewport_full</h5><p>此方法可以设置浏览器全屏显示</p>
<h5 id="set-user-agent"><a href="#set-user-agent" class="headerlink" title="set_user_agent"></a>set_user_agent</h5><p>此方法可以设置浏览器的 User-Agent</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">splash:set_user_agent(<span class="string">'Splash'</span>)</span><br></pre></td></tr></table></figure>
<h5 id="set-custom-headers"><a href="#set-custom-headers" class="headerlink" title="set_custom_headers()"></a>set_custom_headers()</h5><p>此方法可以设置请求的 Headers</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">splash:set_custom_headers(&#123;[<span class="string">"User-Agent"</span>] = <span class="string">"Splash"</span>,</span><br><span class="line">     [<span class="string">"Site"</span>] = <span class="string">"Splash"</span>,</span><br><span class="line">  &#125;)</span><br></pre></td></tr></table></figure>
<h5 id="select"><a href="#select" class="headerlink" title="select"></a>select</h5><p>可以选中符合条件的第一个节点，如果有多个节点符合条件，则只会返回一个，其参数是 CSS 选择器。</p>
<h5 id="select-all"><a href="#select-all" class="headerlink" title="select_all()"></a>select_all()</h5><p>此方法可以选中所有的符合条件的节点，其参数是 CSS 选择器。</p>
<h5 id="mouse-click"><a href="#mouse-click" class="headerlink" title="mouse_click"></a>mouse_click</h5><p>此方法可以模拟鼠标点击操作，传入的参数为坐标值 x、y，也可以直接选中某个节点直接调用此方法。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span><span class="params">(splash)</span></span></span><br><span class="line">  splash:go(<span class="string">"https://www.baidu.com/"</span>)</span><br><span class="line">  <span class="built_in">input</span> = splash:<span class="built_in">select</span>(<span class="string">"#kw"</span>)</span><br><span class="line">  <span class="built_in">input</span>:send_text(<span class="string">'Splash'</span>)</span><br><span class="line">  submit = splash:<span class="built_in">select</span>(<span class="string">'#su'</span>)</span><br><span class="line">  submit:mouse_click()</span><br><span class="line">  splash:wait(<span class="number">3</span>)</span><br><span class="line">  <span class="keyword">return</span> splash:png()</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h4 id="Splash-API-调用"><a href="#Splash-API-调用" class="headerlink" title="Splash API 调用"></a>Splash API 调用</h4><p>上述Splash Lua 脚本的用法，是在 Splash 页面里面测试运行的。</p>
<p>Splash 提供了一些 HTTP API 接口，请求这些接口并传递相应的参数即可获取页面渲染后的结果。</p>
<h5 id="render-html"><a href="#render-html" class="headerlink" title="render.html"></a>render.html</h5><p>用于获取 JavaScript 渲染的页面的 HTML 代码，接口地址就是 Splash 的运行地址加此接口名称</p>
<p><code>url = &#39;http://localhost:8050/render.html?url=https://www.baidu.com&#39;</code></p>
<p><code>url = &#39;http://localhost:8050/render.html?url=https://www.taobao.com&amp;amp;wait=5&#39;</code></p>
<h5 id="render-png"><a href="#render-png" class="headerlink" title="render.png"></a>render.png</h5><p>此接口可以获取网页截图,返回的是 PNG 格式的图片二进制数据</p>
<p><code>&#39;http://localhost:8050/render.png?url=https://www.jd.com&amp;wait=5&amp;width=1000&amp;height=700&#39;</code></p>
<h5 id="render-jpeg"><a href="#render-jpeg" class="headerlink" title="render.jpeg"></a>render.jpeg</h5><p>和 render.png 类似，返回的是 JPEG 格式的图片二进制数据。</p>
<p>另外此接口相比 render.png 还多了一个参数 quality，可以用来设置图片质量。</p>
<h5 id="render-har"><a href="#render-har" class="headerlink" title="render.har"></a>render.har</h5><p>此接口用于获取页面加载的 HAR 数据</p>
<p><code>http://localhost:8050/render.har?url=https://www.jd.com&amp;wait=5</code></p>
<h5 id="render-json"><a href="#render-json" class="headerlink" title="render.json"></a>render.json</h5><p>此接口包含了前面接口的所有功能，返回结果是 Json 格式</p>
<p><code>http://localhost:8050/render.json?url=https://httpbin.org&amp;html=1&amp;har=1</code></p>
<p>可以通过传入不同参数控制其返回结果。比如，传入 html=1，返回结果即会增加源代码数据；传入 png=1，返回结果即会增加页面 PNG 截图数据；传入 har=1，则会获得页面 HAR 数据。</p>
<h5 id="execute"><a href="#execute" class="headerlink" title="execute"></a>execute</h5><p>用此接口便可实现与 Lua 脚本的对接。实现一些交互操作。</p>
<p>将lua脚本转化为 URL 编码后的字符串，拼接到 execute 接口后面</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"></span><br><span class="line">lua = <span class="string">'''</span></span><br><span class="line"><span class="string">function main(splash)</span></span><br><span class="line"><span class="string">    return 'hello'</span></span><br><span class="line"><span class="string">end</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://localhost:8050/execute?lua_source='</span> + quote(lua)</span><br><span class="line">response = requests.get(url)</span><br><span class="line">print(response.text)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Ajax</tag>
        <tag>Selenium</tag>
        <tag>Slash</tag>
      </tags>
  </entry>
  <entry>
    <title>python爬虫学习之数据存储</title>
    <url>/2020/07/29/python%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/</url>
    <content><![CDATA[<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>TXT, JSON, CSV等，以及关系型数据库MySQL，菲关系型数据库MongoDB、Redis 等</p>
<a id="more"></a>
<h3 id="文件存储"><a href="#文件存储" class="headerlink" title="文件存储"></a>文件存储</h3><h4 id="TXT文本存储"><a href="#TXT文本存储" class="headerlink" title="TXT文本存储"></a>TXT文本存储</h4><p>文件写入还有一种简写方法，那就是使用 with as 语法。在 with 控制块结束时，文件会自动关闭，所以就不需要再调用 close 方法了。这种保存方式可以简写如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'explore.txt'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.write(<span class="string">'\n'</span>.join([question, author, answer]))</span><br><span class="line">    file.write(<span class="string">'\n'</span> + <span class="string">'='</span> * <span class="number">50</span> + <span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h4><p>JSON，全称为 JavaScript Object Notation, 也就是 JavaScript 对象标记，它通过对象和数组的组合来表示数据，构造简洁但是结构化程度非常高，是一种轻量级的数据交换格式。</p>
<h5 id="对象和数组"><a href="#对象和数组" class="headerlink" title="对象和数组"></a>对象和数组</h5><p>在 JavaScript 语言中，一切都是对象。因此，任何支持的类型都可以通过 JSON 来表示，例如字符串、数字、对象、数组等</p>
<p><strong>对象</strong> ：它在 JavaScript 中是使用花括号 {} 包裹起来的内容，数据结构为 {key1：value1, key2：value2, …} 的键值对结构。在面向对象的语言中，key 为对象的属性，value 为对应的值。键名可以使用整数和字符串来表示。值的类型可以是任意类型。</p>
<p><strong>数组</strong> ：数组在 JavaScript 中是方括号 [] 包裹起来的内容，数据结构为 [“java”, “javascript”, “vb”, …] 的索引结构。在 JavaScript 中，数组是一种比较特殊的数据类型，它也可以像对象那样使用键值对，但还是索引用得多。同样，值的类型可以是任意类型。</p>
<h5 id="读取和写入"><a href="#读取和写入" class="headerlink" title="读取和写入"></a>读取和写入</h5><p>loads() string to json # <strong>json数据需要使用双引号（</strong>double quotes<strong>）来包围</strong></p>
<p>dumps() json to string <code>son.dumps(data, indent=2)</code></p>
<p>注意：文本含有中文字符时，指定编码方式为<strong>utf-8</strong> 并且将ensure_ascii设为False：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'MaoYan_result.txt'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(json.dumps(content, ensure_ascii=<span class="literal">False</span>) + <span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h4><p>见前篇：<a href="https://yuqie.github.io/2020/07/25/python%E4%B9%8Bcsv/" target="_blank" rel="noopener">python之csv</a></p>
<h3 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h3><p>关系型数据库是基于<strong>关系模型</strong>的数据库，而关系模型是通过二维表来保存的，所以它的存储方式就是行列组成的表，每一列是一个字段，每一行是一条记录。表可以看作某个实体的集合，而实体之间存在联系，这就需要表与表之间的关联关系来体现，如主键外键的关联关系。多个表组成一个数据库，也就是关系型数据库。</p>
<p>关系型数据库有多种，如 SQLite、MySQL、Oracle、SQL Server、DB2 等。</p>
<h4 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h4><p>在 Python 2 中，连接 MySQL 的库大多是使用 MySQLdb，但是此库的官方并不支持 Python 3，所以在Python3中使用 PyMySQL 操作 MySQL 数据库。</p>
<h5 id="创建新的数据库："><a href="#创建新的数据库：" class="headerlink" title="创建新的数据库："></a>创建新的数据库：</h5><p><code>&quot;CREATE DATABASE spiders DEFAULT CHARACTER SET utf8&quot;</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql  </span><br><span class="line"></span><br><span class="line">db = pymysql.connect(host=<span class="string">'localhost'</span>,user=<span class="string">'root'</span>, password=<span class="string">'123456'</span>, port=<span class="number">3306</span>)  </span><br><span class="line">cursor = db.cursor()  </span><br><span class="line">cursor.execute(<span class="string">"CREATE DATABASE spiders DEFAULT CHARACTER SET utf8"</span>)  </span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>
<p>之后重新连接数据库，指定参数db</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">db = pymysql.connect(host=<span class="string">'localhost'</span>, user=<span class="string">'root'</span>, password=<span class="string">'123456'</span>, port=<span class="number">3306</span>, db=<span class="string">'spiders'</span>)</span><br><span class="line">cursor = db.cursor()</span><br></pre></td></tr></table></figure>
<h5 id="创建表："><a href="#创建表：" class="headerlink" title="创建表："></a>创建表：</h5><p><code>&#39;CREATE TABLE IF NOT EXISTS students (id VARCHAR(255) NOT NULL, name VARCHAR(255) NOT NULL, age INT NOT NULL, PRIMARY KEY (id))&#39;</code></p>
<h5 id="插入数据："><a href="#插入数据：" class="headerlink" title="插入数据："></a>插入数据：</h5><p><code>&#39;INSERT INTO students(id, name, age) values(% s, % s, % s)&#39;</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">try:</span><br><span class="line">    cursor.execute(sql, (id, user, age))</span><br><span class="line">    db.commit()</span><br><span class="line">except:</span><br><span class="line">    db.rollback()</span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>
<ul>
<li>对于数据插入、更新、删除操作，都需要执行 db 对象的 commit 方法才能真正生效，这个方法才是真正将语句提交到数据库执行的方法。</li>
<li>异常处理。如果执行失败，则调用 rollback 执行数据回滚，可以保证事务的一致性。</li>
<li>事务机制可以确保数据的一致性，也就是这件事要么发生了，要么没有发生。比如插入一条数据，不会存在插入一半的情况，要么全部插入，要么都不插入，这就是事务的原子性。</li>
<li>事务的 4 个属性，也称为 ACID 特性。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>原子性（atomicity）</td>
<td>事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做</td>
</tr>
<tr>
<td>一致性（consistency）</td>
<td>事务必须使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的</td>
</tr>
<tr>
<td>隔离性（isolation）</td>
<td>一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰</td>
</tr>
<tr>
<td>持久性（durability）</td>
<td>持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响</td>
</tr>
</tbody>
</table>
</div>
<p><strong>动态数据传入</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'id'</span>: <span class="string">'20120001'</span>,</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'Bob'</span>,</span><br><span class="line">    <span class="string">'age'</span>: <span class="number">20</span></span><br><span class="line">&#125;</span><br><span class="line">table = <span class="string">'students'</span></span><br><span class="line">keys = <span class="string">', '</span>.join(data.keys())</span><br><span class="line">values = <span class="string">', '</span>.join([<span class="string">'% s'</span>] * len(data))</span><br><span class="line">sql = <span class="string">'INSERT INTO &#123;table&#125;(&#123;keys&#125;) VALUES (&#123;values&#125;)'</span>.format(table=table, keys=keys, values=values)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">   <span class="keyword">if</span> cursor.execute(sql, tuple(data.values())):</span><br><span class="line">       print(<span class="string">'Successful'</span>)</span><br><span class="line">       db.commit()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">'Failed'</span>)</span><br><span class="line">    db.rollback()</span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>
<h5 id="更新数据："><a href="#更新数据：" class="headerlink" title="更新数据："></a>更新数据：</h5><p>现一种去重的方法，如果数据存在，则更新数据；如果数据不存在，则插入数据。</p>
<p><code>INSERT INTO students(id, name, age) VALUES (% s, % s, % s) ON DUPLICATE KEY UPDATE id = % s, name = % s, age = % s</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sql = <span class="string">'INSERT INTO &#123;table&#125;(&#123;keys&#125;) VALUES (&#123;values&#125;) ON DUPLICATE KEY UPDATE'</span>.format(table=table, keys=keys, values=values)</span><br><span class="line">update = <span class="string">','</span>.join([<span class="string">"&#123;key&#125; = % s"</span>.format(key=key) <span class="keyword">for</span> key <span class="keyword">in</span> data])</span><br><span class="line">sql += update</span><br></pre></td></tr></table></figure>
<h5 id="删除数据："><a href="#删除数据：" class="headerlink" title="删除数据："></a>删除数据：</h5><p><code>&#39;DELETE FROM  {table} WHERE {condition}&#39;.format(table=table, condition=condition)</code></p>
<h5 id="查询数据："><a href="#查询数据：" class="headerlink" title="查询数据："></a>查询数据：</h5><p>查询年龄 20 岁及以上的学生<code>&#39;SELECT * FROM students WHERE age &gt;= 20&#39;</code></p>
<p>fetchone 方法，这个方法可以获取结果的第一条数据，返回结果是元组形式.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sql = <span class="string">'SELECT * FROM students WHERE age &gt;= 20'</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    cursor.execute(sql)</span><br><span class="line">    print(<span class="string">'Count:'</span>, cursor.rowcount)</span><br><span class="line">    row = cursor.fetchone()</span><br><span class="line">    <span class="keyword">while</span> row:</span><br><span class="line">        print(<span class="string">'Row:'</span>, row)</span><br><span class="line">        row = cursor.fetchone()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">'Error'</span>)</span><br></pre></td></tr></table></figure>
<p>fetchall 方法，它可以得到结果的所有数据。然后将其结果和类型打印出来，它是二重元组，每个元素都是一条记录，我们将其遍历输出出来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sql = <span class="string">'SELECT * FROM students WHERE age &gt;= 20'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    cursor.execute(sql)</span><br><span class="line">    results = cursor.fetchall()</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> results:</span><br><span class="line">        print(row)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">'Error'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="非关系型数据库存储"><a href="#非关系型数据库存储" class="headerlink" title="非关系型数据库存储"></a>非关系型数据库存储</h3><p>NoSQL，全称 Not Only SQL，意为不仅仅是 SQL，泛指非关系型数据库。NoSQL 是基于<strong>键值对</strong>的，而且不需要经过 SQL 层的解析，数据之间没有耦合性，性能非常高。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>类型</th>
<th>代表</th>
</tr>
</thead>
<tbody>
<tr>
<td>键值存储数据库</td>
<td>Redis、Voldemort 和 Oracle BDB 等</td>
</tr>
<tr>
<td>列存储数据库</td>
<td>Cassandra、HBase 和 Riak 等</td>
</tr>
<tr>
<td>文档型数据库</td>
<td>CouchDB 和 MongoDB 等</td>
</tr>
<tr>
<td>图形数据库</td>
<td>Neo4J、InfoGrid 和 Infinite Graph 等</td>
</tr>
</tbody>
</table>
</div>
<p>对于<strong>爬虫的数据存储</strong>来说，一条数据可能存在<strong>某些字段提取失败而缺失</strong>的情况，而且<strong>数据可能随时调整</strong>。另外，数据之间还存在<strong>嵌套关系</strong>。如果使用关系型数据库存储，一是需要提前建表，二是如果存在数据嵌套关系的话，需要进行序列化操作才可以存储，这非常不方便。</p>
<h4 id="MongoDB"><a href="#MongoDB" class="headerlink" title="MongoDB"></a>MongoDB</h4><p>MongoDB 是由 <strong>C++ </strong> 语言编写的非关系型数据库，是一个基于<strong>分布式文件存储</strong> 的开源数据库系统，其内容存储形式类似 JSON 对象，它的字段值可以包含其他文档、数组及文档数组。</p>
<p><a href="https://www.jianshu.com/p/d99f6fd8b209" target="_blank" rel="noopener">安装MongoDB</a></p>
<p>CMD命令进入某个目录: 进入某个磁盘，直接盘符代号：如D：，不用CD 命令切换; 进入除根录以下的文件夹, cd 文件夹路径.</p>
<p>遇到warning：Access control is not enabled for the database.</p>
<p>原因分析：新版本的MongDB增加了安全性设计，推荐用户创建使用数据库时进行验证。如果用户想建立简单连接，则会提示警示信息。</p>
<p>解决办法：创建管理员并设置密码</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">use admin</span><br><span class="line">db.createUser(</span><br><span class="line">  &#123;</span><br><span class="line">    user: "userAdmin", //用户名</span><br><span class="line">    pwd: "123", //密码</span><br><span class="line">    roles: [ &#123; role: "userAdminAnyDatabase", db: "admin" &#125; ] //权限</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>重启MongoDB服务器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mongod --auth --port <span class="number">27017</span> --dbpath &lt;关联路径:bin/&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>端口默认就是27017可以不指定</p>
<p><a href="https://blog.csdn.net/ttxsely/article/details/77726164" target="_blank" rel="noopener">https://blog.csdn.net/ttxsely/article/details/77726164</a></p>
</li>
</ul>
<h5 id="连接MongoDB"><a href="#连接MongoDB" class="headerlink" title="连接MongoDB"></a>连接MongoDB</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line">client = pymongo.MongoClient(host=<span class="string">'localhost'</span>, port=<span class="number">27017</span>)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">client = MongoClient(<span class="string">'mongodb://localhost:27017/'</span>)</span><br></pre></td></tr></table></figure>
<h5 id="指定数据库"><a href="#指定数据库" class="headerlink" title="指定数据库"></a>指定数据库</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">db = client.test</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">db = client[test]</span><br></pre></td></tr></table></figure>
<h5 id="指定集合（collection）"><a href="#指定集合（collection）" class="headerlink" title="指定集合（collection）"></a>指定集合（collection）</h5><p><strong>集合</strong>类似于关系型数据库中的<strong>表</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">collection = db.students</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">collection = db[<span class="string">'students'</span>]</span><br></pre></td></tr></table></figure>
<h5 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">student = &#123;</span><br><span class="line">    <span class="string">'id'</span>: <span class="string">'20170101'</span>,</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'Jordan'</span>,</span><br><span class="line">    <span class="string">'age'</span>: <span class="number">20</span>,</span><br><span class="line">    <span class="string">'gender'</span>: <span class="string">'male'</span></span><br><span class="line">&#125;</span><br><span class="line">result = collection.insert(student)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>在 MongoDB 中，每条数据其实都有一个_id 属性来唯一标识。如果没有显式指明该属性，MongoDB 会自动产生一个 ObjectId 类型的_id 属性。insert() 方法会在执行后返回_id 值。</p>
</li>
<li><p>以列表形式传递可同时插入多条数据。</p>
</li>
<li><p>PyMongo 3.x 版本中，官方不推荐使用 insert() 方法。而是推荐使用 insert_one() 和 insert_many() 方法来分别插入单条记录和多条记录。</p>
<p>insert_one() （返回InsertOneResult对象），用其 inserted_id 属性获取_id。</p>
<p>insert_many() （返回的类型是 InsertManyResult），调用 inserted_ids 属性可以获取插入数据的_id 列表。</p>
</li>
</ul>
<h5 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h5><ul>
<li>find_one() 查询得到的是单个结果，类型为字典：<code>result = collection.find_one({&#39;name&#39;: &#39;Mike&#39;})</code></li>
<li>find() 则返结果是 Cursor 类型，它相当于一个生成器：<code>results = collection.find({&#39;age&#39;: 20})</code></li>
<li>比较符号和功能符号：</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>$lt</td>
<td>小于</td>
<td>{‘age’: {‘$lt’: 20}}</td>
</tr>
<tr>
<td>$gt</td>
<td>大于</td>
<td>{‘age’: {‘$gt’: 20}}</td>
</tr>
<tr>
<td>$lte</td>
<td>小于等于</td>
<td>{‘age’: {‘$lte’: 20}}</td>
</tr>
<tr>
<td>$gte</td>
<td>大于等于</td>
<td>{‘age’: {‘$gte’: 20}}</td>
</tr>
<tr>
<td>$ne</td>
<td>不等于</td>
<td>{‘age’: {‘$ne’: 20}}</td>
</tr>
<tr>
<td>$in</td>
<td>在范围内</td>
<td>{‘age’: {‘$in’: [20, 23]}}</td>
</tr>
<tr>
<td>$nin</td>
<td>不在范围内</td>
<td>{‘age’: {‘$nin’: [20, 23]}}</td>
</tr>
<tr>
<td>正则匹配查询</td>
<td>以 M 开头</td>
<td>{‘$regex’: ‘^M.*’}</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
<th>示例</th>
<th>示例含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>$regex</td>
<td>匹配正则表达式</td>
<td>{‘$regex’: ‘^M.*’}</td>
<td>name 以 M 开头</td>
</tr>
<tr>
<td>$exists</td>
<td>属性是否存在</td>
<td>{‘name’: {‘$exists’: True}}</td>
<td>name 属性存在</td>
</tr>
<tr>
<td>$type</td>
<td>类型判断</td>
<td>{‘age’: {‘$type’: ‘int’}}</td>
<td>age 的类型为 int</td>
</tr>
<tr>
<td>$mod</td>
<td>数字模操作</td>
<td>{‘age’: {‘$mod’: [5, 0]}}</td>
<td>年龄模 5 余 0</td>
</tr>
<tr>
<td>$text</td>
<td>文本查询</td>
<td>{‘$text’: {‘$search’: ‘Mike’}}</td>
<td>text 类型的属性中包含 Mike 字符串</td>
</tr>
<tr>
<td>$where</td>
<td>高级条件查询</td>
<td>{‘$where’: ‘obj.fans_count == obj.follows_count’}</td>
<td>自身粉丝数等于关注数</td>
</tr>
</tbody>
</table>
</div>
<h5 id="计数"><a href="#计数" class="headerlink" title="计数"></a>计数</h5><p><code>count = collection.find({&#39;age&#39;: 20}).count()</code></p>
<h5 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h5><p><code>results = collection.find().sort(&#39;name&#39;, pymongo.ASCENDING)</code></p>
<p>调用 pymongo.ASCENDING 指定升序。如果要降序排列，可以传入 pymongo.DESCENDING。</p>
<h5 id="偏移"><a href="#偏移" class="headerlink" title="偏移"></a>偏移</h5><p>例如，忽略前两个元素，得到第三个及以后的元素：</p>
<p><code>results = collection.find().sort(&#39;name&#39;, pymongo.ASCENDING).skip(2)</code></p>
<p>可以用 limit() 方法指定要取的结果个数：</p>
<p><code>results = collection.find().sort(&#39;name&#39;, pymongo.ASCENDING).skip(2).limit(2)</code></p>
<ul>
<li><p>在数据库数量非常庞大的时候，如千万、亿级别，最好不要使用大的偏移量来查询数据，因为这样很可能导致内存溢出。这时需要记录好上次查询的_id，使用类似如下操作来查询:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from bson.objectid import ObjectId</span><br><span class="line">collection.find(&#123;&#39;_id&#39;: &#123;&#39;$gt&#39;: ObjectId(&#39;593278c815c2602678bb2b8d&#39;)&#125;&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h5><ul>
<li><p>update</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">condition = &#123;<span class="string">'name'</span>: <span class="string">'Kevin'</span>&#125;</span><br><span class="line">student = collection.find_one(condition)</span><br><span class="line">student[<span class="string">'age'</span>] = <span class="number">25</span></span><br><span class="line">result = collection.update(condition, student)</span><br><span class="line"><span class="comment"># 使用 $set 操作符对数据进行更新</span></span><br><span class="line">result = collection.update(condition, &#123;<span class="string">'$set'</span>: student&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>update_one()</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第二个参数不能再直接传入修改后的字典,而是需要使用 &#123;'$set': student&#125;</span></span><br><span class="line">condition = &#123;<span class="string">'age'</span>: &#123;<span class="string">'$gt'</span>: <span class="number">20</span>&#125;&#125;</span><br><span class="line">result = collection.update_one(condition, &#123;<span class="string">'$inc'</span>: &#123;<span class="string">'age'</span>: <span class="number">1</span>&#125;&#125;) <span class="comment"># 执行之后会将第一条符合条件的数据年龄加 1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>update_many()，则会将所有符合条件的数据都更新</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = collection.update_many(condition, &#123;<span class="string">'$inc'</span>: &#123;<span class="string">'age'</span>: <span class="number">1</span>&#125;&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h5><ul>
<li><p>remove()</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = collection.delete_one(&#123;<span class="string">'name'</span>: <span class="string">'Kevin'</span>&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>delete_one()</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = collection.delete_one(&#123;<span class="string">'name'</span>: <span class="string">'Kevin'</span>&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>delete_many()</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = collection.delete_many(&#123;<span class="string">'age'</span>: &#123;<span class="string">'$lt'</span>: <span class="number">25</span>&#125;&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="其他操作"><a href="#其他操作" class="headerlink" title="其他操作"></a>其他操作</h5><ul>
<li>组合方法，如 find_one_and_delete()、find_one_and_replace() 和 find_one_and_update(</li>
<li>对索引进行操作，如 create_index()、create_indexes() 和 drop_index() 等。</li>
</ul>
<h4 id="Redis-存储"><a href="#Redis-存储" class="headerlink" title="Redis 存储"></a>Redis 存储</h4><p>Redis 是一个基于<strong>内存</strong> 的高效的键值型非关系型数据库，存取效率极高，而且支持多种存储数据结构。</p>
<p>StrictRedis：set和get操作。</p>
<h5 id="连接-Redis"><a href="#连接-Redis" class="headerlink" title="连接 Redis"></a>连接 Redis</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> redis <span class="keyword">import</span> StrictRedis  </span><br><span class="line"></span><br><span class="line">redis = StrictRedis(host=<span class="string">'localhost'</span>, port=<span class="number">6379</span>, db=<span class="number">0</span>, password=<span class="string">'foobared'</span>)  <span class="comment"># default： localhost、6379、0 和 None</span></span><br></pre></td></tr></table></figure>
<p>使用 ConnectionPool 来连接</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> redis <span class="keyword">import</span> StrictRedis, ConnectionPool  </span><br><span class="line"></span><br><span class="line">pool = ConnectionPool(host=<span class="string">'localhost'</span>, port=<span class="number">6379</span>, db=<span class="number">0</span>, password=<span class="string">'foobared'</span>)  </span><br><span class="line">redis = StrictRedis(connection_pool=pool)</span><br></pre></td></tr></table></figure>
<p>ConnectionPool 还支持通过 URL 来构建, URL 的格式支持有如下 3 种</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># redis://[:password]@host:port/db   # 创建 Redis TCP 连接</span></span><br><span class="line"><span class="comment"># rediss://[:password]@host:port/db  # Redis TCP+SSL 连接</span></span><br><span class="line"><span class="comment"># unix://[:password]@/path/to/socket.sock?db=db # Redis UNIX socket 连接</span></span><br><span class="line">    </span><br><span class="line">url = <span class="string">'redis://:foobared@localhost:6379/0'</span>  </span><br><span class="line">pool = ConnectionPool.from_url(url)  </span><br><span class="line">redis = StrictRedis(connection_pool=pool)</span><br></pre></td></tr></table></figure>
<h5 id="键操作"><a href="#键操作" class="headerlink" title="键操作"></a>键操作</h5><h5 id="字符串操作"><a href="#字符串操作" class="headerlink" title="字符串操作"></a>字符串操作</h5><p>键值对形式存储</p>
<p>set(name,value) </p>
<p>mset(name,value)</p>
<p>get(value)</p>
<p>mget(value)</p>
<p>getset(name, value)</p>
<p>incr(name, amount=1)  键名为 name 的 value 增值操作，默认为 1，键不存在则被创建并设为 </p>
<p>decr(name, amount=1)</p>
<p>append(key, value)</p>
<h5 id="列表操作"><a href="#列表操作" class="headerlink" title="列表操作"></a>列表操作</h5><div class="table-container">
<table>
<thead>
<tr>
<th>方　　法</th>
<th>作　　用</th>
<th>参数说明</th>
<th>示　　例</th>
<th>示例说明</th>
<th>示例结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>rpush(name, *values)</td>
<td>在键名为 name 的列表末尾添加值为 value 的元素，可以传多个</td>
<td>name：键名；values：值</td>
<td>redis.rpush(‘list’, 1, 2, 3)</td>
<td>向键名为 list 的列表尾添加 1、2、3</td>
<td>3，列表大小</td>
</tr>
<tr>
<td>lpush(name, *values)</td>
<td>在键名为 name 的列表头添加值为 value 的元素，可以传多个</td>
<td>name：键名；values：值</td>
<td>redis.lpush(‘list’, 0)</td>
<td>向键名为 list 的列表头部添加 0</td>
<td>4，列表大小</td>
</tr>
<tr>
<td>llen(name)</td>
<td>返回键名为 name 的列表的长度</td>
<td>name：键名</td>
<td>redis.llen(‘list’)</td>
<td>返回键名为 list 的列表的长度</td>
<td>4</td>
</tr>
<tr>
<td>lrange(name, start, end)</td>
<td>返回键名为 name 的列表中 start 至 end 之间的元素</td>
<td>name：键名；start：起始索引；end：终止索引</td>
<td>redis.lrange(‘list’, 1, 3)</td>
<td>返回起始索引为 1 终止索引为 3 的索引范围对应的列表</td>
<td>[b’3’, b’2’, b’1’]</td>
</tr>
<tr>
<td>ltrim(name, start, end)</td>
<td>截取键名为 name 的列表，保留索引为 start 到 end 的内容</td>
<td>name：键名；start：起始索引；end：终止索引</td>
<td>ltrim(‘list’, 1, 3)</td>
<td>保留键名为 list 的索引为 1 到 3 的元素</td>
<td>True</td>
</tr>
</tbody>
</table>
</div>
<h5 id="集合操作"><a href="#集合操作" class="headerlink" title="集合操作"></a>集合操作</h5><p>集合中的元素都是不重复的</p>
<h5 id="有序集合操作"><a href="#有序集合操作" class="headerlink" title="有序集合操作"></a>有序集合操作</h5><p>有序集合比集合多了一个分数字段，利用它可以对集合中的数据进行排序</p>
<h5 id="散列操作"><a href="#散列操作" class="headerlink" title="散列操作"></a>散列操作</h5><p>散列表的数据结构</p>
<h5 id="RedisDump"><a href="#RedisDump" class="headerlink" title="RedisDump"></a>RedisDump</h5><p>提供了 Redis 数据的导入和导出功能，redis-dump 用于导出数据，redis-load 用于导入数据。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>csv</tag>
        <tag>数据处理</tag>
        <tag>数据库</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title>记人生的第一次面试</title>
    <url>/2020/07/21/%E8%AE%B0%E4%BA%BA%E7%94%9F%E7%9A%84%E7%AC%AC%E4%B8%80%E6%AC%A1%E9%9D%A2%E8%AF%95/</url>
    <content><![CDATA[<p>写在最前面：快26岁高龄才经历人生中第一次工作面试，值得写篇博客纪念一下。</p>
<a id="more"></a>
<h2 id="形式："><a href="#形式：" class="headerlink" title="形式："></a>形式：</h2><p>网络面试；2个HR，10分钟。</p>
<h2 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h2><ol>
<li><p>1分钟自我介绍；</p>
</li>
<li><p>问了本科院系是下属院系（民办挂名）还是正经院系？</p>
<blockquote>
<p>原话不太一样，导致一开始竟然没有听出来HR的意思，还一本正经地向HR介绍。</p>
</blockquote>
</li>
<li><p>研究生升学是保研还是考研？</p>
</li>
<li><p>为什么选择招商银行，之后不打算做研究了么？</p>
<blockquote>
<p>主要从所学专业既可以继续在实验室探究更前沿的东西，也可以与企业，工业结合起来，并且战略客户部（有细分，房地产，新能源，电力等等）以及投资银行部（涉及行业研究）的岗位和专业有相关性，这样可以做到学以致用。</p>
</blockquote>
</li>
<li><p>能否接受城市的调剂？</p>
<blockquote>
<p>只有北京和深圳两个选项，个人无所谓，所以回答可以接受。</p>
</blockquote>
</li>
<li><p>能否接受岗位的调剂？</p>
<blockquote>
<p>报名表需要填写三个志愿，我先表示可以接受调剂，然后陈述第二个志愿与自己的契合点，但第三个志愿表现得有点不太乐意，HR问我帮你修改成前两个志愿可以么，我表示可以ORZ。深圳的职位和北京的不太一样（不一样怎么调剂城市呢），忘了问能不能加上深圳那边的某一个岗位。</p>
</blockquote>
</li>
</ol>
<h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><ol>
<li>语速过快。</li>
<li>有点抢话，有时候没有听完HR的问题就开始接话准备回答了。</li>
</ol>
<hr>
<p>耐心等待结果！</p>
<p>​</p>
<p>​</p>
<p>​</p>
]]></content>
      <categories>
        <category>日常记录</category>
      </categories>
      <tags>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title>《Scikit-Learn与TensorFlow机器学习实用指南》-第二部分</title>
    <url>/2020/09/03/%E3%80%8AScikit-Learn%E4%B8%8ETensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97%E3%80%8B-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/</url>
    <content><![CDATA[<p>学习资料参考：</p>
<p><a href="https://www.cntofu.com/book/27/docs/2.%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE.md" target="_blank" rel="noopener">一个完整的机器学习项目.md</a></p>
<p><a href="https://github.com/ageron/handson-ml2" target="_blank" rel="noopener">原书Github上代码</a></p>
<p><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" target="_blank" rel="noopener">Oreilly上原书第二版（可以在线阅读）</a></p>
<p><a href="https://github.com/apachecn/hands-on-ml-zh/blob/master/docs/1.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88.md" target="_blank" rel="noopener">第一版翻译</a></p>
<p><a href="https://www.jianshu.com/p/3470a6efbe8d" target="_blank" rel="noopener">简书第一版</a></p>
<p><a href="https://www.jianshu.com/p/86626c79814a" target="_blank" rel="noopener">简书第二版第二部分</a></p>
<p><a href="https://www.jianshu.com/p/4a94798f7dcc" target="_blank" rel="noopener">简书《Scikit-Learn、Keras与TensorFlow机器学习实用指南》第一版和第二版对照</a></p>
<p><a href="https://blog.csdn.net/jiaoyangwm/article/details/82387883#%E7%BB%83%E4%B9%A0%E9%A2%987" target="_blank" rel="noopener">练习题答案参考</a> <a href="https://blog.csdn.net/leowinbow/article/details/88581039" target="_blank" rel="noopener">参考2</a></p>
<a id="more"></a>
<h2 id="第10章-使用Keras搭建人工神经网络"><a href="#第10章-使用Keras搭建人工神经网络" class="headerlink" title="第10章 使用Keras搭建人工神经网络"></a>第10章 使用Keras搭建人工神经网络</h2><p>需要安装<a href="https://www.jianshu.com/p/3a76e4f0504a" target="_blank" rel="noopener">Tensorflow</a>和Keras</p>
<p>人工神经网络是受大脑中的生物神经元启发而来的机器学习模型。</p>
<p>人工神经网络是深度学习的核心，它不仅样式多样、功能强大，还具有可伸缩性，这让人工神经网络适宜处理庞大且复杂的机器学习任务，例如对数十亿张图片分类（谷歌图片）、语音识别（苹果Siri）、向数亿用户每天推荐视频（Youtube）、或者通过学习几百围棋世界冠军（DeepMind的AlphaGo）。</p>
<h3 id="神经元的逻辑计算"><a href="#神经元的逻辑计算" class="headerlink" title="神经元的逻辑计算"></a>神经元的逻辑计算</h3><p>1943年神经生理学家Warren McCulloch和数学家Walter Pitts在他们里程碑的论文<a href="https://scholar.google.com/scholar?q=A+Logical+Calculus+of+Ideas+Immanent+in+Nervous+Activity+author%3Amcculloch" target="_blank" rel="noopener">《A Logical Calculus of Ideas Immanent in Nervous Activity》</a> 中介绍了一个简单的生物神经元模型，它后来演化成了人工神经元：一个或多个二元（开或关）输入，一个二元输出。当达到一定的输入量时，神经元就会产生输出。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-51a591f44c8f7bba.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="感知机（单个TLU）"><a href="#感知机（单个TLU）" class="headerlink" title="感知机（单个TLU）"></a>感知机（单个TLU）</h3><p>感知机是最简单的人工神经网络结构之一，由 Frank Rosenblatt 发明于 1957年。</p>
<p>它基于一种稍微不同的人工神经元，阈值逻辑单元（TLU），或称为线性阈值单元（LTU）：输入和输出是数字（而不是二元开/关值），并且每个输入连接都一个权重。TLU计算其输入的加权和（$z = W_1x_1 + W_2x_2 + … + W_nx_n = x^T·W）$，然后将阶跃函数应用于该和，并输出结果：$h_W(x) = step(z)$，其中$z = x^T·W$。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-c40c1380818019d3.png?imageMogr2/auto-orient/strip|imageView2/2/w/1113/format/webp" alt="img"></p>
<h4 id="阶跃函数："><a href="#阶跃函数：" class="headerlink" title="阶跃函数："></a><strong>阶跃函数</strong>：</h4><p>单位阶跃函数（Heaviside step function）:</p>
<script type="math/tex; mode=display">
heaviside(z)=\left \{ \begin{array} {ll} 0& if\ z<0\\1&if \ z\geq 0 \end{array} \right.\\
sgn(z)=\left \{ \begin{array} {ll} 0& if\ z<0\\0 & if\ z =0\\1&if \ z\gt 0 \end{array} \right.</script><p>单一TLU 可用于简单的线性二元分类。它计算输入的线性组合，如果结果超过阈值，它输出正类或者输出负类（就像逻辑回归分类或线性SVM分类）。</p>
<p><strong>感知器只由一层 TLU 组成，每个TLU连接到所有输入</strong>。当一层的神经元连接着前一层的每个神经元时，该层被称为<strong>全连接层，或紧密层</strong>。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-878dec9a6b1e9c09.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>通常再添加一个<strong>偏置特征（$X_0=1$）</strong>：这种偏置特性通常用一种称为偏置神经元的特殊类型的神经元来表示，它总是输出 1。</p>
<p>一个全连接层神经网络的输出：$h_{W,b}(x) = \phi (XW+B)$</p>
<h4 id="Hebb规则"><a href="#Hebb规则" class="headerlink" title="Hebb规则"></a>Hebb规则</h4><p>如何训练感知机：感知器一次被馈送一个训练实例，对于每个实例，它进行预测。对于每一个产生错误预测的输出神经元，修正输入的连接权重，以获得正确的预测。</p>
<script type="math/tex; mode=display">
\omega_{i,j}^{(next \ step)}=\omega_{i,j}+\eta (y_j-\hat y_j)x_i</script><p><strong>每个输出神经元的决策边界是线性的，因此感知器不能学习复杂的模式</strong>（比如 Logistic 回归分类器）。如果训练实例是线性可分的，Rosenblatt 证明该算法将收敛到一个解。这被称为<strong>感知器收敛定理</strong>。</p>
<p><strong>感知机不输出类概率，而是基于硬阈值进行预测。</strong></p>
<h4 id="感知机的局限性"><a href="#感知机的局限性" class="headerlink" title="感知机的局限性"></a>感知机的局限性</h4><ol>
<li>不能解决一些琐碎的问题（例如，异或（XOR）分类问题）（线性分类模型都不能解决异或问题）</li>
</ol>
<p>可以通过堆叠多个感知机消除，由此产生的人工神经网络被称为<strong>多层感知机（MLP）</strong>。特别地，MLP 可以解决 XOR 问题：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-a8b41a11c481fc03.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="多层感知机（MLP）"><a href="#多层感知机（MLP）" class="headerlink" title="多层感知机（MLP）"></a>多层感知机（MLP）</h3><p>MLP 由一个输入层、一个或多个称为隐藏层的 TLU 组成，一个 TLU 层称为输出层（见图 10-7）。靠近输入层的层，通常被称为浅层，靠近输出层的层通常被称为上层。除了输出层，每一层都有一个偏置神经元，并且全连接到下一层。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-eb971779e84208ec.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>信号是从输入到输出单向流动，因此这种架构被称为<strong>前馈神经网络（FNN）</strong></p>
<p>当人工神经网络有多个隐含层时，称为<strong>深度神经网络（DNN）</strong></p>
<h3 id="反向传播（Back-Propagation）"><a href="#反向传播（Back-Propagation）" class="headerlink" title="反向传播（Back Propagation）"></a>反向传播（Back Propagation）</h3><p>一种训练 MLP 的方法，使用了高效梯度计算的梯度下降算法只需要两次网络传播（一次向前，一次向后），就可以算出网络误差的、和每个独立模型参数相关的梯度。</p>
<blockquote>
<ol>
<li>每次处理一个微批次（假如每个批次包含32个实例），用训练集多次训练BP，每次被称为一个周期（epoch）；</li>
<li>每个微批次先进入输入层，输入层再将其发到第一个隐藏层。计算得到该层所有神经元的（微批次的每个实例的）输出。输出接着传到下一层，直到得到输出层的输出。这个过程就是<strong>前向传播</strong>：就像做预测一样，只是保存了每个中间结果，中间结果要用于反向传播；</li>
<li>然后计算输出误差（使用损失函数比较目标值和实际输出值，然后返回误差）；</li>
<li>通过<strong>链式法则</strong>（对多个变量做微分）计算每个输出连接对误差的贡献量；</li>
<li>使用<strong>链式法则</strong>，计算最后一个隐藏层的每个连接对误差的贡献，这个过程不断向后传播，直到到达输入层。</li>
<li>BP算法做一次梯度下降步骤，用刚刚计算的误差梯度调整所有连接权重。</li>
</ol>
</blockquote>
<p>对每个训练实例，BP算法先做一次预测（前向传播），然后计算误差，然后反向通过每一层以测量误差贡献量（反向传播），最后调整所有连接权重以降低误差（梯度下降）。（每个循环：向前，向后，调整参数）</p>
<p><strong>注意：</strong></p>
<blockquote>
<p><strong>要机初始化隐藏层的连接权重</strong>。假如所有的权重和偏置都初始化为0，则在给定一层的所有神经元都是一样的，BP算法对这些神经元的调整也会是一样的。换句话，就算每层有几百个神经元，模型的整体表现就像每层只有一个神经元一样，模型会显得笨笨的。如果权重是随机初始化的，就可以打破对称性，训练出不同的神经元。</p>
<p><strong>自动计算梯度被称为自动微分。</strong>反向传播使用的是<strong>反向模式自微分</strong>。这种方法快而准，当函数有多个变量（连接权重）和多个输出（损失函数）要微分时也能应对。</p>
</blockquote>
<h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>用其他激活函数代替阶跃函数（因为阶跃函数只包含平坦的段，因此没有梯度，而 Logistic函数处处都有一个定义良好的非零导数，允许梯度下降在每步上取得一些进展。）</p>
<ul>
<li><p>sigmoid（Logistic）函数：输出范围0~1</p>
<p>$\sigma(z)=\frac{1}{1+\exp(-z)}$</p>
</li>
</ul>
<ul>
<li><p>双曲正切函数： S形，连续可微，输出范围-1~1</p>
<p>$\tanh (z) = 2σ(2z) – 1$</p>
</li>
<li><p>ReLU 函数：连续，但在<code>z=0</code>处不可微，没有最大输出值，但效果好，计算快速</p>
<p>$ReLU(z) = max(0, z)$</p>
</li>
<li><p>softplus函数：ReLU函数的平滑变体,z是负值时，softplus接近0，z是正值时，softplus接近z</p>
<p>$softplus(z) = log(1 + exp(z))$</p>
</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-cfc40648369f3b02.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong>设置激活函数的原因</strong>：</p>
<p>如果将几个线性变化链式组合起来，得到的还是线性变换。比如，对于 <code>f(x) = 2x + 3</code> 和 <code>g(x) = 5x – 1</code> ，两者组合起来仍是线性变换：<code>f(g(x)) = 2(5x – 1) + 3 = 10x + 1</code>。<strong>如果层之间不具有非线性，则深层网络和单层网络其实是等同的，这样就不能解决复杂问题。</strong>相反的，足够深且有非线性激活函数的DNN（深度神经网络），在理论上可以近似于任意连续函数。</p>
<h3 id="回归MLP"><a href="#回归MLP" class="headerlink" title="回归MLP"></a>回归MLP</h3><p>预测一个单值，就只需要一个输出神经元；一次预测多个值，则每一维度都要有一个神经元。</p>
<p>回归问题可以不用激活函数，如果想限制输出落到一定范围内，可以使用激活函数。</p>
<p><strong>损失函数</strong>：一般使用<strong>均方误差</strong>，但如果训练集有许多异常值，则可以使用<strong>平均绝对误差</strong>。也可以使用<strong>Huber损失函数</strong>，它是前两者的组合。</p>
<blockquote>
<p>提示：当误差小于阈值δ时（一般为1），Huber损失函数是二次的；误差大于阈值时，Huber损失函数是线性的。相比均方误差，线性部分可以让Huber对异常值不那么敏感，二次部分可以让收敛更快，也比均绝对误差更精确。</p>
</blockquote>
<p><strong>回归MLP的典型架构</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-51306abe073c8ea2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="分类MLP"><a href="#分类MLP" class="headerlink" title="分类MLP"></a>分类MLP</h3><p>二元分类问题：需要一个使用Logistic激活的输出神经元：输出一个0和1之间的值，作为正类的估计概率。</p>
<p>多标签二元分类问题：需要为每个正类配一个输出神经元。多个输出概率的和不一定非要等于1。</p>
<p>多分类：softmax函数可以保证，每个估计概率位于0和1之间，并且各个值相加等于1。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-be616eb033cc7b19.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong>损失函数</strong>： 预测概率分布，可以使用交叉商损失函数</p>
<p><strong>分类MLP的典型架构</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9e017b74d26835cf.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="用Keras实现MLP"><a href="#用Keras实现MLP" class="headerlink" title="用Keras实现MLP"></a>用Keras实现MLP</h3><blockquote>
<p>Keras是一个深度学习高级API，可以用它轻松地搭建、训练、评估和运行各种神经网络。是François Chollet开发的，于2015年3月开源。为了进行神经网络计算，必须要有计算后端的支持。目前可选三个流行库：TensorFlow、CNTK和Theano。</p>
<p>TensorFlow捆绑了自身的Keras实现 —— tf.keras，它只支持TensorFlow作为后端，但提供了更多使用的功能：例如，tf.keras支持TensorFlow的Data API，加载数据更轻松，预处理数据更高效。</p>
<p>排在Keras和TensorFlow之后最流行的深度学习库，是Facebook的PyTorch。</p>
</blockquote>
<p><strong>keras中<code>Sequential API</code>可以搭建序列化的神经网络</strong></p>
<p><strong>复杂模型可以通过<code>Functional API</code>搭建</strong></p>
<p>Wide &amp; Deep是一个非序列化的神经网络模型。由Heng-Tze Cheng在2016年在提出。这个模型可以将全部或部分输入与输出层连起来，既可以学到深层模式（使用深度路径）和简单规则（使用短路径）。作为对比，常规MLP会强制所有数据流经所有层，因此数据中的简单模式在多次变换后会被扭曲。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-cc7f49f651ae6a8a.png?imageMogr2/auto-orient/strip|imageView2/2/w/951/format/webp" alt="img"></p>
<p><strong>使用Subclassing API搭建动态模型</strong></p>
<p>Sequential API和Functional API都是声明式的：只有声明创建每个层以及层的连接方式，才能给模型加载数据以进行训练和推断。</p>
<blockquote>
<p>优点：模型可以方便的进行保存、克隆和分享；模型架构得以展示，便于分析；框架可以推断数据形状和类型，便于及时发现错误（加载数据之前就能发现错误）。调试也很容易，因为模型是层的静态图。</p>
<p>缺点：模型是静态的。不适合一些模型包含循环、可变数据形状、条件分支，和其它的动态特点的情况。</p>
</blockquote>
<p>对<code>Model</code>类划分子类，在构造器中创建需要的层，调用<code>call()</code>进行计算，。</p>
<blockquote>
<p>优点是：</p>
<ol>
<li>将层的创建和和使用分割了</li>
</ol>
<p>代价是：</p>
<ol>
<li>模型架构隐藏在<code>call()</code>方法中，所以Keras不能对其检查</li>
<li>不能保存或克隆</li>
<li>当调用<code>summary()</code>时，得到的只是层的列表，没有层的连接信息</li>
<li>Keras不能提前检查数据类型和形状，所以很容易犯错。</li>
</ol>
</blockquote>
<h4 id="保存和恢复模型"><a href="#保存和恢复模型" class="headerlink" title="保存和恢复模型"></a>保存和恢复模型</h4><p>Keras使用HDF5格式保存模型架构（包括每层的超参数）和每层的所有参数值（连接权重和偏置项）。还保存了优化器（包括超参数和状态）。</p>
<p>加载：<code>keras.models.load_model</code> </p>
<blockquote>
<p><strong>注意</strong> </p>
<p>这种加载模型的方法只对Sequential API或Functional API有用，不适用于Subclassing API。对于后者，可以用save_weights()和load_weights()保存参数，其它的就得手动保存恢复了。</p>
</blockquote>
<h4 id="使用调回"><a href="#使用调回" class="headerlink" title="使用调回"></a>使用调回</h4><p>对于大数据集上，训练时间长的情况，不仅要在训练结束时保存模型检查点，在一定时间间隔内也要保存，以免电脑宕机造成损失。</p>
<p><code>fit()</code>方法接受参数<code>callbacks</code>，可以让用户指明一个Keras列表，让Keras在训练开始和结束、每个周期开始和结束、甚至是每个批次的前后调用。例如，<code>ModelCheckpoint</code>可以在每个时间间隔保存检查点，默认是每个周期结束之后</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.compile(loss=<span class="string">"mse"</span>, optimizer=keras.optimizers.SGD(lr=<span class="number">1e-3</span>))</span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">"my_keras_model.h5"</span>, save_best_only=<span class="literal">True</span>)</span><br><span class="line">history = model.fit(X_train, y_train, epochs=<span class="number">10</span>,</span><br><span class="line">                    validation_data=(X_valid, y_valid),</span><br><span class="line">                    callbacks=[checkpoint_cb])</span><br><span class="line">model = keras.models.load_model(<span class="string">"my_keras_model.h5"</span>) <span class="comment"># rollback to best model</span></span><br><span class="line">mse_test = model.evaluate(X_test, y_test)</span><br></pre></td></tr></table></figure>
<h3 id="使用TensorBoard进行可视化"><a href="#使用TensorBoard进行可视化" class="headerlink" title="使用TensorBoard进行可视化"></a>使用TensorBoard进行可视化</h3><p>要使用TensorBoard，必须修改程序，将要可视化的数据输出为二进制的日志文件event files。每份二进制数据称为摘要summary，TensorBoard服务器会监测日志文件目录，自动加载更新并可视化：这样就能看到实时数据（稍有延迟），比如训练时的学习曲线。通常，将TensorBoard服务器指向根日志目录，程序的日志写入到它的子目录，这样一个TensorBoard服务就能可视化并比较多次运行的数据，而不会将其搞混。</p>
<h3 id="神经网络参数微调"><a href="#神经网络参数微调" class="headerlink" title="神经网络参数微调"></a>神经网络参数微调</h3><h4 id="微调神经网络的超参数"><a href="#微调神经网络的超参数" class="headerlink" title="微调神经网络的超参数"></a>微调神经网络的超参数</h4><ol>
<li>直接试验超参数的组合，看哪一个在验证集（或使用K折交叉验证）的表现最好。</li>
</ol>
<p>例如，可以使用<code>GridSearchCV</code>或<code>RandomizedSearchCV</code>探索超参数空间</p>
<blockquote>
<p>必须将Keras模型包装进模仿Scikit-Learn回归器的对象中。第一步是给定一组超参数，创建一个搭建和编译Keras模型的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)</span><br></pre></td></tr></table></figure>
<p>因为超参数太多，最好使用随机搜索而不是网格搜索</p>
</blockquote>
<ol>
<li><p>其他探索超参数空间的方法：</p>
<p>核心思想：当某块空间的区域表现好时，就多探索这块区域。这些方法可以代替用户做“放大”工作，可以在更短的时间得到更好的结果。</p>
</li>
</ol>
<blockquote>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fhyperopt%2Fhyperopt" target="_blank" rel="noopener">Hyperopt</a><br>一个可以优化各种复杂搜索空间（包括真实值，比如学习率和离散值，比如层数）的库。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fmaxpumperla%2Fhyperas" target="_blank" rel="noopener">Hyperas</a>，<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2FAvsecz%2Fkopt" target="_blank" rel="noopener">kopt</a> 或 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fautonomio%2Ftalos" target="_blank" rel="noopener">Talos</a><br>用来优化Keras模型超参数的库（前两个是基于Hyperopt的）。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fkerastuner" target="_blank" rel="noopener">Keras Tuner</a><br>Google开发的简单易用的Keras超参数优化库，还有可视化和分析功能。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fscikit-optimize.github.io%2F" target="_blank" rel="noopener">Scikit-Optimize (<code>skopt</code>)</a><br>一个通用的优化库。类<code>BayesSearchCV</code>使用类似于<code>GridSearchCV</code>的接口做贝叶斯优化。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2FJasperSnoek%2Fspearmint" target="_blank" rel="noopener">Spearmint</a><br>一个贝叶斯优化库。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fzygmuntz%2Fhyperband" target="_blank" rel="noopener">Hyperband</a><br>一个快速超参数调节库，基于Lisha Li的论文 《Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization》，<a href="https://links.jianshu.com/go?to=https%3A%2F%2Farxiv.org%2Fabs%2F1603.06560" target="_blank" rel="noopener">https://arxiv.org/abs/1603.06560</a>。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Frsteca%2Fsklearn-deap" target="_blank" rel="noopener">Sklearn-Deap</a><br>一个基于进化算法的超参数优化库，接口类似<code>GridSearchCV</code>。</p>
</blockquote>
<p>Google的AutoML套间已经可以在云服务上使用了</p>
<p>用进化算法训练独立的神经网络很成功，已经取代梯度下降了。</p>
<h4 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h4><p>对于许多问题，开始时只用一个隐藏层就能得到不错的结果。只要有足够多的神经元，只有一个隐藏层的MLP就可以对复杂函数建模。但是对于复杂问题，深层网络比浅层网络有更高的参数效率：深层网络可以用指数级别更少的神经元对复杂函数建模，因此对于同样的训练数据量性能更好。</p>
<p>真实世界的数据通常都是有层次化结构的，深层神经网络正式利用了这一点：浅隐藏层对低级结构（比如各种形状的线段和方向），中隐藏层结合这些低级结构对中级结构（方，圆）建模，深隐藏层和输出层结合中级结构对高级结构（比如，脸）建模。</p>
<p><strong>迁移学习</strong>：层级化的结构不仅帮助深度神经网络收敛更快，也提高了对新数据集的泛化能力。例如，如果已经训练好了一个图片人脸识别的模型，现在想训练一个识别发型的神经网络，可以复用第一个网络的浅层。网络不用从多数图片的低级结构开始学起；只要学高级结构（发型）就行了。</p>
<h4 id="每个隐藏层的神经元数"><a href="#每个隐藏层的神经元数" class="headerlink" title="每个隐藏层的神经元数"></a>每个隐藏层的神经元数</h4><p>输入层和输出层的神经元数是由任务确定的输入和输出类型决定的。</p>
<p>对于隐藏层，惯用的方法是模拟金字塔的形状，神经元数逐层递减 —— 底层思想是，许多低级特征可以聚合成少得多的高级特征。然而，这种方法已经被抛弃了，因为所有隐藏层使用同样多的神经元不仅表现更好，要调节的超参数也只变成了一个，而不是每层都有一个。</p>
<p>和层数相同，可以逐步提高神经元的数量，直到发生过拟合为止。<strong>实际中，通常的简便而高效的方法是使用层数和神经元数都超量的模型，然后使用早停和其它正则技术防止过拟合，称这种方法为“弹力裤”</strong>：不浪费时间选择尺寸完美匹配的裤子，而是选择一条大的弹力裤，它能自动收缩到合适的尺寸。通过这种方法，可以避免影响模型的瓶颈层。另一方面，如果某层的神经元太少，就没有足够强的表征能力，保存所有的输入信息（比如，只有两个神经元的的层只能输出2D数据，如果用它处理3D数据，就会丢失信息）。无论模型网络的其它部分如何强大，丢失的信息也找不回来了。</p>
<blockquote>
<p>通常，增加层数比增加每层的神经元的收益更高。</p>
</blockquote>
<h4 id="学习率，批次大小和其它超参数"><a href="#学习率，批次大小和其它超参数" class="headerlink" title="学习率，批次大小和其它超参数"></a>学习率，批次大小和其它超参数</h4><p><strong>学习率</strong>：</p>
<blockquote>
<p>通常最佳学习率是最大学习率的一般左右（最大学习率是指超过一定值，训练算法发生分叉的学习率）。找到最佳学习率的方式之一是从一个极小值开始（比如10-5）训练模型几百次，直到学习率达到一个比较大的值（比如10）。通过每次迭代，将学习率乘以一个常数（例如 exp(log(106)/500，通过500次迭代，从10-5到10 ）。将损失作为学习率的函数画出来（学习率使用log），可以看到损失一开始是下降的。一段时间后，学习率会变得非常高，损失也会升高。最佳学习率要比损失开始升高的点低一点（通常比拐点低10倍）。然后就可以重新初始化模型，用这个学习率开始训练了</p>
</blockquote>
<p><strong>优化器：</strong></p>
<blockquote>
<p>选择一个更好的优化器（并调节超参数）而不是传统的小批量梯度下降优化器</p>
</blockquote>
<p><strong>批次大小：</strong></p>
<blockquote>
<p>批次大小对模型的表现和训练时间非常重要。使用大批次的好处是硬件（比如GPU）可以快速处理，每秒可以处理更多实例。因此，许多人建议批次大小开到GPU内存的最大值。</p>
<p>缺点：在实际中，大批次会导致训练不稳定，特别是在训练开始时，并且不如小批次模型的泛化能力好。</p>
</blockquote>
<p>一种策略是通过学习率热身使用大批次，如果训练不稳定或效果不好，就换成小批次。</p>
<p><strong>激活函数：</strong></p>
<blockquote>
<p>通常来讲，ReLU适用于所有隐藏层。对于输出层，取决于任务。</p>
</blockquote>
<p><strong>迭代次数：</strong></p>
<blockquote>
<p>对于大多数情况，不用调节训练的迭代次数：直接使用早停。</p>
</blockquote>
<h3 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fplayground.tensorflow.org%2F" target="_blank" rel="noopener">TensorFlow Playground</a>是TensorFlow团队推出的一个便利的神经网络模拟器。只需点击几下，就能训练出二元分类器，通过调整架构和超参数，可以从直观上理解神经网络是如何工作的，以及超参数的作用。如下所示：</p>
<p>a. 神经网络学到的模式。点击左上的运行按钮，训练默认的神经网络。注意是如何找到分类任务的最优解的。第一个隐藏层学到了简单模式，第二个隐藏层将简单模式结合为更复杂的模式。通常，层数越多，得到的模式越复杂。</p>
<p>b. 激活函数。用ReLU激活函数代替tanh，再训练一次网络。注意，找到解变得更快了，且是线性的，这归功于ReLU函数的形状。</p>
<p>c. 局部最小值的风险。将网络只设定为只有一个隐藏层，且只有3个神经元。进行多次训练（重置网络权重，点击Reset按钮）。可以看到训练时间变化很大，甚至有时卡在了局部最小值。</p>
<p>d. 神经网络太小的状况。去除一个神经元，只剩下两个。可以看到，即使尝试多次，神经网络现也不能找到最优解。模型的参数太少，对训练集数据欠拟合。</p>
<p>e. 神经网络足够大的状况。将神经元数设为8，再多次训练神经网络。可以看到过程很快且不会卡住。这是一个重要的发现：大神经网络几乎从不会卡在局部最小值，即使卡住了，局部最小值通常也是全局最小值。但是仍然可能在平台期卡住相当长时间。</p>
<p>f. 梯度消失的风险。选择spiral数据集（右下角位于DATA下面的数据集），模型架构变为四个隐藏层，每层八个神经元。可以看到，训练耗时变长，且经常在平台期卡住很长时间。另外，最高层（右边）的神经元比最底层变得快。这个问题被称为“梯度消失”，可以通过更优的权重初始化、更好的优化器（比如AdaGrad或Adam）、或批次正态化（见第11章）解决。</p>
<p>g. 再尝试尝试其它参数。</p>
</li>
<li><p>用原始神经元（像图10-3中的神经元）画ANN，可以计算 A ⊕ B （ ⊕ 表示 XOR操作）。提示：A ⊕ B = (A ∧ ¬ B) ∨ (¬ A ∧ B)或者<em>A</em> ⊕ <em>B</em> = (<em>A</em> ∨ <em>B</em>) ∧ (¬ <em>A</em> ∨ ¬ <em>B</em>)</p>
<blockquote>
<p><img src="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/assets/mls2_aain01.png" alt="mls2 aain01"></p>
</blockquote>
</li>
<li><p>为什么逻辑回归比经典感知机（即使用感知机训练算法训练的单层的阈值逻辑单元）更好？如何调节感知机，使其等同于逻辑回归分类器？</p>
<blockquote>
<p>逻辑回归可以收敛而不要求数据集线性可分，并且给出实例处于不同类别的概率。</p>
<p>但经典感知机只有当数据集是线性可分时才能收敛，并且不能给出概率。</p>
<p>使用逻辑斯蒂函数作为激活函数（如果有多个类别，可以用softmax函数），并使用梯度下降法训练模型，其结果等同于逻辑回归分类器。</p>
</blockquote>
</li>
<li><p>为什么逻辑激活函数对训练MLP的前几层很重要？</p>
<blockquote>
<p>因为逻辑激活函数处处可微，所以可以使用梯度下降</p>
</blockquote>
</li>
<li><p>说出三种流行的激活函数，并画出来。</p>
<blockquote>
<p>sigmoid ReLU:  tanh:</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-cfc40648369f3b02.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
</blockquote>
</li>
<li><p>假设一个MLP的输入层有10个神经元，接下来是有50个人工神经元的的隐藏层，最后是一个有3个人工神经元的输出层。所有的神经元使用ReLU激活函数。回答以下问题：</p>
<ul>
<li>输入矩阵X的形状是什么？</li>
</ul>
<blockquote>
<p>m x 10， m是训练批次的大小</p>
</blockquote>
<ul>
<li>隐藏层的权重矢量Wh和偏置项bh的形状是什么?</li>
</ul>
<blockquote>
<p>权重矢量Wh:10 x 50</p>
<p>偏置项bh: 50 (每一个隐藏层有一个偏置向)</p>
</blockquote>
<ul>
<li>输出层的权重矢量Wo和偏置项bo的形状是什么?</li>
</ul>
<blockquote>
<p>权重矢量Wo:50x  3</p>
<p>偏置项bo: 3</p>
</blockquote>
<ul>
<li>输出矩阵Y的形状是什么？</li>
</ul>
<blockquote>
<p>m x 3</p>
</blockquote>
<ul>
<li>写出用X、Wh、bh、Wo、bo计算矩阵Y的等式。</li>
</ul>
<blockquote>
<p>$Y = ReLU(ReLU(X W_h + b_h) W_o + b_o)$</p>
</blockquote>
</li>
<li><p>如果要将邮件分为垃圾邮件和正常邮件，输出层需要几个神经元？输出层应该使用什么激活函数？如果任务换成MNIST，输出层需要多少神经元，激活函数是什么？再换成第2章中的房价预测，输出层又该怎么变？</p>
<blockquote>
<p>要将邮件分为垃圾邮件和正常邮件，输出层仅仅需要1个神经元，sigmoid激活函数</p>
<p>如果数据集为MNIST，总共有十个类别，输出层需要10个神经元，softmax激活函数</p>
<p>房价预测是回归问题：输出层只需要一个神经元，并且不需要激活函数</p>
</blockquote>
</li>
<li><p>反向传播是什么及其原理？反向传播和逆向autodiff有什么不同？</p>
<blockquote>
<p>反向传播是一种训练 MLP 的方法，使用了高效梯度计算的梯度下降算法只需要两次网络传播（一次向前，一次向后），就可以算出网络误差的、和每个独立模型参数相关的梯度。</p>
<p>反向传播指的是反向传输，计算梯度，梯度下降的整个过程，而反向模式自微分仅仅是反向传播中用来计算梯度的一个手段。</p>
</blockquote>
</li>
<li><p>列出所有简单MLP中需要调节的超参数？如果MLP过拟合训练数据，如何调节超参数？</p>
<blockquote>
<p>隐藏层的数量，每个隐藏层中神经元的数量，激活函数的选择</p>
<p>一般来说ReLU函数对于隐藏层表现很好，输出层的激活函数需要看输出的需求：</p>
<p>二分类：逻辑函数</p>
<p>多分类：softmax</p>
<p>回归不需要激活函数</p>
<p>过拟合可以早停，或者减少隐藏层的数量，减少每层神经元的数量。</p>
</blockquote>
</li>
<li><p>在MNIST数据及上训练一个深度MLP。</p>
<p>使用<code>keras.datasets.mnist.load_data()</code>加载数据，看看能否使准确率超过98%，利用本章介绍的方法（逐步指数级提高学习率，画误差曲线，找到误差升高的点）搜索最佳学习率。保存检查点，使用早停，用TensorBoard画学习曲线的图。</p>
</li>
</ol>
<hr>
<h2 id="第11章-训练深度神经网络"><a href="#第11章-训练深度神经网络" class="headerlink" title="第11章 训练深度神经网络"></a>第11章 训练深度神经网络</h2><h3 id="梯度消失-爆炸问题"><a href="#梯度消失-爆炸问题" class="headerlink" title="梯度消失/爆炸问题"></a>梯度消失/爆炸问题</h3><p>梯度消失问题： 随着算法进展到较低层，梯度往往变得越来越小。 结果，梯度下降更新使得低层连接权重实际上保持不变，并且训练永远不会收敛到最优解。</p>
<p>梯度爆炸问题：梯度可能变得越来越大，许多层得到了非常大的权重更新，算法发散。</p>
<p>2010 年左右，Xavier Glorot 和 Yoshua Bengio 发表的题为<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fproceedings.mlr.press%2Fv9%2Fglorot10a%2Fglorot10a.pdf" target="_blank" rel="noopener">《Understanding the Difficulty of Training Deep Feedforward Neural Networks》</a>的论文发现：使用流行的 sigmoid 激活函数和当时最受欢迎的权重初始化方法的组合，即随机初始化时使用平均值为 0，标准差为 1 的正态分布，每层输出的方差远大于其输入的方差。随着网络前向传播，每层的方差持续增加，直到激活函数在顶层饱和。logistic函数的平均值为 0.5 而不是 0（双曲正切函数的平均值为 0，表现略好于深层网络中的logistic函数），使得情况更坏。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-c252c67afc52e2f9.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="Glorot-和-He-初始化"><a href="#Glorot-和-He-初始化" class="headerlink" title="Glorot 和 He 初始化"></a>Glorot 和 He 初始化</h3><p>理想情况：需要每层输出的方差等于其输入的方差，并且反向传播时，流经一层的前后，梯度的方差也要相同。</p>
<p>实际上：不可能保证两者都是一样的，除非这个层具有相同数量的输入和神经元（这两个数被称为该层的扇入<code>fan-in</code>和扇出<code>fan-out</code>）</p>
<p>Glorot 和 Bengio提出了一个折衷办法：随机初始化连接权重必须如下:</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-34956eb953f08cc1.png?imageMogr2/auto-orient/strip|imageView2/2/w/702/format/webp" alt="img"></p>
<p>其中$fan_{avg} = (fan_{in} + fan_{out}) / 2$</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-8ccaf8b0c543be01.png?imageMogr2/auto-orient/strip|imageView2/2/w/956/format/webp" alt="img"></p>
<p>默认情况下，Keras使用均匀分布的Glorot初始化函数。</p>
<h3 id="非饱和激活函数"><a href="#非饱和激活函数" class="headerlink" title="非饱和激活函数"></a>非饱和激活函数</h3><p>Glorot 和 Bengio 在 2010 年的论文中的一个见解是，消失/爆炸的梯度问题部分是由于激活函数的选择不好造成的。</p>
<p><strong>“ReLU 死区” </strong> 在训练过程中，一些神经元会“死亡”，即它们停止输出 0 以外的任何东西。</p>
<blockquote>
<p>在训练期间，如果神经元的权重得到更新，使得神经元输入的加权和为负，ReLU函数的梯度为0，神经元就只能输出0了。</p>
</blockquote>
<h4 id="ReLU-函数的变体"><a href="#ReLU-函数的变体" class="headerlink" title="ReLU 函数的变体"></a>ReLU 函数的变体</h4><h4 id="leaky-ReLU："><a href="#leaky-ReLU：" class="headerlink" title="leaky ReLU："></a>leaky ReLU：</h4><p> $LeakyReLU_α(z)= max(αz，z)$</p>
<p>超参数<code>α</code>定义了函数“leak”的程度：它是<code>z &lt; 0</code>时函数的斜率，通常设置为 0.01。这个小斜率保证 leaky ReLU 永不死亡；</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-2e50453795b314b6.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="随机化-leaky-ReLU（RReLU）"><a href="#随机化-leaky-ReLU（RReLU）" class="headerlink" title="随机化 leaky ReLU（RReLU）"></a>随机化 leaky ReLU（RReLU）</h4><p>其中<code>α</code>在训练期间在给定范围内随机，并在测试期间固定为平均值。它表现相当好，似乎是一个正则项（减少训练集的过拟合风险）。</p>
<h4 id="参数化的-leaky-ReLU（PReLU）"><a href="#参数化的-leaky-ReLU（PReLU）" class="headerlink" title="参数化的 leaky ReLU（PReLU）"></a>参数化的 leaky ReLU（PReLU）</h4><p><code>α</code>被授权在训练期间参与学习（不是作为超参数，<code>α</code>变成可以像任何其他参数一样被反向传播修改的参数）。PReLU在大型图像数据集上的表现强于 ReLU，但是对于较小的数据集，其具有过度拟合训练集的风险。</p>
<h4 id="指数线性单元（exponential-linear-unit，ELU）"><a href="#指数线性单元（exponential-linear-unit，ELU）" class="headerlink" title="指数线性单元（exponential linear unit，ELU）"></a>指数线性单元（exponential linear unit，ELU）</h4><p><img src="https://upload-images.jianshu.io/upload_images/7178691-e996caccf4ed7c10.png?imageMogr2/auto-orient/strip|imageView2/2/w/936/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-7bdffc790dc8451f.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>ELU 激活函数的主要缺点是计算速度慢于 ReLU 及其变体（由于使用指数函数），但是在训练过程中，这是通过更快的收敛速度来补偿的。</p>
<h4 id="Scaled-ELU（SELU）激活函数"><a href="#Scaled-ELU（SELU）激活函数" class="headerlink" title="Scaled ELU（SELU）激活函数"></a>Scaled ELU（SELU）激活函数</h4><p>ELU的伸缩变体,2017年提出。</p>
<p>只要神经网络中都是紧密层，并且所有隐藏层都是用的SELU激活函数，则这个网络是自归一的：训练过程中，每层输出的平均值是0，标准差是1，这样就解决了梯度消失爆炸问题。对于全紧密层的网络（尤其是很深的），SELU的效果常常优于其他激活函数。</p>
<p>自归一的条件：</p>
<ul>
<li>输入特征必须是标准的（平均值是0，标准差是1）；</li>
<li>每个隐藏层的权重必须是LeCun正态初始化的。在Keras中，要设置<code>kernel_initializer=&quot;lecun_normal&quot;</code>；</li>
<li>网络架构必须是顺序的。如果要在非顺序网络（比如RNN）或有跳连接的网络（跳过层的连接，比如Wide&amp;Deep）中使用SELU，就不能保证是自归一的，所以SELU就不会比其它激活函数更优；</li>
<li>这篇论文只是说如果所有层都是紧密层才保证自归一，但有些研究者发现SELU激活函数也可以提高卷积神经网络的性能。</li>
</ul>
<blockquote>
<p>一般来说 SELU &gt; ELU &gt; leaky ReLU（及其变体）&gt; ReLU &gt; tanh &gt; sigmoid</p>
<ul>
<li>如果网络架构不能保证自归一，则ELU可能比SELU的性能更好（因为SELU在z=0时不是平滑的）。</li>
<li>如果关心运行延迟，则 leaky ReLU 更好。 如果不想多调整另一个超参数，你以使用前面提到的默认的<code>α</code>值（leaky ReLU 为 0.3）</li>
<li>如果神经网络过拟合，则使用RReLU</li>
<li>如果有庞大的训练数据集，则为 PReLU</li>
<li>如果有充足的时间和计算能力，可以使用交叉验证来评估其他激活函数</li>
</ul>
<p>但是，因为ReLU是目前应用最广的激活函数，许多库和硬件加速器都使用了针对ReLU的优化，如果速度是首要的，ReLU可能仍然是首选。</p>
</blockquote>
<h3 id="批归一化（Batch-Normalization）"><a href="#批归一化（Batch-Normalization）" class="headerlink" title="批归一化（Batch Normalization）"></a>批归一化（Batch Normalization）</h3><p>使用 He初始化和 ELU（或任何 ReLU 变体）可以显著减少训练开始阶段的梯度消失/爆炸问题，但不能保证在训练期间问题不会再次出现。</p>
<p>2015年，Sergey Ioffe 和 Christian Szegedy 提出了一种称为<strong>批归一化（Batch Normalization，BN）</strong>的方法来解决梯度消失/爆炸问题。</p>
<p><strong>BN</strong></p>
<blockquote>
<p>在每层的激活函数之前或之后在模型中添加操作。操作就是将输入平均值变为0，方差变为1，然后用两个新参数，一个做缩放，一个做偏移。这个操作可以让模型学习到每层输入值的最佳缩放值和平均值。</p>
<p>一般如果模型第一层使用了BN层，则不用标准化训练集（比如使用<code>StandardScaler</code>）；BN层做了标准化工作（虽然是近似的，每次每次只处理一个批次，但能做缩放和平移）。</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-1248ce61162010fe.png?imageMogr2/auto-orient/strip|imageView2/2/w/761/format/webp" alt="img"></p>
<p>其中，</p>
<ul>
<li>μB是整个小批量B的均值矢量</li>
<li>σB是输入标准差矢量，也是根据整个小批量估算的。</li>
<li>mB是小批量中的实例数量。</li>
<li><img src="https://math.jianshu.com/math?formula=%5Cwidehat%7BX%7D" alt="\widehat{X}">(i)是以为零中心和标准化的实例i的输入矢量。</li>
<li>γ是层的缩放参数的矢量（每个输入一个缩放参数）。</li>
<li>⊗表示元素级别的相乘（每个输入乘以对应的缩放参数）</li>
<li>β是层的偏移参数（偏移量）矢量（每个输入一个偏移参数）</li>
<li>ϵ是一个很小的数字，以避免被零除（通常为<code>10^-5</code>）。 这被称为平滑项（拉布拉斯平滑，Laplace Smoothing）。</li>
<li>z(i) 是BN操作的输出：它是输入的缩放和移位版本。</li>
</ul>
<p>在训练时，BN将输入标准化，然后做了缩放和平移。测试时又如何呢？</p>
<blockquote>
<p>一种解决方法是等到训练结束，用模型再运行一次训练集，算出每个BN层的平均值和标准差。然后用这些数据做预测，而不是批输入的平均值和标准差。</p>
<p>大部分批归一化实现是通过<strong>层输入的平均值和标准差的移动平均值</strong>来计算的。这也是Keras在<code>BatchNormalization</code>中使用的方法。每个批归一化的层都通过指数移动平均学习了四个参数：<code>γ</code>（输出缩放矢量），<code>β</code>（输出偏移矢量），<code>μ</code>（最终输入平均值矢量）和<code>σ</code>（最终输入标准差矢量）。<code>μ</code>和<code>σ</code>都是在训练过程中计算的，但只在训练后使用。</p>
</blockquote>
<p><strong>BN的优点：</strong></p>
<blockquote>
<ul>
<li>改善了试验的所有深度神经网络，极大提高了ImageNet分类的效果。</li>
<li>梯度消失问题大大减少了，可以使用饱和激活函数，如 tanh 甚至逻辑激活函数。</li>
<li>网络对权重初始化也不那么敏感</li>
<li>能够使用更大的学习率，显著加快了学习过程。</li>
<li>批量标准化也像一个正则化项一样，减少了对其他正则化技术的需求</li>
</ul>
</blockquote>
<p><strong>BN的缺点：</strong></p>
<blockquote>
<ul>
<li>增加模型的复杂性</li>
<li>运行时间的损失</li>
</ul>
<p>前一层计算的是<code>XW + b</code>，BN层计算的是<code>γ⊗(XW + b – μ)/σ + β</code>（忽略了分母中的平滑项<code>ε</code>）。如果定义<code>W′ = γ⊗W/σ</code>和<code>b′ = γ⊗(b – μ)/σ + β</code>，公式就能简化为<code>XW′ + b′</code>。因此如果替换前一层的权重和偏置项（<code>W</code>和<code>b</code>）为<code>W&#39;</code>和<code>b&#39;</code></p>
</blockquote>
<h4 id="使用-Keras-实现批归一化"><a href="#使用-Keras-实现批归一化" class="headerlink" title="使用 Keras 实现批归一化"></a>使用 Keras 实现批归一化</h4><p><code>BatchNormalization</code>类，每个BN层添加了四个参数：γ、 β、 μ 和 σ。后两个参数μ 和 σ是移动平均，不受反向传播影响，Keras称其“不可训练”， 模型中有不可训练的参数量。</p>
<p>超参数：</p>
<blockquote>
<p>超参数<code>momentum</code>是<code>BatchNormalization</code>在更新指数移动平均时使用的。给定一个新值<code>v</code>（一个当前批次的输入平均或标准差新矢量），BN层使用下面的等式更新平均v</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-888f214e6c98e88c.png?imageMogr2/auto-orient/strip|imageView2/2/w/1038/format/webp" alt="img"></p>
<p>超参数是<code>axis</code>：它确定了在哪个轴上归一。默认是-1，即归一化最后一个轴（使用其它轴的平均值和标准差）。</p>
</blockquote>
<h3 id="梯度裁剪"><a href="#梯度裁剪" class="headerlink" title="梯度裁剪"></a>梯度裁剪</h3><p>减少梯度爆炸问题的一种常用技术是在反向传播过程中剪切梯度，使它们不超过某个阈值，这种方法称为梯度裁剪。梯度裁剪在循环神经网络（CNN）中用的很多，因为循环神经网络中用BN很麻烦.</p>
<p>范数裁剪</p>
<h3 id="复用预训练层"><a href="#复用预训练层" class="headerlink" title="复用预训练层"></a>复用预训练层</h3><p>通常不会从零开始训练一个非常大的 DNN ，尝试找到一个现有的神经网络来完成与正在尝试解决的任务类似的任务，然后复用这个网络的较低层：这就是所谓的<strong>迁移学习</strong>。这样不仅能大大加快训练速度，还将需要更少的训练数据。</p>
<blockquote>
<p>一般地说，如果输入具有类似的低级层次的特征，则迁移学习将很好地工作。</p>
</blockquote>
<p>先将所有复用的层冻结（即，使其权重不可训练，梯度下降不能修改权重），然后训练模型，看其表现如何。然后将复用的最上一或两层解冻，让反向传播可以调节它们，再查看性能有无提升。训练数据越多，可以解冻的层越多。解冻时减小学习率也有帮助，可以避免破坏微调而得的权重。</p>
<p><strong>迁移学习在深度卷积网络中表现最好，CNN学到的特征更通用（特别是浅层） </strong></p>
<h4 id="无监督预训练"><a href="#无监督预训练" class="headerlink" title="无监督预训练"></a>无监督预训练</h4><p>使用监督模型，比如自编码器或生成式对抗网络。然后可以复用自编码器或GAN的浅层，加上输出层，使用监督学习微调网络（使用标签数据）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-69fe44e53b9ea29b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="在辅助任务上预训练"><a href="#在辅助任务上预训练" class="headerlink" title="在辅助任务上预训练"></a>在辅助任务上预训练</h4><h3 id="更快的优化器"><a href="#更快的优化器" class="headerlink" title="更快的优化器"></a>更快的优化器</h3><p>四种加速训练的方法（并且达到更好性能的方法）：、</p>
<ol>
<li>对连接权重应用良好的初始化策略，</li>
<li>使用良好的激活函数，</li>
<li>使用批归一化</li>
<li>重用预训练网络的部分（使用辅助任务或无监督学习）。 </li>
<li>使用更快的优化器，而不是常规的梯度下降优化器。</li>
</ol>
<h4 id="动量优化"><a href="#动量优化" class="headerlink" title="动量优化"></a>动量优化</h4><p>梯度下降通过直接减去损失函数<code>J(θ)</code>相对于权重<code>θ</code>的梯度（<code>∇θJ(θ)</code>），乘以学习率<code>η</code>来更新权重<code>θ</code>。 $θ ← θ – η∇_θJ(θ)$。不关心早期的梯度是什么。,如果局部梯度很小，则会非常缓慢。</p>
<p>动量优化关心以前的梯度：在每次迭代时，它将动量矢量<code>m</code>（乘以学习率<code>η</code>）与局部梯度相加，并且通过简单地减去该动量矢量来更新权重.</p>
<p>$m← \beta m+\eta\nabla _\theta J(\theta)$</p>
<p>$\theta \leftarrow\ \theta -m$</p>
<p>为了模拟某种摩擦机制，避免动量过大，该算法引入了一个新的超参数<code>β</code>，简称为动量，它必须设置在 0（高摩擦）和 1（无摩擦）之间。 典型的动量值是 0.9。</p>
<blockquote>
<p>由于动量的原因，优化器可能会超调一些，然后再回来，再次超调，并在稳定在最小值之前多次振荡。 这就是为什么在系统中有一点摩擦的原因之一：它消除了这些振荡，从而加速了收敛。</p>
</blockquote>
<h4 id="Nesterov-加速梯度"><a href="#Nesterov-加速梯度" class="headerlink" title="Nesterov 加速梯度"></a>Nesterov 加速梯度</h4><p>Yurii Nesterov 在 1983 年提出的动量优化的一个小变体几乎总是比普通的动量优化更快。</p>
<p><strong>Nesterov 动量优化或 Nesterov 加速梯度（Nesterov Accelerated Gradient，NAG）*</strong>的思想是测量损失函数的梯度不是在局部位置，而是在动量方向稍微靠前。 与普通的动量优化的唯一区别在于梯度是在<code>θ+βm</code>而不是在<code>θ</code>处测量的。</p>
<p>$m← \beta m+\eta\nabla _\theta J(\theta+\beta m)$</p>
<p>$\theta \leftarrow\ \theta -m$</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-f75650e5b631e9bb.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong>NAG 最终比常规的动量优化快得多。  </strong></p>
<h4 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h4><p>AdaGrad 算法通过沿着最陡的维度缩小梯度向量解决细长碗的问题。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-38590903b6626149.png?imageMogr2/auto-orient/strip|imageView2/2/w/932/format/webp" alt="img"></p>
<p>第一步将梯度的平方累加到矢量<code>s</code>中（⊗符号表示元素级别相乘）。 这个向量化形式相当于向量<code>s</code>的每个元素$s_i$计算$si ← s_i + (∂ / ∂ θ_i J(θ))^2$。换一种说法，每个 $s_i$ 累加损失函数对参数$θ_i$的偏导数的平方。 如果损失函数沿着第<code>i</code>维陡峭，则在每次迭代时， si 将变得越来越大。</p>
<p>第二步几乎与梯度下降相同，但有一个很大的不同：梯度矢量按比例(s+ε)^0.5缩小 （⊘符号表示元素分割，<code>ε</code>是避免被零除的平滑项，通常设置为$10^-10$。 这个矢量化的形式相当于所有θi同时计算</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b852a34b26165cad.png?imageMogr2/auto-orient/strip|imageView2/2/w/282/format/webp" alt="img"></p>
<p><strong>优点</strong></p>
<blockquote>
<p>这种算法会降低学习速度，但对于陡峭的维度，其速度要快于具有温和的斜率的维度。 这被称为<strong>自适应学习率</strong>。 有助于将更新的结果更直接地指向全局最优。 并且不需要那么多的去调整学习率超参数<code>η</code>。</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-d2b7668bc13b3ead.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong>缺点：</strong></p>
<blockquote>
<p>对于简单的二次问题，AdaGrad 经常表现良好，但不幸的是，在训练神经网络时，它经常停止得太早。 学习率被缩减得太多，以至于在达到全局最优之前，算法完全停止。</p>
</blockquote>
<h4 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h4><p>AdaGrad 的风险是降速太快，可能无法收敛到全局最优。RMSProp 算法通过仅累积最近迭代（而不是从训练开始以来的所有梯度）的梯度来修正这个问题。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-a24cf7849a7f0c1c.png?imageMogr2/auto-orient/strip|imageView2/2/w/1006/format/webp" alt="img"></p>
<p>衰变率<code>β</code>通常设定为 0.9。 是这个默认值通常运行良好，可能根本不需要调整它。</p>
<p><strong>通常比 AdaGrad ，动量优化和 Nesterov 加速梯度表现更好。 </strong></p>
<h4 id="Adam-和-Nadam-优化"><a href="#Adam-和-Nadam-优化" class="headerlink" title="Adam 和 Nadam 优化"></a>Adam 和 Nadam 优化</h4><p>Adam，代表自适应矩估计，结合了动量优化和 RMSProp 的思想：就像动量优化一样，它追踪过去梯度的指数衰减平均值，就像 RMSProp 一样，它跟踪过去平方梯度的指数衰减平均值。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-827f2d812a6f5640.png?imageMogr2/auto-orient/strip|imageView2/2/w/1136/format/webp" alt="img"></p>
<p>只看步骤 1, 2 和 5，Adam 与动量优化和 RMSProp 的相似性。 唯一的区别是第 1 步计算指数衰减的平均值，而不是指数衰减的和，但除了一个常数因子（衰减平均值只是衰减和的<code>1 - β1</code>倍）之外，它们实际上是等效的。 步骤 3 和步骤 4 是一个技术细节：由于<code>m</code>和<code>s</code>初始化为 0，所以在训练开始时它们会偏向0，所以这两步将在训练开始时帮助提高<code>m</code>和<code>s</code>。</p>
<p><strong>由于 Adam 是一种自适应学习率算法（如 AdaGrad 和 RMSProp），所以对学习率超参数<code>η</code>的调整较少。 可以使用默认值<code>η= 0.001</code>，使 Adam 相对于梯度下降更容易使用。 </strong></p>
<h5 id="Adam还有两种变体"><a href="#Adam还有两种变体" class="headerlink" title="Adam还有两种变体"></a>Adam还有两种变体</h5><p>AdaMax：</p>
<p>Nadam：Nadam优化是Adam优化加上了Nesterov技巧，所以通常比Adam收敛的快一点。</p>
<blockquote>
<p>目前所有讨论的优化方法都是基于一阶偏导（雅可比矩阵）的。</p>
<p>基于二阶导数（海森矩阵，海森矩阵是雅可比矩阵的骗到）的算法很难应用于深度神经网络，因为每个输出有$n^2$个海森矩阵（n是参数个数），每个输出只有n个雅可比矩阵。因为DNN通常有数万个参数，二阶优化器通常超出了内存，就算内存能装下，计算海森矩阵也非常慢。</p>
<p>训练稀疏模型</p>
<p>以上优化算法都会产生紧密模型，大多数参数都是非零的。 如果运行需要一个非常快的模型，或者需要它占用较少的内存，可能需要用一个稀疏模型来代替。</p>
<p>实现这一点的一个方法是像平常一样训练模型，然后丢掉微小的权重（将它们设置为 0）。但这通常不会生成一个稀疏的模型，而且可能使模型性能下降。更好的选择是在训练过程中应用强 ℓ1 正则化，因为它会推动优化器尽可能多地消除权重</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-5060d73f5a52760d.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="学习率调整"><a href="#学习率调整" class="headerlink" title="学习率调整"></a>学习率调整</h3><p><img src="https://upload-images.jianshu.io/upload_images/7178691-7ac8433cdc7346f1.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="幂调度"><a href="#幂调度" class="headerlink" title="幂调度:"></a>幂调度:</h4><p>设学习率为迭代次数 t 的函数： $η(t) = η_0 /(1 + t/s)^c$。初始学习率$η_0$， 幂<code>c</code>（通常被设置为 1），步数<code>s</code>是超参数。学习率在每步都会下降，s步后，下降到$η_0 / 2$。再经过s步，下降到$η_0 / 3$，然后是η0 / 4、η0 / 5，以此类推。可以看到，策略是一开始很快，然后越来越慢。幂调度需要调节η0和s（也可能有c）。</p>
<h4 id="指数调度"><a href="#指数调度" class="headerlink" title="指数调度:"></a>指数调度:</h4><p>将学习率设置为迭代次数<code>t</code>的函数：$η(t) = η_0 0.1^{t/s}$。 学习率每步都会下降10倍。幂调度的下降是越来越慢，指数调度保持10倍不变。</p>
<h4 id="预定的分段恒定学习率："><a href="#预定的分段恒定学习率：" class="headerlink" title="预定的分段恒定学习率："></a>预定的分段恒定学习率：</h4><p>先在几个周期内使用固定的学习率（比如5个周期内学习率设置为 η0 = 0.1），然后在另一个周期内设更小的学习率（比如50个周期η1 = 0.001），以此类推。虽然这个解决方案可以很好地工作，但是通常需要弄清楚正确的学习速度顺序以及使用时长。</p>
<h4 id="性能调度："><a href="#性能调度：" class="headerlink" title="性能调度："></a>性能调度：</h4><p>每 N 步测量验证误差（就像提前停止一样），当误差下降时，将学习率降低<code>λ</code>倍。</p>
<h4 id="1循环调度："><a href="#1循环调度：" class="headerlink" title="1循环调度："></a>1循环调度：</h4><p>与其它方法相反，1循环调度（Leslie Smith在2018年提出）一开始在前半个周期将学习率η0 线性增加到η1，然后在后半个周期内再线性下降到η0，最后几个周期学习率下降几个数量级（仍然是线性的）。</p>
<p>用前面的方法找到最优学习率的方法确定η1，η0是η1的十分之一。当使用动量时，先用一个高动量（比如0.95），然后在训练上半段下降（比如线性下降到0.85），然后在训练后半部分上升到最高值（0.95），最后几个周期也用最高值完成。</p>
<h3 id="通过正则化避免过拟合"><a href="#通过正则化避免过拟合" class="headerlink" title="通过正则化避免过拟合"></a>通过正则化避免过拟合</h3><p>最好的正则方法之一：早停。另外，虽然批归一化是用来解决梯度不稳定的，但也可以作为正则器。这一节会介绍其它一些最流行的神经网络正则化技术：ℓ1 和 ℓ2正则、dropout和最大范数正则。</p>
<h4 id="ℓ1-和-ℓ2正则"><a href="#ℓ1-和-ℓ2正则" class="headerlink" title="ℓ1 和 ℓ2正则"></a>ℓ1 和 ℓ2正则</h4><p>使用 ℓ2正则约束一个神经网络的连接权重，或ℓ1正则得到稀疏模型（许多权重为0）。</p>
<h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>由 Geoffrey Hinton 于 2012 年提出，并在 Nitish Srivastava 等人的2014年论文中进一步详细描述，并且已被证明是非常成功的：即使是最先进的神经网络，仅仅通过增加dropout就可以提高1-2％的准确度。</p>
<p>在每个训练步骤中，每个神经元（包括输入神经元，但不包括输出神经元）都有一个暂时“丢弃”的概率<code>p</code>，这意味着在这个训练步骤中它将被完全忽略， 在下一步可能会激活。 超参数<code>p</code>称为丢失率，通常设为 10%到50%之间；循环神经网络之间接近20-30%，在卷积网络中接近40-50%。 训练后，神经元不会再丢失。</p>
<p><strong>如何理解dropout</strong></p>
<p>dropout使得神经元不能与其相邻的神经元在训练时共适应，必须尽可能让自己变得有用，也不能过分依赖一些输入神经元，必须注意每个输入神经元。最终对输入的微小变化会不太敏感。最后，会得到一个更稳定、泛化能力更强的网络。</p>
<p>每个训练步骤都会产生一个独特的神经网络。 由于每个神经元可以存在或不存在，总共有$2^N$个可能的网络（其中 N 是可丢弃神经元的总数）。 这是一个巨大的数字，实际上不可能对同一个神经网络进行两次采样。 一旦运行了 10,000 个训练步骤，基本上已经训练了 10,000 个不同的神经网络（每个神经网络只有一个训练实例）。 这些神经网络显然不是独立的，因为它们共享许多权重，但是它们都是不同的。 由此产生的神经网络可以看作是所有这些较小的神经网络的平均集成。</p>
<p><strong>dropout 似乎减缓了收敛速度，但通常会在调参得当时使模型更好</strong></p>
<h5 id="蒙特卡洛（MC）dropout"><a href="#蒙特卡洛（MC）dropout" class="headerlink" title="蒙特卡洛（MC）dropout"></a>蒙特卡洛（MC）dropout</h5><p>蒙特卡洛样本的数量是一个可以调节的超参数。这个数越高，预测和不准确度的估计越高。但是，如果样本数翻倍，推断时间也要翻倍。另外，样本数超过一定数量，提升就不大了。</p>
<h4 id="最大范数正则化"><a href="#最大范数正则化" class="headerlink" title="最大范数正则化"></a>最大范数正则化</h4><p>对于每个神经元，它约束输入连接的权重<code>w</code>，使得 $∥ w ∥_2 ≤ r$，其中<code>r</code>是最大范数超参数，$∥ · ∥_2$ 是 l2 范数</p>
<p><strong>Keras中默认DNN配置</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-19249b3d162bbcb8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1170/format/webp" alt="img"></p>
<p><strong>如果网络只有紧密层，则可以是自归一化的，可以使用如下配置。</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b822155fbb4dd3c4.png?imageMogr2/auto-orient/strip|imageView2/2/w/1166/format/webp" alt="img"></p>
<h3 id="练习-1"><a href="#练习-1" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>使用 He 初始化随机选择权重，是否可以将所有权重初始化为相同的值？</p>
<blockquote>
<p>不可以，所有的权重需要独立随机的生成。</p>
<p>如果将神经元的权重初始化为相同的值，则不能打破结构的对称性，该情况下，每层的神经元都是等价的，反向传播也是相同的，意味着，在训练过程中，每层神经元权重一直保持相同，效果相当于每层只有一个神经元，而且更慢。很明显这样的神经网络不能收敛到一个很好的结果。</p>
</blockquote>
</li>
<li><p>可以将偏置初始化为 0 吗？</p>
<blockquote>
<p>可以，偏置向的影响并不大。</p>
</blockquote>
</li>
<li><p>说出SELU 激活功能与 ReLU 相比的三个优点。</p>
<blockquote>
<ol>
<li>微分一直不为零，防止出现ReLU 死区（一些神经元死掉，只能输出0，原因是：在训练期间，神经元的权重更新后使得神经元输入的加权和为负，ReLU函数的梯度为0，神经元就只能输出0。）</li>
<li>只要神经网络中都是紧密层，并且所有隐藏层都是用的SELU激活函数，则这个网络是自归一的（不能使用正则化方法）</li>
<li>小于零时不是常数0，而是变化的负值，训练过程中，每层输出的平均值是0，标准差是1，这样就解决了梯度消失爆炸问题。</li>
</ol>
</blockquote>
</li>
<li><p>在哪些情况下，您想要使用以下每个激活函数：SELU，leaky ReLU（及其变体），ReLU，tanh，logistic 以及 softmax？</p>
<blockquote>
<p>通常情况下SELU表现很好。但如果神经网络不能自归一，ELU效果可能会更好</p>
<p>如果需要很快的神经网络，可以使用leaky ReLU</p>
<p>ReLU因为形式简单，仍是目前应用最广的激活函数</p>
<p>​</p>
<p>如果需要输出值在-1~1之间，可以在输出层使用tanh激活函数</p>
<p>如果二分类想要输出概率，可以在输出层使用逻辑斯蒂激活函数</p>
<p>多分类问题输出概率，可以在输出层使用sftmax激活函数。</p>
<p>但tanh，logit和softmax激活函数，一般不用于隐藏层。</p>
</blockquote>
</li>
<li><p>如果将<code>momentum</code>超参数设置得太接近 1（例如，0.99999），会发生什么情况？</p>
<blockquote>
<p>如果SGD optimizer 中，momentum设置为0.99999，则算法会很快，但由于动量的原因，优化器可能会超调一些，然后再回来，再次超调，并在稳定在最小值之前多次振荡。总体来讲，大的动量参数收敛时使用得时间比小的动量参数要长。</p>
</blockquote>
</li>
<li><p>请列举您可以生成稀疏模型的三种方法。</p>
<blockquote>
<ol>
<li>像平常一样训练模型，然后丢掉微小的权重（将它们设置为 0）。</li>
<li>在训练过程中应用强 ℓ1 正则化，它会推动优化器尽可能多地消除权重</li>
<li>使用ensorFlow Model Optimization Toolkit</li>
</ol>
</blockquote>
</li>
<li><p>dropout 是否会减慢训练？ 它是否会减慢推断（即预测新的实例）？MC dropout呢？</p>
<blockquote>
<p>dropout会减慢训练，一般会变慢一倍，但一般不会减慢推断速度（因为dropout只在训练模型时开启）。</p>
<p>MC dropout在推断过程中也会开启，所以会使得预测新实例时，速度稍微变慢。但是MC dropout的问题主要在于：需要跑十次（若干次）预测，会减慢速度。</p>
<p>在CIFAR10图片数据集上训练一个深度神经网络：</p>
</blockquote>
<ol>
<li>建立一个 DNN，有20个隐藏层，每层 100 个神经元，使用 He 初始化和 ELU 激活函数。</li>
<li>使用 Nadam 优化和早停，尝试在 CIFAR10 上进行训练，可以使用<code>keras.datasets.cifar10.load_data()</code>加载数据。数据集包括60000张32x32的图片（50000张训练，10000张测试）有10个类，所以需要10个神经元的softmax输出层。记得每次调整架构或超参数之后，寻找合适的学习率。</li>
<li>现在尝试添加批归一化并比较学习曲线：它是否比以前收敛得更快？ 它是否会产生更好的模型？对训练速度有何影响？</li>
<li>尝试用SELU替换批归一化，做一些调整，确保网络是自归一化的（即，标准化输入特征，使用LeCun正态初始化，确保DNN只含有紧密层）。</li>
<li>使用alpha dropout正则化模型。然后，不训练模型，使用MC Dropout能否提高准确率。</li>
<li>用1循环调度重新训练模型，是否能提高训练速度和准确率。</li>
</ol>
</li>
</ol>
<h2 id="第12章-使用TensorFlow自定义模型并训练"><a href="#第12章-使用TensorFlow自定义模型并训练" class="headerlink" title="第12章 使用TensorFlow自定义模型并训练"></a>第12章 使用TensorFlow自定义模型并训练</h2><p>TensorFlow的高级API —— tf.keras，功能强大，可以搭建各种神经网络架构（回归、分类网络、Wide &amp; Deep 网络、自归一化网络），使用了各种方法，（批归一化、dropout和学习率调度）。但当需要实现<strong>自定义损失函数、自定义标准、层、模型、初始化器、正则器、权重约束时</strong>，就需要学习TensorFlow的低级Python API。</p>
<h3 id="TensorFlow速览"><a href="#TensorFlow速览" class="headerlink" title="TensorFlow速览"></a>TensorFlow速览</h3><p>TensorFlow由谷歌大脑团队开发，是一个强大的数值计算库，特别适合做和微调大规模机器学习（也可以做其它的重型计算）。具有如下功能：</p>
<ul>
<li>TensorFlow的核心与NumPy很像，但TensorFlow支持GPU；</li>
<li>TensorFlow支持（多设备和服务器）分布式计算；</li>
<li>TensorFlow使用了即时JIT编译器对计算速度和内存使用优化。编译器的工作是从Python函数提取出计算图，然后对计算图优化（比如剪切无用的节点），最后高效运行（比如自动并行运行独立任务）；</li>
<li>计算图可以导出为迁移形式，因此可以在一个环境中训练一个TensorFlow模型（比如使用Python或Linux），然后在另一个环境中运行（比如在安卓设备上用Java运行）；</li>
<li>TensorFlow实现了<strong>自动微分</strong> ，并提供了一些高效的优化器，比如RMSProp和NAdam，因此可以很容易最小化各种损失函数。</li>
</ul>
<p>TensorFlow还提供了许多其他功能：tf.keras，数据加载（（tf.data），预处理操作（tf.io），图片处理操作（tf.image），信号处理操作（tf.signal）等。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4d1453d7d971cba7.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>TensorFlow的低级操作都是用高效的C++实现的。许多操作有多个实现，称为<code>核</code>：每个核对应一个具体的设备型号，比如CPU、GPU，甚至TPU（张量处理单元）。GPU通过将任务分成小块，在多个GPU线程中并行运行，可以极大提高提高计算的速度。TPU更快：TPU是自定义的ASIC芯片，专门用来做深度学习运算。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-c77b37df3aea8d69.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>TensorBoard可以用来可视化。TensorFlow Extended（TFX），是谷歌推出的用来生产化的库，包括：数据确认、预处理、模型分析和服务。TensorFlow Hub上可以方便下载和复用预训练好的神经网络。还可以从<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Fmodels%2F" target="_blank" rel="noopener">TensorFlow model garden</a>上获取许多神经网络架构，其中一些是预训练好的。<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.tensorflow.org%2Fresources" target="_blank" rel="noopener">TensorFlow Resources</a> </p>
<h3 id="像NumPy一样使用TensorFlow"><a href="#像NumPy一样使用TensorFlow" class="headerlink" title="像NumPy一样使用TensorFlow"></a>像NumPy一样使用TensorFlow</h3><p>TensorFlow的API是围绕张量（tensor）展开的，从一个操作流动（flow）到另一个操作，所以名字叫做TensorFlow。</p>
<p>张量通常是一个多维数组（就像NumPy的<code>ndarray</code>），但也可以是标量（即简单值，比如42）。</p>
<h4 id="张量和运算"><a href="#张量和运算" class="headerlink" title="张量和运算"></a>张量和运算</h4><p>使用<code>tf.constant()</code>创建张量。就像<code>ndarray</code>一样，<code>tf.Tensor</code>也有形状和数据类型（<code>dtype</code>），索引和NumPy中很像，所有张量运算都可以执行。</p>
<p>可以在tf中找到所有基本的数学运算（<code>tf.add()</code>、<code>tf.multiply()</code>、<code>tf.square()</code>、<code>tf.exp()</code>、<code>tf.sqrt()</code>），以及NumPy中的大部分运算（比如<code>tf.reshape()</code>、<code>tf.squeeze()</code>、<code>tf.tile()</code>）。一些tf中的函数与NumPy中不同，例如，<code>tf.reduce_mean()</code>、<code>tf.reduce_sum()</code>、<code>tf.reduce_max()</code>、<code>tf.math.log()</code>等同于<code>np.mean()</code>、<code>np.sum()</code>、<code>np.max()</code>和<code>np.log()</code>。</p>
<blockquote>
<p>TensorFlow中必须使用<code>tf.transpose(t)</code>，不能像NumPy中那样使用<code>t.T</code>。是因为函数<code>tf.transpose(t)</code>所做的和NumPy的属性<code>T</code>并不完全相同：在TensorFlow中，是使用转置数据的复制来生成张量的，而在NumPy中，<code>t.T</code>是数据的转置视图。</p>
<p><code>tf.reduce_sum()</code>操作之所以这么命名，是因为它的GPU核（即GPU实现）所采用的reduce算法不能保证元素相加的顺序，因为32位的浮点数精度有限，每次调用的结果可能会有细微的不同。<code>tf.reduce_mean()</code>也是这样（<code>tf.reduce_max()</code>结果是确定的）。</p>
</blockquote>
<p>Keras API 有自己的低级API，位于<code>keras.backend</code>，包括：函数<code>square()</code>、<code>exp()</code>、<code>sqrt()</code>。</p>
<h4 id="张量和NumPy"><a href="#张量和NumPy" class="headerlink" title="张量和NumPy"></a>张量和NumPy</h4><p>张量和NumPy融合地非常好：使用NumPy数组可以创建张量，张量也可以创建NumPy数组。可以在NumPy数组上运行TensorFlow运算，也可以在张量上运行NumPy运算：</p>
<p><strong>NumPy默认使用64位精度，TensorFlow默认用32位精度。这是因为32位精度通常对于神经网络就足够了，另外运行地更快，使用的内存更少。因此当用NumPy数组创建张量时，一定要设置<code>dtype=tf.float32</code>。。 </strong></p>
<h4 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h4><p>类型转换对性能的影响非常大，TensorFlow不会自动做任何类型转换：只是如果用不兼容的类型执行了张量运算，TensorFlow就会报异常。<strong>例如，不能用浮点型张量与整数型张量相加，也不能将32位张量与64位张量相加。</strong></p>
<h4 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h4><p><code>tf.Tensor</code>值不能修改，意味着不能使用常规张量实现神经网络的权重，因为权重必须要能被反向传播调整。另外，其它的参数也需要随着时间调整（比如，动量优化器要跟踪过去的梯度）。此时需要的是<code>tf.Variable</code>：</p>
<h4 id="其它数据结构"><a href="#其它数据结构" class="headerlink" title="其它数据结构"></a>其它数据结构</h4><p>稀疏张量（<code>tf.SparseTensor</code>）<br>高效表示含有许多0的张量。<code>tf.sparse</code>包含有对稀疏张量的运算。</p>
<p>张量数组（<code>tf.TensorArray</code>）<br>是张量的列表。有默认固定大小，但也可以做成动态的。列表中的张量必须形状相同，数据类型也相同。</p>
<p>嵌套张量（<code>tf.RaggedTensor</code>）<br>张量列表的静态列表，张量的形状和数据结构相同。<code>tf.ragged</code>包里有嵌套张量的运算。</p>
<p>字符串张量<br>类型是<code>tf.string</code>的常规张量，是字节串而不是Unicode字符串，因此如果你用Unicode字符串（比如，Python3字符串café）创建了一个字符串张量，就会自动被转换为UTF-8（b”caf\xc3\xa9”）。另外，也可以用<code>tf.int32</code>类型的张量表示Unicode字符串，其中每项表示一个Unicode码（比如，<code>[99, 97, 102, 233]</code>）。<code>tf.strings</code>包里有字节串和Unicode字符串的运算，以及二者转换的运算。要注意<code>tf.string</code>是原子性的，也就是说它的长度不出现在张量的形状中，一旦将其转换成了Unicode张量（即，含有Unicode码的<code>tf.int32</code>张量），长度才出现在形状中。</p>
<p>集合<br>表示为常规张量（或稀疏张量）。例如<code>tf.constant([[1, 2], [3, 4]])</code>表示两个集合{1, 2}和{3, 4}。通常，用张量的最后一个轴的矢量表示集合。集合运算可以用<code>tf.sets</code>包。</p>
<p>队列<br>用来在多个步骤之间保存张量。TensorFlow提供了多种队列。先进先出（FIFO）队列FIFOQueue，优先级队列PriorityQueue，随机队列RandomShuffleQueue，通过填充的不同形状的批次项队列PaddingFIFOQueue。这些队列都在<code>tf.queue</code>包中。</p>
<h3 id="自定义模型和训练算法"><a href="#自定义模型和训练算法" class="headerlink" title="自定义模型和训练算法"></a>自定义模型和训练算法</h3><h4 id="自定义损失函数"><a href="#自定义损失函数" class="headerlink" title="自定义损失函数"></a>自定义损失函数</h4><p>均方差可能对大误差惩罚过重，导致模型不准确。</p>
<p>均绝对值误差不会对异常值惩罚过重，但训练可能要比较长的时间才能收敛，训练模型也可能不准确。</p>
<p>Huber损失：小于阈值是二次的，大于阈值是线性的。</p>
<p>目前官方Keras API中没有Huber损失，但tf.keras有（使用类<code>keras.losses.Huber</code>的实例），也可以def函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">huber_fn</span><span class="params">(y_true, y_pred)</span>:</span></span><br><span class="line">    error = y_true - y_pred</span><br><span class="line">    is_small_error = tf.abs(error) &lt; <span class="number">1</span></span><br><span class="line">    squared_loss = tf.square(error) / <span class="number">2</span></span><br><span class="line">    linear_loss  = tf.abs(error) - <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">return</span> tf.where(is_small_error, squared_loss, linear_loss)</span><br></pre></td></tr></table></figure>
<h4 id="保存并加载包含自定义组件的模型"><a href="#保存并加载包含自定义组件的模型" class="headerlink" title="保存并加载包含自定义组件的模型"></a>保存并加载包含自定义组件的模型</h4><p>Keras可以保存函数名，所以可以保存含有自定义损失函数的模型。当加载模型时，需要提供一个字典，这个字典可以将函数名和真正的函数映射起来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = keras.models.load_model(<span class="string">"my_model_with_a_custom_loss.h5"</span>,</span><br><span class="line">                                custom_objects=&#123;<span class="string">"huber_fn"</span>: huber_fn&#125;)</span><br></pre></td></tr></table></figure>
<p>创建可以产生一个可配置的损失函数的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_huber</span><span class="params">(threshold=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">huber_fn</span><span class="params">(y_true, y_pred)</span>:</span></span><br><span class="line">        error = y_true - y_pred</span><br><span class="line">        is_small_error = tf.abs(error) &lt; threshold</span><br><span class="line">        squared_loss = tf.square(error) / <span class="number">2</span></span><br><span class="line">        linear_loss  = threshold * tf.abs(error) - threshold**<span class="number">2</span> / <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> tf.where(is_small_error, squared_loss, linear_loss)</span><br><span class="line">    <span class="keyword">return</span> huber_fn</span><br><span class="line">model.compile(loss=create_huber(<span class="number">2.0</span>), optimizer=<span class="string">"nadam"</span>)</span><br></pre></td></tr></table></figure>
<p>但在保存模型时，<code>threshold</code>不能被保存。在加载模型时（注意，给Keras的函数名是“Huber_fn”，不是创造这个函数的函数名），必须要指定<code>threshold</code>的值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = keras.models.load_model(<span class="string">"my_model_with_a_custom_loss_threshold_2.h5"</span>,</span><br><span class="line">                                custom_objects=&#123;<span class="string">"huber_fn"</span>: create_huber(<span class="number">2.0</span>)&#125;)</span><br></pre></td></tr></table></figure>
<p>要解决这个问题，可以创建一个<code>keras.losses.Loss</code>类的子类，然后实现<code>get_config()</code>方法</p>
<blockquote>
<p>Keras API目前只使用子类来定义层、模型、调回和正则器。如果使用子类创建其它组件（比如损失、指标、初始化器或约束），它们不能迁移到其它Keras实现上。</p>
</blockquote>
<h4 id="自定义激活函数、初始化器、正则器和约束"><a href="#自定义激活函数、初始化器、正则器和约束" class="headerlink" title="自定义激活函数、初始化器、正则器和约束"></a>自定义激活函数、初始化器、正则器和约束</h4><p>如果函数有需要连同模型一起保存的超参数，需要对相应的类做子</p>
<h4 id="自定义指标"><a href="#自定义指标" class="headerlink" title="自定义指标"></a>自定义指标</h4><p>损失和指标的概念是不一样的：梯度下降使用损失（比如交叉熵损失）来训练模型，因此损失必须是可微分的（至少是在评估点可微分），梯度不能在所有地方都是0。另外，就算损失比较难解释也没有关系。相反的，指标（比如准确率）是用来评估模型的：指标的解释性一定要好，可以是不可微分的，或者可以在任何地方的梯度都是0。</p>
<p>假设模型在第一个批次做了5个正预测，其中4个是正确的，准确率就是80%。再假设模型在第二个批次做了3次正预测，但没有一个预测对，则准确率是0%。如果对这两个准确率做平均，则平均值是40%。但它不是模型在两个批次上的准确率！事实上，真正值总共有4个，正预测有8个，整体的准确率是50%。</p>
<p><strong>一个批次接一个批次，逐次更新的叫做流式指标（或者静态指标）。</strong></p>
<h4 id="自定义层"><a href="#自定义层" class="headerlink" title="自定义层"></a>自定义层</h4><p>比如，如果模型的层顺序是A、B、C、A、B、C、A、B、C，则完全可以创建一个包含A、B、C的自定义层D，模型就可以简化为D、D、D。</p>
<p>创建一个没有任何权重的自定义层，将其包装进<code>keras.layers.Lambda</code>层。比如，下面的层会对输入做指数运算：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">exponential_layer = keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.exp(x))</span><br></pre></td></tr></table></figure>
<p>创建自定义状态层（即，有权重的层），需要创建<code>keras.layers.Layer</code>类的子类。下面的类实现了一个紧密层的简化版本：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDense</span><span class="params">(keras.layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, units, activation=None, **kwargs)</span>:</span></span><br><span class="line">        super().__init__(**kwargs)</span><br><span class="line">        self.units = units</span><br><span class="line">        self.activation = keras.activations.get(activation)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self, batch_input_shape)</span>:</span></span><br><span class="line">        self.kernel = self.add_weight(</span><br><span class="line">            name=<span class="string">"kernel"</span>, shape=[batch_input_shape[<span class="number">-1</span>], self.units],</span><br><span class="line">            initializer=<span class="string">"glorot_normal"</span>)</span><br><span class="line">        self.bias = self.add_weight(</span><br><span class="line">            name=<span class="string">"bias"</span>, shape=[self.units], initializer=<span class="string">"zeros"</span>)</span><br><span class="line">        super().build(batch_input_shape) <span class="comment"># must be at the end</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.activation(X @ self.kernel + self.bias)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span><span class="params">(self, batch_input_shape)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.TensorShape(batch_input_shape.as_list()[:<span class="number">-1</span>] + [self.units])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span></span><br><span class="line">        base_config = super().get_config()</span><br><span class="line">        <span class="keyword">return</span> &#123;**base_config, <span class="string">"units"</span>: self.units,</span><br><span class="line">                <span class="string">"activation"</span>: keras.activations.serialize(self.activation)&#125;</span><br></pre></td></tr></table></figure>
<p>要创建一个有多个输入（比如<code>Concatenate</code>）的层，<code>call()</code>方法的参数应该是包含所有输入的元组。相似的，<code>compute_output_shape()</code>方法的参数应该是一个包含每个输入的批次形状的元组。要创建一个有多输出的层，<code>call()</code>方法要返回输出的列表，<code>compute_output_shape()</code>方法要返回批次输出形状的列表（每个输出一个形状）。例如，下面的层有两个输入和三个输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyMultiLayer</span><span class="params">(keras.layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        X1, X2 = X</span><br><span class="line">        <span class="keyword">return</span> [X1 + X2, X1 * X2, X1 / X2]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span><span class="params">(self, batch_input_shape)</span>:</span></span><br><span class="line">        b1, b2 = batch_input_shape</span><br><span class="line">        <span class="keyword">return</span> [b1, b1, b1] <span class="comment"># 可能需要处理广播规则</span></span><br></pre></td></tr></table></figure>
<p>只能使用Functional和Subclassing API，Sequential API不成（只能使用单输入和单输出的层）。</p>
<p>如果层需要在训练和测试时有不同的行为（比如，如果使用<code>Dropout</code> 或 <code>BatchNormalization</code>层），那么必须给<code>call()</code>方法加上<code>training</code>参数，用这个参数确定该做什么。比如，创建一个在训练中（为了正则）添加高斯噪音的层，但不改动训练：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyGaussianNoise</span><span class="params">(keras.layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, stddev, **kwargs)</span>:</span></span><br><span class="line">        super().__init__(**kwargs)</span><br><span class="line">        self.stddev = stddev</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, X, training=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> training:</span><br><span class="line">            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)</span><br><span class="line">            <span class="keyword">return</span> X + noise</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span><span class="params">(self, batch_input_shape)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> batch_input_shape</span><br></pre></td></tr></table></figure>
<h4 id="自定义模型"><a href="#自定义模型" class="headerlink" title="自定义模型"></a>自定义模型</h4><p> 自定义模型案例：包含残差块层，残块层含有跳连接</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-647e362f4abb081e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong><code>Model</code>类是<code>Layer</code>类的子类</strong></p>
<h4 id="基于模型内部的损失和指标"><a href="#基于模型内部的损失和指标" class="headerlink" title="基于模型内部的损失和指标"></a>基于模型内部的损失和指标</h4><p>前面的自定义损失和指标都是基于标签和预测（或者还有样本权重）。有时，需要基于模型的其它部分定义损失，比如隐藏层的权重或激活函数。达到正则的目的，或监督模型的内部。</p>
<p>要基于模型内部自定义损失，需要先做基于这些组件的计算，然后将结果传递给<code>add_loss()</code>方法。</p>
<h4 id="自定义训练循环"><a href="#自定义训练循环" class="headerlink" title="自定义训练循环"></a>自定义训练循环</h4><h5 id="使用自动微分计算梯度"><a href="#使用自动微分计算梯度" class="headerlink" title="使用自动微分计算梯度"></a>使用自动微分计算梯度</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(w1, w2)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">3</span> * w1 ** <span class="number">2</span> + <span class="number">2</span> * w1 * w2</span><br></pre></td></tr></table></figure>
<p>函数对<code>w1</code>的偏导是<code>6 * w1 + 2 * w2</code>，还能算出它对<code>w2</code>的偏导是<code>2 * w1</code>。例如，在点<code>(w1, w2) = (5, 3)</code>，这两个偏导数分别是36和10，在这个点的梯度矢量就是（36, 10）。但对于神经网络来说，函数会复杂得多，可能会有上万个参数，用手算偏导几乎是不可能的任务。一个解决方法是计算每个偏导的大概值，通过调节参数，查看输出的变化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>w1, w2 = <span class="number">5</span>, <span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>eps = <span class="number">1e-6</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(f(w1 + eps, w2) - f(w1, w2)) / eps</span><br><span class="line"><span class="number">36.000003007075065</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(f(w1, w2 + eps) - f(w1, w2)) / eps</span><br><span class="line"><span class="number">10.000000003174137</span></span><br></pre></td></tr></table></figure>
<p>上述方法很容易实现，但只是大概。并且，需要对每个参数至少要调用一次<code>f()</code>（不是至少两次，因为可以只计算一次<code>f(w1, w2)</code>）。这样，对于大神经网络，就不怎么可控。需要通过TensorFlow实现自动微分</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">w1, w2 = tf.Variable(<span class="number">5.</span>), tf.Variable(<span class="number">3.</span>)</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    z = f(w1, w2)</span><br><span class="line"><span class="comment"># 创建了tf.GradientTape记录器，能自动记录变量的每个操作，</span></span><br><span class="line">gradients = tape.gradient(z, [w1, w2])</span><br></pre></td></tr></table></figure>
<p><code>gradient()</code>方法只逆向算了一次，无论有多少个变量，效率很高。</p>
<h4 id="TensorFlow的函数和图"><a href="#TensorFlow的函数和图" class="headerlink" title="TensorFlow的函数和图"></a>TensorFlow的函数和图</h4><p>使用TensorFlow的自动图生成特征：</p>
<p><code>tf.function()</code>在底层分析了<code>cube()</code>函数的计算，然后生成了一个等价的计算图！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cube</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">3</span></span><br><span class="line"></span><br><span class="line">tf_cube = tf.function(cube)</span><br></pre></td></tr></table></figure>
<p>另外，也可以使用<code>tf.function</code>作为装饰器，更常见一些：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tf_cube</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>TensorFlow优化了计算图，删掉了没用的节点，简化了表达式（比如，1 + 2会替换为3）。当优化好的计算图准备好之后，TF函数可以在图中，按合适的顺序高效执行运算（该并行的时候就并行）。作为结果，TF函数比普通的Python函数快的做，特别是在做复杂计算时。大多数时候，根本没必要知道底层到底发生了什么，如果需要对Python函数加速，将其转换为TF函数就行。</p>
<h5 id="自动图和跟踪"><a href="#自动图和跟踪" class="headerlink" title="自动图和跟踪"></a>自动图和跟踪</h5><p>TensorFlow是先分析Python函数源码，得出所有的数据流控制语句，比如for循环，while循环，if条件，还有break、continue、return。这个第一步被称为<strong>自动图（AutoGraph）</strong>。分析完源码之后，自动图中的所有控制流语句都被替换成相应的TensorFlow方法，比如<code>tf.while_loop()</code>（while循环）和<code>tf.cond()</code>（if判断）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-cd0d53808f2cf8a8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>然后，TensorFlow调用这个“升级”方法，但没有向其传递参数，而是传递一个符号张量（symbolic tensor）——没有任何真实值的张量，只有名字、数据类型和形状。</p>
<p>函数会以图模式运行，意味着每个TensorFlow运算会在图中添加一个表示自身的节点，然后输出<code>tensor(s)</code>（与常规模式相对，这被称为动态图执行，或动态模式）。在图模式中，TF运算不做任何计算。最后的图是跟踪中生成的。节点表示运算，箭头表示张量。</p>
<h5 id="TF-函数规则"><a href="#TF-函数规则" class="headerlink" title="TF 函数规则"></a>TF 函数规则</h5><p>大多数时候，将Python函数转换为TF函数是琐碎的：要用<code>@tf.function</code>装饰，或让Keras来负责。但是，也有一些规则：</p>
<blockquote>
<ul>
<li>调用任何外部库，包括NumPy，甚至是标准库，调用只会在跟踪中运行，不会是图的一部分。</li>
<li>可以调用其它Python函数或TF函数，但是它们要遵守相同的规则，因为TensorFlow会在计算图中记录它们的运算。注意，其它函数不需要用<code>@tf.function</code>装饰。</li>
<li>如果函数创建了一个TensorFlow变量（或任意其它静态TensorFlow对象，比如数据集或队列），它必须在第一次被调用时创建TF函数，否则会导致异常。通常，最好在TF函数的外部创建变量（比如在自定义层的<code>build()</code>方法中）。如果你想将一个新值赋值给变量，要确保调用它的<code>assign()</code>方法，而不是使用<code>=</code>。</li>
<li>Python的源码可以被TensorFlow使用。如果源码用不了（比如，如果是在Python shell中定义函数，源码就访问不了，或者部署的是编译文件<code>*.pyc</code>），图的生成就会失败或者缺失功能。</li>
<li>TensorFlow只能捕获迭代张量或数据集的for循环。因此要确保使用<code>for i in tf.range(x)</code>，而不是<code>for i in range(x)</code>，否则循环不能在图中捕获，而是在会在追踪中运行。</li>
<li>出于性能原因，最好使用矢量化的实现方式，而不是使用循环。</li>
</ul>
</blockquote>
<h3 id="练习-2"><a href="#练习-2" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>如何用一句话描述TensorFlow？它的主要特点是什么？能列举出其它流行的深度学习库吗？</p>
<blockquote>
<p>TensorFlow是由谷歌大脑团队开发的一个强大的开源数值计算库，适合做和微调大规模机器学习。</p>
<p>主要特点：</p>
<ul>
<li>TensorFlow的核心与NumPy很像，但TensorFlow支持GPU；</li>
<li>TensorFlow支持（多设备和服务器）分布式计算；</li>
<li>TensorFlow使用了即时JIT编译器对计算速度和内存使用优化。编译器的工作是从Python函数提取出计算图，然后对计算图优化（比如剪切无用的节点），最后高效运行（比如自动并行运行独立任务）；</li>
<li>计算图可以导出为迁移形式，因此可以在一个环境中训练一个TensorFlow模型（比如使用Python或Linux），然后在另一个环境中运行（比如在安卓设备上用Java运行）；</li>
<li>TensorFlow实现了<strong>自动微分</strong> ，并提供了一些高效的优化器，比如RMSProp和NAdam，因此可以很容易最小化各种损失函数。</li>
</ul>
<p>其他流形的深度学习库有：PyTorch（Facebook）Theano，Caffe2，MXNet, Microsoft Cognitive Toolkit</p>
</blockquote>
</li>
<li><p>TensorFlow是NumPy的简单替换吗？二者有什么区别？</p>
<blockquote>
<p>不是</p>
<ul>
<li>TensorFlow和NumPy的函数名并不完全相同，本质是因为函数做得操作不同（NumPy中属性T和TensorFlow中的tf.transpose()）</li>
<li>大部分TF数据结构都是不可变的（除了变量这一类），但Numpy可变</li>
</ul>
</blockquote>
</li>
<li><p><code>tf.range(10)</code>和<code>tf.constant(np.arange(10))</code>能拿到相同的结果吗？</p>
<blockquote>
<p>基本一致</p>
<p>前者32位整数（TensorFlow中默认），后者64位整数（NumPy默认64位）</p>
</blockquote>
</li>
<li><p>列举出除了常规张量之外，TensorFlow的其它六种数据结构？</p>
<blockquote>
<p>稀疏张量，张量数组，嵌套张量，字符串张量，集合和队列</p>
</blockquote>
</li>
<li><p>可以通过函数或创建<code>keras.losses.Loss</code>的子类来自定义损失函数。两种方法各在什么时候使用？</p>
<blockquote>
<p>当自定义损失函数需要超参数时，需要创建<code>keras.losses.Loss</code>的子类</p>
</blockquote>
</li>
<li><p>相似的，自定义指标可以通过定义函数或创建<code>keras.metrics.Metric</code>的子类。两种方法各在什么时候使用？</p>
<blockquote>
<p>当自定义指标需要超参数时，需要创建<code>keras.metrics.Metric</code>的子类</p>
</blockquote>
</li>
<li><p>什么时候应该创建自定义层，而不是自定义模型？</p>
<blockquote>
<p>当需要自定义模型内部组件时，比如重复使用层的时候需要自定义层。</p>
<p>自定义层是<code>Layer</code>类的子类，自定义模型是<code>Model</code>类的子类。</p>
</blockquote>
</li>
<li><p>什么时候需要创建自定义的训练循环？</p>
<blockquote>
<p>在某些特殊情况下，<code>fit()</code>方法可能不够灵活。比如在神经网络模型中对不同的层使用不同的优化器，Wide &amp; Deep论文使用了两个优化器：一个用于宽路线，一个用于深路线。</p>
</blockquote>
</li>
<li><p>自定义Keras组件可以包含任意Python代码吗，或者Python代码需要转换为TF函数吗？</p>
<blockquote>
<p>可以在<code>tf.py_function()</code>运算中包装任意的Python代码，但这么做的话会使性能下降，因为TensorFlow不能做任何图优化。</p>
<p>不一定需要把Python代码转化为TF函数：</p>
<ul>
<li>可以在构建层或者模型的时候设置 <code>dynamic=True</code></li>
<li>或者，在编译的时候设置 <code>run_eagerly=True</code></li>
</ul>
</blockquote>
</li>
<li><p>如果想让一个函数可以转换为TF函数，要遵守设么规则？</p>
<blockquote>
<p>​</p>
</blockquote>
</li>
<li><p>什么时候需要创建一个动态Keras模型？怎么做？为什么不让所有模型都是动态的？</p>
<blockquote>
<ul>
<li>debug的时候可以创建动态Keras模型，因为没有编译，所以没有转换为TF Function，可以使Python Debug，或者想要在模型中包裹任意Python代码时，也可以创建动态Keras模型。</li>
<li>只需要在创建时设置 <code>dynamic=True</code> ，或者在编译时设置<code>run_eagerly=True</code></li>
<li>动态模型，不能使用TensorFlow的图计算（graph feature），训练和预测速度会下降。</li>
</ul>
</blockquote>
</li>
<li><p>实现一个具有层归一化的自定义层（第15章会用到）：</p>
<p>a. <code>build()</code>方法要定义两个可训练权重α 和 β，形状都是<code>input_shape[-1:]</code>，数据类型是<code>tf.float32</code>。α用1初始化，β用0初始化。</p>
<p>b. <code>call()</code>方法要计算每个实例的特征的平均值μ和标准差σ。你可以使用<code>tf.nn.moments(inputs, axes=-1, keepdims=True)</code>，它可以返回平均值μ和方差σ2（计算其平方根得到标准差）。函数返回<code>α⊗(X - μ)/(σ + ε) + β</code>，其中<code>⊗</code>表示元素级别惩罚，<code>ε</code>是平滑项（避免发生除以0，而是除以0.001）。</p>
<p>c. 确保自定义层的输出和<code>keras.layers.LayerNormalization</code>层的输出一致（或非常接近）。</p>
</li>
</ol>
<ol>
<li><p>训练一个自定义训练循环，来处理Fashion MNIST数据集。</p>
<p>a. 展示周期、迭代，每个周期的平均训练损失、平均准确度（每次迭代会更新），还有每个周期结束后的验证集损失和准确度。</p>
<p>b. 深层和浅层使用不同的优化器，不同的学习率。</p>
</li>
</ol>
<h2 id="第13章-使用TensorFlow加载和预处理数据"><a href="#第13章-使用TensorFlow加载和预处理数据" class="headerlink" title="第13章 使用TensorFlow加载和预处理数据"></a>第13章 使用TensorFlow加载和预处理数据</h2><p>介绍Data API，TFRecord格式，以及如何创建自定义预处理层，和使用Keras的预处理层。</p>
<h3 id="Data-API"><a href="#Data-API" class="headerlink" title="Data API"></a>Data API</h3><p><code>tf.data.Dataset.from_tensor_slices()</code>创建一个存储于内存中的数据集</p>
<h4 id="链式转换"><a href="#链式转换" class="headerlink" title="链式转换"></a>链式转换</h4><p><code>dataset.repeat(3).batch(7)</code> </p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e2753af12c9e73a0.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<blockquote>
<p>数据集方法不修改数据集，只是生成新的数据集而已，所以要做新数据集的赋值</p>
</blockquote>
<p><code>dataset.map(lambda x: x * 2)</code> 对于复杂的处理，通常需要多线程来加速：需设置参数<code>num_parallel_calls</code>。注意，传递给<code>map()</code>方法的函数必须是可以转换为TF Function。</p>
<p><code>map()</code>方法是对每个元素做转换的，<code>apply()</code>方法是对数据整体做转换的。</p>
<p>用<code>filter()</code>方法做过滤：<code>dataset.filter(lambda x: x &lt; 10)</code></p>
<p><code>take()</code>方法可以用来查看数据</p>
<h4 id="打散数据"><a href="#打散数据" class="headerlink" title="打散数据"></a>打散数据</h4><p>当训练集中的实例是独立同分布时，梯度下降的效果最好。实现独立同分布的一个简单方法是使用<code>shuffle()</code>方法。</p>
<blockquote>
<p>shuffle()创建一个新数据集，其前面是一个缓存，缓存中是源数据集的开头元素。无论何时取元素，会从缓存中随机取出一个元素，从源数据集中取一个新元素替换。从缓冲器取元素，直到缓存为空。必须要指定缓存的大小，最好大一点，否则随机效果不明显。但不要超出内存大小。如果希望随机的顺序是固定的，可以提供一个随机种子。</p>
</blockquote>
<p>对于大数据集，因为缓存比数据集小太多，随机缓存方法就不能用。解决方法是<strong>将源数据本身打乱</strong>，为了将实例进一步打散，一个常用的方法是<strong>将源数据分成多个文件</strong>，训练时随机顺序读取。但是，相同文件中的实例仍然靠的太近。为了避免这点，可以<strong>同时随机读取多个文件，做交叉</strong>。在最顶层，可以用<code>shuffle()</code>加一个随机缓存。</p>
<h4 id="多行数据交叉"><a href="#多行数据交叉" class="headerlink" title="多行数据交叉"></a>多行数据交叉</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.data.Dataset.list_files(train_filepaths, seed=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<p>默认，<code>list_files()</code>函数返回一个文件路径打散的数据集。也可以设置<code>shuffle=False</code>，文件路径就不打散了。</p>
<p>然后，调用<code>leave()</code>方法，一次读取5个文件，做交叉操作（跳过第一行表头，使用<code>skip()</code>方法，可以设定参数<code>num_parallel_calls</code>为想要的线程数（<code>map()</code>方法也有这个参数），并行读取文件。</p>
<blockquote>
<p>提示：为了交叉得更好，最好让文件有相同的长度，否则长文件的尾部不会交叉。</p>
</blockquote>
<h4 id="预处理数据"><a href="#预处理数据" class="headerlink" title="预处理数据"></a>预处理数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_mean, X_std = [...] <span class="comment"># mean and scale of each feature in the training set</span></span><br><span class="line">n_inputs = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(line)</span>:</span></span><br><span class="line">  defs = [<span class="number">0.</span>] * n_inputs + [tf.constant([], dtype=tf.float32)]</span><br><span class="line">  fields = tf.io.decode_csv(line, record_defaults=defs)</span><br><span class="line">  x = tf.stack(fields[:<span class="number">-1</span>])</span><br><span class="line">  y = tf.stack(fields[<span class="number">-1</span>:])</span><br><span class="line">  <span class="keyword">return</span> (x - X_mean) / X_std, y</span><br></pre></td></tr></table></figure>
<h4 id="整合"><a href="#整合" class="headerlink" title="整合"></a>整合</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">csv_reader_dataset</span><span class="params">(filepaths, repeat=<span class="number">1</span>, n_readers=<span class="number">5</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                       n_read_threads=None, shuffle_buffer_size=<span class="number">10000</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                       n_parse_threads=<span class="number">5</span>, batch_size=<span class="number">32</span>)</span>:</span></span><br><span class="line">    dataset = tf.data.Dataset.list_files(filepaths)</span><br><span class="line">    dataset = dataset.interleave(</span><br><span class="line">        <span class="keyword">lambda</span> filepath: tf.data.TextLineDataset(filepath).skip(<span class="number">1</span>),</span><br><span class="line">        cycle_length=n_readers, num_parallel_calls=n_read_threads)</span><br><span class="line">    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)</span><br><span class="line">    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)</span><br><span class="line">    <span class="keyword">return</span> dataset.batch(batch_size).prefetch(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="预提取"><a href="#预提取" class="headerlink" title="预提取"></a>预提取</h4><p>通过调用<code>prefetch(1)</code>，创建了一个高效的数据集，总能提前一个批次。换句话说，当训练算法在一个批次上工作时，数据集已经准备好下一个批次了（从硬盘读取数据并做预处理）</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-86355457e5a7a1c2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<blockquote>
<p>提示：如果想买一块GPU显卡的话，它的处理能力和显存都是非常重要的。另一个同样重要的，是显存带宽，即每秒可以进入或流出内存的GB数。</p>
</blockquote>
<p>如果数据集不大，内存放得下，可以使用数据集的<code>cache()</code>方法将数据集存入内存。通常这步是在加载和预处理数据之后，在打散、重复、分批次之前。这样做的话，每个实例只需做一次读取和处理，下一个批次仍能提前准备。</p>
<h3 id="TFRecord格式"><a href="#TFRecord格式" class="headerlink" title="TFRecord格式"></a>TFRecord格式</h3><p>虽然使用CSV文件,常见又简单方便，但不够高效，不支持大或复杂的数据结构（比如图片或音频）。这就是TFRecord要解决的。</p>
<p>TFRecord格式是TensorFlow偏爱的存储大量数据并高效读取的数据。它是非常简单的二进制格式，只包含不同大小的二进制记录的数据（每个记录包括一个长度、一个CRC校验和，校验和用于检查长度是否正确，真是的数据，和一个数据的CRC校验和，用于检查数据是否正确）。</p>
<p>使用<code>tf.io.TFRecordWriter</code>类创建TFRecord文件,使用<code>tf.data.TFRecordDataset</code>来读取一个或多个TFRecord文件</p>
<blockquote>
<p>提示：默认情况下，<code>TFRecordDataset</code>会逐一读取数据，但通过设定<code>num_parallel_reads</code>可以并行读取并交叉数据。另外，也可以使用<code>list_files()</code>和<code>interleave()</code>获得同样的结果。</p>
</blockquote>
<h4 id="压缩TFRecord文件"><a href="#压缩TFRecord文件" class="headerlink" title="压缩TFRecord文件"></a>压缩TFRecord文件</h4><p>可以通过设定<code>options</code>参数，创建压缩的TFRecord文件，当读取压缩TFRecord文件时，需要指定压缩类型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">options = tf.io.TFRecordOptions(compression_type=<span class="string">"GZIP"</span>)</span><br><span class="line"><span class="keyword">with</span> tf.io.TFRecordWriter(<span class="string">"my_compressed.tfrecord"</span>, options) <span class="keyword">as</span> f:</span><br><span class="line">  [...]</span><br><span class="line">dataset = tf.data.TFRecordDataset([<span class="string">"my_compressed.tfrecord"</span>],</span><br><span class="line">                                  compression_type=<span class="string">"GZIP"</span>)</span><br></pre></td></tr></table></figure>
<h4 id="协议缓存"><a href="#协议缓存" class="headerlink" title="协议缓存"></a>协议缓存</h4><p>每条记录可以使用任何二进制格式，TFRecord文件通常包括序列化的协议缓存（也称为protobuf）。这是一种可移植、可扩展的高效二进制格式，是谷歌在2001年开发，并在2008年开源的；协议缓存现在使用广泛，特别是在gRPC，谷歌的远程调用系统中。定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">syntax = <span class="string">"proto3"</span>;</span><br><span class="line">message Person &#123;</span><br><span class="line">  string name = <span class="number">1</span>;</span><br><span class="line">  int32 id = <span class="number">2</span>;</span><br><span class="line">  repeated string email = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当<code>.proto</code>文件中有了一个定义，就可以用协议缓存编译器<code>protoc</code>编译，来生成Python（或其它语言）的访问类。</p>
<h4 id="TensorFlow协议缓存"><a href="#TensorFlow协议缓存" class="headerlink" title="TensorFlow协议缓存"></a>TensorFlow协议缓存</h4><p>TFRecord文件主要使用的协议缓存是<code>tf.train.Example</code>，表示数据集中的一个实例，包括命名特征的列表，每个特征可以是字节串列表、或浮点列表、或整数列表。下面是一个协议缓存的定义：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">syntax = <span class="string">"proto3"</span>;</span><br><span class="line">message BytesList &#123; repeated bytes value = <span class="number">1</span>; &#125;</span><br><span class="line">message FloatList &#123; repeated float value = <span class="number">1</span> [packed = true]; &#125;</span><br><span class="line">message Int64List &#123; repeated int64 value = <span class="number">1</span> [packed = true]; &#125;</span><br><span class="line">message Feature &#123;</span><br><span class="line">    oneof kind &#123;</span><br><span class="line">        BytesList bytes_list = <span class="number">1</span>;</span><br><span class="line">        FloatList float_list = <span class="number">2</span>;</span><br><span class="line">        Int64List int64_list = <span class="number">3</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line">message Features &#123; map&lt;string, Feature&gt; feature = <span class="number">1</span>; &#125;;</span><br><span class="line">message Example &#123; Features features = <span class="number">1</span>; &#125;;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>一般来说，你需要写一个转换脚本，读取当前格式（例如csv），为每个实例创建<code>Example</code>协议缓存，序列化并存储到若干TFRecord文件中，最好再打散。</p>
</blockquote>
<h4 id="加载和解析Example"><a href="#加载和解析Example" class="headerlink" title="加载和解析Example"></a>加载和解析Example</h4><p>要加载序列化的<code>Example</code>协议缓存，需要再次使用<code>tf.data.TFRecordDataset</code>，使用<code>tf.io.parse_single_example()</code>解析每个<code>Example</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature_description = &#123;</span><br><span class="line">    <span class="string">"name"</span>: tf.io.FixedLenFeature([], tf.string, default_value=<span class="string">""</span>),</span><br><span class="line">    <span class="string">"id"</span>: tf.io.FixedLenFeature([], tf.int64, default_value=<span class="number">0</span>),</span><br><span class="line">    <span class="string">"emails"</span>: tf.io.VarLenFeature(tf.string),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> serialized_example <span class="keyword">in</span> tf.data.TFRecordDataset([<span class="string">"my_contacts.tfrecord"</span>]):</span><br><span class="line">    parsed_example = tf.io.parse_single_example(serialized_example,</span><br><span class="line">                                                feature_description)</span><br></pre></td></tr></table></figure>
<p>长度固定的特征会像常规张量那样解析，而长度可变的特征会作为稀疏张量解析。可以使用<code>tf.sparse.to_dense()</code>将稀疏张量转变为紧密张量。</p>
<h4 id="使用SequenceExample协议缓存处理嵌套列表"><a href="#使用SequenceExample协议缓存处理嵌套列表" class="headerlink" title="使用SequenceExample协议缓存处理嵌套列表"></a>使用<code>SequenceExample</code>协议缓存处理嵌套列表</h4><p>下面是<code>SequenceExample</code>协议缓存的定义：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">message FeatureList &#123; repeated Feature feature = <span class="number">1</span>; &#125;;</span><br><span class="line">message FeatureLists &#123; map&lt;string, FeatureList&gt; feature_list = <span class="number">1</span>; &#125;;</span><br><span class="line">message SequenceExample &#123;</span><br><span class="line">    Features context = <span class="number">1</span>;</span><br><span class="line">    FeatureLists feature_lists = <span class="number">2</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>须要使用<code>tf.io.parse_single_sequence_example()</code>来解析单个的<code>SequenceExample</code>或用<code>tf.io.parse_sequence_example()</code>解析一个批次。两个函数都是返回一个包含上下文特征（字典）和特征列表（也是字典）的元组。如果特征列表包含大小可变的序列（就像前面的例子），可以将其转化为嵌套张量，使用<code>tf.RaggedTensor.from_sparse()</code></p>
<h3 id="预处理输入特征"><a href="#预处理输入特征" class="headerlink" title="预处理输入特征"></a>预处理输入特征</h3><p>为神经网络准备数据需要将所有特征转变为数值特征，做一些归一化工作等等。</p>
<blockquote>
<ul>
<li>可以在准备数据文件的时候做，使用NumPy、Pandas、Scikit-Learn这样的工作。</li>
<li>可以在用Data API加载数据时，实时预处理数据（比如，使用数据集的<code>map()</code>方法，就像前面的例子）。</li>
<li>可以给模型加一个预处理层。</li>
</ul>
</blockquote>
<p><strong>用Lambda层实现标准化层</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">means = np.mean(X_train, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">stds = np.std(X_train, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">eps = keras.backend.epsilon()</span><br><span class="line">model = keras.models.Sequential([</span><br><span class="line">    keras.layers.Lambda(<span class="keyword">lambda</span> inputs: (inputs - means) / (stds + eps)),</span><br><span class="line">    [...] <span class="comment"># 其它层</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p><strong>独立的自定义层</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Standardization</span><span class="params">(keras.layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">adapt</span><span class="params">(self, data_sample)</span>:</span></span><br><span class="line">        self.means_ = np.mean(data_sample, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        self.stds_ = np.std(data_sample, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())</span><br><span class="line">        </span><br><span class="line">std_layer = Standardization()</span><br><span class="line">std_layer.adapt(data_sample)</span><br></pre></td></tr></table></figure>
<h4 id="使用独热矢量编码类型特征"><a href="#使用独热矢量编码类型特征" class="headerlink" title="使用独热矢量编码类型特征"></a>使用独热矢量编码类型特征</h4><p>创建了查找表，传入初始化器并指明未登录词（oov）桶的数量。如果查找的类型不在词典中，查找表会计算这个类型的哈希，使用哈希分配一个未知的类型给未登录词桶。索引序号接着现有序号，</p>
<p>原因：如果类型数足够大（例如，邮编、城市、词、产品、或用户），数据集也足够大，或者数据集持续变化，这样的话，获取类型的完整列表就不容易了。一个解决方法是根据数据样本定义（而不是整个训练集），为其它不在样本中的类型加上一些未登录词桶。训练中碰到的未知类型越多，要使用的未登录词桶就要越多。事实上，如果未登录词桶的数量不够，就会发生碰撞：不同的类型会出现在同一个桶中，所以神经网络就无法区分了。</p>
<blockquote>
<p>一个重要的原则，如果类型数小于10，可以使用独热编码。如果类型超过50个（使用哈希桶时通常如此），最好使用嵌入。类型数在10和50之间时，最好对两种方法做个试验，看哪个更合适。</p>
</blockquote>
<h4 id="用嵌入编码类型特征"><a href="#用嵌入编码类型特征" class="headerlink" title="用嵌入编码类型特征"></a>用嵌入编码类型特征</h4><p>嵌入是一个可训练的表示类型的紧密矢量。默认时，嵌入是随机初始化的，<code>&quot;NEAR BAY&quot;</code>可能初始化为<code>[0.131, 0.890]</code>，<code>&quot;NEAR OCEAN&quot;</code>可能初始化为<code>[0.631, 0.791]</code>。</p>
<blockquote>
<p>表征的越好，越利于神经网络做出准确的预测，而训练会让嵌入更好的表征类型，这被称为表征学习</p>
</blockquote>
<h5 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h5><p>用神经网络预测给定词附近的词，得到了非常好的词嵌入。例如，同义词有非常相近的词嵌入，语义相近的词，比如法国、西班牙和意大利靠的也很近，词嵌入在嵌入空间的轴上的分布也是有意义的。</p>
<blockquote>
<p>独热编码加紧密层（没有激活函数和偏差项），等价于嵌入层。但是，嵌入层用的计算更少（嵌入矩阵越大，性能差距越明显）。紧密层的权重矩阵扮演的是嵌入矩阵的角色。例如，大小为20的独热矢量和10个单元的紧密层加起来，等价于<code>input_dim=20</code>、<code>output_dim=10</code>的嵌入层。作为结果，嵌入的维度超过后面的层的神经元数是浪费的。</p>
</blockquote>
<h4 id="Keras预处理层"><a href="#Keras预处理层" class="headerlink" title="Keras预处理层"></a>Keras预处理层</h4><p><code>keras.layers.Normalization</code>用来做特征标准化，<code>TextVectorization</code>层用于将文本中的词编码为词典的索引。对于这两个层，都是用数据样本调用它的<code>adapt()</code>方法，然后如常使用。其它的预处理层也是这么使用的。</p>
<p><code>keras.layers.Discretization</code>层，它能将连续数据切成不同的组，将每个组斌吗为独热矢量。例如，可以用它将价格分成是三类，低、中、高，编码为[1, 0, 0]、[0, 1, 0]、[0, 0, 1]。</p>
<p><code>TextVectorization</code>层也有一个选项用于输出词频向量，而不是词索引。例如，如果词典包括三个词，比如<code>[&quot;and&quot;, &quot;basketball&quot;, &quot;more&quot;]</code>，则<code>&quot;more and more&quot;</code>会映射为<code>[1, 0, 2]</code>：<code>&quot;and&quot;</code>出现了一次，<code>&quot;basketball&quot;</code>没有出现，<code>&quot;more&quot;</code>出现了两次。这种词表征称为<strong>词袋 </strong> ，因为它完全失去了词的顺序。</p>
<p>词频向量中应该降低常见词的影响。一个常见的方法是<strong>将词频除以出现该词的文档数的对数</strong>。这种方法称为<strong>词频-逆文档频率（TF-IDF）</strong>。例如，假设<code>&quot;and&quot;</code>、<code>&quot;basketball&quot;</code>、<code>&quot;more&quot;</code>分别出现在了200、10、100个文档中：最终的矢量应该是<code>[1/log(200), 0/log(10), 2/log(100)]</code>，大约是<code>[0.19, 0., 0.43]</code>。<code>TextVectorization</code>层会有TF-IDF的选项。</p>
<h3 id="TF-Transform"><a href="#TF-Transform" class="headerlink" title="TF Transform"></a>TF Transform</h3><p>TensorFlow没有捆绑，需要pip安装</p>
<p>在数据训练前，处理每个实例，而不是在训练中每个周期处理一次实例。</p>
<p>如果数据集小到可以存入内存，可以使用<code>cache()</code>方法。但如果太大，可以<strong>使用Apache Beam或Spark</strong>。它们可以在大数据上做高效的数据预处理，还可以分布进行，使用它们就能在训练前处理所有训练数据了。</p>
<p>TF Transform是<a href="https://links.jianshu.com/go?to=https%3A%2F%2Ftensorflow.org%2Ftfx" target="_blank" rel="noopener">TensorFlow Extended (TFX)</a>的一部分，这是一个端到端的TensorFlow模型生产化平台。</p>
<h3 id="TensorFlow-Datasets（TFDS）项目"><a href="#TensorFlow-Datasets（TFDS）项目" class="headerlink" title="TensorFlow Datasets（TFDS）项目"></a>TensorFlow Datasets（TFDS）项目</h3><p>TensorFlow没有捆绑TFDS，所以需要使用pip安装库<code>tensorflow-datasets</code>。然后调用函数<code>tfds.load()</code>，就能下载数据集了（除非之前下载过），返回的数据是数据集的字典（通常是一个是训练集，一个是测试集）。</p>
<h3 id="练习-3"><a href="#练习-3" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>为什么要使用Data API </p>
<blockquote>
<p>当数据集很大，或者保存在不同文件中是，可以用Data API来读入数据，处理数据</p>
</blockquote>
</li>
<li><p>将大数据分成多个文件有什么好处？</p>
<blockquote>
<p>可以对数据进行打散，交叉（shuffle）</p>
<p>还可以对数据进行分布式计算处理</p>
</blockquote>
</li>
<li><p>训练中，如何断定输入管道是瓶颈？如何处理瓶颈？</p>
<blockquote>
<p>如果GPU没有完全被利用时，可能是输入管道达到了瓶颈。</p>
<p>可以多线程来加速</p>
</blockquote>
</li>
<li><p>可以将任何二进制数据存入TFRecord文件吗，还是只能存序列化的协议缓存？</p>
<blockquote>
<p>可以将任意的二级制数据存入</p>
<p>但通常情况下都是村塾序列化的协议缓存，可以被多平台，多语言利用。</p>
</blockquote>
</li>
<li><p>为什么要将数据转换为Example协议缓存？为什么不使用自己的协议缓存？</p>
<blockquote>
<p>TensorFlow为Example提供了许多操作，可以不需要自己定义format解释（parse）</p>
<p>如果不能满足自己的需求时3，可以自定义协议缓存，然后用protoc编译。</p>
</blockquote>
</li>
<li><p>使用TFRecord时，什么时候要压缩？为什么不系统化的做？</p>
<blockquote>
<p>需要下载或传输数据时可以压缩，这样可以减少数据压缩时间。</p>
</blockquote>
</li>
<li><p>数据预处理可以在写入数据文件时，或在tf.data管道中，或在预处理层中，或使用TF Transform。这几种方法各有什么优缺点？</p>
<blockquote>
<p>| 项目             | 优点                                                         | 缺点                                                         |<br>| ———————— | —————————————————————————————— | —————————————————————————————— |<br>| 在tf.data管道中  | 1. preprocessing logics 和 data augmentation很简单 2. 可以构建管道 | 1. 降低训练过程的速度 2. 每个实例会在每个epoch处理一次，不像在写入文件就处理那样，只需一次。2. 训练好的模型仍然需要处理好的数据 |<br>| 在预处理层中     | 1. 只需要在训练和预测的时候写一次代码。2.                    | 1. 降低训练速度。2. 每个实例会在每个epoch处理一次，3. 默认情况下，数据在GPU上处理（因为数据处理是在模型里），不能CPU处理数据，GPU跑模型 |<br>| 使用TF Transform | 1.  the preprocessed data is materialized, 2. 每个实例只需要处理一次，3. 代码只需写一次. | 使用比较困难                                                 |<br>| 在写入数据文件时 | 1. 训练过程会变得很快， 2. 数据处理之后比较小，节省空间，方便下载  3. 方便检查数据 | 1. 有很多preprocessing logics 2，data augmentation时，需要很大的磁盘空间和时间 3，需要在建模之前处理 |</p>
</blockquote>
</li>
<li><p>说出几种常见的编码类型特征的方法。文本如何编码？</p>
<blockquote>
<ol>
<li>ordinal encoding：每个类比给一个编号，但是编号有距离，而不代表实际的距离</li>
<li>one-hot encoding，独热编码</li>
<li>embeddings，嵌入编码</li>
</ol>
<p>文本：</p>
<ol>
<li>统计单词的频率，使用词袋，一句话有表示单词频次的矢量表示，可以使用TF-IDF方法，即除以log（单词出现的文件的个数）来降低常用单词的分数。</li>
<li>count <em>n</em>-grams，统计连续的n个单词，可以保留上下文关系。</li>
<li>除了对单词编码，还可以对字母或者subword tokens编码。</li>
</ol>
</blockquote>
</li>
<li><p>加载Fashion MNIST数据集；将其分成训练集、验证集和测试集；打散训练集；将每个数据存为多个TFRecord文件。每条记录应该是有两个特征的序列化的Example协议缓存：序列化的图片（使用<code>tf.io.serialize_tensor()</code>序列化每张图片）和标签。然后使用tf.data为每个集合创建一个高效数据集。最后，使用Keras模型训练这些数据集，用预处理层标准化每个特征。让输入管道越高效越好，使用TensorBoard可视化地分析数据。</p>
</li>
<li><p>这道题中，要下载一个数据集，分割它，创建一个tf.data.Dataset，用于高效加载和预处理，然后搭建一个包含嵌入层的二分类模型：</p>
<p>a. 下载<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fimdb" target="_blank" rel="noopener">Large Movie Review Dataset</a>，它包含50000条IMDB的影评。数据分为两个目录，train和test，每个包含12500条正面评价和12500条负面评价。每条评价都存在独立的文本文件中。还有其他文件和文件夹（包括预处理的词袋），但这个练习中用不到。</p>
<p>b. 将测试集分给成验证集（15000）和测试集（10000）。</p>
<p>c. 使用tf.data，为每个集合创建高效数据集。</p>
<p>d.创建一个二分类模型，使用<code>TextVectorization</code>层来预处理每条影评。如果<code>TextVectorization</code>层用不了（或者你想挑战下），则创建自定义的预处理层：使用<code>tf.strings</code>包中的函数，比如<code>lower()</code>来做小写，<code>regex_replace()</code>来替换带有空格的标点，<code>split()</code>来分割词。用查找表输出词索引，<code>adapt()</code>方法中要准备好。</p>
<p>e. 加入嵌入层，计算每条评论的平均嵌入，乘以词数的平方根。这个缩放过的平均嵌入可以传入剩余的模型中。</p>
<p>f. 训练模型，看看准确率能达到多少。尝试优化管道，让训练越快越好。</p>
<p>g. 使用TFDS加载同样的数据集：<code>tfds.load(&quot;imdb_reviews&quot;)</code>。</p>
</li>
</ol>
<h2 id="第14章-使用卷积神经网络实现深度计算机视觉"><a href="#第14章-使用卷积神经网络实现深度计算机视觉" class="headerlink" title="第14章 使用卷积神经网络实现深度计算机视觉"></a>第14章 使用卷积神经网络实现深度计算机视觉</h2><p>CNN没有GPU可能会很慢</p>
<h3 id="视神经结构"><a href="#视神经结构" class="headerlink" title="视神经结构"></a>视神经结构</h3><p>David H. Hubel 和 Torsten Wiesel 在1958年和1959年在猫的身上做了一系列研究，对视神经中枢做了研究（并在1981年荣获了诺贝尔生理学或医学奖）。特别的，他们指出视神经中的许多神经元都有一个<strong>局部感受野（local receptive field）</strong>，也就是说，这些神经元只对有限视觉区域的刺激作反应。</p>
<p>Yann LeCun等人再1998年发表了一篇里程碑式的论文，提出了著名的LeNet-5架构，被银行广泛用来识别手写支票的数字。这个架构中的一些组件，我们已经学过了，比如全连接层、sigmod激活函数，但CNN还引入了两个新组件：卷积层和池化层。</p>
<blockquote>
<p>全连接层的深度神经网络尽管在小图片（比如MNIST）任务上表现不错，但由于参数过多，在大图片任务上表现不佳。举个例子，一张100 × 100像素的图片总共有10000个像素点，如果第一层有1000个神经元（如此少的神经元，已经限制信息的传输量了），那么就会有1000万个连接。这仅仅是第一层的情况。CNN是通过部分连接层和权重共享解决这个问题的。</p>
</blockquote>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积层是CNN最重要的组成部分：第一个卷积层的神经元，不是与图片中的每个像素点都连接，而是只连着局部感受野的像素。同理，第二个卷积层中的每个神经元也只是连着第一层中一个小方形内的神经元。这种架构可以让第一个隐藏层聚焦于小的低级特征，然后在下一层组成大而高级的特征。这种<strong>层级式的结构</strong>在真实世界的图片很常见，这是CNN能在图片识别上取得如此成功的原因之一。</p>
<blockquote>
<p>目前所学过的所有多层神经网络的层，都是由一长串神经元组成的，所以在将图片输入给神经网络之前，必须将图片打平成1D的。在CNN中，每个层都是2D的，更容易将神经元和输入做匹配。</p>
</blockquote>
<p>位于给定层第<code>i</code>行、第<code>j</code>列的神经元，和前一层的第<code>i</code>行到第<code>i + fh – 1</code>行、第<code>j</code>列到第<code>j + fw – 1</code>列的输出相连，fh和fw是感受野的高度和宽度（见图14-3）。为了让卷积层能和前一层有相同的高度和宽度，通常给输入加上0，这被称为<strong>零填充（zero padding）。</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-1cfddd1d6ac1db56.png?imageMogr2/auto-orient/strip|imageView2/2/w/1102/format/webp" alt="img"></p>
<p><strong>间隔感受野，将大输入层和小卷积层连接起来</strong>。可以极大降低模型的计算复杂度。一个感受野到下一个感受野的距离称为<strong>步长</strong>。5 × 7 的输入层（加上零填充），连接着一个3 × 4的层，使用 3 × 3 的感受野，步长是2。位于上层第<code>i</code>行、第<code>j</code>列的神经元，连接着前一层的第<code>i × sh</code>到<code>i × sh + fh – 1</code>行、第<code>j × sw</code>到<code>j × sw + fw – 1</code>列的神经元的输出，sh和sw分别是垂直和水平步长。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9968acd895a0095e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1049/format/webp" alt="img"></p>
<h3 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h3><p>神经元的权重可以表示为感受野大小的图片。例如，图14-5展示了两套可能的权重（称为权重，或卷积核）。第一个是黑色的方形，中央有垂直白线（7 × 7的矩阵，除了中间的竖线都是1，其它地方是0）；使用这个矩阵，神经元只能注意到中间的垂直线（因为其它地方都乘以0了）。第二个过滤器也是黑色的方形，但是中间是水平的白线。使用这个权重的神经元只会注意中间的白色水平线。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-8607c8748eef3e4f.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>一层的全部神经元都用一个过滤器，就能输出一个<strong>特征映射（feature map），特征映射可以高亮图片中最为激活过滤器的区域。</strong></p>
<h3 id="堆叠多个特征映射"><a href="#堆叠多个特征映射" class="headerlink" title="堆叠多个特征映射"></a>堆叠多个特征映射</h3><p> 计算卷积层中给定神经元的输出</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-fb733f1a729f0406.png?imageMogr2/auto-orient/strip|imageView2/2/w/1052/format/webp" alt="img"></p>
<blockquote>
<p>同一特征映射中的所有神经元共享一套参数，极大地减少了模型的参数量。当CNN认识了一个位置的图案，就可以在任何其它位置识别出来。相反的，当常规DNN学会一个图案，只能在特定位置识别出来。</p>
</blockquote>
<h3 id="内存需求"><a href="#内存需求" class="headerlink" title="内存需求"></a>内存需求</h3><p>CNN的另一个问题是卷积层需要很高的内存。特别是在训练时，因为反向传播需要所有前向传播的中间值。</p>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>明白卷积层的原理了，池化层就容易多了。池化层的目的是对输入图片做降采样（即，收缩），以降低计算负载、内存消耗和参数的数量（降低过拟合）。</p>
<p>和卷积层一样，池化层中的每个神经元也是之和前一层的感受野里的有限个神经元相连。和前面一样，必须定义感受野的大小、步长和填充类型。但是，池化神经元没有权重，它所要做的是使用聚合函数，比如最大或平均，对输入做聚合。</p>
<p>除了可以减少计算、内存消耗、参数数量，最大池化层还可以带来对小偏移的不变性</p>
<p>最大池化层的缺点：</p>
<ol>
<li>池化层破坏了信息：即使感受野的核是2 × 2，步长是2，输出在两个方向上都损失了一半，总共损失了75%的信息。</li>
<li>对于某些任务，不变性不可取。比如语义分割（将像素按照对象分类）：如果输入图片向右平移了一个像素，输出也应该向右平移一个降速。此时强调的就是等价：输入发生小变化，则输出也要有对应的小变化。</li>
</ol>
<p><strong>平均池化层</strong>和最大池化层很相似，但计算的是感受野的平均值。平均池化层在过去很流行，但最近人们使用最大池化层更多，因为最大池化层的效果更好。初看很奇怪，因为计算平均值比最大值损失的信息要少。但是从反面看，最大值保留了最强特征，去除了无意义的特征，可以让下一层获得更清楚的信息。另外，最大池化层提供了更强的平移不变性，所需计算也更少。</p>
<p><strong>全局平均池化层</strong>。它计算整个特征映射的平均值（就像是平均池化层的核的大小和输入的空间维度一样）。这意味着，全局平均池化层对于每个实例的每个特征映射，只输出一个值。虽然这么做对信息的破坏性很大，却可以用来做输出层。</p>
<p><strong>深度方向最大池化层：</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4030e5fa51363eb8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="CNN架构"><a href="#CNN架构" class="headerlink" title="CNN架构"></a>CNN架构</h3><p>CNN的典型架构是：几个卷积层叠起来（每个卷积层后面跟着一个ReLU层）+ 池化层+卷积层（+ReLU），+池化层。图片在流经神经网络的过程中，变得越来越小，但得益于卷积层，却变得越来越深（特征映射变多了）。在CNN的顶部，还有一个常规的前馈神经网络，由几个全连接层（+ReLU）组成，最终层输出预测（比如，一个输出类型概率的softmax层）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4590999c8c41bf3e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Flenet5" target="_blank" rel="noopener">LeNet-5</a> 也许是最广为人知的CNN架构。由Yann LeCun在1998年创造出来的，被广泛用于手写字识别（MNIST）。结构如下：</p>
<p><img src="//upload-images.jianshu.io/upload_images/7178691-ed2580d5b84531fb.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F80" target="_blank" rel="noopener">AlexNet CNN 架构</a>是2012 ImageNet ILSVRC冠军：Top-5误差率达到了17%，由Alex Krizhevsky、Ilya Sutskever 和 Geoffrey Hinton发明。AlexNet和LeNet-5很相似，只是更大更深，是首个将卷积层堆叠起来的网络，而不是在每个卷积层上再加一个池化层。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-1c5bbecf35d2e8d9.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<blockquote>
<p>数据增强是通过生成许多训练实例的真实变种，来人为增大训练集。因为可以降低过拟合，成为了一种正则化方法。生成出来的实例越真实越好：最理想的情况，人们无法区分增强图片是原生的还是增强过的。简单的添加白噪声没有用，增强修改要是可以学习的（白噪声不可学习）。</p>
<p>例如，可以轻微偏移、旋转、缩放原生图，再添加到训练集中（见图14-12）。这么做可以使模型对位置、方向和物体在图中的大小，有更高的容忍度。如果想让模型对不同光度有容忍度，可以生成对比度不同的照片。通常，还可以水平翻转图片（文字不成、不对称物体也不成）。通过这些变换，可以极大的增大训练集。</p>
</blockquote>
<p>AlexNet还在C1和C3层的ReLU之后，使用了强大的归一化方法，称为<strong>局部响应归一化（LRN）</strong>：激活最强的神经元抑制了相同位置的相邻特征映射的神经元（这样的竞争性激活也在生物神经元上观察到了）。这么做可以让不同的特征映射专业化，特征范围更广，提升泛化能力。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-39ad65a741a0b167.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F81" target="_blank" rel="noopener">GoogLeNet 架构</a>是Google Research的Christian Szegedy及其同事发明的，是2014年ILSVRC的冠军 ，top-5误差率降低到了7%以内。能取得这么大的进步，很大的原因是它的网络比之前的CNN更深。创始模块（inception module）的子网络让GoogLeNet可以用更高的效率使用参数：实际上，GoogLeNet的参数量比AlexNet小10倍（大约是600万，而不是AlexNet的6000万）。</p>
<p><strong>创始模块的架构</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4c0d23d3db687219.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h3><p>ILSVRC 2014年的亚军是<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F83" target="_blank" rel="noopener">VGGNet</a>，作者是来自牛津大学Visual Geometry Group（VGC）的Karen Simonyan 和 Andrew Zisserman。VGGNet的架构简单而经典，2或3个卷积层和1个池化层，然后又是2或3个卷积层和1个池化层，以此类推（总共达到16或19个卷积层）。最终加上一个有两个隐藏层和输出层的紧密网络。VGGNet只用3 × 3的过滤器，但数量很多。</p>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p>何凯明使用<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F82" target="_blank" rel="noopener"><em>Residual Network</em> (或 <em>ResNet</em>)</a>赢得了ILSVRC 2015的冠军，top-5误差率降低到了3.6%以下。ResNet的使用了极深的卷积网络，共152层（其它的变体有1450或152层）。反映了一个总体趋势：<strong>模型变得越来越深，参数越来越少</strong>。训练这样的深度网络的方法是使用跳连接（也被称为快捷连接）：输入信号添加到更高层的输出上。</p>
<p>残差学习：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e911c02ef15d5001.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="使用预训练模型做迁移学习"><a href="#使用预训练模型做迁移学习" class="headerlink" title="使用预训练模型做迁移学习"></a>使用预训练模型做迁移学习</h3><h3 id="分类和定位"><a href="#分类和定位" class="headerlink" title="分类和定位"></a>分类和定位</h3><p>定位图片中的物体可以表达为一个回归任务：预测物体的范围框，一个常见的方法是预测物体中心的水平和垂直坐标，和其高度和宽度。</p>
<p>MSE作为损失函数来训练模型效果很好，但不是评估模型预测边框的好指标。最常见的指标是交并比（Intersection over Union (IoU)）：预测边框与目标边框的重叠部分，除以两者的并集。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-67bc697752690e26.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h3><p>分类并定位图片中的多个物体的任务被称为目标检测。</p>
<h3 id="全卷积网络（fully-convolutional-network，FCN）"><a href="#全卷积网络（fully-convolutional-network，FCN）" class="headerlink" title="全卷积网络（fully convolutional network，FCN）"></a>全卷积网络（fully convolutional network，FCN）</h3><h3 id="全卷积层"><a href="#全卷积层" class="headerlink" title="全卷积层"></a>全卷积层</h3><p>FCN是Jonathan Long在2015年的一篇<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Ffcn" target="_blank" rel="noopener">论文</a>汇总提出的，用于语义分割（根据所属目标，对图片中的每个像素点进行分类）</p>
<h3 id="只看一次（YOLO）"><a href="#只看一次（YOLO）" class="headerlink" title="只看一次（YOLO）"></a>只看一次（YOLO）</h3><p>只看一次”（You Only Look Once，YOLO）是一个非常流行（非常快且准确）的<strong>目标检测架构</strong>的名字，是Joseph Redmon在2015年的一篇<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fyolo" target="_blank" rel="noopener">论文</a>中提出的，2016年优化为<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fyolo2" target="_blank" rel="noopener">YOLOv2</a>，2018年优化为<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fyolo3" target="_blank" rel="noopener">YOLOv3</a>。速度快到甚至可以在实时视频中运行。</p>
<p>平均精度均值（mean Average Precision，mAP）</p>
<blockquote>
<p>目标检测中非常常见的指标是平均精度均值。</p>
<p>假设当召回率为10%时，分类器的精确率是90%，召回率为20%时，精确率是96%。这里就没有取舍关系：使用召回率为20%的分类器就好，因为此时精确率更高。所以当召回率至少有10%时，需要找到最高精确率，即96%。因此，一个衡量模型性能的方法是计算召回率至少为0%时，计算最大精确率，再计算召回率至少为10%时的最大精确率，再计算召回率至少为20%时的最大精确率，以此类推。最后计算这些最大精确率的平均值，这个指标称为平均精确率（Average Precision (AP)）。当有超过两个类时，可以计算每个类的AP，然后计算平均AP（即，mAP）。</p>
</blockquote>
<p>IOU阈值:</p>
<blockquote>
<p>在目标检测中，还有另外一个复杂度：如果系统检测到了正确的类，但是定位错了，当然不能将其作为正预测。一种方法是定义IOU阈值：例如，只有当IOU超过0.5时，预测才是正确的。相应的mAP表示为mAP@0.5（或mAP@50%，或AP50）。</p>
</blockquote>
<h3 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h3><p>在语义分割中，每个像素根据其所属的目标来进行分类。相同类的不同目标是不做区分的。</p>
<h3 id="练习-4"><a href="#练习-4" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>对于图片分类，CNN相对于全连接DNN的优势是什么？</p>
<blockquote>
<ol>
<li>CNN神经元之间部分连接，参数少</li>
<li>当CNN的核学会识别一个特征后，可以在图像任意位置识别该特征，而DNN只能在特定的位置识别。</li>
<li>DNN将图像数据flatten，每个像素之间的位置关系不能被保持</li>
</ol>
</blockquote>
</li>
<li><p>考虑一个CNN，有3个卷积层，每个都是3 × 3的核，步长为2，零填充。最低的层输出100个特征映射，中间的输出200个特征映射，最上面的输出400个。输入图片是200 × 300像素的RGB图。这个CNN的总参数量是多少？如果使用32位浮点数，做测试需要多少内存？批次是50张图片，训练时的内存消耗是多少？</p>
<blockquote>
<p>第一层：[3x3x3(RGB三通道)+1（偏置向）]*100=2800</p>
<p>第二层：[3x3x100+1]*200=180200</p>
<p>第三层：[3x3x200+1]*400=720400</p>
<p>所以三层共有903400个参数。</p>
<hr>
<p>32位浮点数在内存中占4个字节。假设stride=2</p>
<p>第一层有100个feature map，4x100x100x150=6百万字节（6MB）</p>
<p>同理第二层：4x200x50x75=3MB</p>
<p>第三层：4x400x25x38=1.5MB</p>
<p>但是只需同时保证两层的计算结果，最大为前两层：9MB</p>
<p>参数占用内存：4*903400=3.6MB</p>
<p>共12.6MB</p>
<hr>
<p>反向传播要求保留向前计算的所有结果，每个实例三层-10.5MB，mini-batch=50，需要525MB</p>
<p>50张图片需要：50x4x200x300x3=36MB</p>
<p>参数需要3.6MB</p>
<p>还需要一些内存记录梯度</p>
<p>共需要564.6MB</p>
</blockquote>
</li>
<li><p>如果训练CNN时GPU内存不够，解决该问题的5种方法是什么？</p>
<blockquote>
<ol>
<li>减小batch的大小</li>
<li>使用更大的strider</li>
<li>去掉几层卷积层</li>
<li>使用16位浮点数，而不是32位浮点数</li>
<li>分布式训练，将CNN分布到多台计算机上</li>
</ol>
</blockquote>
</li>
<li><p>为什么使用最大池化层，而不是同样步长的卷积层？</p>
<blockquote>
<p>最大池化层不需要参数，同样不长的卷积层需要参数。</p>
</blockquote>
</li>
<li><p>为什么使用局部响应归一化层？</p>
<blockquote>
<p>LRN:激活最强的神经元抑制了相同位置的相邻特征映射的神经元（这样的竞争性激活也在生物神经元上观察到了）。这么做可以让不同的特征映射专业化，特征范围更广，提升泛化能力。</p>
</blockquote>
</li>
<li><p>AlexNet相对于LeNet-5的创新在哪里？GoogLeNet、ResNet、SENet、Xception的创新又是什么？</p>
<blockquote>
<p>AlexNet箱规与LeNet-5 更大更深，并且将卷积层链接到一起，而不是卷积层+池化层</p>
<p>GoogLeNet：引入创始模块，可以层数更深，而参数更少</p>
<p>ResNet：跳接</p>
<p>SENet： 在原始架构的每个单元（比如创始模块或残差单元）上添加了一个小的神经网络，称为SE块</p>
<p>Xception：使用depthwise separable convolutional layers</p>
</blockquote>
</li>
<li><p>什么是全卷积网络？如何将紧密层转变为卷积层？</p>
<blockquote>
<p>FCN: 完全由卷积层和池化层构成。在目标检测和语义分割领域很有用，因为只需要扫描图片一次。</p>
<p>将紧密层替换为核大小等于层输入大小的卷积层，使用valid padding，激活函数可以不用变。</p>
</blockquote>
<p>语义分割的主要技术难点是什么？</p>
<blockquote>
<p>在流经CNN网络过程中，一些空间信息会消失</p>
</blockquote>
</li>
<li><p>从零搭建你的CNN，并在MNIST上达到尽可能高的准确率。</p>
</li>
<li><p>使用迁移学习来做大图片分类，经过下面步骤：</p>
<p>a. 创建每个类至少有100张图片的训练集。例如，你可以用自己的图片基于地点来分类（沙滩、山、城市，等等），或者使用现成的数据集（比如从TensorFlow Datasets）。</p>
<p>b. 将其分成训练集、验证集、训练集。</p>
<p>c. 搭建输入管道，包括必要的预处理操作，最好加上数据增强。</p>
<p>d. 在这个数据集上，微调预训练模型。</p>
</li>
<li><p>尝试下TensorFlow的<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fstyletuto" target="_blank" rel="noopener">风格迁移教程</a>。用深度学习生成艺术作品很有趣。</p>
</li>
</ol>
<h2 id="第15章-使用RNN和CNN处理序列"><a href="#第15章-使用RNN和CNN处理序列" class="headerlink" title="第15章 使用RNN和CNN处理序列"></a>第15章 使用RNN和CNN处理序列</h2><p>循环神经网络，一类可以预测未来的网络（当然，是到某一点为止）</p>
<p>RNN面对的两大难点：</p>
<ul>
<li>不稳定梯度（换句话说，在第11章中讨论的梯度消失/爆炸），可以使用多种方法缓解，包括循环dropout和循环层归一化。</li>
<li>有限的短期记忆，可以通过LSTM 和 GRU 单元延长。</li>
</ul>
<h3 id="循环神经元和层"><a href="#循环神经元和层" class="headerlink" title="循环神经元和层"></a>循环神经元和层</h3><p>最简单的 RNN，由一个神经元接收输入，产生一个输出，并将输出发送回自己。 在每个时间步<code>t</code>（也称为一个帧），这个循环神经元接收输入x(t)以及它自己的前一时间步长 y(t-1) 的输出。 因为第一个时间步骤没有上一次的输出，所以是0。可以用时间轴来表示这个微小的网络。 这被称为随时间展开网络。</p>
<p> 循环神经网络（左），随时间展开网络（右）</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e945414fcaeeed67.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>一层循环神经元（左），及其随时间展开（右）</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-79c6bd0d2b869c73.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>每个循环神经元有两组权重：一组用于输入x(t)，另一组用于前一时间步长 y(t-1) 的输出。 </p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b26a1770e6dc75da.png?imageMogr2/auto-orient/strip|imageView2/2/w/1046/format/webp" alt="img"></p>
<h3 id="记忆单元"><a href="#记忆单元" class="headerlink" title="记忆单元"></a>记忆单元</h3><p>由于时间<code>t</code>的循环神经元的输出，是由所有先前时间步骤计算出来的的函数，你可以说它有一种记忆形式。神经网络的一部分，保留一些跨越时间步长的状态，称为存储单元（或简称为单元）。单个循环神经元或循环神经元层是非常基本的单元，只能学习短期规律。</p>
<p>一般情况下，时间步<code>t</code>的单元状态，记为 h(t)（<code>h</code>代表“隐藏”），是该时间步的某些输入和前一时间步状态的函数：h(t) = f(h(t–1), x(t))。 其在时间步<code>t</code>的输出，表示为 y(t)，也和前一状态和当前输入的函数有关。 我们已经讨论过的基本单元，输出等于单元状态，但是在更复杂的单元中并不总是如此。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-860eda4472257180.png?imageMogr2/auto-orient/strip|imageView2/2/w/1095/format/webp" alt="img"></p>
<p>序列到序列（左上），序列到矢量（右上），矢量到序列（左下），延迟序列到序列（右下）</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-22b08969517e84c2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<blockquote>
<p>一个序列到矢量的网络，称为编码器，后面跟着一个称为解码器的矢量到序列的网络。 可以用于将句子从一种语言翻译成另一种语言。 给网络输入一种语言的一句话，编码器会把这个句子转换成单一的矢量表征，然后解码器将这个矢量解码成另一种语言的句子。 这种称为<strong>编码器 - 解码器</strong>的两步模型，比用单个序列到序列的 RNN实时地进行翻译要好得多，<strong>因为句子的最后一个单词可以影响翻译的第一句话，所以需要等到听完整个句子才能翻译。</strong></p>
</blockquote>
<h3 id="训练RNN"><a href="#训练RNN" class="headerlink" title="训练RNN"></a>训练RNN</h3><p>训练RNN诀窍是在时间上展开，然后只要使用常规反向传播。 这个策略被称为<strong>时间上的反向传播（BPTT）</strong>。</p>
<h3 id="预测时间序列"><a href="#预测时间序列" class="headerlink" title="预测时间序列"></a>预测时间序列</h3><p>研究网站每小时的活跃用户数，或是所在城市的每日气温，或公司的财务状况，用多种指标做季度衡量。在这些任务中，数据都是一个序列，每步有一个或多个值，被称为<strong>时间序列</strong>。在前两个任务中，每个时间步只有一个值，它们是<strong>单变量时间序列</strong>。在财务状况的任务中，每个时间步有多个值（利润、欠账，等等），所以是<strong>多变量时间序列</strong>。</p>
<ul>
<li>典型的任务是预测未来值，称为“预测”。</li>
<li>另一个任务是填空：预测（或“后测”）过去的缺失值，这被称为“填充”。</li>
</ul>
<blockquote>
<p>当处理时间序列时（和其它类型的时间序列），输入特征通常用3D数组来表示，其形状是 [批次大小, 时间步数, 维度]，对于单变量时间序列，其维度是1，多变量时间序列的维度是其维度数。</p>
</blockquote>
<h3 id="基线模型"><a href="#基线模型" class="headerlink" title="基线模型"></a>基线模型</h3><p>使用RNN之前，最好有基线指标，否则做出来的模型可能比基线模型还糟。例如，最简单的方法，是预测每个序列的最后一个值。这个方法被称为<strong>朴素预测</strong>，有时很难被超越。</p>
<h3 id="实现一个简单地RNN"><a href="#实现一个简单地RNN" class="headerlink" title="实现一个简单地RNN"></a>实现一个简单地RNN</h3><p>不用指定输入序列的长度（和之前的模型不同），因为循环神经网络可以处理任意的时间步（这就是为什么将第一个输入维度设为<code>None</code>）</p>
<blockquote>
<p>趋势和季节性</p>
<p>还有其它预测时间序列的模型，比如权重移动平均模型或自动回归集成移动平均（ARIMA）模型。某些模型需要先移出趋势和季节性。例如，如果要研究网站的活跃用户数，它每月会增长10%，就需要去掉这个趋势。训练好模型之后，在做预测时，你可以将趋势加回来做最终的预测。相似的，如果要预测防晒霜的每月销量，会观察到明显的季节性：每年夏天卖的多。需要将季节性从时间序列去除，比如计算每个时间步和前一年的差值（这个方法被称为差分）。然后，当训练好模型，做预测时，可以将季节性加回来，来得到最终结果。</p>
<p>使用RNN时，一般不需要做这些，但在有些任务中可以提高性能，因为模型不是非要学习这些趋势或季节性。</p>
</blockquote>
<h3 id="深度RNN"><a href="#深度RNN" class="headerlink" title="深度RNN"></a>深度RNN</h3><p>将多个神经元的层堆起来，就形成了深度RNN。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-0a727314de2f6f56.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="处理长序列"><a href="#处理长序列" class="headerlink" title="处理长序列"></a>处理长序列</h3><p>在训练长序列的 RNN 模型时，必须运行许多时间步，展开的RNN变成了一个很深的网络。正如任何深度神经网络一样，它面临<strong>不稳定梯度问题</strong>，使训练无法停止，或训练不稳定。另外，当RNN处理长序列时，<strong>RNN会逐渐忘掉序列的第一个输入</strong>。</p>
<h4 id="应对不稳定梯度"><a href="#应对不稳定梯度" class="headerlink" title="应对不稳定梯度"></a>应对不稳定梯度</h4><p>好的参数初始化方式，更快的优化器，dropoutd都可以应对RNN的梯度不稳定。但是非饱和激活函数（如 ReLU）的帮助不大；事实上，它会导致RNN更加不稳定。</p>
<blockquote>
<p>假设梯度下降更新了权重，可令第一个时间步的输出提高。因为每个时间步使用的权重相同，第二个时间步的输出也会提高，这样就会导致输出爆炸 —— 不饱和激活函数不能阻止这个问题。要降低爆炸风险，可以<strong>使用更小的学习率</strong>，更简单的方法是<strong>使用饱和激活函数</strong>，比如双曲正切函数（所以tanh是默认选项）。</p>
</blockquote>
<p>批归一化也没什么帮助。不能在时间步骤之间使用批归一化，只能在循环层之间使用。</p>
<p><strong>层归一化，由Jimmy Lei Ba等人在2016年提出：跟批归一化很像，但不是在批次维度上做归一化，而是在特征维度上归一化。</strong>这么做的一个优势是可以独立对每个实例，实时计算所需的统计量。训练和测试中的行为是一致的（这点和BN相反），且不需要使用指数移动平均来估计训练集中所有实例的特征统计。和BN一样，层归一化会学习每个输入的比例和偏移参数。<strong>在RNN中，层归一化通常用在输入和隐藏态的线型组合之后。</strong></p>
<h4 id="处理短期记忆问题"><a href="#处理短期记忆问题" class="headerlink" title="处理短期记忆问题"></a>处理短期记忆问题</h4><p>由于数据在RNN中流动时会经历转换，每个时间步都损失了一定信息。一定时间后，第一个输入实际上会在 RNN 的状态中消失。</p>
<p><strong>长短时记忆神经单元 LSTM：</strong></p>
<p>长短时记忆单元在 1997 年<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgoo.gl%2Fj39AGv" target="_blank" rel="noopener">由 Sepp Hochreiter 和 Jürgen Schmidhuber 首次提出</a>，并在接下来的几年内经过 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fgraves" target="_blank" rel="noopener">Alex Graves</a>、<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F94" target="_blank" rel="noopener">Haşim Sak</a>、<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F95" target="_blank" rel="noopener">Wojciech Zaremba</a> 等人的改进，逐渐完善。如果把 LSTM 单元看作一个黑盒，可以将其当做基本单元一样来使用，但 LSTM 单元比基本单元性能更好：收敛更快，能够感知数据的长时依赖。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-a333026f0dd537b5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>可以认为 h(t) 是短期记忆状态，c(t) 是长期记忆状态。</p>
<ul>
<li>输出 g(t)的层是主要层。它的常规任务是分析当前的输入 x(t) 和前一时刻的短时状态 h(t-1)。基本单元中与这种结构一样，直接输出了 h(t)   和 y(t) 。而LSTM 单元中的该层的输出不会直接出去，将最重要的部分保存在长期状态中（其余部分丢掉）。</li>
<li>其它三个全连接层被是门控制器（gate controller）。其采用 Logistic 作为激活函数，输出范围在 0 到 1 之间。可以看到，这三个层的输出提供给了逐元素乘法操作，当输入为 0 时门关闭，输出为 1 时门打开。具体讲：</li>
<li>遗忘门（由 f(t) 控制）决定哪些长期记忆需要被删除；</li>
<li>输入门（由 i(t) 控制） 决定哪部分 g(t) 应该被添加到长时状态中。</li>
<li>输出门（由 o(t) 控制）决定长时状态的哪些部分要读取和输出为 h(t) 和y(t)。</li>
</ul>
<p>LSTM 单元能够学习识别重要输入（输入门的作用），存储进长时状态，并保存必要的时间（遗忘门功能），并在需要时提取出来。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-33df138d7fe796c5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1040/format/webp" alt="img"></p>
<h4 id="LSTM的变体"><a href="#LSTM的变体" class="headerlink" title="LSTM的变体"></a>LSTM的变体</h4><h5 id="窥孔连接"><a href="#窥孔连接" class="headerlink" title="窥孔连接"></a>窥孔连接</h5><p>在基本 LSTM 单元中，门控制器只能观察当前输入 x(t) 和前一时刻的短时状态 h(t-1)。不妨让各个门控制器窥视一下长时状态，获取一些上下文信息。</p>
<p> Felix Gers 和 Jürgen Schmidhuber 在 2000 年提出了一个 LSTM 的变体，带有叫做窥孔连接的额外连接：把前一时刻的长时状态 c(t-1) 输入给遗忘门和输入门，当前时刻的长时状态c(t)输入给输出门。这么做时常可以提高性能，但不一定每次都能有效，也没有清晰的规律显示哪种任务适合添加窥孔连接。</p>
<h5 id="GRU-单元"><a href="#GRU-单元" class="headerlink" title="GRU 单元"></a>GRU 单元</h5><p><img src="https://upload-images.jianshu.io/upload_images/7178691-b3d78efe2539d55c.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>门控循环单元（GRU）由Kyunghyun Cho于2014年提出，引入了编码器-解码器网络。GRU单元是 LSTM 单元的简化版本，能实现同样的性能。简化主要在一下几个方面：</p>
<ul>
<li>长时状态和短时状态合并为一个矢量 h(t)。</li>
<li>用一个门控制器z(t)控制遗忘门和输入门。如果门控制器输出 1，则遗忘门打开（=1），输入门关闭（1 - 1 = 0）。如果输出0，则相反。换句话说，如果当有记忆要存储，那么就必须先在其存储位置删掉该处记忆。这构成了 LSTM 本身的常见变体。</li>
<li>GRU 单元取消了输出门，每个时间步输出全态矢量。但是，增加了一个控制门 r(t) 来控制前一状态的哪些部分呈现给主层g(t)。</li>
</ul>
<h3 id="使用1D卷积层处理序列"><a href="#使用1D卷积层处理序列" class="headerlink" title="使用1D卷积层处理序列"></a>使用1D卷积层处理序列</h3><p>对于音频、长时间序列或长序列，学习长时模式就很困难。应对的方法之一，是使用缩短输入序列，例如使用1D卷积层。</p>
<h3 id="WaveNet"><a href="#WaveNet" class="headerlink" title="WaveNet"></a>WaveNet</h3><p>WaveNet架构将1D卷积层叠起来，每一层膨胀率（如何将每个神经元的输入分开）变为2倍：第一个卷积层一次只观察两个时间步，下一层观察四个时间步（感受野是4个时间步的长度），下一层观察八个时间步，以此类推。用这种方式，底下的层学习短时模式，上面的层学习长时模式。得益于翻倍的膨胀率，这个网络可以非常高效地处理极长的序列。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-93e236002a0fa2e2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="练习-5"><a href="#练习-5" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>你能说出序列到序列RNN 的几个应用吗？序列到矢量的应用？矢量到序列的应用？</p>
<blockquote>
<p>序列到序列RNN：可以预测天气，股票信息。</p>
<p>序列到矢量RNN：判断音乐的流派</p>
<p>矢量到序列RNN：通过几个参数创建一段音乐</p>
</blockquote>
</li>
<li><p>RNN层的输入要有多少维？每一维表示什么？输出呢？</p>
<blockquote>
<p>RNN需要有三维的输入：batch size x time steps x number of input feature</p>
</blockquote>
</li>
<li><p>如果搭建深度序列到序列RNN，哪些RNN层要设置<code>return_sequences=True</code>？序列到矢量RNN又如何？</p>
<blockquote>
<p>深度序列到序列RNN：所有的RNN层都需要设置<code>return_sequences=True</code></p>
<p>sequence-to-vector RNN：除了顶层的所有RNN层都需要设置<code>return_sequences=True</code></p>
</blockquote>
</li>
<li><p>假如有一个每日单变量时间序列，想预测接下来的七天。要使用什么RNN架构？</p>
<blockquote>
<p>序列到矢量RNN：除了顶层都设置 <code>return_sequences=True</code> ，输出层使用七个神经元.</p>
</blockquote>
</li>
<li><p>训练RNN的困难是什么？如何应对？</p>
<blockquote>
<p>梯度不稳定：使用小学习率，梯度裁剪，层归一化，dropout</p>
<p>短期记忆：使用LSTM<code>or</code>GRU层</p>
</blockquote>
</li>
<li><p>画出LSTM单元的架构图？</p>
<blockquote>
<p>​</p>
</blockquote>
</li>
<li><p>为什么在RNN中使用1D卷积层？</p>
<blockquote>
<p>RNN层是串行的，为了预测t时间之后的结果，需要先计算早些时候结果，使得它不能并行计算，</p>
<p>另一方面，一维卷积层不需要之前结果的记忆，可以根据输入中某一窗口的数值计算得到任意时刻的输出。</p>
<p>再者，1D卷积层不是循环的（recurrent），梯度不稳定问题将大大改善</p>
<p>在RNN网络中使用一层或者多层1D卷积层预处理输入数据，可以downsampling，帮助RNN探测到long-term patterns</p>
</blockquote>
</li>
<li><p>哪种神经网络架构可以用来分类视频？</p>
<blockquote>
<p>对于音频、长时间序列或长序列，学习长时模式就很困难。应对的方法之一，使用1D卷积层缩短输入序列.</p>
</blockquote>
</li>
<li><p>为SketchRNN数据集（TensorFlow Datasets中有），训练一个分类模型。</p>
</li>
<li><p>下载<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fbach" target="_blank" rel="noopener">Bach chorales</a>数据集，并解压。它含有382首巴赫作曲的赞美歌。每首的长度是100到640时间步，每个时间步包含4个整数，每个整数对应一个钢琴音符索引（除了0，表示没有音符）。训练一个可以预测下一个时间步（四个音符）的模型，循环、卷积、或混合架构。然后使用这个模型来生成类似巴赫的音乐，每个时间一个音符：可以给模型一首赞美歌的开头，然后让其预测接下来的时间步，然后将输出加到输入上，再让模型继续预测。或者查看<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fcoconet" target="_blank" rel="noopener">Google的 Coconet 模型</a>，它是Google来做巴赫曲子的。</p>
</li>
</ol>
<h2 id="第16章-使用RNN和注意力机制进行自然语言处理"><a href="#第16章-使用RNN和注意力机制进行自然语言处理" class="headerlink" title="第16章 使用RNN和注意力机制进行自然语言处理"></a>第16章 使用RNN和注意力机制进行自然语言处理</h2><h3 id="有状态RNN"><a href="#有状态RNN" class="headerlink" title="有状态RNN"></a>有状态RNN</h3><p>无状态RNN：在每个训练迭代中，模型从全是0的隐藏状态开始训练，然后在每个时间步更新其状态，在最后一个时间步，隐藏态就被丢掉，以后再也不用了。如果让RNN保留这个状态，供下一个训练批次使用如何呢？这么做的话，尽管反向传播只在短序列传播，模型也可以学到长时规律。这被称为有状态RNN。</p>
<h3 id="集束搜索"><a href="#集束搜索" class="headerlink" title="集束搜索"></a>集束搜索</h3><p>它跟踪k个最大概率的句子列表，在每个解码器步骤延长一个词，然后再关注其中k个最大概率的句子。参数k被称为集束宽度。</p>
<h3 id="视觉注意力"><a href="#视觉注意力" class="headerlink" title="视觉注意力"></a>视觉注意力</h3><p>最先用途之一是利用视觉注意力生成图片标题：卷积神经网络首先处理图片，生成一些特征映射，然后用带有注意力机制的解码器RNN来生成标题，每次生成一个词。在每个解码器时间步（每个词），解码器使用注意力模型聚焦于图片的一部分。</p>
<h3 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h3><p>多头注意力基于缩放点积注意力层（Scaled Dot-Product Attention），</p>
<blockquote>
<p>假设编码器分析输入句子“They played chess”，编码器分析出“They”是主语，“played”是动词，然后用词的表征编码这些信息。假设解码器已经翻译了主语，接下来要翻译动词。要这么做的话，它需要从输入句子取动词。这有点像查询字典：编码器创建了字典{“subject”: “They”, “verb”: “played”, …}，解码器想查找键“verb”对应的值是什么。但是，模型没有离散的token来表示键（比如“subject” 或 “verb”）；它只有这些（训练中学到的）信息的矢量化表征所以用来查询的键，不会完美对应前面字典中的键。解决的方法是计算查询词和键的相似度，然后用softmax函数计算概率权重。如果表示动词的键和查询词很相似，则键的权重会接近于1。然后模型可以计算对应值的加权和，如果“verb”键的权重接近1，则加权和会接近于词“played”的表征。</p>
</blockquote>
<p>缩放点积注意力：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-da0506216d22820b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1124/format/webp" alt="img"></p>
<h3 id="练习-6"><a href="#练习-6" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>有状态RNN和无状态RNN相比，优点和缺点是什么？</p>
<blockquote>
<p>无状态RNN只能找到不大于训练窗口长度的pattern</p>
<p>有状态RNN可以找到longer-term patterns，但是有状态RNN中，相邻批次的数据可能是不独立的，identically distributed</p>
</blockquote>
</li>
<li><p>为什么使用编码器-解码器RNN，而不是普通的序列到序列RNN，来做自动翻译？</p>
<blockquote>
<p>单独训练单词，自动翻译的结果不会很好。</p>
<p>普通的序列到序列RNN在读入第一个单词就开始翻译，但是编码器-解码器RNN会读完整个句子再翻译</p>
</blockquote>
</li>
<li><p>如何处理长度可变的输入序列？长度可变的输出序列怎么处理？</p>
<blockquote>
<p>padding the shorter sequences, 使用遮挡忽略padding token，这样每一批次中所有的序列可以由相同的长度。之后tf.keras中嵌套张量可以用来表示长度可变的序列。</p>
<p>如果输出序列的长度可以提前预知（比如和输入的长度相同），可以直接根据长度忽略掉序列长度后的token，计算损失函数；如果输出序列的长度未知，可以输出一个表示序列结束的token</p>
</blockquote>
</li>
<li><p>什么是集束搜索，为什么要用集束搜索？可以用什么工具实现集束搜索？</p>
<blockquote>
<p>beam search: 提高编码器-解码器模型的表现，算法跟踪k个最大概率的句子列表，在每个解码器步骤延长一个词，然后再关注其中k个最大概率的句子，k称为集束宽度。该算法可以并行。</p>
<p>Tensorflow addons可以用来实现集束搜索。</p>
</blockquote>
</li>
<li><p>什么是注意力机制？用处是什么？</p>
<blockquote>
<p>注意力机制最早用于编码器-解码器模型，用于长输入，可以让解码器在每个时间步关注特别的（被编码器编码的）词。</p>
</blockquote>
</li>
<li><p>Transformer架构中最重要的层是什么？它的目的是什么？</p>
</li>
<li><p>什么时候需要使用采样softmax？</p>
</li>
<li><p>Hochreiter 和 Schmidhuber 在关于LSTM的<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F93" target="_blank" rel="noopener">论文</a>中使用了嵌入Reber语法。这是一种人工的语法，用来生成字符串，比如 “BPBTSXXVPSEPE”。查看Jenny Orr对它的<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F108" target="_blank" rel="noopener">介绍</a>。选择一个嵌入Reber语法（比如Jenny Orr的论文中展示的），然后训练一个RNN来判断字符串是否符合语法。你需要先写一个函数来生成训练批次，其中50%符合语法，50%不符合语法。</p>
</li>
<li><p>训练一个编码器-解码器模型，它可以将日期字符串从一个格式变为另一个格式（例如，从“April 22, 2019”变为“2019-04-22”）。</p>
</li>
<li><p>阅读TensorFlow的<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fnmttuto" target="_blank" rel="noopener">《Neural Machine Translation with Attention tutorial》</a>。</p>
</li>
<li><p>使用一个最近的语言模型（比如，BERT），来生成一段更具信服力的莎士比亚文字。</p>
</li>
</ol>
<h2 id="第17章-使用自编码器和GAN做表征学习和生成式学习"><a href="#第17章-使用自编码器和GAN做表征学习和生成式学习" class="headerlink" title="第17章 使用自编码器和GAN做表征学习和生成式学习"></a>第17章 使用自编码器和GAN做表征学习和生成式学习</h2><p>自编码器是能够在无监督（即，训练集是未标记）的情况下学习输入数据的紧密表征（叫做潜在表征或编码）的人工神经网络。这些编码通常具有比输入数据低得多的维度，使得自编码器对降维有用。自编码器还可以作为强大的特征检测器，它们可以用于无监督的深度神经网络预训练。一些自编码器是生成式模型：他们能够随机生成与训练数据非常相似的新数据。</p>
<p>对抗生成网络（GAN）生成的人脸可以非常逼真，甚至让人认为他们是真实存在的人。</p>
<p>自编码器和GAN都是无监督的，都可以学习紧密表征，都可以用作生成模型，有许多相似的应用，但原理非常不同：</p>
<blockquote>
<p>自编码器是通过学习，将输入复制到输出。听起来很简单，但内部结构会使其相当困难。例如，可以限制潜在表征的大小，或者可以给输入添加噪音，训练模型恢复原始输入。这些限制组织自编码器直接将输入复制到输出，可以强迫模型学习数据的高效表征。总而言之，编码是自编码器在一些限制下学习恒等函数的副产品。</p>
<p>GAN包括两个神经网络：一个生成器尝试生成和训练数据相似的数据，一个判别器来区分真实数据和假数据。特别之处在于，生成器和判别器在训练过程中彼此竞争：生成器就像一个制造伪钞的罪犯，而判别器就像警察一样，要把真钱挑出来。对抗训练（训练竞争神经网络），被认为是近几年的一大进展。在2016年，Yann LeCun甚至说GAN是过去10年机器学习领域最有趣的发明。</p>
</blockquote>
<h3 id="自编码器"><a href="#自编码器" class="headerlink" title="自编码器"></a>自编码器</h3><p>自编码器通常具有与多层感知器相同的体系结构，但输出层中的神经元数量必须等于输入数量。由于自编码器试图重构输入，所以输出通常被称为重建，并且损失函数包含重建损失，当重建与输入不同时，重建损失会对模型进行惩罚。由于内部表征具有比输入数据更低的维度（它是 2D 而不是 3D），所以自编码器被认为是不完整的。 不完整的自编码器不能简单地将其输入复制到编码，但它必须找到一种方法来输出其输入的副本。 它被迫学习输入数据中最重要的特征（并删除不重要的特征）。</p>
<p>自编码器不限于紧密网络：还有卷积自编码器和循环自编码器。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-96e89d75c6e86056.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="栈式自编码器"><a href="#栈式自编码器" class="headerlink" title="栈式自编码器"></a>栈式自编码器</h3><p>自编码器可以有多个隐藏层。 在这种情况下，它们被称为栈式自编码器（或深度自编码器）。栈式自编码器的架构以中央隐藏层（编码层）为中心通常是对称的。 </p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-97d3ae02870c17ac.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="使用栈式自编码器做无监督预训练"><a href="#使用栈式自编码器做无监督预训练" class="headerlink" title="使用栈式自编码器做无监督预训练"></a>使用栈式自编码器做无监督预训练</h4><p>用所有训练数据训练自编码器，然后用编码器层创建新的神经网络</p>
<h4 id="关联权重"><a href="#关联权重" class="headerlink" title="关联权重"></a>关联权重</h4><p>将解码器层的权重与编码器层的权重相关联。 这样减半了模型中的权重数量，加快了训练速度，并限制了过度拟合的风险。</p>
<h4 id="一次训练一个自编码器"><a href="#一次训练一个自编码器" class="headerlink" title="一次训练一个自编码器"></a>一次训练一个自编码器</h4><p>不是一次完成整个栈式自编码器的训练，而是一次训练一个浅自编码器，然后将所有这些自编码器堆叠到一个栈式自编码器（因此名称）中，通常要快得多，</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-95d0229917d60063.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>现在的一大趋势是Geoffrey Hinton等人在2006年发现的，靠这种贪婪层级方法，可以用无监督方式训练神经网络。他们还使用了受限玻尔兹曼机（RBM，见附录E）。但在2007年，Yoshua Bengio发现只用自编码器也可以达到不错的效果。</p>
<h3 id="卷积自编码器"><a href="#卷积自编码器" class="headerlink" title="卷积自编码器"></a>卷积自编码器</h3><p>对于图片任务，卷积神经网络比紧密网络的效果更好。所以如果想用自编码器来处理图片的话（例如，无监督预训练或降维），需要搭建一个卷积自编码器。编码器是一个包含卷积层和池化层的常规CNN。</p>
<h3 id="循环自编码器"><a href="#循环自编码器" class="headerlink" title="循环自编码器"></a>循环自编码器</h3><p>如果想用自编码器处理序列，比如对时间序列或文本无监督学习和降维，则循环神经网络要优于紧密网络。搭建循环自编码器很简单：编码器是一个序列到矢量的RNN，而解码器是矢量到序列的RNN。</p>
<h3 id="学习方法"><a href="#学习方法" class="headerlink" title="学习方法"></a>学习方法</h3><p>为了让自编码学习特征，我们限制了编码层的大小（使它处于不完整的状态）。还可以使用许多其他的限制方法，可以让编码层和输入层一样大，甚至更大，得到一个过完成的自编码器。</p>
<h4 id="降噪自编码"><a href="#降噪自编码" class="headerlink" title="降噪自编码"></a>降噪自编码</h4><p>为其输入添加噪声，对其进行训练以恢复原始的无噪声输入。 噪声可以是添加到输入的纯高斯噪声，或者可以随机关闭输入，就像 dropout。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-870922646a65a746.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="稀疏自编码器"><a href="#稀疏自编码器" class="headerlink" title="稀疏自编码器"></a>稀疏自编码器</h4><p>特征提取的另一种约束是稀疏性：通过向损失函数添加适当的项，让自编码器减少编码层中活动神经元的数量。</p>
<p> Kullback-Leibler 散度，具有比均方误差更强的梯度，</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b6809b315bb6dba7.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>给定两个离散的概率分布<code>P</code>和<code>Q</code>，这些分布之间的 KL 散度，记为 DKL(P // Q)</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-a96113128470474a.png?imageMogr2/auto-orient/strip|imageView2/2/w/816/format/webp" alt="img"></p>
<h3 id="变分自编码器（VAE）"><a href="#变分自编码器（VAE）" class="headerlink" title="变分自编码器（VAE）"></a>变分自编码器（VAE）</h3><p>特点：</p>
<ol>
<li>它们是概率自编码器，意味着即使在训练之后，它们的输出部分也是偶然确定的（相对于仅在训练过程中使用随机性的自编码器的去噪）。</li>
<li>它们是生成自编码器，这意味着它们可以生成看起来像从训练集中采样的新实例。</li>
</ol>
<p>与 RBM （受限玻尔兹曼机）非常相似。编码器产生平均编码<code>μ</code>和标准差<code>σ</code>。 然后从平均值<code>μ</code>和标准差<code>σ</code>的高斯分布随机采样实际编码。 之后，解码器正常解码采样的编码。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-8103b55a6c0b39cb.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>损失函数：重建损失+潜在的损失</p>
<p>潜在损失：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9e0614d9745baf00.png?imageMogr2/auto-orient/strip|imageView2/2/w/928/format/webp" alt="img"></p>
<p>n是编码维度，μi 和 σi是编码的第ith个成分的平均值和标准差。矢量u和σ是编码器的输出。</p>
<p>一种常见的变体是训练编码器输出<code>γ= log(σ^2)</code>而不是<code>σ</code>。 这个方法的计算更稳定，且可以加速训练。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-fd8844d61cc65f10.png?imageMogr2/auto-orient/strip|imageView2/2/w/986/format/webp" alt="img"></p>
<h3 id="对抗生成网络（GAN）"><a href="#对抗生成网络（GAN）" class="headerlink" title="对抗生成网络（GAN）"></a>对抗生成网络（GAN）</h3><p>Ian Goodfellow在2014年提出，本质很简单：让神经网络互相竞争，让其在竞争中进步。</p>
<ul>
<li><p>生成器</p>
<p>使用随机分布作为输入（通常为高斯分布），并输出一些数据，比如图片。可以将随机输入作为生成文件的潜在表征（即，编码）。生成器的作用和变分自编码器中的解码器差不多，可以用同样的方式生成图片（只要输入一些高斯噪音，就能输出全新的图片）。但是，生成器的训练过程很不一样。</p>
</li>
</ul>
<ul>
<li><p>判别器</p>
<p>从训练集取出一张图片，判断图片是真是假。</p>
</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e3e9a45c0fefb30e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>每次训练迭代分成两个阶段：</p>
<ol>
<li><p>第一个阶段，训练判别器。</p>
<p>从训练集取样一批真实图片，数量与假图片相同。假图片的标签设为0，真图片的标签设为1，判别器用这个有标签的批次训练一步，使用二元交叉熵损失。反向传播在这一阶段只优化判别器的权重。</p>
</li>
<li><p>第二个阶段，训练生成器。</p>
<p>首先用生成器产生另一个批次的假图片，再用判别器来判断图片是真是假。这一次不添加真图片，但所有标签都设为1（真）：换句话说，我们想让生成器产生可以让判别器信以为真的图片。判别器的权重在这一步是冷冻的，所以反向传播只影响生成器。</p>
</li>
</ol>
<h4 id="训练GAN的难点"><a href="#训练GAN的难点" class="headerlink" title="训练GAN的难点"></a>训练GAN的难点</h4><p>在训练中，生成器和判别器不断试图超越对方，这是一个零和博弈。随着训练的进行，可能会达成博弈学家称为纳什均衡的状态：每个选手都不改变策略，并认为对方也不会改变策略。不同的初始状态和动力学会导致不同的均衡。</p>
<p>论文作者证明，GAN只能达到一种均衡状态：生成器产生完美的真实图片，同时让判别器来判断（50%为真，50%为假）。</p>
<p>最大的困难是模式坍塌：生成器的输出逐渐变得不那么丰富。为什么会这样？假设生成器产生的鞋子图片比其它类的图片更让人信服，假鞋子图片就会更多的欺骗判别器，就会导致生成更多的鞋子图片。逐渐的，生成器会忘掉如何生成其它类的图片。同时，判别器唯一能看到的就是鞋子图片，所以判别器也会忘掉如何判断其它类的图片。GAN会逐渐在一些类上循环，从而对哪一类都不擅长。</p>
<p>GAN会对超参数特别敏感：微调超参数会特别花费时间。</p>
<h3 id="深度卷积GAN（DCGAN）"><a href="#深度卷积GAN（DCGAN）" class="headerlink" title="深度卷积GAN（DCGAN）"></a>深度卷积GAN（DCGAN）</h3><p>搭建稳定卷积GAN的建议如下：</p>
<ul>
<li>（判别器中）用卷积步长（strided convolutions）、（生成器中）用转置卷积，替换池化层。</li>
<li>生成器和判别器都使用批归一化，除了生成器的输出层和判别器的输入层。</li>
<li>去除深层架构中的全连接隐藏层。</li>
<li>生成器的输出层使用tanh激活，其它层使用ReLU激活。</li>
<li>判别器的所有层使用leaky ReLU激活。</li>
</ul>
<h3 id="条件GAN（CGAN）"><a href="#条件GAN（CGAN）" class="headerlink" title="条件GAN（CGAN）"></a>条件GAN（CGAN）</h3><p>如果将图片的类作为另一个输入，输入给生成器和判别器，它们都能学到每个类的样子，你就可以控制生成器产生图片的类。这被称为条件GAN（CGAN）。</p>
<h3 id="方法：用于提高输出的散度（避免模式坍塌），使训练更稳定："><a href="#方法：用于提高输出的散度（避免模式坍塌），使训练更稳定：" class="headerlink" title="方法：用于提高输出的散度（避免模式坍塌），使训练更稳定："></a>方法：用于提高输出的散度（避免模式坍塌），使训练更稳定：</h3><h4 id="GAN的渐进式变大"><a href="#GAN的渐进式变大" class="headerlink" title="GAN的渐进式变大"></a>GAN的渐进式变大</h4><p>建议在训练时，先从生成小图片开始，然后逐步给生成器和判别器添加卷积层，生成越来越大的图片（4 × 4, 8 × 8, 16 × 16, …, 512 × 512, 1,024 × 1,024）。这个方法和栈式自编码器的贪婪层级训练很像。余下的层添加到生成器的末端和判别器的前端，之前训练好的层仍然可训练。</p>
<h4 id="小批次标准差层"><a href="#小批次标准差层" class="headerlink" title="小批次标准差层"></a>小批次标准差层</h4><p>添加在判别器的靠近末端的位置。对于输入的每个位置，计算批次（<code>S = tf.math.reduce_std(inputs, axis=[0, -1])</code>）中，所有通道所有实例的标准差。接着，这些标准差对所有点做平均，得到一个单值（<code>v = tf.reduce_mean(S)</code>）。最后，给批次中的每个实例添加一个额外的特征映射，填入计算得到的单值（<code>tf.concat([inputs, tf.fill([batch_size, height, width, 1], v)], axis=-1)</code>）。如果生成器产生的图片没有什么偏差，则判别器的特征映射的标准差会特别小。有了这个层，判别器就可以做出判断。可以让生成器产生高散度的输出，降低模式坍塌的风险。</p>
<h4 id="相等的学习率"><a href="#相等的学习率" class="headerlink" title="相等的学习率"></a>相等的学习率</h4><p>使用一个简单的高斯分布（平均值为0，标准差为1）初始化权重，而不使用He初始化。但是，权重在运行时（即，每次执行层）会变小：会除以<img src="https://math.jianshu.com/math?formula=%5Csqrt%7B2%2Fninputs%7D" alt="\sqrt{2/ninputs}">，ninputs是层的输入数。使用这个方法可以显著提升GAN使用RMSProp、Adam和其它适应梯度优化器时的性能。事实上，这些优化器用估计标准差归一化了梯度更新，所以有较大动态范围的参数需要更长时间训练，而较小动态范围的参数可能更新过快，会导致不稳定。通过缩放模型的部分参数，可以保证参数的动态范围在训练过程中一致，可以用相同的速度学习。这样既加速了训练，也做到了稳定。</p>
<h4 id="像素级归一化层"><a href="#像素级归一化层" class="headerlink" title="像素级归一化层"></a>像素级归一化层</h4><p>生成器的每个卷积层之后添加。它能归一化每个激活函数，基于相同图片相同位置的所有激活，而且跨通道（除以平均激活平方的平方根）。在TensorFlow的代码中，这是<code>inputs / tf.sqrt(tf.reduce_mean(tf.square(X), axis=-1, keepdims=True) + 1e-8)</code>（平滑项1e-8用于避免零除）。这种方法可以避免生成器和判别器的过分竞争导致的激活爆炸。</p>
<h3 id="StyleGAN"><a href="#StyleGAN" class="headerlink" title="StyleGAN"></a>StyleGAN</h3><p>Nvidia团队在2018年的一篇<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fstylegan" target="_blank" rel="noopener">论文</a>中提出了高性能的高清图片生成架构，StyleGAN。作者在生成器中使用了风格迁移方法，使生成的图片和训练图片在每个层次，都有相同的局部结构，极大提升了图片的质量。判别器和损失函数没有变动，只修改了生成器。StyleGAN包含两个网络</p>
<ol>
<li><p>映射网络</p>
<p>一个八层的MLP，将潜在表征<code>z</code>（即，编码）映射为矢量<code>w</code>。矢量然后传给仿射变换，输出许多矢量。这些矢量在不同级别控制着生成图片的风格，从细粒度纹理（比如，头发颜色）到高级特征（比如，成人或孩子）。总而言之，映射网络将编码变为许多风格矢量。</p>
</li>
<li><p>合成网络</p>
<p>负责生成图片。它有一个固定的学好的输入（这个输入在训练之后是不变的，但在训练中被反向传播更新）。和之前一样，合成网络使用多个卷积核上采样层处理输入，但有两处不同：首先，输入和所有卷积层的输出（在激活函数之前）都添加了噪音。第二，每个噪音层的后面是一个适应实例归一化（AdaIN）层：它独立标准化每个特征映射（减去平均值，除以标准差），然后使用风格矢量确定每个特征映射的缩放和偏移（风格矢量对每个特征映射包含一个缩放和一个偏置项）</p>
</li>
</ol>
<p>StyleGAN使用了一种称为混合正则（或风格混合）的方法，生成图的一定比例使用两个编码来生成。特别的，编码c1 和 c2发送给映射网络，得到两个风格矢量w1 和 w2。然后合成网络使用风格w1生成第一级，用w2生成其余的。级的选取是随机的。这可以防止模型认为临近的级是有关联的，会导致GAN的局部性，每个风格矢量只会影响生成图的有限数量的特性。</p>
<h3 id="练习-7"><a href="#练习-7" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>自编码器主要用来做什么？</p>
<blockquote>
<p>无监督预训练，特征提取，降维，生成模型，异常值检测</p>
</blockquote>
</li>
<li><p>假设你想训练一个分类器，有许多未打标签的训练数据，只有一千多打了标签的数据。如何使用自编码器来解决这个问题？</p>
<blockquote>
<p>用所有的数据训练一个自编码器，然后将编码器部分用作分类器，用有标签的数据训练。如果有标签数据特别少，可能需要先冻结重复使用的几层。</p>
</blockquote>
</li>
<li><p>如果自编码器完美重建了输入，它一定是个好的自编码器吗？如何评估自编码器的表现？</p>
<blockquote>
<p>不一定，如果自编码器非常复杂，重建结果非常好，但是可能不能学到特征，泛化能力不好。</p>
<p>但是反过来，如果重建结果不好，那一定不是一个好的自编码器。</p>
<p>计算重建损失函数来评估自编码器的表现。</p>
</blockquote>
</li>
<li><p>自编码器的欠完成和过完成是什么？超欠完成的风险是什么？过完成的风险是什么？</p>
<blockquote>
<p>欠完成（undercomplete）：coding层比输入和输出层小，重建输入比较困难。</p>
<p>过完成（overcomplete）：coding层比输入和输出层大，仅仅将输入copy到输出，无法学习有用的特征。</p>
</blockquote>
</li>
<li><p>如何将栈式自编码器的权重连起来？这么做的意义是什么？</p>
<blockquote>
<p>将自编码器的编码器和解码器的权重连起来（解码器的权重=编码器权重的转置），减少参数的个数，使得训练收敛更快，减少过拟合的风险。</p>
</blockquote>
</li>
<li><p>什么是生成式模型？可以举出生成式自编码器的例子吗？</p>
<blockquote>
<p>生成模型可以随机生成可以以假乱真的数据实例。</p>
<p>在MNIST上训练的生成模型，可以随机生成手写数字的图像，一般情况下，生成模型的输出分布和训练集上的分布相似。如果想要输出特定类别的输出，可以使用变分编码器。</p>
</blockquote>
</li>
<li><p>GAN是什么？可以用于什么任务？</p>
<blockquote>
<p>GAN（generative adversarial network）生成对抗网络：是一种神经网络模型，有生成器和判别器两个部分。生成器的目的生成和训练集相似的实例，欺骗判别器，而判别器得目的是从生成的实例中分辨哪些是真正的实例。在每一轮训练中，判别器类似于二分类器，而生成器最大化判别器的误差。</p>
<p>GAN可以用于：高级的图像处理任务：上色，超分辨率，将草图生成照片化的图像。</p>
</blockquote>
</li>
<li><p>训练GAN的难点是什么？</p>
<blockquote>
<p>最大的困难是模式坍塌：生成器的输出逐渐变得不那么丰富。</p>
<p>训练不稳定，可能开始表现很好，几次迭代之后开始坍塌或者发散。</p>
<p>GAN会对超参数特别敏感：微调超参数会特别花费时间。</p>
</blockquote>
</li>
<li><p>用去噪音自编码器预训练一个图片分类器。可以使用MNIST，或是更复杂的图片数据集，比如CIFAR10。不管用的是什么数据集，遵循下面的步骤：</p>
<ul>
<li>将数据集分成训练集和测试集。在完整训练集上，训练一个深度去噪音自编码器。</li>
<li>检查图片正确重建了。可视化最激活编码层神经元的图片。</li>
<li>搭建一个分类DNN，使用自编码器的浅层。用训练集中的500张图片来训练。然后判断预训练是否提升了性能？</li>
</ul>
</li>
<li><p>用刚才选择的数据集，训练一个变分自编码器。用它来生成图片。或者，用一个没有标签的数据集，来生成新样本。</p>
</li>
<li><p>训练一个DCGAN来处理选择的数据集，生成新图片。添加经验接力，看看它是否有作用。再将其变为一个条件GAN，可以控制生成的类。</p>
</li>
</ol>
<h2 id="第18章-强化学习"><a href="#第18章-强化学习" class="headerlink" title="第18章 强化学习"></a>第18章 强化学习</h2><p> 2013 年一个革命性的发展：来自英国的研究者发起了Deepmind 项目，这个项目可以学习去玩任何从头开始的 Atari 游戏，在多数游戏中，比人类玩的还好，它仅使用像素作为输入而没有使用游戏规则的任何先验知识。在 2016 年 3 月以他们的系统AlphaGo战胜了世界围棋冠军李世石而告终。DeepMind 在 2014 被谷歌以超过 5 亿美元收购。</p>
<p>原理：将深度学习运用到强化学习领域</p>
<p>策略梯度和深度 Q 网络（DQN），包括讨论马尔可夫决策过程（MDP）。</p>
<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>在强化学习中，智能体在环境（environment）中观察（observation）并且做出决策（action），随后它会得到奖励（reward）。它的目标是去学习如何行动能最大化<strong>期望奖励</strong>。</p>
<h3 id="OpenAI-Gym"><a href="#OpenAI-Gym" class="headerlink" title="OpenAI Gym"></a>OpenAI Gym</h3><p>OpenAI Gym 是一个工具包，它提供各种各样的模拟环境（Atari 游戏，棋盘游戏，2D 和 3D 物理模拟等等）</p>
<h3 id="评价行为：信用分配问题"><a href="#评价行为：信用分配问题" class="headerlink" title="评价行为：信用分配问题"></a>评价行为：信用分配问题</h3><p>在强化学习中，智能体获得的指导的唯一途径是通过奖励，奖励通常是稀疏的和延迟的。例如，如果智能体在 100 个步骤内设法平衡杆，它怎么知道它采取的 100 个行动中的哪一个是好的，哪些是坏的？它所知道的是，在最后一次行动之后，杆子坠落了，但最后一次行动肯定不是负全责的。这被称为信用分配问题：当智能体得到奖励时，很难知道哪些行为应该被信任（或责备）。</p>
<p>基于这个动作后得分的总和来评估这个个动作，通常在每个步骤中应用衰减因子<code>r</code>。</p>
<h3 id="策略搜索"><a href="#策略搜索" class="headerlink" title="策略搜索"></a>策略搜索</h3><p>智能体用于改变行为的算法称为策略。</p>
<ol>
<li>神经网络策略，把观察作为输入，输出要执行的动作。</li>
<li>搜寻策略空间的方法是遗传算法。</li>
<li>另一种方法是使用优化技术，通过评估奖励关于策略参数的梯度，然后通过跟随梯度向更高的奖励（梯度上升）调整这些参数。这种方法被称为<strong>策略梯度（policy gradient, PG）。</strong></li>
</ol>
<p><strong>策略梯度</strong></p>
<ol>
<li>让神经网络策略玩几次游戏，并在每一步计算梯度，这使得智能体更可能选择行为，但不应用这些梯度。</li>
<li>运行几次后，计算每个动作的得分（使用前面段落中描述的方法）。</li>
<li>如果一个动作的分数是正的，这意味着动作是好的，可应用较早计算的梯度，以便将来有更大的的概率选择这个动作。但是，如果分数是负的，这意味着动作是坏的，要应用相反梯度来使得这个动作在将来采取的可能性更低。我们的方法就是简单地将每个梯度向量乘以相应的动作得分。</li>
<li>最后，计算所有得到的梯度向量的平均值，并使用它来执行梯度下降步骤。</li>
</ol>
<h4 id="马尔可夫决策过程"><a href="#马尔可夫决策过程" class="headerlink" title="马尔可夫决策过程"></a>马尔可夫决策过程</h4><p>在二十世纪初，数学家 Andrey Markov 研究了<strong>没有记忆的随机过程，称为马尔可夫链</strong>。这样的过程具有固定数量的状态，并且在每个步骤中随机地从一个状态演化到另一个状态。它从状态<code>S</code>演变为状态<code>S&#39;</code>的概率是固定的，它只依赖于<code>(S, S&#39;)</code>对，而不是依赖于过去的状态（系统没有记忆）。</p>
<p><strong>马尔可夫决策过程</strong>最初是在 20 世纪 50 年代由 Richard Bellman <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F133" target="_blank" rel="noopener">描述</a>的。它们类似于马尔可夫链，但有一个不同：在状态转移的每一步中，一个智能体可以选择几种可能的动作中的一个，并且过渡概率取决于所选择的动作。此外，一些状态过渡返回一些奖励（正或负），智能体的目标是找到一个策略，随着时间的推移将最大限度地提高奖励。</p>
<p>估计任何状态<code>S</code>的最佳状态值的方法，记作<code>V(s)</code>，它是智能体在其采取最佳行为达到状态<code>s</code>后所有衰减未来奖励的总和的平均期望。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-6c97696a5b56dafd.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>Bellman 发现了一种非常类似的算法来估计最优状态-动作值（<em>state-action values</em>），通常称为 Q 值。状态行动<code>(S, A)</code>对的最优 Q 值，记为<code>Q*(s, a)</code>，是智能体在到达状态<code>S</code>，然后选择动作<code>A</code>之后平均衰减未来奖励的期望的总和。但是在它看到这个动作的结果之前，假设它在该动作之后的动作是最优的。</p>
<h4 id="时间差分学习"><a href="#时间差分学习" class="headerlink" title="时间差分学习"></a>时间差分学习</h4><p>具有离散动作的强化学习问题通常可以被建模为马尔可夫决策过程，但是智能体最初不知道转移概率是什么（它不知道<code>T(s, a, s′)</code>），并且它不知道奖励会是什么（它不知道<code>R(s, a, s′)</code>）。它必须经历每一个状态和每一次转变并且至少知道一次奖励，并且如果要对转移概率进行合理的估计，就必须经历多次。</p>
<p>时间差分学习（TD 学习）算法与数值迭代算法非常类似，但考虑到智能体仅具有 MDP 的部分知识。</p>
<h4 id="Q-学习"><a href="#Q-学习" class="headerlink" title="Q-学习"></a>Q-学习</h4><p>Q-学习算法是 Q 值迭代算法的改编版本，其适应转移概率和回报在初始未知的情况。</p>
<p>Q-学习被称为离线策略算法，因为正在训练的策略不是正在执行的策略。</p>
<p><strong>缺点：</strong>不能很好地扩展到具有许多状态和动作的大（甚至中等）的 MDP。</p>
<p><strong>解决方案：</strong>找到一个函数Qθ(s,a)，使用可管理数量的参数（根据矢量θ）来近似 Q 值。这被称为<strong>近似 Q 学习。</strong></p>
<p>在2013年， DeepMind 表明使用深度神经网络可以工作得更好，特别是对于复杂的问题。它不需要任何特征工程。用于估计 Q 值的 DNN 被称为深度 Q 网络（DQN），并且使用近似 Q 学习的 DQN 被称为<strong>深度 Q 学习。</strong></p>
<h4 id="深度Q-学习的变体"><a href="#深度Q-学习的变体" class="headerlink" title="深度Q-学习的变体"></a>深度Q-学习的变体</h4><h5 id="固定Q-值目标"><a href="#固定Q-值目标" class="headerlink" title="固定Q-值目标"></a>固定Q-值目标</h5><p>在基本的深度Q-学习算法中，模型不仅做预测还自己设置目标。有点像一只狗追自己的尾巴。反馈循环使得网络不稳定：会发生分叉、摇摆、冻结，等等。要解决问题，DeepMind在2013年的论文中使用了两个DQN，而不是一个：第一个是在线模型，它在每一步进行学习，并移动智能体；另一个是目标模型只定义目标。目标模型只是在线模型的克隆。</p>
<h5 id="双DQN"><a href="#双DQN" class="headerlink" title="双DQN"></a>双DQN</h5><h5 id="优先经验接力"><a href="#优先经验接力" class="headerlink" title="优先经验接力"></a>优先经验接力</h5><h5 id="对决DQN"><a href="#对决DQN" class="headerlink" title="对决DQN"></a>对决DQN</h5><h4 id="探索策略"><a href="#探索策略" class="headerlink" title="探索策略"></a>探索策略</h4><p>只有在探索策略充分探索 MDP 的情况下，Q 学习才能起作用。尽管一个纯粹的随机策略保证最终访问每一个状态和每个转换多次，但可能需要很长的时间这样做。因此，一个更好的选择是使用 ε 贪婪策略：在每个步骤中，它以概率<code>ε</code>随机地或以概率为<code>1-ε</code>贪婪地选择具有最高 Q 值的动作。ε 贪婪策略的优点（与完全随机策略相比）是，它将花费越来越多的时间来探索环境中有趣的部分，因为 Q 值估计越来越好，同时仍花费一些时间访问 MDP 的未知区域。</p>
<h3 id="练习-8"><a href="#练习-8" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>如何定义强化学习？它与传统的监督和非监督学习有什么不同？</p>
<blockquote>
<p>​</p>
</blockquote>
</li>
<li><p>你能想到什么本章没有提到过的强化学习的应用？环境是什么？智能体是什么？什么是可能的动作，什么是奖励？</p>
<blockquote>
<p>音乐个人化：环境是用户个人化的网络电台。智能体是软件决定下一首播放音乐。可能动作是播放目录下的任一首音乐。如果用户没有切换音乐则获得奖励，如果用户跳过该音乐则负奖励，如果用户离开，或者非常大的负奖励。</p>
</blockquote>
</li>
<li><p>什么是衰减率？如果修改了衰减率那最优策略会变化吗？</p>
<blockquote>
<p>在评估一个动作的时候，强化学习通常会把几步的奖励加起来，给最近的奖励大的权重，之前的奖励小的权重。衰减率就是这个权重的差别。</p>
<p>如果修改了衰减率最优策略肯定会发生变化。</p>
</blockquote>
</li>
<li><p>如何测量强化学习智能体的表现？</p>
<blockquote>
<p>用几步的奖励和来评估强化学习智能体的表现。</p>
</blockquote>
</li>
<li><p>什么是信用分配问题？它怎么出现的？怎么解决？</p>
<blockquote>
<p>产生信用分配问题的原因是不知道之前的动作对当下动作获得奖励的贡献。</p>
<p>使用shorter-term rewards。</p>
</blockquote>
</li>
<li><p>使用接力缓存的目的是什么？</p>
<blockquote>
<p>一个智能体会在环境的某一部分中停留一段时间，所以在这一阶段经历类似。将所有经验存储在接力缓存（或接力记忆）中，每次训练迭代，从中随机采样一个批次。这样可以降低训练批次中的经验相关性，可以极大的提高训练效果。</p>
<p><a href="https://www.zhihu.com/question/52064135" target="_blank" rel="noopener">知乎相关答案</a></p>
</blockquote>
</li>
<li><p>什么是off策略 RL 算法？</p>
<blockquote>
<p>在强化学些中利用动作来探索（exploration 行为策略），之后得到应用的策略中去（exploitation 目标策略）</p>
<p>on-policy的目标策略和行为策略相同，直接利用数据优化策略，但可能学习到局部最优，没有办法很好的同时探索，利用。而off-policy RL将目标策略和行为策略分开，可以在保持探索的同时，更能求到全局最优值。</p>
<p>Q-learning就是一个这样的例子。</p>
</blockquote>
</li>
<li><p>使用策略梯度处理 OpenAI gym 的“LunarLander-v2” 环境。需要安装<code>Box2D</code>依赖（<code>python3 -m pip install gym[box2d]</code>）。</p>
</li>
<li><p>用任何可行的算法，使用TF-Agents训练可以达到人类水平的可以玩SpaceInvaders-v4的智能体。</p>
</li>
<li><p>如果你有大约 100 美元备用，你可以购买 Raspberry Pi 3 再加上一些便宜的机器人组件，在 Pi 上安装 TensorFlow，然后让我们嗨起来~！举个例子，看看 Lukas Biewald 的这个<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F2" target="_blank" rel="noopener">有趣的帖子</a>，或者看看 GoPiGo 或 BrickPi。从简单目标开始，比如让机器人转向最亮的角度（如果有光传感器）或最近的物体（如果有声呐传感器），并移动。然后可以使用深度学习：比如，如果机器人有摄像头，可以实现目标检测算法，检测人并向人移动。还可以利用RL算法让智能体自己学习使用马达达到目的。</p>
</li>
</ol>
<h2 id="第19章-规模化训练和部署TensorFlow模型"><a href="#第19章-规模化训练和部署TensorFlow模型" class="headerlink" title="第19章 规模化训练和部署TensorFlow模型"></a>第19章 规模化训练和部署TensorFlow模型</h2><h3 id="练习-9"><a href="#练习-9" class="headerlink" title="练习"></a>练习</h3><ol>
<li>SavedModel包含什么？如何检查内容？</li>
<li>什么时候使用TF Serving？它有什么特点？可以用什么工具部署TF Serving？</li>
<li>如何在多个TF Serving实例上部署模型？</li>
<li>为什么使用gRPC API而不是REST API，查询TF Serving模型？</li>
<li>在移动和嵌入设备上运行，TFLite减小模型的大小有什么方法？</li>
<li>什么是伪量化训练，有什么用？</li>
<li>什么是模型并行和数据并行？为什么推荐后者？</li>
<li>在多台服务器上训练模型时，可以使用什么分布策略？如何进行选择？</li>
<li>训练模型（或任意模型），部署到TF Serving或Google Cloud AI Platform上。写客户端代码，用REST API 或 gRPC API做查询。更新模型，部署新版本。客户端现在查询新版本。回滚到第一个版本。</li>
<li>用一台机器多个GPU、<code>MirroredStrategy</code>策略，训练模型（如果没有GPU，可以使用带有GPU的Colaboratory，创建两个虚拟GPU）。再用<code>CentralStorageStrategy</code>训练一次，比较训练时间。</li>
<li>在Google Cloud AI Platform训练一个小模型，使用黑盒超参数调节。</li>
</ol>
<p>​                                                                                                                                                                                          </p>
]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>sklearn</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在Jupyter Notebook中使用Python虚拟环境？</title>
    <url>/2020/08/25/%E5%A6%82%E4%BD%95%E5%9C%A8Jupyter%20Notebook%E4%B8%AD%E4%BD%BF%E7%94%A8Python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%EF%BC%9F/</url>
    <content><![CDATA[<p>电脑中多版本python并存，直接安装过python，使用过anaconda全家桶，同时创建过虚拟环境（虽然我也不知道两个都是python3.7为啥要用虚拟环境），这就导致了一个问题。</p>
<a id="more"></a>
<h2 id="虚拟环境下运行spyder"><a href="#虚拟环境下运行spyder" class="headerlink" title="虚拟环境下运行spyder"></a>虚拟环境下运行spyder</h2><p>在打开spyder时，默认使用base，如何使用虚拟环境呢？</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda activate env</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入环境后</span></span><br><span class="line">spyder</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果已经打开spyder了</span></span><br><span class="line">spyder --new-instance</span><br></pre></td></tr></table></figure>
<h2 id="Jupyter-notebook使用虚拟环境"><a href="#Jupyter-notebook使用虚拟环境" class="headerlink" title="Jupyter notebook使用虚拟环境"></a>Jupyter notebook使用虚拟环境</h2><p>即便通过anaconda创造了新的虚拟环境，但是在jupyter 中并没有体现出来。</p>
<blockquote>
<p>尝试过<code>conda activate env</code> 进入虚拟环境，再执行jupyter notebook，结果还是使用默认python（D:\\Program Files (x86)\\Anaconda3\py37\\python.exe’），此时会出现一些包import失败的问题。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如何查看使用的是哪个版本的python</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path</span><br><span class="line">sys.executable</span><br></pre></td></tr></table></figure>
<h3 id="解决办法1："><a href="#解决办法1：" class="headerlink" title="解决办法1："></a>解决办法1：</h3><p>直接在sys.path这个列表append虚拟环境下的python路径和python库路径。</p>
<p>但是这种解决方案没有永久性，退出之后重新打开该文件运行时，则又会import失败，输出sys.path，发现之前加入的路径也不存在了。</p>
<h3 id="解决办法2："><a href="#解决办法2：" class="headerlink" title="解决办法2："></a>解决办法2：</h3><p><strong>用anaconda内生插件解决问题</strong> </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda install nb_conda</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看已有的kernels</span></span><br><span class="line">jupyter kernelspec list</span><br></pre></td></tr></table></figure>
<p>再次启动jupyter notebook，就能看到<strong>所有虚拟环境</strong>都显示出来了。</p>
<p><strong>用jupyter插件解决问题</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda activate env</span><br><span class="line">conda install ipykernel</span><br><span class="line">python -m ipykernel install --name --display-name</span><br></pre></td></tr></table></figure>
<p>网上还有方法是安装ipykernel，不知道为什么，我可以看到kernel显示了虚拟环境，但是切换之后，没有效果，sys.exectubale仍然输出默认python的路径。</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ol>
<li>anaconda powershell prompt 和 anaconda prompt的区别：前者多了一些linux命令，如pwd等，类似windows下cmd和windows powershell的区别。</li>
<li>虽然可以在prompt中通过cd切换文件夹，再打开jupyter notebook，或者在jupyter notebook命令后指定文件夹路径，但略显繁琐。<ul>
<li>在windows powershell下也可以运行jupyter notebook，所以可以在windows下打开文件夹，shift+鼠标右键，打开windows powershell，输入jupyter notebook命令</li>
<li>打开目标文件夹，选中上方文件位置栏，输入jupyter notebook即可</li>
<li>另外，如果想在windows powershell中激活虚拟环境，可执行：<code>conda init</code></li>
</ul>
</li>
<li>也可以到该文件夹下，右键-git bash，在git bash中启动jupyter notebook</li>
<li>注意2,3需要将anaconda安装路径里面的Scripts和Library\bin路径添加到windows系统环境变量中。</li>
</ol>
<h2 id="jupyter-notebook快捷键"><a href="#jupyter-notebook快捷键" class="headerlink" title="jupyter notebook快捷键"></a>jupyter notebook快捷键</h2><p>Jupyter Notebook 有两种键盘输入模式。</p>
<ol>
<li>编辑模式（enter进入），可以向单元中键入代码或文本；此时单元框线为绿色。</li>
<li>命令模式（Esc开启），键盘输入运行程序命令；此时单元框线为灰蓝色。</li>
</ol>
<h3 id="编辑模式"><a href="#编辑模式" class="headerlink" title="编辑模式"></a>编辑模式</h3><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>含义</th>
<th>命令</th>
<th>含义</th>
<th>命令</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>tab</td>
<td>代码补全或缩进</td>
<td>Ctrl+Up</td>
<td>跳到单元开头</td>
<td>Shift+Enter</td>
<td>运行本单元，选中下一单元</td>
</tr>
<tr>
<td>shift+tab</td>
<td>提示</td>
<td>Ctrl+End</td>
<td>跳到单元末尾</td>
<td>Ctrl+Enter</td>
<td>运行本单元</td>
</tr>
<tr>
<td>ctrl+]</td>
<td>缩进</td>
<td>Ctrl+Down</td>
<td>跳到单元末尾</td>
<td>Alt+Enter</td>
<td>运行本单元，在下面插入一单元</td>
</tr>
<tr>
<td>ctrl+[</td>
<td>解除缩进</td>
<td>Ctrl+Left</td>
<td>跳到左边一个字首</td>
<td>Ctrl+Shift+-</td>
<td>分割单元</td>
</tr>
<tr>
<td>ctrl+A</td>
<td>全选</td>
<td>Ctrl+Right</td>
<td>跳到右边一个字首</td>
<td>Ctrl+Shift+Subtract</td>
<td>分割单元</td>
</tr>
<tr>
<td>ctrl+Z</td>
<td>复原</td>
<td>Ctrl+Backspace</td>
<td>删除前面一个字</td>
<td>Ctrl+S</td>
<td>文件存盘</td>
</tr>
<tr>
<td>ctrl+shift+z</td>
<td>再做</td>
<td>Ctrl+Delete</td>
<td>删除后面一个字</td>
<td>Shift</td>
<td>忽略</td>
</tr>
<tr>
<td>ctrl+y</td>
<td>再做</td>
<td>Esc</td>
<td>进入命令模式</td>
<td>Up</td>
<td>光标上移或转入上一单元</td>
</tr>
<tr>
<td>ctrl+Home</td>
<td>跳到单元开头</td>
<td>Ctrl+M</td>
<td>进入命令模式</td>
<td>Down</td>
<td>光标下移或转入下一单元</td>
</tr>
</tbody>
</table>
</div>
<h3 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h3><div class="table-container">
<table>
<thead>
<tr>
<th>命令</th>
<th>含义</th>
<th>命令</th>
<th>含义</th>
<th>命令</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>enter</td>
<td>转入编辑模式</td>
<td>C</td>
<td>复制选中的单元</td>
<td>Shift+Enter</td>
<td>运行本单元，选中下一单元</td>
</tr>
<tr>
<td>Y</td>
<td>单元转入代码状态</td>
<td>V</td>
<td>粘贴到下方单元</td>
<td>Ctrl+Enter</td>
<td>运行本单元</td>
</tr>
<tr>
<td>M</td>
<td>单元转入markdown状态</td>
<td>Z</td>
<td>恢复删除的最后一个单元</td>
<td>Alt+Enter</td>
<td>运行本单元，在下面插入一单元</td>
</tr>
<tr>
<td>R</td>
<td>单元转入raw状态</td>
<td>DD</td>
<td>删除选中的单元</td>
<td>shift+K</td>
<td>扩大选中上方单元</td>
</tr>
<tr>
<td>1</td>
<td>设定 1 级标题</td>
<td>Ctrl+S</td>
<td>文件存盘</td>
<td>shift+J</td>
<td>扩大选中下方单元</td>
</tr>
<tr>
<td>2</td>
<td>设定 12级标题</td>
<td>S</td>
<td>文件存盘</td>
<td>shift+O</td>
<td>转换输出滚动</td>
</tr>
<tr>
<td>A</td>
<td>在上方插入新单元</td>
<td>L</td>
<td>转换行号</td>
<td>shift</td>
<td>忽略</td>
</tr>
<tr>
<td>B</td>
<td>在下方插入新单元</td>
<td>O</td>
<td>转换输出</td>
<td>K</td>
<td>选中上方单元</td>
</tr>
<tr>
<td>X</td>
<td>剪切选中的单元</td>
<td>Q</td>
<td>关闭页面</td>
<td>J</td>
<td>选中下方单元</td>
</tr>
<tr>
<td>shift+V</td>
<td>粘贴到上方单元</td>
<td>H</td>
<td>显示快捷键帮助</td>
<td>Up</td>
<td>选中上方单元</td>
</tr>
<tr>
<td>shift+M</td>
<td>合并选中的单元</td>
<td>space</td>
<td>向下滚动</td>
<td>Down</td>
<td>选中下方单元</td>
</tr>
</tbody>
</table>
</div>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://blog.csdn.net/w55100/article/details/88925697" target="_blank" rel="noopener">简书：使用anaconda虚拟环境运行Jupyter Notebook详解</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/50456606" target="_blank" rel="noopener">Jupyter notebok 环境配置，与kernel切换（切换虚拟环境）</a></p>
<p><a href="https://blog.csdn.net/guolaoban11/article/details/103469952?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param" target="_blank" rel="noopener">jupyter notebook 打开任意文件夹，最简捷！！</a></p>
<p><a href="https://blog.csdn.net/lzbmc/article/details/102955750" target="_blank" rel="noopener">Jupyter Notebook在指定文件夹（位置）打开</a></p>
<p><a href="https://blog.csdn.net/lawme/article/details/51034543" target="_blank" rel="noopener">Jupyter Notebook 的快捷键</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>jupyter notebook</tag>
      </tags>
  </entry>
  <entry>
    <title>三星平板N8000刷机</title>
    <url>/2020/08/26/%E4%B8%89%E6%98%9F%E5%B9%B3%E6%9D%BFN8000%E5%88%B7%E6%9C%BA/</url>
    <content><![CDATA[<blockquote>
<p>刷机包+工具如下：</p>
<p>CWMRecoveryGTN8000.tar +  lineage-14.1-20170116-UNOFFICIAL-n8000.zip</p>
<p>线刷宝（用以进入挖煤模式）+ Odin</p>
</blockquote>
<a id="more"></a>
<p>家里小朋友在上网课，想买个平板，唤起了我对三星平板的记忆，大概13年入手，不过一两年没开过机了。</p>
<p>好不容易返校，拿出平板，发现不错，还能充电，也能开机。里面乱七八糟都是些啥，还有人人，干脆恢复出厂设置吧。</p>
<p>问题就出在这里，恢复出厂设置后发现没有三星应用中心了，也不能更新，因为之前用了kingsroot。那似乎只能刷机了。</p>
<ol>
<li><p>开机键+电源上键进入recovery模式，有install from external storage的选项，但是不支持第三方ROM包。</p>
<p>强行刷第三方包，会出出现：</p>
<p>E:failed to verify whole-file signature<br>e:signature verification failed<br>installation aborted</p>
</li>
<li><p>要刷第三方ROM包，需要先刷第三方recovery包。</p>
<p>电源键+音量下键进入挖煤模式，使用Odin刷入第三方REC包，旧版选择PDA，新版选择AP，其他不要勾选，一些默认勾选的也要去掉，点击start，几秒钟就可以了。</p>
</li>
</ol>
<p><img src="http://www.galaxyclub.cn//Upload/IMAGES/18/0507/126b124121ee40feb9f95aa5bc78c040_650x0.png" alt="【技术】Odin中的术语BL、AP、CP、CSC是什么意思？"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>BL(Bootloader) **</strong>：**</th>
<th>代表 <strong>引导程序</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AP (Application Processor or PDA)  **</strong>：**</td>
<td>表示<strong>Android系统</strong>（可能代表Android系统分区）; 在之前的Odin版本中，这被称为“PDA”</td>
</tr>
<tr>
<td><strong>CP(Core Processor**</strong>） ：**</td>
<td><strong> </strong>代表 <strong>调制解调器</strong></td>
</tr>
<tr>
<td><strong>CSC(Co numer Software Customization) **</strong>：**</td>
<td>代表 <strong>消费者软件定制</strong>，它包含特定于该地区的软件包，运营商品牌和APN设置（就像不同的运营商的数据接入点名称不通）。</td>
</tr>
<tr>
<td><strong>PIT (Partition Information Table)  **</strong>：**</td>
<td>代表 <strong>分区信息表</strong>，如果你搞砸分区表，或者由于分区表布局的变化，你只需要用它就好了。</td>
</tr>
</tbody>
</table>
</div>
<p>但又遇到问题了：电源键+音量下键无法进入挖煤模式，不知道是否跟之前用第三方软件root过有关，并且我的板子的电源键也不太好用，事态似乎陷入了僵局，只能求助第三方刷机软件<a href="http://www.xianshuabao.com/features/?fromsite=bd_xsb" target="_blank" rel="noopener">线刷宝</a>。</p>
<p>进入挖煤模式后，ID:COM 变成蓝色（实际上，正常开机连接时，应该是蓝色，挖煤模式连接时应为黄色，可能还是之前root过得原因）</p>
<p>不需要付费模式，只需要借助工具箱进入挖煤模式即可！也可以通过线刷宝进入recovery模式（谁让我的电源键不好用呢）。</p>
<ol>
<li>输入第三方ROM包</li>
</ol>
<p>将第三方包的zip文件放大存储卡中，卡刷，选择external card，这一步比较顺利。</p>
<p>因为一些帖子有反馈说无法联网，我没有遇到这个问题，顺利进入系统。但是无法调出键盘输入界面。</p>
<ol>
<li>将平板变成显示器</li>
</ol>
<p><a href="https://zhuanlan.zhihu.com/p/81255397" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/81255397</a></p>
<p><strong>Spacedesk</strong> 电脑和平板需要处于同一局域网下</p>
<p><strong>Splashtop Wired XDisplay</strong> 通过数据线连接，需要在google play上下载</p>
<p><strong>Twomon SE</strong></p>
<p><a href="https://www.splashtop.com/cn/wiredxdisplay](https://www.splashtop.com/cn/wiredxdisplay" target="_blank" rel="noopener">https://www.splashtop.com/cn/wiredxdisplay](https://www.splashtop.com/cn/wiredxdisplay</a>)</p>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><p>主要参考<a href="https://www.jianshu.com/p/182975bd9ee6" target="_blank" rel="noopener">简书</a>和<a href="https://blog.csdn.net/wulong710/article/details/91956773" target="_blank" rel="noopener">CSDN</a> 上的两个帖子。</p>
<p><a href="https://sspai.com/post/43338" target="_blank" rel="noopener">Android 玩机终极指南</a> 这个也值得一看。</p>
]]></content>
      <categories>
        <category>日常记录</category>
      </categories>
      <tags>
        <tag>刷机</tag>
        <tag>三星</tag>
        <tag>N8000</tag>
      </tags>
  </entry>
  <entry>
    <title>词云</title>
    <url>/2020/08/18/%E8%AF%8D%E4%BA%91/</url>
    <content><![CDATA[<p><a href="https://python123.io/tutorials/word_cloud/" target="_blank" rel="noopener">python123你不知道的词云</a></p>
<a id="more"></a>
<p>关键问题：<strong>如何做到词语之间紧密排布但又没有重叠</strong></p>
<h3 id="integral-image积分图"><a href="#integral-image积分图" class="headerlink" title="integral_image积分图"></a>integral_image积分图</h3><p>重叠检测方法：</p>
<p>词云布局方法：贪心策略</p>
<p><strong>矩形检测的积分图算法似乎不能很好的支持文字的旋转</strong></p>
<h3 id="四叉树"><a href="#四叉树" class="headerlink" title="四叉树"></a>四叉树</h3><p><strong>层次边界框</strong>（Hierarchical bounding boxes）来快速实现两个词语间的重叠检测。本质上是一棵记录空间信息的四叉树。</p>
<p>四叉树的构建并不困难，将图片横纵各切一刀，平均分割为「左上、左下、右上、右下」四个区域，如果某个区域中有内容（此时可以用积分图算法判断），那么继续将这个区域分割为四个部分，直到区域的大小小于某个值。</p>
<p>四叉树每深一层，对形状的描述就越精确，每一次分隔，都能排除一些空白矩形区域，剩下的有像素的区域，都记录到了树中。</p>
<p>之后两颗四叉树逐层判断。</p>
<h3 id="矩形螺旋布局"><a href="#矩形螺旋布局" class="headerlink" title="矩形螺旋布局"></a>矩形螺旋布局</h3><p>一种贪心布局策略，所有的单词紧密放置在图中心的螺旋形状上。每个单词都从螺旋的中心位置开始检测，如果不能放置，就移动到螺旋的下一个位置。</p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>一种策略的想法来源于四叉树。先把图像分割为多个矩形区域，比如 800×600 的图片，分割为 48（8×6）个区域，每个区域长宽都是 100 像素。布局每个单词后，就将这个单词添加到对应的区域中，这样在布局一个新的单词时，只要根据单词大概的大小和放置的位置，在有限的几个区域中进行重叠检测，大幅降低了需要进行重叠检测的次数。</p>
<p>第二种策略更多来源于经验。假如要放置数十个大小差不多的单词，第一个单词检测了螺旋上的 200 个坐标后，找到一个放置位置，那么下一个单词就跳过这 200 个坐标（因为大概率重叠），在第 300 个坐标上放置，下一个单词从第 300 个坐标开始……如果检测到了图片边界未找到可以放置的坐标，那么回到初始位置重新寻找。</p>
<h3 id="其他资源"><a href="#其他资源" class="headerlink" title="其他资源"></a>其他资源</h3><p><a href="https://github.com/TommyZihao/zihaowordcloud" target="_blank" rel="noopener">同济子豪兄在github上的词云可视化教程（wordcloud）</a></p>
<p>在线词云生成网站：</p>
<p><a href="http://www.yciyun.com/" target="_blank" rel="noopener">易词云</a></p>
<p><a href="http://www.picdata.cn/picdata/index.php" target="_blank" rel="noopener">图悦</a></p>
<p><a href="https://me.bdp.cn/home.html" target="_blank" rel="noopener">BDP</a></p>
<p><a href="https://www.jianshu.com/p/615c9d285c54" target="_blank" rel="noopener">https://www.jianshu.com/p/615c9d285c54</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>wordcloud</tag>
      </tags>
  </entry>
  <entry>
    <title>《Scikit-Learn与TensorFlow机器学习实用指南》-第一部分</title>
    <url>/2020/08/25/%E3%80%8AScikit-Learn%E4%B8%8ETensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97%E3%80%8B/</url>
    <content><![CDATA[<p>学习资料参考：</p>
<p><a href="https://www.cntofu.com/book/27/docs/2.%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE.md" target="_blank" rel="noopener">一个完整的机器学习项目.md</a></p>
<p><a href="https://github.com/ageron/handson-ml2" target="_blank" rel="noopener">原书Github上代码</a></p>
<p><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" target="_blank" rel="noopener">Oreilly上原书第二版（可以在线阅读）</a></p>
<p><a href="https://github.com/apachecn/hands-on-ml-zh/blob/master/docs/1.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88.md" target="_blank" rel="noopener">第一版翻译</a></p>
<p><a href="https://www.jianshu.com/p/3470a6efbe8d" target="_blank" rel="noopener">简书第一版</a></p>
<p><a href="https://www.jianshu.com/p/86626c79814a" target="_blank" rel="noopener">简书第二版第二部分</a></p>
<p><a href="https://www.jianshu.com/p/4a94798f7dcc" target="_blank" rel="noopener">简书《Scikit-Learn、Keras与TensorFlow机器学习实用指南》第一版和第二版对照</a></p>
<p><a href="https://blog.csdn.net/jiaoyangwm/article/details/82387883#%E7%BB%83%E4%B9%A0%E9%A2%987" target="_blank" rel="noopener">练习题答案参考</a> <a href="https://blog.csdn.net/leowinbow/article/details/88581039" target="_blank" rel="noopener">参考2</a></p>
<a id="more"></a>
<h2 id="第01章-机器学习概览"><a href="#第01章-机器学习概览" class="headerlink" title="第01章 机器学习概览"></a>第01章 机器学习概览</h2><ol>
<li><p>os.makedirs(IMAGES_PATH, exist_ok=True)</p>
</li>
<li><p>pd.merge(left=oecd_bli, right=gdp_per_capita, left_index=True, right_index=True)</p>
<p>left_index和right_index：指定是否以索引为参考进行合并</p>
<!--more-->
<h4 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h4><ol>
<li>如何定义机器学习？</li>
</ol>
<blockquote>
<p>机器学习是通过编程让计算机从数据中进行学习的科学（和艺术）。</p>
<p><strong>更广义的概念：</strong></p>
<p>机器学习是让计算机具有学习的能力，无需进行明确编程。 —— 亚瑟·萨缪尔，1959</p>
<p><strong>工程性的概念：</strong></p>
<p>计算机程序利用经验 E 学习任务 T，性能是 P，如果针对任务 T 的性能 P 随着经验 E 不断增长，则称为机器学习。 —— 汤姆·米切尔，1997</p>
</blockquote>
<ol>
<li>机器学习可以解决的四类问题？</li>
</ol>
<blockquote>
<p>分类，回归，聚类，降维</p>
<p>机器学习可以根据训练时监督的量和类型进行分类。主要有四类：监督学习、非监督学习、半监督学习和强化学习。</p>
</blockquote>
<ol>
<li>什么是带标签的训练集？</li>
</ol>
<blockquote>
<p>在监督学习中，用来训练算法的训练数据包含了答案，称为标签。</p>
</blockquote>
<ol>
<li>最常见的两个监督任务是什么？</li>
</ol>
<blockquote>
<ol>
<li>分类：例如垃圾邮件过滤器：用许多带有归类（垃圾邮件或普通邮件）的邮件样本进行训练，过滤器必须还能对新邮件进行分类。</li>
<li>回归：预测目标数值，例如给出一些特征（里程数、车龄、品牌等等）称作预测值，来预测一辆汽车的价格。。要训练这个系统，需要给出大量汽车样本，包括它们的预测值和标签（即，它们的价格）。</li>
</ol>
</blockquote>
<ol>
<li>指出四个常见的非监督任务？</li>
</ol>
<blockquote>
<ol>
<li><strong>聚类算法</strong> ，检测相似访客的分组。假设有一份关于博客访客的大量数据，不告诉算法某个访客属于哪一类：它会自己找出关系，无需帮助。例如，算法可能注意到 40% 的访客是喜欢漫画书的男性，通常是晚上访问，20% 是科幻爱好者，他们是在周末访问等等。如果使用<strong>层次聚类分析</strong> ，它可能还会细分每个分组为更小的组。这可以帮助你为每个分组定位博文。</li>
<li><strong>可视化算法</strong> ：给算法大量复杂的且不加标签的数据，算法输出数据的2D或3D图像。算法会试图保留数据的结构（即尝试保留输入的独立聚类，避免在图像中重叠），这样就可以明白数据是如何组织起来的，也许还能发现隐藏的规律。</li>
<li><strong>降维</strong> ：降维的目的是简化数据、但是不能失去大部分信息。做法之一是合并若干相关的特征。例如，汽车的里程数与车龄高度相关，降维算法就会将它们合并成一个，表示汽车的磨损。这叫做<strong>特征提取</strong> 。</li>
<li><strong>异常检测（anomaly detection）</strong> ：例如，检测异常的信用卡转账以防欺诈，检测制造缺陷，或者在训练之前自动从训练数据集去除异常值。异常检测的系统使用正常值训练的，当它碰到一个新实例，它可以判断这个新实例是像正常值还是异常值。</li>
</ol>
</blockquote>
<ol>
<li>要让一个机器人能在各种未知地形行走，你会采用什么机器学习算法？</li>
</ol>
<blockquote>
<p>强化学习：</p>
</blockquote>
<ol>
<li>要对你的顾客进行分组，你会采用哪类算法？</li>
</ol>
<blockquote>
<p>非监督学习</p>
</blockquote>
<ol>
<li>垃圾邮件检测是监督学习问题，还是非监督学习问题？</li>
</ol>
<blockquote>
<p>监督学习：因为有标签</p>
</blockquote>
<ol>
<li>什么是在线学习系统？</li>
</ol>
<blockquote>
<p>从导入的数据流进行持续学习</p>
<p>在在线学习中，是用数据实例持续地进行训练，可以一次一个或一次几个实例（称为小批量）。每个学习步骤都很快且廉价，所以系统可以动态地学习收到的最新数据</p>
<p><img src="https://github.com/apachecn/hands-on-ml-zh/raw/master/images/chapter_1/1-13.png" alt="img"></p>
</blockquote>
<ol>
<li>什么是核外学习？</li>
</ol>
<blockquote>
<p>在线学习算法也适用于在超大数据集（一台计算机不足以用于存储它）上训练系统（这称作核外学习，<em>out-of-core</em> learning）。算法每次只加载部分数据，用这些数据进行训练，然后重复这个过程，直到使用完所有数据</p>
</blockquote>
<ol>
<li>什么学习算法是用相似度做预测？</li>
</ol>
<blockquote>
<p>基于实例学习：系统先用记忆学习案例，然后使用相似度测量推广到新的例子</p>
<p>例如，垃圾邮件检测器，不仅能标记和已知的垃圾邮件相同的邮件，也要能标记类似垃圾邮件的邮件。需要测量两封邮件的相似性。一个（简单的）相似度测量方法是统计两封邮件包含的相同单词的数量。如果一封邮件含有许多垃圾邮件中的词，就会被标记为垃圾邮件。</p>
</blockquote>
<ol>
<li>模型参数和学习算法的超参数的区别是什么？</li>
</ol>
<blockquote>
<p>学习算法搜寻模型参数值，使代价函数最小</p>
<p>超参数（hyperparameter）是一个学习算法的参数（而不是模型的），控制正则化的度。</p>
</blockquote>
<ol>
<li>基于模型学习的算法搜寻的是什么？最成功的策略是什么？基于模型学习如何做预测？</li>
</ol>
<blockquote>
<p>搜寻使得代价函数（测量线性模型的预测值和训练样本之间的距离差）最小的模型参数</p>
<p>线性回归算法</p>
<p>研究数据-选择模型-用训练数据进行训练（学习算法搜寻模型参数值，使得代价函数最小）-使用模型对新案例进行预测（这称作推断）</p>
</blockquote>
<ol>
<li>机器学习的四个主要挑战是什么？</li>
</ol>
<blockquote>
<p>训练数据量不足</p>
<p>没有代表性的训练数据</p>
<p>低质量数据</p>
<p>不相关的特征</p>
<p>过拟合</p>
<p>欠拟合</p>
</blockquote>
<ol>
<li>如果模型在训练集上表现好，但推广到新实例表现差，问题是什么？给出三个可能的解决方案。</li>
</ol>
<blockquote>
<p>过拟合：利用超参数正则化</p>
<p>不相关特征：</p>
<ul>
<li>特征选择：在所有存在的特征中选取最有用的特征进行训练。</li>
<li>特征提取：组合存在的特征，生成一个更有用的特征（如前面看到的，可以使用降维算法）。</li>
<li>收集新数据创建新特征。</li>
</ul>
<p>低质量数据：如果训练集中的错误、异常值和噪声（错误测量引入的）太多，系统检测出潜在规律的难度就会变大，性能就会降低。</p>
<ul>
<li>如果一些实例是明显的异常值，最好删掉它们或尝试手工修改错误；</li>
<li>如果一些实例缺少特征（比如，你的 5% 的顾客没有说明年龄），你必须决定是否忽略这个属性、忽略这些实例、填入缺失值（比如，年龄中位数），或者训练一个含有这个特征的模型和一个不含有这个特征的模型，等等。</li>
</ul>
</blockquote>
<ol>
<li>什么是测试集，为什么要使用它？</li>
</ol>
<blockquote>
<p>测试集：用来训练模型的数据集</p>
</blockquote>
<ol>
<li>验证集的目的是什么？</li>
</ol>
<blockquote>
<p>验证集：数据中分出来，对模型进行测试的数据集。</p>
<p>评估模型推广到新样本的效果（即对新样本的性能），可以将模型部署到生产环境，观察它的性能。这么做可以，但如果模型的性能很差，就会引起用户抱怨。更好的选项是将数据分成训练集和测试集。用训练集进行训练，用测试集进行测试。对新样本的错误率称作<strong>推广错误（或样本外错误）</strong> ，通过模型对测试集的评估，可以预估这个错误。这个值可以我们模型对新样本的性能。</p>
</blockquote>
<ol>
<li>如果用测试集调节超参数，会发生什么？</li>
</ol>
<blockquote>
<p>过拟合</p>
<p>在测试集上多次测量了推广误差率，调整了模型和超参数，以使模型最适合这个集合。这意味着模型对新数据的性能不会高。</p>
</blockquote>
<ol>
<li>什么是交叉验证，为什么它比验证集好？</li>
</ol>
<blockquote>
<p>交叉验证：训练集分成互补的子集，每个模型用不同的子集训练，再用剩下的子集验证。一旦确定模型类型和超参数，最终的模型使用这些超参数和全部的训练集进行训练，用测试集得到推广误差率。</p>
<p>而使用验证集：用训练集和多个超参数训练多个模型，选择在验证集上有最佳性能的模型和超参数。当对模型满意时，用测试集再做最后一次测试，以得到推广误差率的预估，会“浪费”过多训练数据在验证集上。</p>
</blockquote>
</li>
</ol>
<hr>
<h2 id="第02章-一个完整的机器学习项目"><a href="#第02章-一个完整的机器学习项目" class="headerlink" title="第02章 一个完整的机器学习项目"></a>第02章 一个完整的机器学习项目</h2><p>[Python API：crc32函数 计算CRC校验值](<a href="https://b）" target="_blank" rel="noopener">https://b）</a></p>
<p><a href="https://blog.csdn.net/liuyu60305002/article/details/6307152" target="_blank" rel="noopener">模2运算</a></p>
<p><a href="https://blog.csdn.net/sparkliang/article/details/5671510" target="_blank" rel="noopener">CRC32算法详细推导</a></p>
<blockquote>
<p>crc32用于计算 <em>data</em> 的 CRC (A cyclic redundancy check 32，循环冗余校验) 值。计算的结果是一个 32 位的整数。本质是<strong>模2除法模2运算包括模2加、模2减、模2乘、模2除四种二进制运算，不考虑进位和借位）</strong>， 的余数，采用的除数不同，CRC的类型也就不一样。通常，CRC的除数用生成多项式来表示。</p>
<p>此算法没有加密强度，不应用于身份验证和数字签名。仅<strong>为验证数据的正确性</strong> ，不适合作为通用散列算法。</p>
<h4 id="特点：检错能力极强，开销小等"><a href="#特点：检错能力极强，开销小等" class="headerlink" title="特点：检错能力极强，开销小等"></a>特点：检错能力极强，开销小等</h4><h4 id="本质"><a href="#本质" class="headerlink" title="本质"></a>本质</h4><p>CRC 算法是以 GF(2) 多项式算术为数学基础的， GF(2) 多项式中只有一个变量 x ，其系数也只有 0 和 1 ，比如：</p>
<p>​    1 <em>x^6 + 0</em>x^5 + 1<em>x^4 + 0</em>x^3 + 0<em>x^2 +1</em>x^1 + 1*x^0</p>
<p>​       = x^6 + x^4 + x + 1</p>
<p>加减运算不考虑进位和退位。说白了就是下面的运算规则：</p>
<p>​    0 + 0 = 0    0 - 0 = 0</p>
<p>​    0 + 1 = 1    0 - 1 = 1</p>
<p>​    1 + 0 = 1    1 - 0 = 1</p>
<p>​    1 + 1 = 0    1 - 1 = 0<br>看看这个规则，其实就是一个<strong>异或运算</strong> 。</p>
<p>每个生成多项式的系数只能是 0 或 1 ，因此可以把它转化为二进制形式表示， 比如 g(x)=x^4 + x + 1 ，那么 g(x) 对应的二进制形式就是 10011 ， 于是把 GF(2) 多项式的除法转换成了二进制形式，和普通除法没有区别，只是加减运算没有进位和退位。</p>
<p>比如基于上述规则计算 11010/1001 ，那么商是 11 ，余数就是 1。</p>
<h4 id="CRC-校验的基本过程"><a href="#CRC-校验的基本过程" class="headerlink" title="CRC 校验的基本过程"></a>CRC 校验的基本过程</h4><p>采用 CRC 校验时，发送方和接收方用同一个生成多项式 g(x) ， g(x) 是一个 GF(2) 多项式，并且 g(x) 的首位和最后一位的系数必须为 1 。</p>
<p>CRC 的处理方法是：发送方用发送数据的二进制多项式 t(x) 除以 g(x) ，得到余数 y(x) 作为 CRC 校验码。校验时，以计算的校正结果是否为 0 为据，判断数据帧是否出错。设生成多项式是 r 阶的（最高位是 x^r ）具体步骤如下面的描述。</p>
<p>发送方：</p>
<p>1 ）在发送的 m 位数据的二进制多项式 t(x) 后添加 r 个 0 ，扩张到 m+ r 位，以容纳 r 位的校验码，追加 0 后的二进制多项式为  T(x) ；</p>
<p>2 ）用 T(x) 除以生成多项式 g(x) ，得到 r 位的余数 y(x) ，它就是 CRC 校验码；</p>
<p>3 ）把 y(x) 追加到 t(x) 后面，此时的数据 s(x) 就是包含了 CRC 校验码的待发送字符串；由于 s(x) = t(x) y(x) ，因此 s(x) 肯定能被 g(x) 除尽。</p>
<p>接收方：</p>
<p>1 ）接收数据 n(x) ，这个 n(x) 就是包含了 CRC 校验码的 m+r 位数据；</p>
<p>2 ）计算 n(x) 除以 g(x) ，如果余数为 0 则表示传输过程没有错误，否则表示有错误。从 n(x) 去掉尾部的 r 位数据，得到的就是原始数据。</p>
<p>生成多项式不是随意选择的，以下是一些标准的 CRC 算法的生成多项式：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>标准</th>
<th>生成多项式</th>
<th>16 进制表示</th>
</tr>
</thead>
<tbody>
<tr>
<td>CRC12</td>
<td>x^12 + x^11 + x^3 + x^2 + x + 1</td>
<td>0x80F</td>
</tr>
<tr>
<td>CRC16</td>
<td>x^16 + x^15 + x^2 + 1</td>
<td>0x8005</td>
</tr>
<tr>
<td>CRC16-CCITT</td>
<td>x^16 + x^12 + x^5 + 1</td>
<td>0x1021</td>
</tr>
<tr>
<td>CRC32</td>
<td>x^32 + x^26 + x^23 + x^22 + x^16 + x^12 + x^11+ x^10 + x^8 + x^7 + x^5 + x^4 + x^2 + x + 1</td>
<td>0x04C11DB7</td>
</tr>
</tbody>
</table>
</div>
<p>在python 3.0 之后: 返回值永远是无符号数。要在所有的 Python 版本和平台上获得相同的值，请使用 <strong>crc32(data) &amp; 0xffffffff</strong>。</p>
</blockquote>
<p><strong>问题：</strong> </p>
<p>使用本章的房产数据集：</p>
<ol>
<li>尝试一个支持向量机回归器（<code>sklearn.svm.SVR</code>），使用多个超参数，比如<code>kernel=&quot;linear&quot;</code>（多个超参数<code>C</code>值）。现在不用担心这些超参数是什么含义。最佳的<code>SVR</code>预测表现如何？</li>
</ol>
<blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;<span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line"></span><br><span class="line">&gt;svm_reg = SVR(kernel=<span class="string">"linear"</span>)</span><br><span class="line">&gt;svm_reg.fit(housing_prepared, housing_labels)</span><br><span class="line">&gt;housing_predictions = svm_reg.predict(housing_prepared)</span><br><span class="line">&gt;svm_mse = mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line">&gt;svm_rmse = np.sqrt(svm_mse)</span><br><span class="line">&gt;svm_rmse <span class="comment"># output: 111094.6308539982</span></span><br></pre></td></tr></table></figure>
<p>结果不好。</p>
</blockquote>
<ol>
<li>尝试用<code>RandomizedSearchCV</code>替换<code>GridSearchCV</code>。</li>
</ol>
<blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line">&gt;<span class="keyword">from</span> scipy.stats <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line">&gt;param_distribs = &#123;</span><br><span class="line">       <span class="string">'n_estimators'</span>: randint(low=<span class="number">1</span>, high=<span class="number">200</span>),</span><br><span class="line">       <span class="string">'max_features'</span>: randint(low=<span class="number">1</span>, high=<span class="number">8</span>),</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&gt;forest_reg = RandomForestRegressor(random_state=<span class="number">42</span>)</span><br><span class="line">&gt;rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,</span><br><span class="line">                               n_iter=<span class="number">10</span>, cv=<span class="number">5</span>, scoring=<span class="string">'neg_mean_squared_error'</span>, random_state=<span class="number">42</span>)</span><br><span class="line">&gt;rnd_search.fit(housing_prepared, housing_labels)</span><br></pre></td></tr></table></figure>
</blockquote>
<ol>
<li>尝试在准备流水线中添加一个只选择最重要属性的转换器。</li>
</ol>
<blockquote>
<p>​</p>
</blockquote>
<ol>
<li>尝试创建一个单独的可以完成数据准备和最终预测的流水线。</li>
</ol>
<blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;full_pipeline_with_predictor = Pipeline([</span><br><span class="line">       (<span class="string">"preparation"</span>, full_pipeline),</span><br><span class="line">       (<span class="string">"linear"</span>, LinearRegression())</span><br><span class="line">   ])</span><br><span class="line"></span><br><span class="line">&gt;full_pipeline_with_predictor.fit(housing, housing_labels)</span><br><span class="line">&gt;full_pipeline_with_predictor.predict(some_data)</span><br></pre></td></tr></table></figure>
</blockquote>
<ol>
<li>使用<code>GridSearchCV</code>自动探索一些准备过程中的候选项。</li>
</ol>
<h2 id="第03章-分类"><a href="#第03章-分类" class="headerlink" title="第03章 分类"></a>第03章 分类</h2><p><a href="https://blog.csdn.net/weixin_38145317/article/details/79650188" target="_blank" rel="noopener">SVM、SVC、SVR</a> </p>
<h4 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h4><ol>
<li><p>尝试在 MNIST 数据集上建立一个分类器，使它在测试集上的精度超过 97%。提示：<code>KNeighborsClassifier</code>非常适合这个任务。你只需要找出一个好的超参数值（试一下对权重和超参数<code>n_neighbors</code>进行网格搜索）。</p>
<p>​</p>
</li>
<li><p>写一个函数可以是 MNIST 中的图像任意方向移动（上下左右）一个像素。然后，对训练集上的每张图片，复制四个移动后的副本（每个方向一个副本），把它们加到训练集当中去。最后在扩展后的训练集上训练你最好的模型，并且在测试集上测量它的精度。你应该会观察到你的模型会有更好的表现。这种人工扩大训练集的方法叫做数据增强，或者训练集扩张。</p>
<p>​</p>
</li>
<li><p>拿 Titanic 数据集去捣鼓一番。开始这个项目有一个很棒的平台：Kaggle</p>
<p>​</p>
</li>
<li><p>建立一个垃圾邮件分类器（这是一个更有挑战性的练习）：</p>
</li>
</ol>
<ul>
<li>下载垃圾邮件和非垃圾邮件的样例数据。地址是<a href="https://spamassassin.apache.org/publiccorpus/" target="_blank" rel="noopener">Apache SpamAssassin 的公共数据集</a></li>
<li>解压这些数据集，并且熟悉它的数据格式。</li>
<li>将数据集分成训练集和测试集</li>
<li>写一个数据准备的流水线，将每一封邮件转换为特征向量。你的流水线应该将一封邮件转换为一个稀疏向量，对于所有可能的词，这个向量标志哪个词出现了，哪个词没有出现。举例子，如果所有邮件只包含了<code>&quot;Hello&quot;,&quot;How&quot;,&quot;are&quot;, &quot;you&quot;</code>这四个词，那么一封邮件（内容是：<code>&quot;Hello you Hello Hello you&quot;</code>）将会被转换为向量<code>[1, 0, 0, 1]</code>(意思是：<code>&quot;Hello&quot;</code>出现，<code>&quot;How&quot;</code>不出现，<code>&quot;are&quot;</code>不出现，<code>&quot;you&quot;</code>出现)，或者<code>[3, 0, 0, 2]</code>，如果你想数出每个单词出现的次数。</li>
<li>你也许想给你的流水线增加超参数，控制是否剥过邮件头、将邮件转换为小写、去除标点符号、将所有 URL 替换成<code>&quot;URL&quot;</code>，将所有数字替换成<code>&quot;NUMBER&quot;</code>，或者甚至提取词干（比如，截断词尾。有现成的 Python 库可以做到这点）。</li>
<li>然后 尝试几个不同的分类器，看看你可否建立一个很棒的垃圾邮件分类器，同时有着高召回率和高准确率。</li>
</ul>
<h2 id="第04章-训练模型"><a href="#第04章-训练模型" class="headerlink" title="第04章 训练模型"></a>第04章 训练模型</h2><p>线性回归预测模型：</p>
<p>$\hat y = h_{\theta}(x)=\theta ^T\cdot x$</p>
<p>线性回归模型的MSE损失函数:</p>
<p>$MSE(X,h_\theta)=\frac{1}{m}\sum_{i=1}^{n}(\theta^T\cdot x^{(i)}-y^{(i)})^2$</p>
<h4 id="正态方程"><a href="#正态方程" class="headerlink" title="正态方程"></a><strong>正态方程</strong></h4><p>最小化损失函数 $\hat{\theta} =   (X^T \cdot X)^{-1} \cdot X^T \cdot y $</p>
<p>复杂度：需要计算$X^T\cdot X$ 的逆矩阵，是一个n*n的矩阵，运算复杂度大约在$O(n^{24})$ 到$O(n^{3})$之间。</p>
<p>可以numpy直接求解，也可以使用sklearn：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(X, y)</span><br><span class="line">lin_reg.intercept_, lin_reg.coef_</span><br></pre></td></tr></table></figure>
<p><code>LinearRegression类基于numpy.linalg.lstsq （least squares）</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond=<span class="number">1e-6</span>)</span><br><span class="line">theta_best_svd</span><br></pre></td></tr></table></figure>
<h5 id="pseudoinverse-Moore-Penrose-inverse"><a href="#pseudoinverse-Moore-Penrose-inverse" class="headerlink" title="pseudoinverse (Moore-Penrose inverse)"></a>pseudoinverse (Moore-Penrose inverse)</h5><p>该函数求解的是伪逆矩阵（pseudoinverse），即广义矩阵。其中最著名的伪逆矩阵为摩尔－彭若斯广义逆 A+（Moore–Penrose pseudoinverse)，常应用于求非一致线性方程组的最小范数最小二乘解（最小二乘法），并使得解的形式变得简单。矩阵的摩尔－彭若斯广义逆在实数域和复数域上都是唯一的，并且可以通过奇异值分解求得。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.linalg.pinv(X_b).dot(y)</span><br></pre></td></tr></table></figure>
<p>满足摩尔-彭若斯条件的矩阵G称为矩阵A的摩尔－彭若斯广义逆矩阵，记作A+：</p>
<p><img src="https://img-blog.csdn.net/20170824103329707?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemVhbGZvcnk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="条件"></p>
<p>从摩尔－彭若斯条件出发，彭若斯推导出了摩尔－彭若斯广义逆的一些性质：<br><img src="https://img-blog.csdn.net/20170824103423352?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemVhbGZvcnk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img"></p>
<p> 参考：<a href="https://blog.csdn.net/zealfory/article/details/77526815" target="_blank" rel="noopener">https://blog.csdn.net/zealfory/article/details/77526815</a></p>
<h4 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h4><p>超参数学习率的值决定了步长的大小。如果学习率太小，必须经过多次迭代，算法才能收敛，这是非常耗时的，如果学习率太大，你可能使算法发散，函数值变得越来越大，永远不可能找到一个好的答案。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-4.PNG" alt="学习率过小"></p>
<center>学习率过小</center>

<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-5.PNG" alt="img"></p>
<center>学习率过大</center>

<p><strong>两个主要挑战</strong></p>
<ol>
<li>收敛到局部最小值</li>
</ol>
<p>当使用梯度下降的时候，应该确保所有的特征有着相近的尺度范围（例如：使用 Scikit Learn 的 <code>StandardScaler</code>类），否则它将需要很长的时间才能够收敛。</p>
<h4 id="batch-GD"><a href="#batch-GD" class="headerlink" title="batch-GD"></a>batch-GD</h4><p>使用梯度下降的过程中，需要计算每一个 $\theta_j$ 下损失函数的梯度，即计算关于$\theta_j$ 的损失函数的偏导数，记为： </p>
<script type="math/tex; mode=display">\frac{\partial}{\partial \theta_j} MSE(\theta)=\frac{2}{m}\sum_{i=1}^{m}({\theta^T\cdot x^{(i)}-y^{(i)})x_j^{}(i)}</script><p>写成矩阵的形式：</p>
<script type="math/tex; mode=display">\nabla_\theta MSE(\theta)=\left( \begin{array}{c} \frac{\partial}{\partial \theta_0} MSE(\theta)\\\frac{\partial}{\partial \theta_1} MSE(\theta)\\...\\\frac{\partial}{\partial \theta_n} MSE(\theta) \end{array} \right)=\frac {2}{m} X^T\cdot (X\cdot \theta-y)</script><blockquote>
<p>在这个方程中每一步计算时都包含了整个训练集$X$，这也是为什么这个算法称为<strong>批量梯度下降</strong>：每一次训练过程都使用所有的的训练数据。因此，在大数据集上，其会变得相当的慢。然而，梯度下降的运算规模和特征的数量成正比。训练一个数千数量特征的线性回归模型使用梯度下降要比使用正态方程快的多。</p>
</blockquote>
<p>梯度下降的步长：</p>
<script type="math/tex; mode=display">\theta^{(next step)}=\theta-\eta\nabla_\theta MSE(\theta)</script><p>$\eta$ 为学习率</p>
<p>为了找到一个好的学习率，可以使用网格搜索，设置一个<strong>迭代次数</strong>。设置一个非常大的迭代次数，但是当梯度向量变得非常小（容差 $\epsilon$ ）的时候，结束迭代。</p>
<blockquote>
<p>收敛速率：</p>
<p>当损失函数是凸函数，且斜率不能突变（就像均方差损失函数那样），则它的批量梯度下降算法固定学习率之后，收敛速率是 $O(\frac{1}{iterations})$。换句话说，如果将容差 $\epsilon$ 缩小 10 倍（这样可以得到一个更精确的结果），算法的迭代次数大约会变成原来的 10 倍。</p>
</blockquote>
<h4 id="stochastic-gradient-descent"><a href="#stochastic-gradient-descent" class="headerlink" title="stochastic gradient descent"></a>stochastic gradient descent</h4><p>批量梯度下降的最要问题是计算每一步的梯度时都需要使用整个训练集，这导致在规模较大的数据集上，其会变得非常的慢。</p>
<p>而随机梯度下降，每一步的梯度计算只随机选取训练集中的一个样本。由于每一次迭代，只需要在内存中有一个实例，算法非常快，这使随机梯度算法可以在大规模训练集上使用。</p>
<p>另一方面，由于其随机性，SGD呈现出更多的不规律性：到达最小值不是平缓的下降，损失函数会忽高忽低，只在大体上呈下降趋势。随着时间的推移，非常的靠近最小值，但不会停止在一个值上，而是一直在这个值附近摆动。因此，算法停止时，最后的参数不是最优值。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-9.PNG" alt="img"></p>
<p>当损失函数很不规则时，随机梯度下降算法能够跳过局部最小值。因此，随机梯度下降在寻找全局最小值上比批量梯度下降表现要好。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-6.PNG" alt="img"></p>
<p>虽然随机性可以很好的跳过局部最优值，但同时它却不能达到最小值。解决这个难题的一个办法是<strong>逐渐降低学习率</strong>。</p>
<p>开始时，走的每一步较大（有助于快速前进同时跳过局部最小值），然后变得越来越小，从而使算法到达全局最小值。，这个过程被称为<strong>模拟退火</strong>。</p>
<p>决定每次迭代的学习率的函数称为<code>learning schedule</code>。 如果学习速度降低得过快，可能会陷入局部最小值，甚至在到达最小值的半路就停止了。 如果学习速度降低得太慢，可能在最小值的附近长时间摆动，同时如果过早停止训练，最终只会出现次优解。</p>
<h4 id="mini-batch-GD"><a href="#mini-batch-GD" class="headerlink" title="mini-batch GD"></a>mini-batch GD</h4><p>在迭代的每一步，小批量梯度下降使用一个随机的小型实例集。与随机梯度相比主要优点在于可以通过矩阵运算的硬件优化得到一个较好的训练表现。</p>
<p>小批量梯度下降在参数空间上的表现比随机梯度下降要好的多，尤其在有大量的小型实例集时。作为结果，小批量梯度下降会比随机梯度更靠近最小值。但是，另一方面，它有可能陷在局部最小值中（在遇到局部最小值问题的情况下，和我们之前看到的线性回归不一样）。 </p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-11.PNG" alt="img"></p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E8%A1%A84-1.PNG" alt="img"></p>
<h4 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h4><p>对每个特征进行加权后作为新的特征，然后训练一个线性模型在这个扩展的特征集。 这种方法称为多项式回归。</p>
<p><code>from sklearn.preprocessing import PolynomialFeatures</code></p>
<p>当存在多个特征时，多项式回归能够找出特征之间的关系（这是普通线性回归模型无法做到的）。 这是因为<code>LinearRegression</code>会自动添加当前阶数下特征的所有组合。例如，如果有两个特征 $a,b$，使用 3 阶（<code>degree=3</code>）的<code>LinearRegression</code>时，不仅有 $a^3, a^2, b^3, b^2$，同时也会有它们的其他组合项 $ab, ab^2, a^2b$</p>
<p><code>PolynomialFeatures(degree=d)</code>把一个包含$n$个特征的数组转换为一个包含 $\frac{(n+d)!}{d!n!}$特征的数组。小心大量特征的组合爆炸！</p>
<h4 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h4><p><strong>如何估计一个模型的泛化能力</strong> </p>
<ol>
<li>使用交叉验证。若模型在训练集上表现良好，通过交叉验证指标却得出其泛化能力很差，模型过拟合。如果在这两方面都表现不好，那么欠拟合。这种方法可以告诉我们模型是太复杂还是太简单了。</li>
<li>观察学习曲线：画出模型在训练集上的表现，同时画出以训练集规模为自变量的训练集函数。为了得到图像，需要在训练集的不同规模子集上进行多次训练。</li>
</ol>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-15.PNG" alt="img"></p>
<center>欠拟合</center>

<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-16.PNG" alt="img"></p>
<center>过拟合</center>

<blockquote>
<p>偏差和方差的权衡</p>
<p>在统计和机器学习领域有个重要的理论：一个模型的<strong>泛化误差</strong>由三个不同误差的和决定：</p>
<ul>
<li>偏差：泛化误差的这部分误差是由于错误的假设决定的。例如实际是一个二次模型，你却假设了一个线性模型。一个高偏差的模型最容易出现欠拟合。</li>
<li>方差：这部分误差是由于模型对训练数据的微小变化较为敏感，一个多自由度的模型更容易有高的方差（例如一个高阶多项式模型），因此会导致模型过拟合。</li>
<li>不可约误差：这部分误差是由于数据本身的噪声决定的。降低这部分误差的唯一方法就是进行数据清洗（例如：修复数据源，修复坏的传感器，识别和剔除异常值）。</li>
</ul>
</blockquote>
<h4 id="线性模型的正则化"><a href="#线性模型的正则化" class="headerlink" title="线性模型的正则化"></a>线性模型的正则化</h4><p>正则化这个模型（即限制它）：模型有越少的自由度，就越难以拟合数据。例如，正则化一个多项式模型，一个简单的方法就是减少多项式的阶数。</p>
<p>对于一个线性模型，正则化的典型实现就是约束模型中参数的权重。</p>
<h5 id="岭回归（Ridge）"><a href="#岭回归（Ridge）" class="headerlink" title="岭回归（Ridge）"></a>岭回归（Ridge）</h5><p>岭回归（也称为 Tikhonov 正则化）是线性回归的正则化版：在损失函数上直接加上一个正则项。这使得学习算法不仅能够拟合数据，而且能够使模型的参数权重尽量的小。注意到这个正则项只有在训练过程中才会被加到损失函数。当得到完成训练的模型后，我们应该使用没有正则化的测量方法去评价模型的表现。</p>
<blockquote>
<p>提示</p>
<p>一般情况下，训练过程使用的损失函数和测试过程使用的评价函数是不一样的。除了正则化，还有一个不同：训练时的损失函数应该在优化过程中易于求导，而在测试过程中，评价函数更应该接近最后的客观表现。一个好的例子：在分类训练中我们使用对数损失（马上我们会讨论它）作为损失函数，但是我们却使用精确率/召回率来作为它的评价函数。</p>
</blockquote>
<p>岭回归损失函数：</p>
<p>$J(\theta)=MSE(\theta)+\alpha \frac{1}{2} \sum_{i=1}^{n}{\theta _i ^2}$</p>
<p>$\theta_0$是没有被正则化的，所以累加从i=1开始，而不是i=0开始。如果定义w作为特征的权重向量（$\theta_1$到$\theta_n$），则正则项可以简写成$\frac{1}{2}(||w||_2)^2$ ，$||\cdot||_2$表示$l_2$范数。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-17.PNG" alt="img"></p>
<h6 id="封闭方程的解"><a href="#封闭方程的解" class="headerlink" title="封闭方程的解"></a>封闭方程的解</h6><script type="math/tex; mode=display">\hat \theta=(X^T\cdot X+\alpha A)^{-1}\cdot X^T\cdot y</script><p>A是一个除了左上角有一个0的nxn的单位矩阵，表示偏差$\theta_0​$不被正则化。</p>
<h6 id="随机梯度下降法求解"><a href="#随机梯度下降法求解" class="headerlink" title="随机梯度下降法求解"></a>随机梯度下降法求解</h6><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sgd_reg = SGDRegressor(penalty=<span class="string">"l2"</span>)</span><br><span class="line"><span class="comment"># penalty参数指的是正则项的惩罚类型。指定“l2”表明你要在损失函数上添加一项：权重向量 l2 范数平方的一半，这就是简单的岭回归。</span></span><br></pre></td></tr></table></figure>
<h5 id="Lasso回归"><a href="#Lasso回归" class="headerlink" title="Lasso回归"></a>Lasso回归</h5><p>Lasso 回归（也称 Least Absolute Shrinkage，或者 Selection Operator Regression）是另一种正则化版的线性回归：就像岭回归那样，它也在损失函数上添加了一个正则化项，但是它使用权重向量的$l_1$ 范数而不是权重向量 $l_2$范数平方的一半。</p>
<p>$J(\theta)=MSE(\theta)+\alpha \sum_{i=1}^{n}{|\theta _i|}$</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-18.PNG" alt="img"></p>
<p>Lasso 回归的一个重要特征是它倾向于完全消除最不重要的特征的权重（即将它们设置为零）。例如，右图中的虚线所示$\alpha=10^{-7}$，曲线看起来像一条二次曲线，而且几乎是线性的，这是因为所有的高阶多项特征都被设置为零。换句话说，Lasso回归自动的进行特征选择同时输出一个稀疏模型（即，具有很少的非零权重）。</p>
<p>Lasso 回归子梯度向量:</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-93eea6b5c197bbc8d7be8b4c14e9f8f3.gif" alt="g(\theta,J)=\nabla_{\theta}MSE(\theta)+ \alpha{\left(\begin{matrix} sign(\theta_1)\\ sign(\theta_2)\\ \vdots \\ sign(\theta_n)\\ \end{matrix}\right)}\ where\ sign(\theta_i)= \begin{cases} -1, &amp;\theta_i&lt;0 \\ 0, &amp;\theta_i=0 \\ +1,&amp;\theta_i&gt;0 \\ \end{cases}"></p>
<h5 id="弹性网络（ElasticNet）"><a href="#弹性网络（ElasticNet）" class="headerlink" title="弹性网络（ElasticNet）"></a>弹性网络（ElasticNet）</h5><p>弹性网络介于 Ridge 回归和 Lasso 回归之间。它的正则项是 Ridge 回归和 Lasso 回归正则项的简单混合，同时你可以控制它们的混合率 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-4b43b0aee35624cd95b910189b3dc231.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-4b43b0aee35624cd95b910189b3dc231.gif" alt="r"></a></p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-e4da079f692fe35778bbdf1fdf120d99.gif" alt="J(\theta)=MSE(\theta)+r\alpha\sum\limits_{i=1}n\left|\theta_i \right|+\frac{1-r}{2}\alpha\sum\limits_{i=1}n\theta_i^2"></p>
<h5 id="早起停止法（Early-Stopping）"><a href="#早起停止法（Early-Stopping）" class="headerlink" title="早起停止法（Early Stopping）"></a>早起停止法（Early Stopping）</h5><p>对于迭代学习算法，有一种非常特殊的正则化方法，就像梯度下降在验证错误达到最小值时立即停止训练那样。我们称为早期停止法。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-20.PNG" alt="img"></p>
<h5 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h5><blockquote>
<p>一些回归算法也可以用于分类（反之亦然）。 Logistic 回归（也称为 Logit 回归）通常用于估计一个实例属于某个特定类别的概率。 若估计的概率大于 50%，则模型预测这个实例属于当前类（称为正类，标记为“1”），反之预测它不属于当前类（即属于负类 ，标记为“0”）。 这样便成为了一个二元分类器。</p>
</blockquote>
<p>逻辑回归模型的概率估计：</p>
<p>$\hat p=h_\theta=\sigma(\theta^T\cdot x)$</p>
<p>其中$\sigma()$是Logistic函数，是一个sigmoid函数，输出是介于0到1之间的数字。</p>
<p>逻辑函数：</p>
<p>$\sigma(t)=\frac{1}{1+\exp(-t)}$</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-21.PNG" alt="img"></p>
<p>逻辑回归预测模型：</p>
<p>$\hat y = \left\{ \begin{array}{cl} 0,&amp; \hat p &lt; 0.5 \\ 1,&amp; \hat p \geq 0.5 \end{array} \right.$</p>
<h6 id="训练和损失函数"><a href="#训练和损失函数" class="headerlink" title="训练和损失函数"></a>训练和损失函数</h6><p>单个样本的损失函数：</p>
<p>$c(\theta)=\left \{ \begin{array}{lc} -\log(\hat p), &amp;y=1 \\ -\log(1-\hat p),&amp; y=0 \end{array}\right.$</p>
<p>整个训练集的损失函数只是所有训练实例的平均值。</p>
<p>逻辑回归的损失函数：<br>$J (\theta) = -\frac{1}{m} \sum_{i=1}^{m}[y^{(i)}log(\hat p^{(i)})+(1-y^{(i)})log(1-\hat p^{(i)})]$</p>
<p>但是这个损失函数对于求解最小化损失函数的$\theta是没有公式解的（没有等价的正态方程），但该损失函数是凸的，所以梯度下降（或任何其他优化算法）一定能够找到全局最小值。</p>
<p>逻辑回归损失函数的偏导数：</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial \theta_j}J(\theta_J)=\frac{1}{m}\sum_{i=1}^{m}(\sigma({\theta^T\cdot x^{(i)})-y^{(i)})x_j^{}(i)}</script><h6 id="决策边界"><a href="#决策边界" class="headerlink" title="决策边界"></a>决策边界</h6><p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-23.PNG" alt="img"></p>
<p>概率=0.5的分界线</p>
<p>逻辑回归模型也可以 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-8524eb1789cf2093cfccc4c297138c7f.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-8524eb1789cf2093cfccc4c297138c7f.gif" alt="\ell_1"></a> 或者 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-f2d02eaf32cb7a351989198531c0d12a.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-f2d02eaf32cb7a351989198531c0d12a.gif" alt="\ell_2"></a> 惩罚使用进行正则化。Scikit-Learn 默认添加了 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-f2d02eaf32cb7a351989198531c0d12a.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-f2d02eaf32cb7a351989198531c0d12a.gif" alt="\ell_2"></a> 惩罚。</p>
<h5 id="Softmax回归"><a href="#Softmax回归" class="headerlink" title="Softmax回归"></a>Softmax回归</h5><p>Logistic 回归模型可以直接推广到支持多类别分类，不必组合和训练多个二分类器， 其称为 Softmax 回归或多类别 Logistic 回归。</p>
<p>当给定一个实例 $x$ 时，Softmax 回归模型首先计算 $k$ 类的分数，然$s_k(x)$ 后将分数应用在<code>Softmax</code>函数（也称为归一化指数）上，估计出每类的概率。</p>
<p>k类的Softmax得分：</p>
<p>$s_k(x)=\theta^T\cdot x$</p>
<blockquote>
<p>每个类都有自己独一无二的参数向量 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-9f888eddb683fe5f80f87f44bd727b08.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-9f888eddb683fe5f80f87f44bd727b08.gif" alt="\theta_k"></a>。 所有这些向量通常作为行放在参数矩阵 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-b9dce96eb3d5a71b28f9f198c28d2d1b.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-b9dce96eb3d5a71b28f9f198c28d2d1b.gif" alt="\Theta"></a> 中。</p>
</blockquote>
<p>Softmax函数：</p>
<script type="math/tex; mode=display">
\hat p_k=\sigma(s(x))_k=\frac{\exp(s_k(x))}{\sum_{j=1}^{K}{\exp(s_j(x))}}</script><p>$K$ 表示类的总数</p>
<p>Softmax 回归模型分类器预测结果:</p>
<p>$\hat y=argmax\  \sigma(s(x))_k=argmax\ s_k(x) = argmax \ (\theta_k^T\cdot x)$</p>
<blockquote>
<p>Softmax 回归分类器一次只能预测一个类（即它是多类的，但不是多输出的），因此它只能用于判断互斥的类别，如不同类型的植物。 不能用它来识别一张照片中的多个人。</p>
</blockquote>
<h6 id="训练和损失函数-1"><a href="#训练和损失函数-1" class="headerlink" title="训练和损失函数"></a>训练和损失函数</h6><p>目标是建立一个模型在目标类别上有着较高的概率（因此其他类别的概率较低）</p>
<p>交叉熵:</p>
<script type="math/tex; mode=display">
J (\theta) = -\frac{1}{m} \sum_{i=1}^{m}\sum_{k=1}^{K}y^{(i)}_klog(\hat p^{(i)}_k)</script><blockquote>
<p>交叉熵源于信息论。</p>
<p>假设你想要高效地传输每天的天气信息。如果有八个选项（晴天，雨天等），则可以使用3位对每个选项进行编码，因为 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-5f344a952e29992de54b8cfe645b2d5b.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-5f344a952e29992de54b8cfe645b2d5b.gif" alt="2^3=8"></a>。但是，如果你认为几乎每天都是晴天，更高效的编码“晴天”的方式是：只用一位（0）。剩下的七项使用四位（从 1 开始）。交叉熵度量每个选项实际发送的平均比特数。 如果你对天气的假设是完美的，交叉熵就等于天气本身的熵（即其内部的不确定性）。 但是，如果你的假设是错误的（例如，如果经常下雨）交叉熵将会更大，称为 Kullback-Leibler 散度（KL 散度）。</p>
<p>两个概率分布 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-83878c91171338902e0fe0fb97a8c47a.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-83878c91171338902e0fe0fb97a8c47a.gif" alt="p"></a> 和 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-7694f4a66316e53c8cdd9d9954bd611d.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-7694f4a66316e53c8cdd9d9954bd611d.gif" alt="q"></a> 之间的交叉熵定义为：<a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-6bc68f603b52e51645b4bbd318f8cdfe.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-6bc68f603b52e51645b4bbd318f8cdfe.gif" alt="H(p,q)=-\sum_xp(x)\log q(x)"></a>（分布至少是离散的）</p>
</blockquote>
<p>$k$ 类交叉熵的梯度向量:</p>
<p>$\nabla_{\theta_k} J (\Theta) = -\frac{1}{m} \sum_{i=1}^{m}(p^{(i)}_k - y^{(i)}_k )x^{(i)})$</p>
<h4 id="Exercise"><a href="#Exercise" class="headerlink" title="Exercise"></a>Exercise</h4><ol>
<li><p>如果你有一个数百万特征的训练集，你应该选择哪种线性回归训练算法？</p>
<blockquote>
<p>mini-batch GD或者SGD</p>
</blockquote>
</li>
<li><p>假设你训练集中特征的数值尺度（scale）有着非常大的差异，哪种算法会受到影响？有多大的影响？对于这些影响你可以做什么？</p>
<blockquote>
<p>如果训练集的特征尺度差距太大，损失函数的等高线会呈椭圆状，利用梯度下降来求最优解的过程中会很难收敛，梯度方向变化很剧烈，收敛速度很慢，并且可能不会收敛到最优点。</p>
<p>对数据进行缩放（StandardScaler），归一化</p>
</blockquote>
</li>
<li><p>训练 Logistic 回归模型时，梯度下降是否会陷入局部最低点？</p>
<blockquote>
<p>不会，其损失函数是一个凸函数。</p>
</blockquote>
</li>
<li><p>在有足够的训练时间下，是否所有的梯度下降都会得到相同的模型参数？</p>
<blockquote>
<p>不是，SGD因为随机性，达到损失函数只会呈现大体下降趋势，随着时间的推移，会非常靠近最小值，但只会在附近摆动。</p>
<p>mini-batch GD也会有一定的摆动。</p>
</blockquote>
</li>
<li><p>假设你使用批量梯度下降法，画出每一代的验证误差。当你发现验证误差一直增大，接下来会发生什么？你怎么解决这个问题？</p>
<blockquote>
<p>模型发散，难以收敛。减小学习率</p>
<p>或者模型过拟合，需要早停</p>
</blockquote>
</li>
<li><p>当验证误差升高时，立即停止小批量梯度下降是否是一个好主意？</p>
<blockquote>
<p>不是，因为mini-batch的损失函数随时间大体下降，但会有一定波动。</p>
<p>更好的选择是定期保存模型，如果经过很长一段时间仍然没有改进的话，可以恢复到保存的最好模型。</p>
</blockquote>
</li>
<li><p>哪个梯度下降算法（在我们讨论的那些算法中）可以最快到达解的附近？哪个的确实会收敛？怎么使其他算法也收敛？</p>
<blockquote>
<p>SGD最快</p>
<p>梯度下降法</p>
<p>逐步减小学习率</p>
</blockquote>
</li>
<li><p>假设你使用多项式回归，画出学习曲线，在图上发现学习误差和验证误差之间有着很大的间隙。这表示发生了什么？有哪三种方法可以解决这个问题？</p>
<blockquote>
<p>如果学习误差比验证误差小很多，说明发生了过拟合。</p>
<p>可以通过正则化（岭回归，Lasso回归和弹性网络）这个模型降低过拟合程度。</p>
<p>也可以提供更多的训练数据。</p>
<p>或者改变模型。</p>
</blockquote>
</li>
<li><p>假设你使用岭回归，并发现训练误差和验证误差都很高，并且几乎相等。你的模型表现是高偏差还是高方差？这时你应该增大正则化参数 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-7b7f9dbfea05c83784f8b85149852f08.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-7b7f9dbfea05c83784f8b85149852f08.gif" alt="\alpha"></a>，还是降低它？</p>
<blockquote>
<p>高偏差，应该减小$\alpha$。</p>
</blockquote>
</li>
<li><p>你为什么要这样做：</p>
</li>
</ol>
<ul>
<li><p>使用岭回归代替线性回归？</p>
<blockquote>
<p>模型有正则化的时候会比没有正则化的时候又更好的泛化性能，岭回归就是对模型的参数做了正则化，约束其幅值变化不能太大，否则会容易出现过拟合。</p>
</blockquote>
</li>
<li><p>Lasso 回归代替岭回归？</p>
<blockquote>
<p>当特征仅有少数是真正有用的时候，对重要的特征进行选择，将无用特征的权重降为零，增加模型的可解释性。</p>
</blockquote>
</li>
<li><p>弹性网络代替 Lasso 回归？</p>
<blockquote>
<p>当特征数量比样本的数量大的时候，或者特征之间有很强的相关性时，Lasso 可能会表现的不规律。</p>
</blockquote>
</li>
</ul>
<ol>
<li><p>假设你想判断一副图片是室内还是室外，白天还是晚上。你应该选择二个逻辑回归分类器，还是一个 Softmax 分类器？</p>
<blockquote>
<p>两个逻辑回归分类器</p>
</blockquote>
</li>
<li><p>在 Softmax 回归上应用批量梯度下降的早期停止法（不使用 Scikit-Learn）。</p>
<blockquote>
<p>​</p>
</blockquote>
</li>
</ol>
<hr>
<h2 id="第05章-支持向量机"><a href="#第05章-支持向量机" class="headerlink" title="第05章 支持向量机"></a>第05章 支持向量机</h2><p>能够做线性或者非线性的分类，回归，甚至异常值检测。SVM 特别适合应用于复杂但中小规模数据集的分类问题。</p>
<h4 id="线性支持向量机分类"><a href="#线性支持向量机分类" class="headerlink" title="线性支持向量机分类"></a>线性支持向量机分类</h4><p>SVM 分类器的判定边界实线，不仅分开了两种类别，而且还尽可能地远离了最靠近的训练数据点。（最大间隔分类）</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/5-1.jpg" alt="img"></p>
<p>判定边界是由位于“街道”边缘的样本点确定的，这些样本点被称为“支持向量”</p>
<h5 id="软间隔分类"><a href="#软间隔分类" class="headerlink" title="软间隔分类"></a>软间隔分类</h5><p>硬间隔分类有两个问题，</p>
<ol>
<li>只对线性可分的数据起作用.</li>
<li>对异常点敏感。</li>
</ol>
<p>在 Scikit-Learn 库的 SVM 类，可以用<code>C</code>超参数（惩罚系数）来控制这种平衡：较小的<code>C</code>会导致更宽的“街道”，但更多的间隔违规。</p>
<blockquote>
<p>SVM 模型过拟合，可以尝试通过减小超参数<code>C</code>去调整</p>
</blockquote>
<h4 id="非线性支持向量机分类"><a href="#非线性支持向量机分类" class="headerlink" title="非线性支持向量机分类"></a>非线性支持向量机分类</h4><h5 id="增加更多的特征"><a href="#增加更多的特征" class="headerlink" title="增加更多的特征"></a>增加更多的特征</h5><p>通过 Scikit-Learn，可以创建一个流水线（Pipeline）去包含多项式特征（PolynomialFeatures）变换，然后StandardScaler.</p>
<h5 id="多项式核"><a href="#多项式核" class="headerlink" title="多项式核"></a>多项式核</h5><p>添加多项式特征会：大量特征导致的组合爆炸</p>
<h5 id="增加相似特征"><a href="#增加相似特征" class="headerlink" title="增加相似特征"></a>增加相似特征</h5><p>使用相似函数（similarity funtion）计算每个样本与特定地标（landmark）的相似度。</p>
<p>定义一个相似函数，即<strong>高斯径向基函数（Gaussian Radial Basis Function，RBF）</strong>，设置<code>γ = 0.3</code></p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-8b908429a5b5ee2e519f8caa16f82ee1.gif" alt="\phi_{\gamma}(x, \ell) = exp(-\gamma \|x - \ell \|^2)"></p>
<p>是个从 0 到 1 的钟型函数。</p>
<h5 id="高斯-RBF-核"><a href="#高斯-RBF-核" class="headerlink" title="高斯 RBF 核"></a>高斯 RBF 核</h5><p>相似特征法在所有额外特征上的计算成本可能很高，特别是在大规模的训练集上。</p>
<h5 id="计算复杂性"><a href="#计算复杂性" class="headerlink" title="计算复杂性"></a>计算复杂性</h5><p><code>LinearSVC</code>类基于<code>liblinear</code>库，它实现了线性 SVM 的优化算法。它并不支持核技巧，但是它样本和特征的数量几乎是线性的：训练时间复杂度大约为<code>O(m × n)</code>。</p>
<p>SVC 类基于<code>libsvm</code>库，它实现了支持核技巧的算法。训练时间复杂度通常介<code>于O(m^2 × n)</code>和<code>O(m^3 × n)</code>之间。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/tb-5-1.jpg" alt="img"></p>
<h4 id="SVM回归"><a href="#SVM回归" class="headerlink" title="SVM回归"></a>SVM回归</h4><p>SVM 回归任务是限制间隔违规情况下，尽量放置更多的样本在“街道”上。“街道”的宽度由超参数<code>ϵ</code>控制。</p>
<p>可以使用 Scikit-Learn 的<code>LinearSVR</code>类去实现线性 SVM 回归。</p>
<p>处理非线性回归任务，可以使用核化的 SVM 模型。</p>
<blockquote>
<p>LinearSVR没有support_属性</p>
</blockquote>
<h4 id="背后机制"><a href="#背后机制" class="headerlink" title="背后机制"></a>背后机制</h4><p>首先，关于符号的约定：在第 4 章，我们将所有模型参数放在一个矢量<code>θ</code>里，包括偏置项<code>θ0</code>，<code>θ1</code>到<code>θn</code>的输入特征权重，和增加一个偏差输入<code>x0 = 1</code>到所有样本。</p>
<p>在本章中，我们将使用一个不同的符号约定，在处理 SVM 上，这更方便，也更常见：<strong>偏置项被命名为b，特征权重向量被称为w</strong>，在输入特征向量中不再添加偏置特征。</p>
<h5 id="决策函数和预测"><a href="#决策函数和预测" class="headerlink" title="决策函数和预测"></a>决策函数和预测</h5><p>线性 SVM 分类器通过简单地计算决策函数 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-7781983bd977537b3c5d060e217ea82a.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-7781983bd977537b3c5d060e217ea82a.gif" alt="w \cdot x+b = w_1 x_1 + ... + w_n x_n + b"></a> 来预测新样本的类别：如果结果是正的，预测类别<code>ŷ</code>是正类，为 1，否则他就是负类，为 0。</p>
<p>$\hat y = \left \{ \begin{array}{ll}  0 &amp; if \ w^T\cdot x+b&lt;0 \\1 &amp; \ w^T\cdot x+b\geq0\end{array}\right.$</p>
<p>训练线性 SVM 分类器意味着找到<code>w</code>值和<code>b</code>值使得这一个间隔尽可能大，同时避免间隔违规（硬间隔）或限制它们（软间隔）</p>
<h5 id="训练目标"><a href="#训练目标" class="headerlink" title="训练目标"></a>训练目标</h5><p>决策函数的斜率：它等于权重向量的范数 $||\omega||$ ，斜率除于 2，那么间隔将增加两倍。权重向量<code>w</code>越小，间隔越大。</p>
<p>目标是最小化$||\omega||$ ，从而获得大的间隔。如果想要避免间隔违规（硬间隔），对于正的训练样本，需要决策函数大于 1，对于负训练样本，小于 -1。即：$t^{(i)}\ w^T\cdot x^{(i)}+b\geq1$</p>
<p><strong>可以将硬间隔线性 SVM 分类器表示为约束优化问题:</strong></p>
<script type="math/tex; mode=display">
minimize \frac{1}{2} \omega^T\cdot \omega \\
subject \  to\  t^{(i)}\ w^T\cdot x^{(i)}+b\geq1 \ \ \ for \ i=1,2,3,\cdots , m</script><blockquote>
<p><a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-9a84ebda628c391e3046dfc2307e3c85.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-9a84ebda628c391e3046dfc2307e3c85.gif" alt="1/2 w^T w"></a> 等于 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-98c822c91ab5af02c383eb03fa5b5446.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-98c822c91ab5af02c383eb03fa5b5446.gif" alt="1/2 \|w\|^2"></a>，最小化 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-9a84ebda628c391e3046dfc2307e3c85.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-9a84ebda628c391e3046dfc2307e3c85.gif" alt="1/2 w^T w"></a>，而不是最小化 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-03549015bd48d379883d926e6857b448.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-03549015bd48d379883d926e6857b448.gif" alt="\|w\|"></a>。因为<a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-03549015bd48d379883d926e6857b448.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-03549015bd48d379883d926e6857b448.gif" alt="\|w\|"></a> 在<code>w=0</code>处是不可微的。优化算法在可微函数表现得更好。</p>
</blockquote>
<p>软间隔：</p>
<p>对每个样本应用一个松弛变量（slack variable）$\zeta^{(i)}\geq0$ 。$\zeta^{(i)}$表示了第<code>i</code>个样本允许违规间隔的程度。</p>
<p>现在有两个不一致的目标：</p>
<ol>
<li>使松弛变量尽可能的小，从而减小间隔违规.</li>
<li>使<code>1/2 w·w</code>尽量小，从而增大间隔。</li>
</ol>
<p>这时<code>C</code>超参数发挥作用：它允许我们在两个目标之间权衡。</p>
<script type="math/tex; mode=display">
minimize\  \frac{1}{2} \omega^T\cdot \omega +C\sum_{i=1}^{m}\zeta^{(i)}\\

subject \  to\  t^{(i)}\ w^T\cdot x^{(i)}+b\geq1-\zeta^{(i)}\ \  and \ \ \zeta^{(i)} \geq0 \ \  for \ i=1,2,3,\cdots , m</script><h5 id="二次间隔"><a href="#二次间隔" class="headerlink" title="二次间隔"></a>二次间隔</h5><p>硬间隔和软间隔都是<strong>线性约束的凸二次规划优化问题</strong>。这些问题被称之为二次规划（QP）问题。</p>
<h5 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h5><p>给出一个约束优化问题，即原始问题（primal problem），它可能表示不同但是和另一个问题紧密相连，称为对偶问题（Dual Problem）。对偶问题的解通常是对原始问题的解给出一个下界约束，但在某些条件下，它们可以获得相同解。</p>
<p><strong>线性 SVM 的对偶形式（核技巧的基本）</strong>：</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/eq-5-6.gif" alt="img"></p>
<p>一旦找到最小化公式的向量<code>α</code>，可以计算<code>w</code>和<code>b</code>，从而使原始问题最小化。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/eq-5-7.gif" alt="img"></p>
<p>训练样本的数量比特征数量小的时候，对偶问题比原始问题要快得多。</p>
<h5 id="核化支持向量机"><a href="#核化支持向量机" class="headerlink" title="核化支持向量机"></a>核化支持向量机</h5><p>把一个 2 次多项式变换应用到二维空间的训练集，然后在变换后的训练集上训练一个线性SVM分类器。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/eq-5-8.gif" alt="img"></p>
<p>转换后向量的点积等于原始向量点积的平方:</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/eq-5-9.gif" alt="img"></p>
<p><strong>核技巧的精髓:</strong></p>
<p>不需要对训练样本进行转换：仅仅需要在对偶问题公式中，将点积替换成它点积的平方。</p>
<p>函数$K(a, b) = (a^T b)^2$ 被称为二次多项式核（polynomial kernel）。在机器学习，核函数是一个能计算点积的函数，并只基于原始向量<code>a</code>和<code>b</code>，不需要计算（甚至知道）转换<code>ϕ</code>。</p>
<p><strong>一些常见的核函数</strong></p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/eq-5-10.gif" alt="img"></p>
<blockquote>
<p>Mercer 定理</p>
<p>根据 Mercer 定理，如果函数<code>K(a, b)</code>满足一些 Mercer 条件的数学条件(<code>K</code>函数在参数内必须是连续，对称，即<code>K(a, b)=K(b, a)</code>，等)，那么存在函数<code>ϕ</code>，将<code>a</code>和<code>b</code>映射到另一个空间（可能有更高的维度），有 $K(a, b) = \phi(a)^T ϕ(b)$。所以可以用<code>K</code>作为核函数，即使不知道<code>ϕ</code>。使用高斯核（Gaussian RBF kernel）情况下，它实际是将每个训练样本映射到无限维空间，所以不需要知道是怎么执行映射的也是一件好事。</p>
<p>注意一些常用核函数（例如 Sigmoid 核函数）并不满足所有的 Mercer 条件，然而在实践中通常表现得很好。</p>
</blockquote>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/eq-5-11.gif" alt="img"></p>
<p>也需要使用同样的技巧来计算偏置项<code>b</code></p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/eq-5-12.gif" alt="img"></p>
<p>支持向量才满足<code>α(i)≠0</code>，做出预测只涉及计算为支持向量部分的输入样本 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-992fd41f053d328db0ca0287eed0e2e9.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-992fd41f053d328db0ca0287eed0e2e9.gif" alt="x^{(n)}"></a> 的点积，而不是全部的训练样本。</p>
<h5 id="在线支持向量机"><a href="#在线支持向量机" class="headerlink" title="在线支持向量机"></a>在线支持向量机</h5><p>线学习意味着增量地学习，不断有新实例。</p>
<p>于线性SVM分类器，一种方式是使用梯度下降（例如使用<code>SGDClassifire</code>）最小化代价函数：</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/eq-5-13.gif" alt="img"></p>
<p>第一个和会使模型有一个小的权重向量<code>w</code>，从而获得一个更大的间隔。第二个和计算所有间隔违规的总数。如果样本位于“街道”上和正确的一边，或它与“街道”正确一边的距离成比例，则间隔违规等于 0。最小化保证了模型的间隔违规尽可能小并且少。</p>
<blockquote>
<p>Hinge 损失</p>
<p>函数<code>max(0, 1–t)</code>被称为 Hinge 损失函数（如下）。当<code>t≥1</code>时，Hinge 值为 0。如果<code>t&lt;1</code>,它的导数（斜率）为 -1，若<code>t&gt;1</code>，则等于0。在<code>t=1</code>处，它是不可微的，但就像套索回归（Lasso Regression）一样，仍然可以在<code>t=0</code>时使用梯度下降法（即 -1 到 0 之间任何值）<img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/5-hinge.jpg" alt="img"></p>
</blockquote>
<p>大规模的非线性问题，可能需要考虑使用神经网络。</p>
<h4 id="Exercise-1"><a href="#Exercise-1" class="headerlink" title="Exercise"></a>Exercise</h4><ol>
<li><p>支持向量机背后的基本思想是什么</p>
<blockquote>
<p>支持向量机的背后的基本思想：寻找具有最大间隔的分类平面，来对正负样本进行分类。</p>
</blockquote>
</li>
<li><p>什么是支持向量</p>
<blockquote>
<p>支持向量就是最大间隔平面边界上样本点，这些样本点被称为“支持向量”</p>
</blockquote>
</li>
<li><p>当使用 SVM 时，为什么标准化输入很重要？</p>
<blockquote>
<p>因为SVM 对特征缩放比较敏感，对特征进行缩放可以使得判定边界更宽。</p>
<p>SVM寻找具有最大分类间隔的平面，如果不对输入进行归一化，SVM会忽略小的特征。</p>
</blockquote>
</li>
<li><p>分类一个样本时，SVM 分类器能够输出一个置信值吗？概率呢？</p>
<blockquote>
<p>SVM分类器通过简单地计算决策函数$\omega \cdot x+b$来预测新样本的类别，如果小于0，则为负类，如果大于等于0，则为正类。</p>
<p>SVM分类器不会输出每个类别的概率。</p>
</blockquote>
</li>
<li><p>在一个有数百万训练样本和数百特征的训练集上，你是否应该使用 SVM 原始形式或对偶形式来训练一个模型？</p>
<blockquote>
<p>线性SVM的训练时间复杂度约为O(m x n)，而对偶形式的复杂度通常介于O(m^2 x n) 到 O(m^3 x n)，m为实例个数，当训练样本变大时，它将变得极其慢。</p>
<p>所以对于大规模线性问题，可以使用SVM的原始形式，而对于大规模的非线性问题，可能需要考虑使用神经网络。</p>
</blockquote>
</li>
<li><p>假设你用 RBF 核来训练一个 SVM 分类器，如果对训练集欠拟合：你应该增大或者减小<code>γ</code>吗？调整参数<code>C</code>呢？</p>
<blockquote>
<p>RBF的形式：$\phi_{\gamma}(x, \ell) = exp(-\gamma |x - \ell |^2)$，是一个钟形曲线，<code>γ</code> 越大，钟形曲线越窄，每个样本的影响范围变得更小，边界更细化。</p>
<p>超参数<code>C</code>控制SCM分类模型的软硬，较小的<code>C</code>会导致更宽的分类间隔平面，但更多的间隔违规。</p>
<p>所以欠拟合时可以增大<code>γ</code>，增大<code>C</code></p>
</blockquote>
</li>
<li><p>使用现有的 QP 解决方案，你应该怎么样设置 QP 参数（<code>H</code>，<code>f</code>，<code>A</code>，和<code>b</code>）去解决一个软间隔线性 SVM 分类器问题？</p>
<blockquote>
<p>软间隔分类：</p>
<script type="math/tex; mode=display">
minimize\  \frac{1}{2} \omega^T\cdot \omega +C\sum_{i=1}^{m}\zeta^{(i)}\\

subject \  to\  t^{(i)}\ w^T\cdot x^{(i)}+b\geq1-\zeta^{(i)}\ \  and \ \ \zeta^{(i)} \geq0 \ \  for \ i=1,2,3,\cdots , m</script><p>QP(二次规划问题，即线性约束的凸二次规划优化问题)</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_5/eq-5-5.gif" alt="img"></p>
<p>H 是 $n_p \times n_p$的单位矩阵，左上角为0（忽略偏置向）</p>
<p>p = $（b,\ \omega_1\ \cdots\ \omega_n)^T$</p>
<p>$f^T\cdot p \ = \     C\cdot max(1-p^T\cdot A_i,0))$</p>
<p>$b_i=1-max(1-p^T\cdot A_i,0)$</p>
<p>$a_i^j=x_j^{(i)}\  \  i=1\cdots n_c;\ j=1\cdots n_p$ 第i个实例的第j个特征，但$x^{(i)}$带一个1的偏置项。</p>
</blockquote>
</li>
<li><p>在一个线性可分的数据集训练一个<code>LinearSVC</code>，并在同一个数据集上训练一个<code>SVC</code>和<code>SGDClassifier</code>，看它们是否产生了大致相同效果的模型。</p>
<blockquote>
<p>​</p>
</blockquote>
</li>
<li><p>在 MNIST 数据集上训练一个 SVM 分类器。因为 SVM 分类器是二元的分类，你需要使用一对多（one-versus-all）来对 10 个数字进行分类。你可能需要使用小的验证集来调整超参数，以加快进程。最后你能达到多少准确度？</p>
</li>
<li><p>在加利福尼亚住宅（California housing）数据集上训练一个 SVM 回归模型</p>
</li>
</ol>
<hr>
<h2 id="第06章-决策树"><a href="#第06章-决策树" class="headerlink" title="第06章 决策树"></a>第06章 决策树</h2><p>决策树是一种多功能机器学习算法， 即可以执行分类任务也可以执行回归任务， 甚至包括多输出（multioutput）任务。</p>
<h3 id="决策树的训练和可视化"><a href="#决策树的训练和可视化" class="headerlink" title="决策树的训练和可视化"></a>决策树的训练和可视化</h3><blockquote>
<p>决策树的众多特性之一就是， 它不需要太多的数据预处理， 尤其是不需要进行特征的缩放或者归一化。</p>
</blockquote>
<ul>
<li>节点的<code>samples</code>属性统计出它应用于多少个训练样本实例。</li>
<li>节点的<code>value</code>属性：这个节点对于每一个类别的样例有多少个。</li>
<li>节点的<code>Gini</code>属性用于测量它的纯度：如果一个节点包含的所有训练样例全都是同一类别的，这个节点是纯的（<code>Gini=0</code>）。</li>
</ul>
<p><strong>Gini分数$G_i$</strong></p>
<p>$G_i=1-\sum_{k=1}^{n}P_{i,k}^2$</p>
<p>$P_{i,k}$是第<code>i</code>个节点中训练实例为的<code>k</code>类实例的比例。</p>
<blockquote>
<p>Scikit-Learn 用的是 CART 算法， CART 算法仅产生二叉树：每一个非叶节点总是只有两个子节点（只有是或否两个结果）。然而，像 ID3 这样的算法可以产生超过两个子节点的决策树模型。</p>
</blockquote>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_6/102" alt="1528081141956"></p>
<h3 id="估计分类概率"><a href="#估计分类概率" class="headerlink" title="估计分类概率"></a>估计分类概率</h3><p>决策树还可以估计某个实例属于特定类<code>k</code>的概率：首先遍历树来查找此实例的叶节点，然后它返回此节点中类<code>k</code>的训练实例的比例。</p>
<blockquote>
<p>假设你发现了一个花瓣长 5 厘米，宽 1.5 厘米的花朵。相应的叶节点是深度为 2 的左节点，因此决策树应该输出以下概率：Iris-Setosa 为 0%（0/54），Iris-Versicolor 为 90.7%（49/54），Iris-Virginica 为 9.3%（5/54）。当然，如果你要求它预测具体的类，它应该输出 Iris-Versicolor（类别 1），因为它具有最高的概率。</p>
</blockquote>
<h3 id="CART训练算法"><a href="#CART训练算法" class="headerlink" title="CART训练算法"></a>CART训练算法</h3><p>Scikit-Learn 用<strong>分裂回归树（Classification And Regression Tree，简称 CART）算法训练决策树（也叫“增长树”）</strong>。</p>
<p>首先使用单个特征<code>k</code>和阈值 $t_k$ 例如，（“花瓣长度<code>≤2.45cm</code>”）将训练集分成两个子集。它如何选择<code>k</code>和 $t_k$ ？它寻找到能够产生最纯粹子集的一对 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-32cb6265eb19ce4be37ecf6650ff766a.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-32cb6265eb19ce4be37ecf6650ff766a.gif" alt="(k, t_k)"></a>，然后通过子集大小加权计算。</p>
<p>算法会尝试最小化成本函数：</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_6/104" alt="1528086977613"></p>
<blockquote>
<p>CART 算法是一种贪婪算法：贪婪地搜索最高级别的最佳分割方式，然后在每个深度重复该过程。 </p>
<p>不检查分割是否能够在几个级别中的全部分割可能中找到最佳方法。</p>
<p>贪婪算法通常会产生一个相当好的解决方法，但它不保证这是全局中的最佳解决方案。</p>
</blockquote>
<h4 id="NP完全问题"><a href="#NP完全问题" class="headerlink" title="NP完全问题"></a>NP完全问题</h4><p>寻找最佳的决策树是NP完成问题(<code>Non-deterministic Polynomial</code>，即多项式复杂程度的非确定性问题)，也会简称为NP-C问题。</p>
<p>决策树的这一特点，说明无法利用计算机在多项式时间内，找出全局最优的解。也正因为如此，大多数决策树算法都采用启发式的算法，如&amp;<strong>贪心算法</strong>，来指导对假设空间的搜索。可以说，决策树最后的结果，是在每一步、每一个节点上做的局部最优选择。决策树得到的结果，无法保证是全局最优解。</p>
<h5 id="P类问题"><a href="#P类问题" class="headerlink" title="P类问题"></a>P类问题</h5><blockquote>
<p> 所有可以在多项式时间内求解的判定问题构成<strong>P类问题</strong></p>
</blockquote>
<p><strong>判定问题</strong>是指回答结果输出为<code>Yes</code>或<code>No</code>的问题，比如：3233是否可以写成两个大于1的数字的乘积？</p>
<p>在设计程序时，需要评估这个程序的时间复杂度，即衡量当问题规模变大后，程序执行所需的时间增长会有多快。如$O(1)$表示常数级别，即不管问题的规模变大多少倍，所耗的时间不会改变；$O(N^2)$表示平方级别，即当问题规模增大至2倍时，所花费的时间则放大至4倍；$O(2^N)$表示指数级别，即当问题规模倍数扩大时，所用时间会呈指数放大。</p>
<p><strong>多项式时间</strong>则是指$O(1)、O(logN)、O(N^2)$等这类可用多项式表示的时间复杂度，通常认为计算机可解决的问题只限于多项式时间内。而$O(2^N)、O(N!)$这类非多项式级别的问题，其复杂度往往已经到了计算机都接受不了的程度。</p>
<h5 id="NP类问题"><a href="#NP类问题" class="headerlink" title="NP类问题"></a>NP类问题</h5><blockquote>
<p>所有非确定性多项式时间内可解的判定问题构成<strong>NP类问题</strong></p>
</blockquote>
<p>NP类问题将问题分为求解和验证两个阶段，问题的求解是非确定性的，无法在多项式时间内得到答案，而问题的验证却是确定的，能够在多项式时间里确定结果。</p>
<p>比如：是否存在一个公式可以计算下一个质数是多少？这个问题的答案目前是无法直接计算出来的，但是如果某人给出了一个公式，我们却可以在多项式时间里对这个公式进行验证。</p>
<h5 id="NP完全问题-1"><a href="#NP完全问题-1" class="headerlink" title="NP完全问题"></a>NP完全问题</h5><blockquote>
<p>NP类问题的一种特殊情况，这类问题中每个问题的复杂度与整个类的复杂度有关联性，假如其中任意一个问题在多项式时间内可解的，则这一类问题都是多项式时间可解。这些问题被称为<strong>NP完全问题</strong>。</p>
</blockquote>
<p>总结这几类问题的特点，可参考如下这个表格：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>问题类型</th>
<th>是否能在多项式时间内求解</th>
<th>是否能在多项式时间内验证</th>
</tr>
</thead>
<tbody>
<tr>
<td>P</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>NP</td>
<td>是 or 否</td>
<td>是</td>
</tr>
<tr>
<td>NP-C</td>
<td>未知</td>
<td>是</td>
</tr>
</tbody>
</table>
</div>
<p>参考：<a href="https://www.jianshu.com/p/dcb0b52f4935" target="_blank" rel="noopener">https://www.jianshu.com/p/dcb0b52f4935</a></p>
<h3 id="计算复杂度"><a href="#计算复杂度" class="headerlink" title="计算复杂度"></a>计算复杂度</h3><p>建立好决策树模型后， 做出<strong>预测</strong>需要遍历决策树， 从根节点一直到叶节点。决策树通常近似左右平衡，因此遍历决策树需要经历大致  $O(log_2m)$个节点。由于每个节点只需要检查一个特征的值，因此总体预测复杂度仅为 $O(log_2m)$，与特征的数量无关。</p>
<p><strong>训练</strong>算法的时候（训练和预测不同）需要比较所有特征（如果设置了<code>max_features</code>会更少一些）在每个节点的所有样本上。训练复杂度为$O(nmlog_m)$</p>
<h3 id="基尼不纯度和信息熵"><a href="#基尼不纯度和信息熵" class="headerlink" title="基尼不纯度和信息熵"></a>基尼不纯度和信息熵</h3><p>默认算法使用 Gini 不纯度来进行检测， 但是也可以通过将标准超参数设置为<code>&quot;entropy&quot;</code>来使用熵不纯度进行检测。</p>
<p><strong>熵的计算：</strong></p>
<script type="math/tex; mode=display">
H_i=-\sum_{k=1\ P_{i,k=!0}}^n{P_{i,k}}log(p_{i,k})</script><p>熵的减少通常称为<strong>信息增益</strong></p>
<blockquote>
<p>基尼指数计算稍微快一点，所以这是一个很好的默认值。</p>
<p>但是，也有的时候它们会产生不同的树，基尼指数会趋于在树的分支中将最多的类隔离出来，而熵指数趋向于产生略微平衡一些的决策树模型。</p>
</blockquote>
<h3 id="正则化超参数"><a href="#正则化超参数" class="headerlink" title="正则化超参数"></a>正则化超参数</h3><p>决策树几乎不对训练数据做任何假设（于此相反的是线性回归等模型，这类模型通常会假设数据是符合线性关系的）。这一类的模型通常会被称为<strong>非参数模型&amp;</strong>，这不是因为它没有任何参数（通常也有很多），而是因为<strong>在训练之前没有确定参数的具体数量，所以模型结构可以根据数据的特性自由生长。</strong></p>
<p>如果不添加约束，树结构模型通常将根据训练数据调整自己，使自身能够很好的拟合数据，而这种情况下大多数会导致<strong>模型过拟合</strong>。</p>
<blockquote>
<p><strong><code>DecisionTreeClassifier</code>类还有一些其他的参数用于限制树模型的形状:</strong></p>
<p><code>min_samples_split</code>（节点在被分裂之前必须具有的最小样本数）</p>
<p><code>min_samples_leaf</code>（叶节点必须具有的最小样本数），<code>min_weight_fraction_leaf</code>（和<code>min_samples_leaf</code>相同，但表示为加权总数的一小部分实例）</p>
<p><code>max_leaf_nodes</code>（叶节点的最大数量）</p>
<p><code>max_features</code>（在每个节点被评估是否分裂的时候，具有的最大特征数量）</p>
<p>增加<code>min_* hyperparameters</code>或者减少<code>max_* hyperparameters</code>会使模型正则化。</p>
<p><strong>剪枝</strong></p>
<p>在没有任何约束条件下训练决策树模型，让模型自由生长，然后再对不需要的节点进行剪枝。</p>
<p>当一个节点的全部子节点都是叶节点时，如果它对纯度的提升不具有统计学意义，我们就认为这个分支是不必要的。</p>
<p>标准的假设检验，例如卡方检测，通常会被用于评估一个概率值 — 即改进是否纯粹是偶然性的结果（也叫原假设）</p>
<p>如果 p 值比给定的阈值更高（通常设定为 5%，也就是 95% 置信度，通过超参数设置），那么节点就被认为是非必要的，它的子节点会被删除。</p>
<p>这种剪枝方式将会一直进行，直到所有的非必要节点都被删光。</p>
</blockquote>
<h3 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h3><p>Scikit-Learn 的<code>DecisionTreeRegressor</code>类构建回归树，不再以最小化不纯度的方式分割训练集，而是试图以最小化 MSE 的方式分割训练集。</p>
<blockquote>
<p> 每个区域的预测值总是该区域中实例的平均目标值。</p>
</blockquote>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_6/108" alt="1528375227547"></p>
<h3 id="不稳定性"><a href="#不稳定性" class="headerlink" title="不稳定性"></a>不稳定性</h3><p>决策树的特点：</p>
<ol>
<li><p>容易理解和解释，易于使用且功能丰富而强大。</p>
</li>
<li><p>决策树很喜欢设定正交化的决策边界，（所有边界都是和某一个轴相垂直的），这使得它对训练数据集的旋转很敏感。</p>
<blockquote>
<p>解决办法：主成分分析PCA</p>
</blockquote>
</li>
<li><p>决策时的主要问题是它对训练数据的微小变化非常敏感</p>
</li>
</ol>
<h3 id="exercise"><a href="#exercise" class="headerlink" title="exercise"></a>exercise</h3><ol>
<li><p>在 100 万例训练集上训练（没有限制）的决策树的近似深度是多少？</p>
<blockquote>
<p>$log_2(m)$，m=100万时，该值大约为20</p>
</blockquote>
</li>
<li><p>节点的基尼指数比起它的父节点是更高还是更低？它是通常情况下更高/更低，还是永远更高/更低？</p>
<blockquote>
<p>节点的基尼指数通常低于其父节点，这是由CART数的训练损失函数所确定的，每个节点经过最优属性分割之后，子节点的基尼指数之和都会小于父节点的基尼指数，然而如果一个孩子节点的基尼指数比另外一个的基尼指数小，则可能比其父节点的基尼不纯度更大，但是其基尼不纯度的增加肯定小于另外孩子基尼不纯度的减少。</p>
</blockquote>
</li>
<li><p>如果决策树过拟合了，减少最大深度是一个好的方法吗？</p>
<blockquote>
<p>是一个好方法，可以对模型进行约束，使其规范化</p>
</blockquote>
</li>
<li><p>如果决策树对训练集欠拟合了，尝试缩放输入特征是否是一个好主意？</p>
<blockquote>
<p>不是，因为决策树对于数据的缩放并不敏感</p>
</blockquote>
</li>
<li><p>如果对包含 100 万个实例的数据集训练决策树模型需要一个小时，在包含 1000 万个实例的培训集上训练另一个决策树大概需要多少时间呢？</p>
<blockquote>
<p>训练复杂度$O(n\times m \log(m))$，如果实例m增加10倍，则复杂度变为$10\times\log(10m)/\log(m)$ 倍，m=100万时，该值为11.7，所以需要11.7个小时</p>
</blockquote>
</li>
<li><p>如果你的训练集包含 100,000 个实例，设置<code>presort=True</code>会加快训练的速度吗？</p>
<blockquote>
<p>只有当数据集小于几千时，才会加速训练实例。如果它包含100,000个实例，那么设置presort=True的训练将会慢得多。</p>
</blockquote>
</li>
<li><p>对<code>moons</code>数据集进行决策树训练并优化模型。</p>
<ol>
<li><p>通过语句<code>make_moons(n_samples=10000, noise=0.4)</code>生成<code>moons</code>数据集</p>
</li>
<li><p>通过<code>train_test_split()</code>将数据集分割为训练集和测试集。</p>
</li>
<li><p>进行交叉验证，并使用网格搜索法寻找最好的超参数值（使用<code>GridSearchCV</code>类的帮助文档）</p>
<p>提示: 尝试各种各样的<code>max_leaf_nodes</code>值</p>
</li>
<li><p>使用这些超参数训练全部的训练集数据，并在测试集上测量模型的表现。你应该获得大约 85% 到 87% 的准确度。</p>
</li>
</ol>
</li>
<li><p>生成森林</p>
<ol>
<li>接着前边的练习，现在，让我们生成 1,000 个训练集的子集，每个子集包含 100 个随机选择的实例。提示：你可以使用 Scikit-Learn 的<code>ShuffleSplit</code>类。</li>
<li>使用上面找到的最佳超参数值，在每个子集上训练一个决策树。在测试集上测试这 1000 个决策树。由于它们是在较小的集合上进行了训练，因此这些决策树可能会比第一个决策树效果更差，只能达到约 80% 的准确度。</li>
<li>见证奇迹的时刻到了！对于每个测试集实例，生成 1,000 个决策树的预测结果，然后只保留出现次数最多的预测结果（您可以使用 SciPy 的<code>mode()</code>函数）。这个函数使你可以对测试集进行多数投票预测。</li>
<li>在测试集上评估这些预测结果，你应该获得了一个比第一个模型高一点的准确率，（大约 0.5% 到 1.5%），恭喜，你已经弄出了一个随机森林分类器模型!</li>
</ol>
</li>
</ol>
<h2 id="第07章-集成学习和随机森林"><a href="#第07章-集成学习和随机森林" class="headerlink" title="第07章 集成学习和随机森林"></a>第07章 集成学习和随机森林</h2><p>合并了一组分类器的预测（像分类或者回归），得到一个比单一分类器更好的预测结果。这一组分类器就叫做<strong>集成</strong>；因此，这个技术就叫做<strong>集成学习</strong>，一个集成学习算法就叫做<strong>集成方法</strong>。一种决策树的集成就叫做<strong>随机森林</strong>。</p>
<p>即使每一个分类器都是一个<strong>弱学习器</strong>（意味着它们也就比瞎猜好点），集成后仍然是一个<strong>强学习器</strong>（高准确率），只要有足够数量的弱学习者，他们就足够多样化。</p>
<h3 id="投票分类"><a href="#投票分类" class="headerlink" title="投票分类"></a>投票分类</h3><p>一个非常简单去创建一个更好的分类器的方法就是去整合每一个分类器的预测然后经过投票去预测分类。这种分类器就叫做<strong>硬投票分类器</strong></p>
<blockquote>
<p>每一个分类器都在同一个数据集上训练，导致其很可能会发生这样的错误。他们可能会犯同一种错误，所以也会有很多票投给了错误类别导致集成的准确率下降。</p>
</blockquote>
<p>所以应该用完全不同的算法得到多样的分类器，使它们会做出不同种类的错误，提高集成的正确率。</p>
<p>如果所有的分类器都能够预测类别的概率（有一个<code>predict_proba()</code>方法），可以让 sklearn 以最高的类概率来预测这个类，平均在所有的分类器上。这种方式叫做<strong>软投票</strong>。其表现比硬投票更好，因为给予高自信的投票更大的权重。</p>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p><strong>有放回采样被称为装袋（<em>Bagging</em>，是 <em>bootstrap aggregating</em> 的缩写）。无放回采样称为粘贴（<em>pasting</em>）</strong></p>
<p>Bagging 和 Pasting 都允许在多个分类器间对训练集进行多次采样，但只有 Bagging可以通过使用不同的训练算法去得到一些不同的分类器。 Pasting是对每一个分类器都使用相同的训练算法，但是在不同的训练集上去训练。</p>
<blockquote>
<p>当所有的分类器被训练后，集成可以通过对所有分类器结果的简单聚合来对新的实例进行预测。<strong>聚合函数</strong>通常对分类是<em>统计模式</em>（例如硬投票分类器）或者对回归是平均。</p>
<p>每一个单独的分类器在如果在原始训练集上都是高偏差，但是聚合降低了偏差和方差。通常情况下，集成的结果是有一个相似的偏差，但是对比与在原始训练集上的单一分类器来讲有更小的方差。</p>
</blockquote>
<p>如果基分类器可以预测类别概率（例如它拥有<code>predict_proba()</code>方法），那么<code>BaggingClassifier</code>会自动的运行软投票。</p>
<h4 id="Out-of-bag"><a href="#Out-of-bag" class="headerlink" title="Out-of-bag"></a>Out-of-bag</h4><p>对于 Bagging 来说，一些实例可能被一些分类器重复采样，但其他的有可能不会被采样。<code>BaggingClassifier</code>默认是有放回的采样<code>m</code>个实例 （<code>bootstrap=True</code>）。意味着平均下来只有63%的训练实例被每个分类器采样，剩下的37%个没有被采样的训练实例就叫做 <em>Out-of-Bag</em> 实例。注意对于每一个的分类器它们的 37% 不是相同的。</p>
<p>可以拿出每一个分类器的 oob 来评估集成本身。</p>
<h4 id="随机贴片与随机子空间"><a href="#随机贴片与随机子空间" class="headerlink" title="随机贴片与随机子空间"></a>随机贴片与随机子空间</h4><p><code>BaggingClassifier</code>也支持采样特征。</p>
<p>对训练实例和特征的采样被叫做随机贴片。保留了所有的训练实例（例如<code>bootstrap=False</code>和<code>max_samples=1.0</code>），但是对特征采样（<code>bootstrap_features=True</code>并且/或者<code>max_features</code>小于 1.0）叫做随机子空间。</p>
<p><strong>采样特征导致更多的预测多样性，用高偏差换低方差。</strong></p>
<h3 id="随机森林（一种bagging模型）"><a href="#随机森林（一种bagging模型）" class="headerlink" title="随机森林（一种bagging模型）"></a>随机森林（一种bagging模型）</h3><p>随机森林算法在树生长时引入了额外的随机；与在节点分裂时需要找到最好分裂特征相反（详见第六章），它<strong>在一个随机的特征集中找最好的特征，</strong>导致了树的差异性，<strong>再一次用高偏差换低方差</strong>，总的来说是一个更好的模型。</p>
<h4 id="极端随机树"><a href="#极端随机树" class="headerlink" title="极端随机树"></a>极端随机树</h4><p>在随机森林上生长树时，在每个结点分裂时只考虑随机特征集上的特征。可以通过对特征使用随机阈值使树更加随机。<strong>这种极端随机的树被称为Extremely Randomized Trees简称为 <em>Extra-Tree</em>。</strong></p>
<blockquote>
<p>因为在每个节点上找到每个特征的最佳阈值是生长树最耗时的任务之一，所以 <em>Extra-Tree</em> 比规则的随机森林训练更快。</p>
</blockquote>
<h4 id="特征重要度"><a href="#特征重要度" class="headerlink" title="特征重要度"></a>特征重要度</h4><p><strong>重要的特征会出现在单一决策树更靠近根部的位置，而不重要的特征会经常出现在靠近叶子的位置。因此可以通过计算一个特征在森林的全部树中出现的平均深度来预测特征的重要性。</strong></p>
<p>随机森林可以非常方便快速得了解哪些特征实际上是重要的，特别是你需要进行特征选择的时候。</p>
<h3 id="提升"><a href="#提升" class="headerlink" title="提升"></a>提升</h3><p>提升（Boosting，最初称为<em>假设增强</em>）指的是可以将几个弱学习者组合成强学习者的集成方法。对于大多数的提升方法的思想就是按顺序去训练分类器，每一个都要尝试修正前面的分类。现如今已经有很多的提升方法了，但最著名的就是 <em>Adaboost</em>（适应性提升，是 <em>Adaptive Boosting</em> 的简称） 和 <em>Gradient Boosting</em>（梯度提升）。</p>
<h4 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h4><p>使一个新的分类器去修正之前分类结果的方法就是<strong>对之前分类结果错误的训练实例多加关注</strong>。这导致新的预测因子越来越多地聚焦于这种情况。这是 <em>Adaboost</em> 使用的技术。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_7/7-7.png" alt="图7-7"></p>
<blockquote>
<p>序列学习技术的一个重要的<strong>缺点</strong>是：它不能被并行化（只能按步骤），因为每个分类器只能在之前的分类器已经被训练和评价后再进行训练。</p>
</blockquote>
<p><strong>Adaboost的算法</strong></p>
<p>每一个实例的权重<code>wi</code>初始都被设为<code>1/m</code></p>
<p>第一个分类器被训练后，在训练集上算出权重误差率<code>r1</code>：</p>
<p><strong>第j个分类器的权重误差率：</strong></p>
<script type="math/tex; mode=display">
r_j\ = \ \frac{\sum_{i=1,\hat y_j^{(i)}\neq y^{(i)}}^m \omega^{(i)}}{\sum _{i=1}^m \omega^{(i)}}</script><p>$\hat y_j^i$ 是第j个分类器对于第i个实例的预测。</p>
<p><strong>分类器的权重</strong></p>
<p>其中<code>η</code>是超参数学习率（默认为 1）。分类器准确率越高，它的权重就越高。</p>
<script type="math/tex; mode=display">
\alpha_j = \eta \log \frac{1-r_j}{r_j}</script><p><strong>权重更新规则</strong></p>
<p>对于<code>i=1, 2, ..., m</code></p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_7/E7-3.png" alt="公式7-3"></p>
<p>随后所有实例的权重都被归一化。</p>
<p>为了进行预测，Adaboost 通过分类器权重 $α_{j}$简单的计算了所有的分类器和权重。预测类别会是权重投票中主要的类别。</p>
<p><strong>Adaboost 分类器</strong></p>
<script type="math/tex; mode=display">
\hat y(x)\ = \ {argmax}_k \ \ \sum^N_{j=1,\hat y_j(x)=k} \alpha_j</script><p>其中<code>N</code>是分类器的数量。</p>
<blockquote>
<p>sklearn 通常使用 Adaboost 的多分类版本 <em>SAMME</em>（<em>分段加建模使用多类指数损失函数</em>）。如果只有两类别，那么 <em>SAMME</em> 是与 Adaboost 相同的。如果分类器可以预测类别概率（有<code>predict_proba()</code>），如果 sklearn 可以使用 <em>SAMME</em> 叫做<code>SAMME.R</code>的变量（R 代表“REAL”），这种依赖于类别概率的通常比依赖于分类器的更好。</p>
</blockquote>
<p>如果 Adaboost 集成<strong>过拟合</strong>，可以尝试<strong>减少基分类器的数量</strong>或者<strong>对基分类器使用更强的正则化</strong>。</p>
<h4 id="梯度提升"><a href="#梯度提升" class="headerlink" title="梯度提升"></a>梯度提升</h4><p>梯度提升也是通过向集成中逐步增加分类器运行的，每一个分类器都修正之前的分类结果。然而，并不像 Adaboost 那样每一次迭代都更改实例的权重，这个方法<strong>使用新的分类器去拟合前面分类器预测的<em>残差</em> </strong>。</p>
<p><strong>梯度提升回归树</strong>（GBRT，<em>Gradient Tree Boosting</em> 或者 <em>Gradient Boosted Regression Trees</em>）</p>
<p><strong>梯度提升决策树</strong> (GBDT， <em>Gradient Boosted Decision Trees</em>)是梯度提升(GB)算法限定基学习器是<strong>回归决策树时的模型，尤其是CART回归树</strong>。</p>
<p>sklean 中的<code>GradientBoostingRegressor</code>可以用来训练 GBRT 集成，也有超参数去控制集成训练，例如基分类器的数量（<code>n_estimators</code>）。超参数<code>learning_rate</code> 确立了每个树的贡献。</p>
<blockquote>
<p>如果把<code>learning_rate</code>设置为一个很小的树，例如 0.1，在集成中就需要更多的树去拟合训练集，但预测通常会更好。这个正则化技术叫做 <strong><em>shrinkage</em></strong>。</p>
</blockquote>
<h5 id="Early-stop-早停"><a href="#Early-stop-早停" class="headerlink" title="Early stop(早停)"></a>Early stop(早停)</h5><p><code>GradientBoostingRegressor</code>有方法<code>staged_predict()</code>：它在训练的每个阶段返回一个迭代器。</p>
<p>与先在一大堆树中训练，然后再回头去找最优数目相反。可以通过设置<code>warm_start=True</code>来实现 早停，这使得当<code>fit()</code>方法被调用时 sklearn 保留现有树，并允许增量训练。</p>
<p><code>GradientBoostingRegressor</code>也支持指定用于训练每棵树的训练实例比例的超参数<code>subsample</code>。例如如果<code>subsample=0.25</code>，那么每个树都会在 25% 随机选择的训练实例上训练。这也是个高偏差换低方差的作用。同样也加速了训练。这个技术叫做<strong><em>随机梯度提升</em></strong>。</p>
<h4 id="极端梯度提升（XGBoost）"><a href="#极端梯度提升（XGBoost）" class="headerlink" title="极端梯度提升（XGBoost）"></a>极端梯度提升（XGBoost）</h4><ol>
<li>提升树只使用了一阶泰勒展开，而XGBoost使用了二阶泰勒展开。</li>
<li>xgboost在<strong>代价函数里加入了正则项，用于控制模型的复杂度</strong>。</li>
<li><strong>列抽样（column subsampling）</strong>。xgboost借鉴了随机森林的做法，支持列抽样（即每次的输入特征不是全部特征），不仅能降低过拟合，还能减少计算</li>
<li><strong>并行化处理</strong>：在训练之前，预先对每个特征内部进行了排序找出候选切割点，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。</li>
</ol>
<p>xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。例如，xgboost支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）</p>
<p><a href="https://zhuanlan.zhihu.com/p/57814935" target="_blank" rel="noopener">参考</a></p>
<h3 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h3><p><strong><em>Stacking</em>（<em>stacked generalization</em> 的缩写），这个算法不使用琐碎的函数（如硬投票）来聚合集合中所有分类器的预测，我直接训练一个模型来执行这个聚合。</strong></p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_7/7-12.png" alt="图7-12"></p>
<p>为了训练这个 <em>blender</em> ，一个通用的方法是<strong>采用保持集</strong>。</p>
<ol>
<li>首先，训练集被分为两个子集，第一个子集被用作训练第一层。</li>
<li>第一层的分类器被用来预测第二个子集（保持集）。</li>
<li>使用这些预测结果作为输入特征来创建一个新的训练集，保持目标数值不变，随后 <em>blender</em> 在这个新的训练集上训练。</li>
</ol>
<p>sklearn 并不直接支持 stacking ，但可以使用开源项目<a href="https://github.com/Menelau/DESlib" target="_blank" rel="noopener">DESlib</a>（基于sklearn）</p>
<h3 id="练习-1"><a href="#练习-1" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>如果你在相同训练集上训练 5 个不同的模型，它们都有 95% 的准确率，那么你是否可以通过组合这个模型来得到更好的结果？如果可以那怎么做呢？如果不可以请给出理由。</p>
<blockquote>
<p>可以通过集成学习将5个模型集成在一起</p>
<p>通过投票的方式预测</p>
</blockquote>
</li>
<li><p>软投票和硬投票分类器之间有什么区别？</p>
<blockquote>
<p>硬投票分类器计算集合中每个分类器的投票，并选择得到最多选票的类。</p>
<p>软投票分类器计算每个类的平均估计类概率，并选择概率最高的类，也就是给置信度高的类更高的权重，但是前提是可以得到每个类的概率。</p>
</blockquote>
</li>
<li><p>是否有可能通过分配多个服务器来加速 bagging 集成系统的训练？pasting 集成，boosting 集成，随机森林，或 stacking 集成怎么样？</p>
<blockquote>
<p>bagging，pasting和stacking都可以并行，随机森林算bagging</p>
<p>boosting是序列学习技术，不能并行。</p>
</blockquote>
</li>
<li><p>out-of-bag 评价的好处是什么？</p>
<blockquote>
<p>包外集成中的每个预测器都使用它没有经过训练的实例进行评估，不需要额外的验证集。</p>
</blockquote>
</li>
<li><p>是什么使 Extra-Tree 比规则随机森林更随机呢？这个额外的随机有什么帮助呢？那这个 Extra-Tree 比规则随机森林谁更快呢？</p>
<blockquote>
<p>Extra-Tree在随机森林上生长树时，在每个结点分裂时只考虑随机特征集上的特征，额不是在每个节点上找到每个特征的最佳阈值，所以训练时 <em>Extra-Tree</em> 比规则的随机森林更快。</p>
</blockquote>
</li>
<li><p>如果你的 Adaboost 模型欠拟合，那么你需要怎么调整超参数？</p>
<blockquote>
<p>如果 Adaboost 集成<strong>过拟合</strong>，可以尝试<strong>减少基分类器的数量</strong>或者<strong>对基分类器使用更强的正则化</strong>。</p>
</blockquote>
</li>
<li><p>如果你的梯度提升过拟合，那么你应该调高还是调低学习率呢？</p>
<blockquote>
<p>降低学习率，或使用早停的方法来寻找正确数量的基学习器。</p>
</blockquote>
</li>
<li><p>导入 MNIST 数据（第三章中介绍），把它切分进一个训练集，一个验证集，和一个测试集（例如 40000 个实例进行训练，10000 个进行验证，10000 个进行测试）。然后训练多个分类器，例如一个随机森林分类器，一个 Extra-Tree 分类器和一个 SVM。接下来，尝试将它们组合成集成，使用软或硬投票分类器来胜过验证集上的所有集合。一旦找到了，就在测试集上实验。与单个分类器相比，它的性能有多好？</p>
</li>
<li><p>从练习 8 中运行个体分类器来对验证集进行预测，并创建一个新的训练集并生成预测：每个训练实例是一个向量，包含来自所有分类器的图像的预测集，目标是图像类别。祝贺你，你刚刚训练了一个 <em>blender</em> ，和分类器一起组成了一个叠加组合！现在让我们来评估测试集上的集合。对于测试集中的每个图像，用所有分类器进行预测，然后将预测馈送到 <em>blender</em> 以获得集合的预测。它与你早期训练过的投票分类器相比如何？</p>
</li>
</ol>
<hr>
<h2 id="第08章-降维"><a href="#第08章-降维" class="headerlink" title="第08章 降维"></a>第08章 降维</h2><blockquote>
<p>警告：降维会丢失一些信息，因此即使这种方法可以加快训练的速度，同时也会让系统表现的稍微差一点。降维会让工作流水线更复杂因而更难维护。所有应该先尝试使用原始的数据来训练，如果训练速度太慢的话再考虑使用降维。在某些情况下，降低训练集数据的维度可能会筛选掉一些噪音和不必要的细节，这可能会让结果比降维之前更好（这种情况通常不会发生；它只会加快训练的速度）。</p>
</blockquote>
<p>降维除了可以加快训练速度外，在数据可视化方面（或者 DataViz）也十分有用。降低特征维度到 2（或者 3）维从而可以在图中画出一个高维度的训练集，让我们可以通过视觉直观的发现一些非常重要的信息，比如聚类。</p>
<p><strong>两种主要的降维方法：投影（projection）和流形学习（Manifold Learning），三种流行的降维技术：主成分分析（PCA），核主成分分析（Kernel PCA）和局部线性嵌入（LLE）。</strong></p>
<h3 id="维数灾难（curse-of-dimentionality）"><a href="#维数灾难（curse-of-dimentionality）" class="headerlink" title="维数灾难（curse of dimentionality）"></a>维数灾难（curse of dimentionality）</h3><p>一个 1,0000 维的单位超正方体中，随机选的点离所有边界大于 0.001（靠近中间位置）的概率（$1-0.998^{10000}$），近似于1，在高维超正方体中，大多数点都分布在边界处。</p>
<p>在一个 1,000,000 维超立方体中随机抽取两点的平均距离，大概为 408.25（大致 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-50eeccb6ef846e2d0af5daef5cab1fa0.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-50eeccb6ef846e2d0af5daef5cab1fa0.gif" alt="\sqrt{1,000,000/6}"></a>）</p>
<p>表明高维数据集有很大风险分布的非常稀疏：大多数训练实例可能彼此远离。也意味着一个新实例可能远离任何训练实例，使得预测的可靠性远低于较低维度数据的预测，因为它们将基于更大的推测（extrapolations）。简而言之，训练集的维度越高，过拟合的风险就越大。</p>
<p>理论上来说，维数爆炸的一个解决方案是增加训练集的大小从而达到拥有足够密度的训练集。</p>
<h3 id="降维的主要方法"><a href="#降维的主要方法" class="headerlink" title="降维的主要方法"></a>降维的主要方法</h3><h4 id="投影（Projection）"><a href="#投影（Projection）" class="headerlink" title="投影（Projection）"></a>投影（Projection）</h4><p>大多数现实生活的问题中，训练实例并不是在所有维度上均匀分布的，许多特征几乎是常数，而其他特征则高度相关（如前面讨论的 MNIST）。<strong>所有训练实例实际上位于（或接近）高维空间的低维子空间内。</strong></p>
<p>投影并不总是降维的最佳方法。在很多情况下，子空间可能会扭曲和转动。</p>
<h4 id="流形学习（Manifold-Learning）"><a href="#流形学习（Manifold-Learning）" class="headerlink" title="流形学习（Manifold Learning）"></a>流形学习（Manifold Learning）</h4><p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_8/8-4.jpeg" alt="img"></p>
<p>瑞士卷一个是二维流形的例子。简而言之，二维流形是一种二维形状，它可以在更高维空间中弯曲或扭曲。一个<code>d</code>维流形是类似于<code>d</code>维超平面的<code>n</code>维空间（其中<code>d &lt; n</code>）的一部分。瑞士卷有些像 2D 平面，但是它实际上是在第三维中卷曲。</p>
<p><strong>通过对训练实例所在的流形进行建模从而达到降维目的，叫做流形学习。</strong>它依赖于流形猜想（manifold assumption），也被称为流形假设（manifold hypothesis），认为大多数现实世界的高维数据集大都靠近一个更低维的流形。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_8/8-6.jpeg" alt="img"></p>
<p>如果在训练模型之前降低训练集的维数，那训练速度肯定会加快，但并不总是会得出更好的训练效果；这一切都取决于数据集。</p>
<h3 id="降维技术"><a href="#降维技术" class="headerlink" title="降维技术"></a>降维技术</h3><h4 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h4><p>主成分分析（Principal Component Analysis）是目前为止最流行的降维算法。首先它找到接近数据集分布的超平面，然后将所有的数据都投影到这个超平面上。</p>
<h5 id="保留最大方差"><a href="#保留最大方差" class="headerlink" title="保留最大方差"></a>保留最大方差</h5><p>选择保持最大方差的轴将原始数据集投影到该轴上的均方距离最小，损失更少的信息。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_8/8-7.jpeg" alt="img"></p>
<h5 id="主成分（Principle-Componets）"><a href="#主成分（Principle-Componets）" class="headerlink" title="主成分（Principle Componets）"></a>主成分（Principle Componets）</h5><p> 定义第<code>i</code>个轴的单位矢量被称为第<code>i</code>个主成分（PC）。</p>
<p><strong>奇异值分解（SVD）</strong>的标准矩阵分解：将训练集矩阵<code>X</code>分解为三个矩阵<code>U·Σ·V^T</code>的点积，其中<code>V^T</code>包含我们想要的所有主成分，</p>
<blockquote>
<p>PCA 假定数据集以原点为中心。Scikit-Learn 的<code>PCA</code>类负责数据集中心化处理。但是，如果自己实现 PCA，或者使用其他库，首先要先对数据做中心化处理。</p>
</blockquote>
<h5 id="投影到d维空间"><a href="#投影到d维空间" class="headerlink" title="投影到d维空间"></a>投影到<code>d</code>维空间</h5><script type="math/tex; mode=display">
X_{d-proj} = X\cdot W_d</script><p>$W_d$定义为包含前<code>d</code>个主成分的矩阵（即由<code>V^T</code>的前<code>d</code>列组成的矩阵）</p>
<h5 id="方差解释率（Explained-Variance-Ratio）"><a href="#方差解释率（Explained-Variance-Ratio）" class="headerlink" title="方差解释率（Explained Variance Ratio）"></a>方差解释率（Explained Variance Ratio）</h5><p>每个主成分的方差解释率，可通过<code>explained_variance_ratio_</code>变量获得。它表示位于每个主成分轴上的数据集方差的比例。</p>
<h5 id="选择正确的维度"><a href="#选择正确的维度" class="headerlink" title="选择正确的维度"></a>选择正确的维度</h5><p>倾向于选择加起来到方差解释率能够达到足够占比（例如 95%）的维度的数量，而不是任意选择要降低到的维度数量。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_8/8-8.jpeg" alt="img"></p>
<h5 id="PCA压缩"><a href="#PCA压缩" class="headerlink" title="PCA压缩"></a>PCA压缩</h5><p>原始数据和重构数据之间的均方距离（压缩然后解压缩）被称为重构误差（reconstruction error）。</p>
<p>PCA逆变换</p>
<script type="math/tex; mode=display">
X_{recovered} = X_{d-proj}\cdot W_d^T</script><h5 id="增量-PCA（Incremental-PCA）"><a href="#增量-PCA（Incremental-PCA）" class="headerlink" title="增量 PCA（Incremental PCA）"></a>增量 PCA（Incremental PCA）</h5><p>有些算法如SVD需要在内存中处理整个训练集。可以将训练集分批，一次只对一个批量使用 IPCA 算法。这对大型训练集非常有用，并且可以在线应用 PCA（即在新实例到达时即时运行）。</p>
<h5 id="随机-PCA（Randomized-PCA）"><a href="#随机-PCA（Randomized-PCA）" class="headerlink" title="随机 PCA（Randomized PCA）"></a>随机 PCA（Randomized PCA）</h5><p>这是一种随机算法，可以快速找到前d个主成分的近似值。它的计算复杂度是<code>O(m × d^2) + O(d^3)</code>，而不是<code>O(m × n^2) + O(n^3)</code>，所以当<code>d</code>远小于<code>n</code>时，它比之前的算法快得多。</p>
<h4 id="核-PCA（Kernel-PCA）"><a href="#核-PCA（Kernel-PCA）" class="headerlink" title="核 PCA（Kernel PCA）"></a>核 PCA（Kernel PCA）</h4><p>核技巧，一种将实例隐式映射到非常高维空间（称为特征空间）的数学技术，让支持向量机可以应用于非线性分类和回归。高维特征空间中的线性决策边界对应于原始空间中的复杂非线性决策边界。</p>
<p>同样的技巧可以应用于 PCA，从而可以执行复杂的非线性投影来降低维度。这就是所谓的核 PCA（kPCA）。它通常能够很好地保留投影后的簇，有时甚至可以展开分布近似于扭曲流形的数据集。</p>
<p><strong>如何选择一种核并调整参数</strong></p>
<blockquote>
<ol>
<li>网格搜索</li>
<li>非监督学习</li>
</ol>
</blockquote>
<h4 id="局部线性嵌入（LLE）"><a href="#局部线性嵌入（LLE）" class="headerlink" title="局部线性嵌入（LLE）"></a>局部线性嵌入（LLE）</h4><p>局部线性嵌入（Locally Linear Embedding）是一种非线性降维（NLDR）方法。这是一种流形学习技术。</p>
<p>LLE 首先测量每个训练实例与其最近邻（c.n.）之间的线性关系，然后寻找能最好地保留这些局部关系的训练集的低维表示。</p>
<blockquote>
<p>擅长展开没有太多噪音的扭曲的流形。</p>
</blockquote>
<h5 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h5><p>对于每个训练实例 $x^{(i)}$，该算法识别其最近的<code>k</code>个邻居，然后尝试将 $x^{(i)}$重构为这些邻居的线性函数。找到权重 $w_{i,j}$从而使  $x^{(i)}$和 $\sum_{j=1}^{m}w_{i,j} x^{(j)}$之间的平方距离尽可能的小，假设如果 $x^{(j)}$不是 $x^{(i)}$的<code>k</code>个最近邻时 $w_{i,j}=0$。</p>
<p>第一步：对局部关系进行线性建模 </p>
<p>$W=argmin_w\ \sum_{i=1}^m | x^{(i)}-\sum_{j=1}^m w_{i,j}x^{(j)}| ^2 \\ subject \ to \ \left \{  \begin{array}{cc} w_{i,j}=0&amp;\ \ if \ x^{j} \  is \ not \ one \ of \ the \ k \ c.n. \ of \ x^{i} \\ \sum_{j=1}^m w_{i,j}=1&amp; for\ i=1,2, \cdots ,m\end{array}\right.$</p>
<p>第二个约束简单地对每个训练实例 $x^{(i)}$的权重进行归一化。</p>
<p>权重矩阵 $\widehat{W}$包含权重 $\hat{w_{i,j}}$]对训练实例的线形关系进行编码。第二步是将训练实例投影到一个<code>d</code>维空间（<code>d &lt; n</code>）中去，同时尽可能的保留这些局部关系。如果 $z^{(i)}$是 $x^{(i)}$]在这个<code>d</code>维空间的图像，那么需要 $z^{(i)}$和 $\sum_{j=1}^{m}\hat{w_{i,j}}\ z^{(j)}$之间的平方距离尽可能的小。看起来与第一步非常相似，但不是保持实例固定并找到最佳权重，而是<strong>保持权重不变，并在低维空间中找到实例图像的最佳位置</strong>。<code>Z</code>是包含所有 $z^{(i)}$]的矩阵。</p>
<p>第二步：保持关系的同时进行降维</p>
<p>$W=argmin_z\ \sum_{i=1}^m | z^{(i)}-\sum_{j=1}^m w_{i,j}z^{(j)}| ^2 $</p>
<p>Scikit-Learn 的 LLE 实现具有如下的计算复杂度：查找<code>k</code>个最近邻为<code>O(m log(m) n log(k))</code>，优化权重为<code>O(m n k^3)</code>，建立低维表示为<code>O(d m^2)</code>。</p>
<h4 id="其他降维方法"><a href="#其他降维方法" class="headerlink" title="其他降维方法"></a>其他降维方法</h4><ul>
<li>多维缩放（MDS）在尝试保持实例之间距离的同时降低了维度</li>
<li>Isomap 通过将每个实例连接到最近的邻居来创建图形，然后在尝试保持实例之间的测地距离时降低维度。</li>
<li>t-分布随机邻域嵌入（t-Distributed Stochastic Neighbor Embedding，<strong>t-SNE</strong>）可以用于降低维度，同时试图保持相似的实例临近并将不相似的实例分开。它主要用于可视化，尤其是用于可视化高维空间中的实例（例如，可以将MNIST图像降维到 2D 可视化）。</li>
<li>线性判别分析（Linear Discriminant Analysis，LDA）实际上是一种分类算法，但在训练过程中，它会学习类之间最有区别的轴，然后使用这些轴来定义用于投影数据的超平面。LDA 的好处是投影会尽可能地保持各个类之间距离，所以在运行另一种分类算法（如 SVM 分类器）之前，LDA 是很好的降维技术。</li>
</ul>
<h3 id="练习-2"><a href="#练习-2" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>减少数据集维度的主要动机是什么？主要缺点是什么？</p>
<blockquote>
<p>动机：</p>
<ol>
<li>加快训练速度(筛选掉一些噪音和不必要的细节，可能会让结果比降维之前更好)</li>
<li>数据可视化方面：降低特征维度到 2（或者 3）维从而可以在图中画出一个高维度的训练集，可以通过视觉直观的发现一些非常重要的信息</li>
<li>节省空间</li>
</ol>
<p>缺点：</p>
<ol>
<li>丢失一些信息，降低算法后续性能</li>
<li>使工作流水线更复杂因而更难维护</li>
<li>降低可解释性</li>
</ol>
</blockquote>
</li>
<li><p>什么是维度爆炸？</p>
<blockquote>
<p>维度爆炸是指高维空间中出现了许多低维空间不存在的问题，在机器学习中，一个常见的表现是，随机采样的高维向量通常非常稀疏，增加了过度拟合的风险，使得在没有大量训练数据的情况下很难识别数据中的模式。</p>
</blockquote>
</li>
<li><p>一旦对某数据集降维，我们可能恢复它吗？如果可以，怎样做才能恢复？如果不可以，为什么？</p>
<blockquote>
<p>一旦数据集通过降维降到了一个较小的维度，就几乎不会完全复现，因为在维度减小的过程中，损失了一部分信息，PCA有逆过程，可以重构一个和原始数据集比较相似的数据集，但是t-SNE没有。</p>
</blockquote>
</li>
<li><p>PCA 可以用于降低一个高度非线性对数据集吗？</p>
<blockquote>
<p>PCA可以显著降低大多数数据集的维数，即使他们是高度非线性的，因为它至少可以消除无用的维度，然而如果没有无用的维度，例如”瑞士卷”，使用PCA降维将会损失许多信息。</p>
</blockquote>
</li>
<li><p>假设你对一个 1000 维的数据集应用 PCA，同时设置方差解释率为 95%，你的最终数据集将会有多少维？</p>
<blockquote>
<p>取决于数据集</p>
<p>如果数据集由几乎完全对齐的点组成，该情况下，PCA可以把数据降到一维，并保持95%的方差结实率</p>
<p>如果数据集中的点完全随机，则该情况下，需要降到所有维度，并且每一维度都有95%的方差。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_8/8-8.jpeg" alt="img"></p>
</blockquote>
</li>
<li><p>在什么情况下你会使用普通的 PCA，增量 PCA，随机 PCA 和核 PCA？</p>
<blockquote>
<p>一般默认使用普通的PCA，但它只在数据集适合内存的情况下工作。</p>
<p>增量PCA对于不适合内存的大型数据集有用，可以分批训练，一次只对一个批量使用 IPCA 算法。但它比常规PCA要慢，所以如果数据集适合内存应该选择常规的PCA。增量PCA也适用于在线任务，当不断有新实例到达，需要动态应用PCA时。</p>
<p>随机PCA：当想要大大减少维度并且数据集适合时，它比普通PCA快得多。</p>
<p>数据呈现复杂的高维非线性时，使用核PCA</p>
</blockquote>
</li>
<li><p>你该如何评价你的降维算法在你数据集上的表现？</p>
<blockquote>
<p>一个降维算法在不丢失太多信息的情况下从数据集中消除了大量的维数，那么它的性能就会很好。</p>
<p>一种测量方法是应用反向变换并测量重构误差。然而，并不是所有的降维算法都提供了反向转换。</p>
<p>如果将降维作为另一种机器学习算法前的预处理步骤，那么可以简单地测量第二种算法的性能;如果降维不会丢失太多信息，那么算法的性能应该与使用原始数据集时一样好。</p>
</blockquote>
</li>
<li><p>将两个不同的降维算法串联使用有意义吗？</p>
<blockquote>
<p>有</p>
<p>一个常见的例子是使用PCA快速摆脱大量无用的维数，然后应用另一种慢得多的降维算法，如LLE。这种分两步的方法可能会产生与仅使用LLE相同的性能，但大大缩短了时间。</p>
</blockquote>
</li>
<li><p>加载 MNIST 数据集（在第 3 章中介绍），并将其分成一个训练集和一个测试集（将前 60,000 个实例用于训练，其余 10,000 个用于测试）。在数据集上训练一个随机森林分类器，并记录了花费多长时间，然后在测试集上评估模型。接下来，使用 PCA 降低数据集的维度，设置方差解释率为 95%。在降维后的数据集上训练一个新的随机森林分类器，并查看需要多长时间。训练速度更快？接下来评估测试集上的分类器：它与以前的分类器比较起来如何？</p>
</li>
<li><p>使用 t-SNE 将 MNIST 数据集缩减到二维，并使用 Matplotlib 绘制结果图。您可以使用 10 种不同颜色的散点图来表示每个图像的目标类别。或者，您可以在每个实例的位置写入彩色数字，甚至可以绘制数字图像本身的降维版本（如果绘制所有数字，则可视化可能会过于混乱，因此您应该绘制随机样本或只在周围没有其他实例被绘制的情况下绘制）。你将会得到一个分隔良好的的可视化数字集群。尝试使用其他降维算法，如 PCA，LLE 或 MDS，并比较可视化结果。</p>
</li>
</ol>
<hr>
<h2 id="第09章-非监督学习"><a href="#第09章-非监督学习" class="headerlink" title="第09章 非监督学习"></a>第09章 非监督学习</h2><p>降维就是最常用的非监督机器学习方法之一。</p>
<h3 id="聚类（clustering）"><a href="#聚类（clustering）" class="headerlink" title="聚类（clustering）"></a>聚类（clustering）</h3><p>将相似的实例聚集在一起</p>
<p><strong>和分类的区别：分类问题有标签，而聚类问题没有标签。</strong></p>
<p><strong>应用场景：</strong></p>
<p>降维，半监督学习，图像分类，推荐系统，搜索引擎，客户细分等</p>
<p>也可以用于异常检测：数据聚类后，和所有cluster相聚很远的数据点可能是有问题的。</p>
<p>半监督学习：只有若干数据有标签，可以聚类后将标签传递给同一cluster</p>
<p>搜索引擎：例如搜索图片，将所有图片聚类，然后根据用户上传的图片，判断在哪一个cluster。</p>
<p>image segmentation：数据监测，追踪，监测物体的边界</p>
<blockquote>
<p> 参考：<a href="https://www.cnblogs.com/LittleHann/p/6595148.html" target="_blank" rel="noopener">https://www.cnblogs.com/LittleHann/p/6595148.html</a></p>
<p>​            <a href="https://zhuanlan.zhihu.com/p/150333968" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/150333968</a></p>
</blockquote>
<p>一些算法有中心：centroid （K-Means）</p>
<p>一些算法分层：hierarchical</p>
<p>一些算法基于密度：DBSCAN</p>
<p>一些算法基于概率：GMM（高斯混合模型）</p>
<h4 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h4><p>1957年，Stuart Lloyd在Bell Labs提出。该算法一般是最快的聚类方法，且一定会收敛，不会永远震荡。</p>
<p><strong>计算复杂度</strong>：一般情况下（数据具有clustering structure）和实例的个数m以及类的个数k呈线性关系。否则，最坏的情况，指数增长（一般很少发生）。</p>
<p><strong>算法：</strong></p>
<ol>
<li>初始化中心，然后将数据分到最近邻的类中。</li>
<li>把所有实例分到相应的类中，计算数据中心</li>
<li>按照新的中心，重新将实例分到相应的类中，计算数据中心</li>
<li>重复2,3，知道中心不发生变化</li>
</ol>
<p><strong>hard-clustering和soft-clustering</strong></p>
<p>hard-clustering将实例分到一个cluster中</p>
<p>soft-clustering给出每个实例在每一个cluster中的评分，可以是距离，或者RBF等等</p>
<p><strong>缺点：</strong></p>
<p>虽然K-Means一定会收敛，但是可能会收敛到局部最优解，和初始中心的设置有很大的关系。</p>
<p><strong>解决办法：</strong></p>
<p>初始化聚类中心的方法：</p>
<ol>
<li><p>提前知道大概的中心位置，可以用<code>init</code>参数传递给KMeans</p>
</li>
<li><p>多次运行kmeans，保留最好的结果。<code>n_init，</code>sklearn中默认为10，用intertia（所有实例距离其最近邻聚类中心的距离的平方和）判定好坏（越小越好）</p>
<blockquote>
<p>sklearn中的score遵循“greater is better”的准则，所以score是intertia的负数。</p>
</blockquote>
</li>
<li><p>改进算法：<strong>K-Means++</strong>（2006年，由David Arthur and Sergei Vassilvitskii提出）</p>
<blockquote>
<p>初始化聚类中心尽可能彼此远离，可以有效避免局部最优解。</p>
<ol>
<li>随机选取第一个中心$c^{(1)}$</li>
<li>以概率$D(x^{(i)})^2/\sum_{j=1}^m D(x^{(j)})^2$ 选取实例作为新的中心$c^{(i)}$，$D(x^{(i)})$表示实例距离已经选定的中心的距离。</li>
<li>重复2直到确定所有中心</li>
</ol>
</blockquote>
<p>sklearn中默认使用这种算法，可以通过设置<code>init=random</code>使用原生K-Means</p>
</li>
</ol>
<h4 id="加速K-Means算法"><a href="#加速K-Means算法" class="headerlink" title="加速K-Means算法"></a>加速K-Means算法</h4><blockquote>
<p>由Charles Elkan于2003年提出。利用<strong>三角不等式的性质（triangle inequality），记录实例和聚类中心距离的上限和下限（lower and upper bounds）加速K-Means，</strong>避免许多无用的距离计算.</p>
<p>sklearn中默认使用这种算法。</p>
</blockquote>
<h4 id="mini-batch-K-Means算法"><a href="#mini-batch-K-Means算法" class="headerlink" title="mini-batch K-Means算法"></a>mini-batch K-Means算法</h4><blockquote>
<p>2000年由David Sculley提出，可以处理内存处理不下的数据（也可以memmap），与regular K-Means相比，快3-4倍，但intertia较差。</p>
<p>sklearn中有MiniBatchKMeans类。</p>
</blockquote>
<h4 id="确定最佳类的个数"><a href="#确定最佳类的个数" class="headerlink" title="确定最佳类的个数"></a>确定最佳类的个数</h4><p>不能用intertia，因为类越多，intertia越小。选取intertia-k的肘部点。</p>
<p><img src="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0908.png" alt="mls2 0908"></p>
<h4 id="silhouette-score（平均轮廓系数）"><a href="#silhouette-score（平均轮廓系数）" class="headerlink" title="silhouette score（平均轮廓系数）"></a><em>silhouette score（平均轮廓系数）</em></h4><p>silhouette score：所有实例silhouette efficient（轮廓系数）的平均。</p>
<p>轮廓系数（-1~1）：(b – a) / max(a, b)，a是同类中其他实例距离的平均（the mean intra-cluster distance），b是到最近邻类中其他实例的平均距离（the mean nearest-cluster distance ），接近+1,意味着实例都处于当前类中，接近-1，意味着实例被分类到了错误的类，接近0，意味着数据点在边界。</p>
<p><img src="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0909.png" alt="mls2 0909"></p>
<p>还可以画出silhouette diagram：算出每个实例的轮廓系数，并将它们分到相应的类里：</p>
<p><img src="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0910.png" alt="mls2 0910"></p>
<p>红色虚线表示silhouette score，凡是处于虚线左侧的刀型图，表示该类的实例和其他类距离过近。</p>
<p>k=4和5中类的大小不一样，4中橙色的类明显更大，而5中类更均匀，所以即使4的silhouette score更大，看上去5的表现更好。</p>
<h4 id="K-Means的局限性"><a href="#K-Means的局限性" class="headerlink" title="K-Means的局限性"></a>K-Means的局限性</h4><ol>
<li><p>需要提前跑几次，防止陷入过拟合</p>
</li>
<li><p>需要自己确定类的个数</p>
</li>
<li><p>当类的大小不均一，或者密度不一，或者分布不是球形时，表现不好</p>
<blockquote>
<p>椭圆分布（elliptical clusters），Gaussian mixture model表现更好</p>
<p>运行K-Means之前，scale the feature</p>
</blockquote>
</li>
</ol>
<h4 id="K-Means的具体应用"><a href="#K-Means的具体应用" class="headerlink" title="K-Means的具体应用"></a>K-Means的具体应用</h4><p><strong>图像分割</strong> <em>Image segmentation</em> ：将图像分成若干部分。</p>
<blockquote>
<ol>
<li>语义分割（semantic segmentation）</li>
<li>实例分割（instance segmentation）</li>
</ol>
<p>一般基于CNN实现。</p>
</blockquote>
<p>颜色分割（color segmentation）：应用场景：从卫星图计算森林面积的大小。</p>
<p><strong>数据预处理</strong></p>
<p>监督学习前使用K-Means对数据进行聚类。降低了数据的维度，更重要的是聚类得到的特征更加线性可分。</p>
<p><strong>用于半监督学习</strong></p>
<p>当有很多没有标签的数据时，可以使用K-Means对有标签的数据进行聚类，将最接近中心的图片（或其他）（representative image）表示出来。将标签传递给类中其他数据，这个过程叫做label  propagation。</p>
<blockquote>
<p>注意：边界上的数据点可能被错误的分类了，所以标签传递最好传递给距离聚类中心最近的一部分数据（比如20%）</p>
</blockquote>
<h4 id="主动学习-active-learning"><a href="#主动学习-active-learning" class="headerlink" title="主动学习(active learning)"></a>主动学习(active learning)</h4><p>不确定度采样<code>Uncertainty Sampling</code></p>
<ol>
<li>用仅有的有标签数据训练模型，用该模型预测所有无标签数据</li>
<li>将预测结果中最不准确（概率最低）的实例拿出来给专家贴标签</li>
<li>重复上述过程</li>
</ol>
<p>更深入了解可以参考：<a href="https://blog.csdn.net/qq_39856931/article/details/106433187" target="_blank" rel="noopener">https://blog.csdn.net/qq_39856931/article/details/106433187</a></p>
<h4 id="KNN和K-Means的区别"><a href="#KNN和K-Means的区别" class="headerlink" title="KNN和K-Means的区别"></a>KNN和K-Means的区别</h4><div class="table-container">
<table>
<thead>
<tr>
<th><strong>KNN</strong></th>
<th><strong>K-Means</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>1.KNN是分类算法  2.监督学习 3.喂给它的数据集是带label的数据，已经是完全正确的数据</td>
<td>1.K-Means是聚类算法  2.非监督学习 3.喂给它的数据集是无label的数据，是杂乱无章的，经过聚类后才变得有点顺序，先无序，后有序</td>
</tr>
<tr>
<td>没有明显的前期训练过程，属于memory-based learning</td>
<td>有明显的前期训练过程</td>
</tr>
<tr>
<td>K的含义：来了一个样本x，要给它分类，即求出它的y，就从数据集中，在x附近找离它最近的K个数据点，这K个数据点，类别c占的个数最多，就把x的label设为c</td>
<td>K的含义：K是人工固定好的数字，假设数据集合可以分为K个簇，由于是依靠人工定好，需要一点先验知识</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>相似点：都包含这样的过程，给定一个点，在数据集中找离它最近的点。即二者都用到了NN(Nears Neighbor)算法，一般用KD树来实现NN。</td>
</tr>
</tbody>
</table>
</div>
<h4 id="DBSCAN（Density-Based-Spatial-Clustering-of-Applications-with-Noise）"><a href="#DBSCAN（Density-Based-Spatial-Clustering-of-Applications-with-Noise）" class="headerlink" title="DBSCAN（Density-Based Spatial Clustering of Applications with Noise）"></a>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）</h4><p>基于局部密度估计（local density estimation），该算法允许对任意形状的数据进行聚类。</p>
<ol>
<li>对于每一个实例，算法计算一个小范围$\epsilon$ 内有多少实例，该范围叫做：实例的$\epsilon$-neighborhood</li>
<li>如果一个实例的$\epsilon$-neighborhood中有超过min_samples个实例，则该实例为core instance</li>
<li>所有在同一个core instance周围的实例属于同一个类，有可能一个core instance的周围有其他core instance。因此，一系列相邻的core instance形成一个cluster</li>
<li>任何实例，如果不是core instance，其相邻范围内也没有core instance，会被认为是异常数据</li>
</ol>
<p>当数据的可以被低密度区域分开时，DBSCAN变现得很好。</p>
<blockquote>
<p>sklearn中的DBSCAN没有predict方法，可以用DBSCAN的聚类中心（或者全部数据，或者除了异常数据的其他数据）训练其他算法（例如KNN），再预测新的数据。</p>
</blockquote>
<p><img src="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0915.png" alt="mls2 0915"></p>
<p>其实有两个数据需要被判定为异常值。</p>
<p>DBSCAN是一个简单但是强大的聚类算法，可以对不规则形状分布的数据进行聚类，并且只有两个超参数eps和min_samples，但如果类中密度变化很大，DBSCAN的表现可能没有那么好。</p>
<p><strong>计算复杂度</strong>：O(m log m)</p>
<h4 id="其他聚类算法"><a href="#其他聚类算法" class="headerlink" title="其他聚类算法"></a>其他聚类算法</h4><h5 id="层次聚类-Agglomerative-clustering"><a href="#层次聚类-Agglomerative-clustering" class="headerlink" title="层次聚类(Agglomerative clustering)"></a>层次聚类(Agglomerative clustering)</h5><p>是一种自底而上的层次聚类方法，它能够根据指定的相似度或距离定义计算出类之间的距离。</p>
<ol>
<li>将每一个元素单独定为一类</li>
<li>重复：每一轮都合并指定距离(对指定距离的理解很重要)最小的类</li>
<li>直到所有的元素都归为同一类</li>
</ol>
<blockquote>
<p>类似水面上的泡泡，会与相邻的泡泡合并</p>
</blockquote>
<p>依据对相似度（距离）的不同定义，将Agglomerative Clustering的聚类方法分为三种：Single-linkage, Complete-linkage和Group average.<br><strong>Single-linkage</strong>:要比较的距离为元素对之间的最小距离<br><strong>Complete-linkage</strong>:要比较的距离为元素对之间的最大距离<br><strong>Group average</strong>：要比较的距离为类之间的平均距离（平均距离的定义与计算：假设有A，B两个类，A中有n个元素，B中有m个元素。在A与B中各取一个元素，可得到他们之间的距离。将nm个这样的距离相加，得到距离和。最后距离和除以nm得到A，B两个类的平均距离。）</p>
<h5 id="BIRCH"><a href="#BIRCH" class="headerlink" title="BIRCH"></a>BIRCH</h5><p>Balanced Iterative Reducing and Clustering using Hierarchies，利用层次方法的平衡迭代规约和聚类，针对large database，并且比batch-K Means快</p>
<p>BIRCH算法利用了一个树结构来帮助我们快速的聚类，这个数结构类似于平衡B+树，一般将它称之为聚类特征树(Clustering Feature Tree，简称CF Tree)。这颗树的每一个节点是由若干个聚类特征(Clustering Feature，简称CF)组成。</p>
<p>可参考：<a href="https://www.cnblogs.com/pinard/p/6179132.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6179132.html</a></p>
<h5 id="Mean-Shift"><a href="#Mean-Shift" class="headerlink" title="Mean-Shift"></a>Mean-Shift</h5><p>也叫做均值漂移，在目标追踪中应用广泛。本身其实是一种<strong>基于密度</strong>的聚类算法。</p>
<p>主要思路是：中心向着密度高的地方移动，直到移动到local density maximum</p>
<ol>
<li>计算某一实例(A)与其周围半径R内的向量距离的平均值M，计算出该点下一步漂移（移动）的方向（A=M+A）。</li>
<li>重复上述过程，直到所有的点不再移动时，其与周围点形成一个类簇，</li>
<li>计算这个类簇与历史类簇的距离，满足小于阈值D即合并为同一个类簇，不满足则自身形成一个类簇。直到所有的数据点选取完毕。</li>
</ol>
<blockquote>
<p>当簇的内部具有密度不均匀时，Mean-shift倾向于将该簇分为几片</p>
<p>计算复杂度：$O(m^2)$,不适合大的数据集</p>
</blockquote>
<h5 id="Affinity-propagation"><a href="#Affinity-propagation" class="headerlink" title="Affinity propagation"></a>Affinity propagation</h5><p>AP(Affinity Propagation)通常被翻译为近邻传播算法或者亲和力传播算法。</p>
<p><strong>一种投票机制</strong>，每个实例对相似的实例投票，选出代表（representatives）一旦算法收敛，每个代表和其投票者聚成一簇。</p>
<blockquote>
<p>计算复杂度：$O(m^2)$,不适合大的数据集</p>
<p>AP算法的基本思想是将全部数据点都当作潜在的聚类中心(称之为exemplar)，然后数据点两两之间连线构成一个网络(相似度矩阵)，再通过网络中各条边的消息(responsibility和availability)传递计算出各样本的聚类中心。</p>
<p>聚类过程中，共有两种消息在各节点间传递，分别是吸引度（responsibility）和归属度（availability）。</p>
<p>AP算法通过迭代过程不断更新每一个点的吸引度和归属度，直到产生m个高质量的Exemplar（相当于质心），同时将其余的数据点分配到相应的聚类中。</p>
<p>可参考：<a href="https://www.biaodianfu.com/affinity-propagation.html" target="_blank" rel="noopener">https://www.biaodianfu.com/affinity-propagation.html</a></p>
</blockquote>
<h5 id="谱聚类"><a href="#谱聚类" class="headerlink" title="谱聚类"></a>谱聚类</h5><p>Spectral clustering，它的主要思想是把所有的数据看做空间中的点，这些点之间可以用边连接起来。距离较远的两个点之间的边权重值较低，而距离较近的两个点之间的边权重值较高，通过对所有数据点组成的图进行切图，让切图后不同的子图间边权重和尽可能的低，而子图内的边权重和尽可能的高，从而达到聚类的目的。</p>
<h3 id="高斯混合模型-Gaussian-mixtures"><a href="#高斯混合模型-Gaussian-mixtures" class="headerlink" title="高斯混合模型 Gaussian mixtures"></a>高斯混合模型 Gaussian mixtures</h3><p><em>Gaussian mixture model</em> (GMM)：多个高斯分布的线性叠加能拟合非常复杂的密度函数；通过足够多的高斯分布叠加，并调节它们的均值，协方差矩阵，以及线性组合的系数，可以精确地逼近任意连续密度。</p>
<p> <code>GaussianMixture</code> class: 需要确定数据有几个高斯分布生成</p>
<blockquote>
<ol>
<li>对于每一个实例，从k个高斯分布（代表着k个簇）中随机选择，选择第j个高斯分布的概率$\phi^{(j)}$, 第i个实例选择的高斯分布记作$z^{(i)}$</li>
<li>如果$z^{(i)}=j$意味着第i个实例被分到了第j个簇中，实例$x^{(i)}~ N(\mu^{(j)},\sum^{(j)})$</li>
</ol>
</blockquote>
<p><img src="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0916.png" alt="mls2 0916"></p>
<h4 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h4><p>sklearn中的类<code>GaussianMixture</code>依据的是EM算法。</p>
<blockquote>
<p>和K-Means算法类似</p>
<ol>
<li>expectation step</li>
</ol>
<p>计算每个实例属于各个簇的概率（软分类）</p>
<ol>
<li>maximization step</li>
</ol>
<p>迭代</p>
<p>EM同样会收敛到不好的结果，所以需要多跑几次，保存最好的结果，<code>n_init=10</code></p>
</blockquote>
<p>GMM是一个生成模型，可以用来生成新的实例。</p>
<p>还可以预测每个实例周围的密度，<code>score_samples()</code>方法，计算实例的PDF（probability density function）的l对数。</p>
<p>对于高维数据，GMM可能陷入困难，需要对模型加以限制（减少自由度，限制分布的形状，大小和取向），通过超参数<code>`covariance_type</code> `</p>
<blockquote>
<p>取值可以是：sphere，diag，tied default：full</p>
</blockquote>
<p><strong>计算复杂度</strong>：取决于实例的个数m，数据的维度n，以及簇的个数k，还有对协方差矩阵的限制。</p>
<blockquote>
<p>diag or spherical：$O(kmn)$</p>
<p>tied or full: $O()kmn^2+kn^3$</p>
</blockquote>
<h4 id="异常值检测"><a href="#异常值检测" class="headerlink" title="异常值检测"></a>异常值检测</h4><p>GMM用于异常值检测（anomaly detection）也叫做outlier detection。</p>
<blockquote>
<p>处在GMM低密度区域的实例可以被认为是异常值。可以自己规定阈值。</p>
</blockquote>
<p>观察学习“正常（normal）”的数据是什么样子的，来检测出异常数据（应用场景：生产线产品部件的检测&amp;异常访问）</p>
<h4 id="新颖性检测"><a href="#新颖性检测" class="headerlink" title="新颖性检测"></a>新颖性检测</h4><p>novelty detection：检测新观察是否是异常值。 在这种情况下，异常值也被称为新颖点（a novelty）。是一种半监督的异常检测方法，在新颖性检测的背景下，新颖点可以形成密集的簇，只要它们处于训练数据的低密度区域中。</p>
<p>GMM尝试fit所有的数据，包括异常值，如果异常点过多，可以</p>
<blockquote>
<ol>
<li>去除最外侧的异常值，在cleaned-up的数据集上再次训练模型</li>
<li>使用更鲁棒的算法：EllipticEnvelope （适合于对数据的鲁棒协方差估计，从而将椭圆适配到中央数据点，忽略中央模式之外的点。）</li>
</ol>
</blockquote>
<h4 id="如何确定cluster的个数"><a href="#如何确定cluster的个数" class="headerlink" title="如何确定cluster的个数"></a>如何确定cluster的个数</h4><p>对于大小不一致或者非球型分布的数据，K-Means中用来确定cluster数目的inertia和轮廓系数都不可行。</p>
<p>我们通过<strong>最小化理论信息标准（theoretical information criterion），如赤池信息量（<em>Akaike information criterion</em> ，AIC）,贝叶斯信息量（BIC，<em>Bayesian information criterion</em>）</strong></p>
<p>定义：(m是实例的个数，p是模型的参数，$\hat L$ 是模型似然函数（likelihood function）的最大值)</p>
<p>$BIC\ = \ \log(m)p-2\ \log(\hat L) \\ AIC  \ = 2p-2\ \log(\hat L)$</p>
<p>BIC和AIC对参数多模型加上penalty，一般情况下，BIC选择的模型比AIC简单，但是不如AIC的模型和数据吻合得好。</p>
<p><strong>似然函数</strong></p>
<p>概率（probability）是指：给定模型的参数，输出x的可信程度。（下图水平黑线，和PDF图）</p>
<p>似然（likelihood）是指：一直输出x的前提下，模型的参数有多可信。（下图垂直蓝色线，和似然函数图）</p>
<p><img src="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0920.png" alt="mls2 0920"></p>
<h4 id="Bayesian-Gaussian-Mixture-Models"><a href="#Bayesian-Gaussian-Mixture-Models" class="headerlink" title="Bayesian Gaussian Mixture Models"></a>Bayesian Gaussian Mixture Models</h4><p>可以赋予不重要的簇权重0，可以通过n_components预设簇的最大值。</p>
<p><img src="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0922.png" alt="mls2 0922"></p>
<p>Stick-Breaking Process (SBP)</p>
<p>Wishart distribution</p>
<p><strong>贝叶斯定理</strong></p>
<p>$p(z|X)=posterior=\frac{likelihood\times prior}{evidence}=\frac{p(X|z)p(z)}{p(X)}$</p>
<p>$p(X)=\int p(X|z)p(z)dz$</p>
<h3 id="其他处理异常值和新颖性检测的算法"><a href="#其他处理异常值和新颖性检测的算法" class="headerlink" title="其他处理异常值和新颖性检测的算法"></a>其他处理异常值和新颖性检测的算法</h3><h4 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h4><p>数据重建，正常值重建后与原始数据差距小，而异常值重建后与异常值差距大</p>
<h4 id="Fast-MCD"><a href="#Fast-MCD" class="headerlink" title="Fast-MCD"></a>Fast-MCD</h4><p>minimum covariance determinant，</p>
<p>认为正常值（inliers）是由单一的高斯模型产生的，不是由该单一高斯模型产生的数据点被认为是outliers</p>
<h4 id="Isolation-Forest"><a href="#Isolation-Forest" class="headerlink" title="Isolation Forest"></a>Isolation Forest</h4><p>孤立森林： 是一个基于Ensemble的快速异常检测方法，具有线性时间复杂度和高精准度，是符合大数据处理要求的state-of-the-art算法。适用于<strong>连续数据（Continuous numerical data）的异常检测</strong>，将异常定义为“容易被孤立的离群点 (more likely to be separated)”——可以理解为分布稀疏且离密度高的群体较远的点。</p>
<p>构建随机森林，其中每一个决策树都是随机的，在每个节点，随机的选择特征和阈值，将数据分为两个部分。</p>
<p>适用于高维数据</p>
<h4 id="Local-Outlier-Factoer（LOF）"><a href="#Local-Outlier-Factoer（LOF）" class="headerlink" title="Local Outlier Factoer（LOF）"></a>Local Outlier Factoer（LOF）</h4><p>一个样本点周围的样本点所处位置的平均密度比上该样本点所在位置的密度。比值越大于1，则该点所在位置的密度越小于其周围样本所在位置的密度，这个点就越有可能是异常点。</p>
<h4 id="One-class-SVM"><a href="#One-class-SVM" class="headerlink" title="One-class SVM"></a>One-class SVM</h4><p>单分类算法，寻找一个超平面将样本中的正例圈出来，预测就是用这个超平面做决策，在圈内的样本就认为是正样本。由于<strong>核函数</strong>计算比较耗时，在海量数据的场景用的并不多；</p>
<p><strong>适用于新颖性检测</strong></p>
<p><img src="https://img2018.cnblogs.com/blog/1226410/201904/1226410-20190424112057869-1957699378.png" alt="img"></p>
<h3 id="密度估计（density-estimation）"><a href="#密度估计（density-estimation）" class="headerlink" title="密度估计（density estimation）"></a>密度估计（density estimation）</h3><p>用来估计随机过程的概率密度函数（probability density function（PDF））（应用场景：异常检测（密度低的地方异常的概率大），数据分析和可视化）</p>
<h3 id="练习-3"><a href="#练习-3" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>How would you define clustering? Can you name a few clustering algorithms?</p>
<blockquote>
<p>聚类是一种无监督学习，将具有相似特征的实例聚集在一起。</p>
<p>K-Means, DBSCAN，层次聚类，BRICH，Mean-shift，Affinity propagation和谱聚类</p>
</blockquote>
</li>
<li><p>What are some of the main applications of clustering algorithms?</p>
<blockquote>
<p>半监督学习</p>
<p>图像分割</p>
<p>数据预处理</p>
<p>异常值检测</p>
<p>新颖性检测</p>
</blockquote>
</li>
<li><p>Describe two techniques to select the right number of clusters when using K-Means.</p>
<blockquote>
<ol>
<li>画出k-inertia图像，选择肘部</li>
<li>画出k-轮廓系数图像，选择最高点</li>
</ol>
</blockquote>
</li>
<li><p>What is label propagation? Why would you implement it, and how?</p>
<blockquote>
<p>因为打标签是非常耗时的，所以实际情况下，数据集中可能只有很少一部分有标签，大部分数据都没有标签，标签传递可以得到更多的带标签的数据，可以进行监督学习（这个过程就是非监督学习）</p>
<p>当数据中仅有少部分具有标签的数据时，可以先进行聚类，然后将标签打到具有相似特征的实例上（离聚类中心最近的有标签数据）。</p>
</blockquote>
</li>
<li><p>Can you name two clustering algorithms that can scale to large datasets? And two that look for regions of high density?</p>
<blockquote>
<p>K-Means和BRICH可以用于大的数据集</p>
<p>DBSCAN和Mean-shift（中心向着密度高的方向移动）寻找区域内高密度的位置</p>
</blockquote>
</li>
<li><p>Can you think of a use case where active learning would be useful? How would you implement it?</p>
<blockquote>
<p>不是随机的选择数据打标签，而是人类专家参与算法的学习，为特定的实例提供标签。</p>
<p>不确定采样</p>
</blockquote>
</li>
<li><p>What is the difference between anomaly detection and novelty detection?</p>
<blockquote>
<p>异常值检测中：模型在包含异常值的数据集上训练，（孤立森林）</p>
<p>新颖性检测中：模型在一个clean的数据及上训练，（单分类-SVM）</p>
</blockquote>
</li>
<li><p>What is a Gaussian mixture? What tasks can you use it for?</p>
<blockquote>
<p>GMM是一种概率模型，假设实例是由若干个高斯模型混合生成的。换句话说，假设数据属于若干椭圆类，但大小，方向，形状和密度都不确定。</p>
<p>可以用来密度检测，异常值检测，聚类。</p>
</blockquote>
</li>
<li><p>Can you name two techniques to find the right number of clusters when using a Gaussian mixture model?</p>
<blockquote>
<p>画出k-AIC或者k-BIC的图像，选择使AIC或者BIC数值最小的聚类个数。</p>
</blockquote>
</li>
<li><p>The classic Olivetti faces dataset contains 400 grayscale 64 × 64–pixel images of faces. Each image is flattened to a 1D vector of size 4,096. 40 different people were photographed (10 times each), and the usual task is to train a model that can predict which person is represented in each picture. Load the dataset using the <code>sklearn.datasets.fetch_olivetti_faces()</code> function, then split it into a training set, a validation set, and a test set (note that the dataset is already scaled between 0 and 1). Since the dataset is quite small, you probably want to use stratified sampling to ensure that there are the same number of images per person in each set. Next, cluster the images using K-Means, and ensure that you have a good number of clusters (using one of the techniques discussed in this chapter). Visualize the clusters: do you see similar faces in each cluster?</p>
</li>
<li><p>Continuing with the Olivetti faces dataset, train a classifier to predict which person is represented in each picture, and evaluate it on the validation set. Next, use K-Means as a dimensionality reduction tool, and train a classifier on the reduced set. Search for the number of clusters that allows the classifier to get the best performance: what performance can you reach? What if you append the features from the reduced set to the original features (again, searching for the best number of clusters)?</p>
</li>
<li><p>Train a Gaussian mixture model on the Olivetti faces dataset. To speed up the algorithm, you should probably reduce the dataset’s dimensionality (e.g., use PCA, preserving 99% of the variance). Use the model to generate some new faces (using the <code>sample()</code> method), and visualize them (if you used PCA, you will need to use its <code>inverse_transform()</code> method). Try to modify some images (e.g., rotate, flip, darken) and see if the model can detect the anomalies (i.e., compare the output of the <code>score_samples()</code> method for normal images and for anomalies).</p>
</li>
<li><p>Some dimensionality reduction techniques can also be used for anomaly detection. For example, take the Olivetti faces dataset and reduce it with PCA, preserving 99% of the variance. Then compute the reconstruction error for each image. Next, take some of the modified images you built in the previous exercise, and look at their reconstruction error: notice how much larger the reconstruction error is. If you plot a reconstructed image, you will see why: it tries to reconstruct a normal face.</p>
</li>
</ol>
]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>sklearn</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>《利用Python进行数据分析》学习</title>
    <url>/2020/08/23/%E3%80%8A%E5%88%A9%E7%94%A8Python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%8B%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>简书： <a href="https://www.jianshu.com/p/04d180d90a3f" target="_blank" rel="noopener">https://www.jianshu.com/p/04d180d90a3f</a></p>
<p>github： <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fiamseancheney%2Fpython_for_data_analysis_2nd_chinese_version" target="_blank" rel="noopener">https://github.com/iamseancheney/python_for_data_analysis_2nd_chinese_version</a></p>
<p>gitbook： <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fseancheney.gitbook.io%2Fpython-for-data-analysis-2nd%2F" target="_blank" rel="noopener">https://seancheney.gitbook.io/python-for-data-analysis-2nd/</a></p>
<p>[TOC]</p>
<h2 id="第2章-Python语法基础，IPython和Jupyter-Notebooks"><a href="#第2章-Python语法基础，IPython和Jupyter-Notebooks" class="headerlink" title="第2章 Python语法基础，IPython和Jupyter Notebooks"></a>第2章 Python语法基础，IPython和Jupyter Notebooks</h2><h3 id="IPython键盘快捷键"><a href="#IPython键盘快捷键" class="headerlink" title="IPython键盘快捷键"></a>IPython键盘快捷键</h3><a id="more"></a>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9ed3866ea25c11f8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e179f5ea00e50691.png?imageMogr2/auto-orient/strip|imageView2/2/w/491/format/webp" alt="img"></p>
<h3 id="IPython魔术命令"><a href="#IPython魔术命令" class="headerlink" title="IPython魔术命令"></a>IPython魔术命令</h3><p>IPython中特殊的命令（Python中没有）被称作“魔术”命令。</p>
<p>line magic %</p>
<p>cell magic %%</p>
<p><code>%timeit</code>可以测量任何Python语句的执行时间：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">20</span>]: a = np.random.randn(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: %timeit np.dot(a, a)</span><br><span class="line"><span class="number">10000</span> loops, best of <span class="number">3</span>: <span class="number">20.9</span> µs per loop</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-c72b11add9b8ccf8.png?imageMogr2/auto-orient/strip|imageView2/2/w/695/format/webp" alt="img"></p>
<h3 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h3><p>IPython中集成了数据可视化和其它用户界面库，比如matplotlib。</p>
<p><code>%matplotlib</code>魔术函数配置了IPython shell和Jupyter notebook中的matplotlib。</p>
<p>在JUpyter中，命令有所不同：<code>%matplotlib inline</code></p>
<h3 id="Python语法基础"><a href="#Python语法基础" class="headerlink" title="Python语法基础"></a>Python语法基础</h3><h4 id="使用缩进"><a href="#使用缩进" class="headerlink" title="使用缩进"></a>使用缩进</h4><p>建议使用四个空格作为默认的缩进，可以使用tab代替四个空格。</p>
<h4 id="万物皆对象"><a href="#万物皆对象" class="headerlink" title="万物皆对象"></a>万物皆对象</h4><h4 id="位置和关键词参数"><a href="#位置和关键词参数" class="headerlink" title="位置和关键词参数"></a>位置和关键词参数</h4><p><code>result = f(a, b, c, d=5, e=&#39;foo&#39;)</code></p>
<h4 id="变量和参数传递："><a href="#变量和参数传递：" class="headerlink" title="变量和参数传递："></a>变量和参数传递：</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b = a</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-3e3a8c6b9c5040fc.png?imageMogr2/auto-orient/strip|imageView2/2/w/892/format/webp" alt="img"></p>
<p>在Python中，a和b实际上是同一个对象.赋值也被称作绑定，我们是把一个名字绑定给一个对象。变量名有时可能被称为绑定变量。</p>
<p>将对象作为参数传递给函数时，新的局域变量创建了对原始对象的引用，而不是复制。如果在函数里绑定一个新对象到一个变量，这个变动不会反映到上一层。</p>
<h4 id="强类型化语言"><a href="#强类型化语言" class="headerlink" title="强类型化语言"></a>强类型化语言</h4><p><code>&#39;5&#39; + 5</code> 会报错，即每个对象都有明确的类型（或类），默许转换只会发生在特定的情况下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">17</span>]: a = <span class="number">4.5</span></span><br><span class="line">In [<span class="number">18</span>]: b = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># String formatting, to be visited later</span></span><br><span class="line">In [<span class="number">19</span>]: print(<span class="string">'a is &#123;0&#125;, b is &#123;1&#125;'</span>.format(type(a), type(b)))</span><br><span class="line">a is &lt;class 'float'&gt;, b is &lt;class 'int'&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: a / b</span><br><span class="line">Out[<span class="number">20</span>]: <span class="number">2.25</span></span><br></pre></td></tr></table></figure>
<p>可以用<code>isinstance</code>函数检查对象是某个类型的实例。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="number">5</span></span><br><span class="line">isinstance(a, int) <span class="comment">#检查对象是否是某个类型的实例</span></span><br><span class="line">isinstance(a, (int, float)) <span class="comment">#检查对象的类型是否在元组中</span></span><br></pre></td></tr></table></figure>
<h4 id="属性和方法"><a href="#属性和方法" class="headerlink" title="属性和方法"></a>属性和方法</h4><p>Python的对象通常都有属性（其它存储在对象内部的Python对象）和方法（对象的附属函数可以访问对象的内部数据）</p>
<p>可以用<code>obj.attribute_name</code>访问属性和方法，也可以用<code>getattr</code>函数，通过名字访问属性和方法。</p>
<h4 id="鸭子类型"><a href="#鸭子类型" class="headerlink" title="鸭子类型"></a>鸭子类型</h4><p>不关心对象的类型，只关心对象是否有某些方法或用途。这通常被称为“鸭子类型”，来自“走起来像鸭子、叫起来像鸭子，那么它就是鸭子”的说法。</p>
<p>通过验证一个对象是否遵循迭代协议，判断它是可迭代的。对于许多对象，这意味着它有一个<code>__iter__</code>魔术方法，其它更好的判断方法是使用<code>iter</code>函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isiterable</span><span class="params">(obj)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        iter(obj)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">except</span> TypeError: <span class="comment"># not iterable</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>可以用这个功能编写可以接受多种输入类型的函数。例如编写一个函数可以接受任意类型的序列（list、tuple、ndarray）或是迭代器。先检验对象是否是列表（或是NUmPy数组），如果不是，将其转变成列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> isinstance(x, list) <span class="keyword">and</span> isiterable(x):</span><br><span class="line">    x = list(x)</span><br></pre></td></tr></table></figure>
<h4 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h4><h4 id="二元运算符和比较运算符"><a href="#二元运算符和比较运算符" class="headerlink" title="二元运算符和比较运算符"></a>二元运算符和比较运算符</h4><p>要判断两个引用是否指向同一个对象，可以使用<code>is</code>方法，<code>is not</code>可以判断两个对象是不同的。使用<code>is</code>比较与<code>==</code>运算符不同，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: b = a</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: c = list(a) <span class="comment"># 因为list总是创建一个新的Python列表（即复制）</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: a <span class="keyword">is</span> b</span><br><span class="line">Out[<span class="number">38</span>]: <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: a <span class="keyword">is</span> <span class="keyword">not</span> c</span><br><span class="line">Out[<span class="number">39</span>]: <span class="literal">True</span></span><br><span class="line">       </span><br><span class="line">In [<span class="number">40</span>]: a == c</span><br><span class="line">Out[<span class="number">40</span>]: <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9fb5f25b33166acf.png?imageMogr2/auto-orient/strip|imageView2/2/w/811/format/webp" alt="img"></p>
<h4 id="可变与不可变对象"><a href="#可变与不可变对象" class="headerlink" title="可变与不可变对象"></a>可变与不可变对象</h4><p>Python中的大多数对象，如列表、字典、NumPy数组，和用户定义的类型（类），都是可变的，意味着这些对象或包含的值可以被修改。其它例如<strong>字符串和元组</strong> ，是不可变的。</p>
<h4 id="标量类型"><a href="#标量类型" class="headerlink" title="标量类型"></a>标量类型</h4><p>Python的标准库中有一些内建的类型，用于处理数值数据、字符串、布尔值，和日期时间。这些单值类型被称为标量类型。</p>
<p>日期和时间处理会是由标准库的<code>datetime</code>模块提供的。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-27a30ac3e7d262a1.png?imageMogr2/auto-orient/strip|imageView2/2/w/808/format/webp" alt="img"></p>
<h4 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h4><p>Python的主要数值类型是<code>int</code>和<code>float</code></p>
<h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4><p>反斜杠是转义字符，意思是它被用来表示特殊字符。</p>
<p>如果字符串中包含许多反斜杠，但没有特殊字符，可以在字符串前面加一个r，表明字符就是它自身。</p>
<p>字符串的模板化或格式化：</p>
<ol>
<li><p><code>format</code>方法，可以替换格式化的参数为字符串，产生一个新的字符串：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">74</span>]: template = <span class="string">'&#123;0:.2f&#125; &#123;1:s&#125; are worth US$&#123;2:d&#125;'</span></span><br><span class="line">In [<span class="number">75</span>]: template.format(<span class="number">4.5560</span>, <span class="string">'Argentine Pesos'</span>, <span class="number">1</span>)</span><br><span class="line">Out[<span class="number">75</span>]: <span class="string">'4.56 Argentine Pesos are worth US$1'</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="字节和Unicode"><a href="#字节和Unicode" class="headerlink" title="字节和Unicode"></a>字节和Unicode</h4><p>在Python 3及以上版本中，Unicode是一级的字符串类型，这样可以更一致的处理ASCII和Non-ASCII文本。在老的Python版本中，字符串都是字节，不使用Unicode编码。</p>
<p>可以用<code>encode</code>将Unicode字符串编码为UTF-8，<code>decode</code> 将UTF-8解码为Unicode编码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">76</span>]: val = <span class="string">"español"</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: val</span><br><span class="line">Out[<span class="number">77</span>]: <span class="string">'español'</span></span><br><span class="line">    </span><br><span class="line">In [<span class="number">78</span>]: val_utf8 = val.encode(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">79</span>]: val_utf8</span><br><span class="line">Out[<span class="number">79</span>]: <span class="string">b'espa\xc3\xb1ol'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: type(val_utf8)</span><br><span class="line">Out[<span class="number">80</span>]: bytes</span><br><span class="line"></span><br><span class="line">In [<span class="number">81</span>]: val_utf8.decode(<span class="string">'utf-8'</span>)</span><br><span class="line">Out[<span class="number">81</span>]: <span class="string">'español'</span></span><br></pre></td></tr></table></figure>
<p><strong>可以在字节文本前加上b</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">85</span>]: bytes_val = <span class="string">b'this is bytes'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: bytes_val</span><br><span class="line">Out[<span class="number">86</span>]: <span class="string">b'this is bytes'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">87</span>]: decoded = bytes_val.decode(<span class="string">'utf8'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">88</span>]: decoded  <span class="comment"># this is str (Unicode) now</span></span><br><span class="line">Out[<span class="number">88</span>]: <span class="string">'this is bytes'</span></span><br></pre></td></tr></table></figure>
<h4 id="None"><a href="#None" class="headerlink" title="None"></a>None</h4><p>None是Python的空值类型。如果一个函数没有明确的返回值，就会默认返回None，None也常常作为函数的默认参数。</p>
<h4 id="时间和日期"><a href="#时间和日期" class="headerlink" title="时间和日期"></a>时间和日期</h4><p>Python内建的<code>datetime</code>模块提供了<code>datetime</code>、<code>date</code>和<code>time</code>类型。<code>datetime</code>类型结合了<code>date</code>和<code>time</code>，是最常使用的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">102</span>]: <span class="keyword">from</span> datetime <span class="keyword">import</span> datetime, date, time</span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: dt = datetime(<span class="number">2011</span>, <span class="number">10</span>, <span class="number">29</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">21</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">104</span>]: dt.day</span><br><span class="line">Out[<span class="number">104</span>]: <span class="number">29</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">105</span>]: dt.minute</span><br><span class="line">Out[<span class="number">105</span>]: <span class="number">30</span></span><br><span class="line">    </span><br><span class="line">In [<span class="number">106</span>]: dt.date()</span><br><span class="line">Out[<span class="number">106</span>]: datetime.date(<span class="number">2011</span>, <span class="number">10</span>, <span class="number">29</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">107</span>]: dt.time()</span><br><span class="line">Out[<span class="number">107</span>]: datetime.time(<span class="number">20</span>, <span class="number">30</span>, <span class="number">21</span>)</span><br></pre></td></tr></table></figure>
<p><code>strftime</code>方法可以将datetime格式化为字符串：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">108</span>]: dt.strftime(<span class="string">'%m/%d/%Y %H:%M'</span>)</span><br><span class="line">Out[<span class="number">108</span>]: <span class="string">'10/29/2011 20:30'</span></span><br></pre></td></tr></table></figure>
<p><code>strptime</code>可以将字符串转换成<code>datetime</code>对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">109</span>]: datetime.strptime(<span class="string">'20091031'</span>, <span class="string">'%Y%m%d'</span>)</span><br><span class="line">Out[<span class="number">109</span>]: datetime.datetime(<span class="number">2009</span>, <span class="number">10</span>, <span class="number">31</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-100f9a20c1536553.png?imageMogr2/auto-orient/strip|imageView2/2/w/692/format/webp" alt="img"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># repalce进行替换</span></span><br><span class="line">In [<span class="number">110</span>]: dt.replace(minute=<span class="number">0</span>, second=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">110</span>]: datetime.datetime(<span class="number">2011</span>, <span class="number">10</span>, <span class="number">29</span>, <span class="number">20</span>, <span class="number">0</span>)</span><br><span class="line"><span class="comment"># 两个datetime对象的差会产生一个datetime.timedelta类型：</span></span><br><span class="line">In [<span class="number">111</span>]: dt2 = datetime(<span class="number">2011</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">22</span>, <span class="number">30</span>)</span><br><span class="line">In [<span class="number">112</span>]: delta = dt2 - dt</span><br><span class="line">In [<span class="number">113</span>]: delta</span><br><span class="line">Out[<span class="number">113</span>]: datetime.timedelta(<span class="number">17</span>, <span class="number">7179</span>) <span class="comment"># 17天、7179秒</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: type(delta)</span><br><span class="line">Out[<span class="number">114</span>]: datetime.timedelta</span><br><span class="line"><span class="comment"># 可以将timedelta添加到datetime，产生一个新的偏移datetime </span></span><br><span class="line">In [<span class="number">115</span>]: dt</span><br><span class="line">Out[<span class="number">115</span>]: datetime.datetime(<span class="number">2011</span>, <span class="number">10</span>, <span class="number">29</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">21</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">116</span>]: dt + delta</span><br><span class="line">Out[<span class="number">116</span>]: datetime.datetime(<span class="number">2011</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">22</span>, <span class="number">30</span>)</span><br></pre></td></tr></table></figure>
<h4 id="控制流"><a href="#控制流" class="headerlink" title="控制流"></a>控制流</h4><h5 id="if语句："><a href="#if语句：" class="headerlink" title="if语句："></a>if语句：</h5><p>if elif else</p>
<h5 id="for循环："><a href="#for循环：" class="headerlink" title="for循环："></a>for循环：</h5><p>可以用continue使for循环提前，跳过剩下的部分；可以用<code>break</code>跳出for循环，break只中断for循环的最内层，其余的for循环仍会运行。</p>
<h5 id="while循环："><a href="#while循环：" class="headerlink" title="while循环："></a>while循环：</h5><h5 id="pass："><a href="#pass：" class="headerlink" title="pass："></a>pass：</h5><p>Python中的非操作语句。代码块不需要任何动作时可以使用（作为未执行代码的占位符）；因为Python需要使用空白字符划定代码块，所以需要pass。</p>
<h4 id="三元表达式"><a href="#三元表达式" class="headerlink" title="三元表达式"></a>三元表达式</h4><p>Python中的三元表达式可以将if-else语句放到一行里，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">value = true-expr <span class="keyword">if</span> condition <span class="keyword">else</span> false-expr</span><br></pre></td></tr></table></figure>
<h2 id="第3章-Python的数据结构、函数和文件"><a href="#第3章-Python的数据结构、函数和文件" class="headerlink" title="第3章 Python的数据结构、函数和文件"></a>第3章 Python的数据结构、函数和文件</h2><h3 id="数据结构和序列"><a href="#数据结构和序列" class="headerlink" title="数据结构和序列"></a>数据结构和序列</h3><h4 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h4><p>元组是一个固定长度，不可改变的Python序列对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建元组</span></span><br><span class="line">tup = <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span></span><br><span class="line"><span class="comment"># 当用复杂的表达式定义元组，最好将值放到圆括号内</span></span><br><span class="line">nested_tup = (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>), (<span class="number">7</span>, <span class="number">8</span>)</span><br><span class="line"><span class="comment"># 用tuple可以将任意序列或迭代器转换成元组</span></span><br><span class="line">tuple([<span class="number">4</span>, <span class="number">0</span>, <span class="number">2</span>]) <span class="comment"># (4, 0, 2)</span></span><br><span class="line">tup = tuple(<span class="string">'string'</span>) <span class="comment"># ('s', 't', 'r', 'i', 'n', 'g')</span></span><br><span class="line"><span class="comment"># 可以用方括号访问元组中的元素，序列是从0开始</span></span><br><span class="line">tup[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 元组中存储的对象可能是可变对象。一旦创建了元组，元组中的对象就不能修改</span></span><br><span class="line">tup = tuple([<span class="string">'foo'</span>, [<span class="number">1</span>, <span class="number">2</span>], <span class="literal">True</span>])</span><br><span class="line">tup[<span class="number">2</span>] = <span class="literal">False</span>  <span class="comment"># 会报错</span></span><br><span class="line"><span class="comment"># 如果元组中的某个对象是可变的，比如列表，可以在原位进行修改</span></span><br><span class="line">tup[<span class="number">1</span>].append(<span class="number">3</span>) <span class="comment"># ('foo', [1, 2, 3], True)</span></span><br><span class="line"><span class="comment"># 可以用加号运算符将元组串联起来</span></span><br><span class="line">(<span class="number">4</span>, <span class="literal">None</span>, <span class="string">'foo'</span>) + (<span class="number">6</span>, <span class="number">0</span>) + (<span class="string">'bar'</span>,) <span class="comment"># (4, None, 'foo', 6, 0, 'bar')</span></span><br><span class="line"><span class="comment"># 元组乘以一个整数，像列表一样，会将几个元组的复制串联起来</span></span><br><span class="line">(<span class="string">'foo'</span>, <span class="string">'bar'</span>) * <span class="number">4</span> <span class="comment"># ('foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'bar')</span></span><br><span class="line"><span class="comment"># 对象本身并没有被复制，只是引用了它</span></span><br></pre></td></tr></table></figure>
<h5 id="拆分元组"><a href="#拆分元组" class="headerlink" title="拆分元组"></a>拆分元组</h5><p>将元组赋值给类似元组的变量，Python会试图拆分等号右边的值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tup = (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line">a,b,c = tup</span><br><span class="line">tup = <span class="number">4</span>, <span class="number">5</span>, (<span class="number">6</span>, <span class="number">7</span>)</span><br><span class="line">a, b, (c, d) = tup</span><br><span class="line"><span class="comment"># 变量拆分常用来迭代元组或列表序列</span></span><br><span class="line">seq = [(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>), (<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)]</span><br><span class="line"><span class="keyword">for</span> a, b, c <span class="keyword">in</span> seq:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 另一个常见用法是从函数返回多个值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 高级的元组拆分功能，例如，从元组的开头“摘取”几个元素。它使用了特殊的语法*rest</span></span><br><span class="line">values = <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span></span><br><span class="line">a, b, *rest = values</span><br><span class="line">rest <span class="comment"># [3, 4, 5]</span></span><br><span class="line"><span class="comment"># rest的部分是想要舍弃的部分，rest的名字不重要。作为惯用写法，许多Python程序员会将不需要的变量使用下划线：</span></span><br><span class="line">a, b, *_ = values</span><br></pre></td></tr></table></figure>
<p>在Python中，替换可以这样做:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">b, a = a, b</span><br></pre></td></tr></table></figure>
<h5 id="tuple方法"><a href="#tuple方法" class="headerlink" title="tuple方法"></a>tuple方法</h5><p>元组的大小和内容不能修改，所以其实例方法都很轻量。其中一个很有用的就是<code>count</code>（也适用于列表），它可以统计某个值得出现频率：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line">a.count(<span class="number">2</span>) <span class="comment"># 4</span></span><br></pre></td></tr></table></figure>
<h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4><p>列表的长度可变、内容可以被修改。可以用方括号定义，或用<code>list</code>函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a_list = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="literal">None</span>]</span><br><span class="line">tup = (<span class="string">'foo'</span>, <span class="string">'bar'</span>, <span class="string">'baz'</span>)</span><br><span class="line">b_list = list(tup) <span class="comment"># ['foo', 'bar', 'baz']</span></span><br></pre></td></tr></table></figure>
<p><code>list</code>函数常用来在数据处理中实体化迭代器或生成器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gen = range(<span class="number">10</span>)</span><br><span class="line">list(gen) <span class="comment"># [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span></span><br></pre></td></tr></table></figure>
<p><code>append</code>在列表末尾添加元素</p>
<p><code>insert</code>在特定的位置插入元素，插入的序号必须在0和列表长度之间</p>
<p><strong>注意：</strong> 警告：与<code>append</code>相比，<code>insert</code>耗费的计算量大，因为需要对后续元素的引用必须在内部迁移，以便为新元素提供空间。如果要在序列的头部和尾部插入元素，可以使用双尾部队列<code>collections.deque</code>。</p>
<p><code>pop</code>, <code>insert</code>的逆运算，移除并返回指定位置的元素</p>
<p><code>remove</code>去除某个值，<code>remove</code>会先寻找第一个值并除去</p>
<p><strong>注意：</strong> 如果不考虑性能，使用<code>append</code>和<code>remove</code>，可以把Python的列表当做完美的“多重集”数据结构。</p>
<p><code>in</code> 和<code>not in</code>检查列表是否包含某个值， </p>
<p><strong>注意：</strong> 在列表中检查是否存在某个值远比字典和集合速度慢，因为Python是线性搜索列表中的值，但在字典和集合中，在同样的时间内还可以检查其它项（基于哈希表）</p>
<h5 id="串联和组合列表"><a href="#串联和组合列表" class="headerlink" title="串联和组合列表"></a>串联和组合列表</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用加号将两个列表串联起来</span></span><br><span class="line">[<span class="number">4</span>, <span class="literal">None</span>, <span class="string">'foo'</span>] + [<span class="number">7</span>, <span class="number">8</span>, (<span class="number">2</span>, <span class="number">3</span>)]</span><br><span class="line">[<span class="number">4</span>, <span class="literal">None</span>, <span class="string">'foo'</span>, <span class="number">7</span>, <span class="number">8</span>, (<span class="number">2</span>, <span class="number">3</span>)]</span><br><span class="line"><span class="comment"># 用extend方法可以追加多个元素</span></span><br><span class="line">x = [<span class="number">4</span>, <span class="literal">None</span>, <span class="string">'foo'</span>]</span><br><span class="line">x.extend([<span class="number">7</span>, <span class="number">8</span>, (<span class="number">2</span>, <span class="number">3</span>)])</span><br><span class="line"><span class="comment">## 通过加法将列表串联的计算量较大，因为要新建一个列表，并且要复制对象。用extend追加元素，尤其是到一个大列表中，更为可取。</span></span><br></pre></td></tr></table></figure>
<h5 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用sort函数将一个列表原地排序（不创建新的对象）</span></span><br><span class="line">a = [<span class="number">7</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line">a.sort()</span><br><span class="line"><span class="comment"># sort 二级排序key</span></span><br><span class="line">b = [<span class="string">'saw'</span>, <span class="string">'small'</span>, <span class="string">'He'</span>, <span class="string">'foxes'</span>, <span class="string">'six'</span>]</span><br><span class="line">b.sort(key=len)</span><br><span class="line"><span class="comment"># sorted函数，它可以产生一个排好序的序列副本</span></span><br></pre></td></tr></table></figure>
<h5 id="二分搜索和维护已排序的列表"><a href="#二分搜索和维护已排序的列表" class="headerlink" title="二分搜索和维护已排序的列表"></a>二分搜索和维护已排序的列表</h5><p><code>bisect</code>模块支持二分查找，和向已排序的列表插入值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> bisect</span><br><span class="line">c = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">7</span>]</span><br><span class="line"><span class="comment"># bisect.bisect可以找到插入值后仍保证排序的位置</span></span><br><span class="line">bisect.bisect(c, <span class="number">5</span>) <span class="comment"># 6</span></span><br><span class="line"><span class="comment"># bisect.insort向这个位置插入值</span></span><br><span class="line">bisect.insort(c, <span class="number">6</span>)</span><br><span class="line"><span class="comment">##  bisect模块不会检查列表是否已排好序，进行检查的话会耗费大量计算。因此，对未排序的列表使用bisect不会产生错误，但结果不一定正确。</span></span><br></pre></td></tr></table></figure>
<h5 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h5><p>用切边可以选取大多数序列类型的一部分，切片的基本形式是在方括号中使用<code>start:stop</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">seq = [<span class="number">7</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">seq[<span class="number">1</span>:<span class="number">5</span>] <span class="comment"># [2, 3, 7, 5]</span></span><br><span class="line"><span class="comment"># 切片也可以被序列赋值</span></span><br><span class="line">seq[<span class="number">3</span>:<span class="number">4</span>] = [<span class="number">6</span>, <span class="number">3</span>]</span><br><span class="line"><span class="comment"># start或stop都可以被省略，省略之后，分别默认序列的开头和结尾</span></span><br><span class="line">seq[<span class="number">3</span>:] </span><br><span class="line"><span class="comment"># 负数表明从后向前切片</span></span><br><span class="line">seq[<span class="number">-4</span>:]  <span class="comment"># [5, 6, 0, 1]</span></span><br><span class="line"><span class="comment"># 第二个冒号后面使用step，可以隔几个取一个元素</span></span><br><span class="line">seq[::<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 使用-1，它可以将列表或元组颠倒过来</span></span><br><span class="line">seq[::<span class="number">-1</span>]</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-522e2b688b755ff3.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="序列函数"><a href="#序列函数" class="headerlink" title="序列函数"></a>序列函数</h4><p>Python有一些有用的序列函数。</p>
<h5 id="enumerate函数"><a href="#enumerate函数" class="headerlink" title="enumerate函数"></a>enumerate函数</h5><p>迭代一个序列时，想要跟踪当前项的序号，可以使用Python内建的<code>enumerate</code>函数，可以返回<code>(i, value)</code>元组序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i, value <span class="keyword">in</span> enumerate(collection):</span><br><span class="line">   <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>索引数据时，使用<code>enumerate</code>的一个好方法是计算序列（唯一的）<code>dict</code>映射到位置的值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">some_list = [<span class="string">'foo'</span>, <span class="string">'bar'</span>, <span class="string">'baz'</span>]</span><br><span class="line">mapping = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i, v <span class="keyword">in</span> enumerate(some_list):</span><br><span class="line">    mapping[v] = i</span><br><span class="line">mapping <span class="comment">#  &#123;'bar': 1, 'baz': 2, 'foo': 0&#125;</span></span><br></pre></td></tr></table></figure>
<h5 id="sorted函数"><a href="#sorted函数" class="headerlink" title="sorted函数"></a>sorted函数</h5><p>返回一个<strong>新的</strong> 排好序的列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">7</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">b = sorted(a)</span><br><span class="line">b <span class="comment"># [0, 1, 2, 2, 3, 6, 7]</span></span><br><span class="line">a <span class="comment"># [7, 1, 2, 6, 0, 3, 2]</span></span><br></pre></td></tr></table></figure>
<h5 id="zip函数"><a href="#zip函数" class="headerlink" title="zip函数"></a>zip函数</h5><p>将多个列表、元组或其它序列成对组合成一个元组列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">seq1 = [<span class="string">'foo'</span>, <span class="string">'bar'</span>, <span class="string">'baz'</span>]</span><br><span class="line">seq2 = [<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>]</span><br><span class="line">zipped = zip(seq1, seq2)</span><br><span class="line">list(zipped) <span class="comment"># [('foo', 'one'), ('bar', 'two'), ('baz', 'three')]</span></span><br><span class="line"><span class="comment"># zip可以处理任意多的序列，元素的个数取决于最短的序列</span></span><br><span class="line">seq3 = [<span class="literal">False</span>, <span class="literal">True</span>]</span><br><span class="line">list(zip(seq1, seq2, seq3)) <span class="comment">#  [('foo', 'one', False), ('bar', 'two', True)]</span></span><br></pre></td></tr></table></figure>
<p><code>zip</code>可以被用来解压序列</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pitchers = [(<span class="string">'Nolan'</span>, <span class="string">'Ryan'</span>), (<span class="string">'Roger'</span>, <span class="string">'Clemens'</span>), (<span class="string">'Schilling'</span>, <span class="string">'Curt'</span>)]</span><br><span class="line">first_names, last_names = zip(*pitchers)</span><br><span class="line">first_names  <span class="comment"># ('Nolan', 'Roger', 'Schilling')</span></span><br><span class="line">last_names   <span class="comment"># ('Ryan', 'Clemens', 'Curt')</span></span><br></pre></td></tr></table></figure>
<p><code>zip</code>的常见用法之一是同时迭代多个序列，可能结合<code>enumerate</code>使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i, (a, b) <span class="keyword">in</span> enumerate(zip(seq1, seq2)):     </span><br><span class="line">    print(<span class="string">'&#123;0&#125;: &#123;1&#125;, &#123;2&#125;'</span>.format(i, a, b))</span><br><span class="line"><span class="number">0</span>: foo, one</span><br><span class="line"><span class="number">1</span>: bar, two</span><br><span class="line"><span class="number">2</span>: baz, three</span><br></pre></td></tr></table></figure>
<h5 id="reversed函数"><a href="#reversed函数" class="headerlink" title="reversed函数"></a>reversed函数</h5><p><code>reversed</code>是一个生成器（zip也是），可以从后向前迭代一个序列。注意：只有实体化（即列表或for循环）之后才能创建翻转的序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list(reversed(range(<span class="number">10</span>))) <span class="comment"># [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]</span></span><br></pre></td></tr></table></figure>
<h4 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h4><p>也称为：哈希映射或关联数组。它是键值对的大小可变集合，键和值都是Python对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 由&#123;&#125;定义</span></span><br><span class="line">d1 = &#123;<span class="string">'a'</span> : <span class="string">'some value'</span>, <span class="string">'b'</span> : [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;</span><br><span class="line"><span class="comment"># 添加</span></span><br><span class="line">d1[<span class="number">7</span>] = <span class="string">'an integer'</span></span><br><span class="line"><span class="comment"># 访问</span></span><br><span class="line">d1[<span class="string">'b'</span>]  <span class="comment"># [1,2,3,4]</span></span><br><span class="line"><span class="comment"># 检查字典中是否包含某个键</span></span><br><span class="line"><span class="string">'b'</span> <span class="keyword">in</span> d1</span><br><span class="line"><span class="comment"># 用del关键字或pop方法（返回值的同时删除键）删除值</span></span><br><span class="line"><span class="keyword">del</span> d1[<span class="string">'b'</span>]</span><br><span class="line">ret = d1.pop(<span class="string">'b'</span>)  <span class="comment"># ret: [1, 2, 3, 4]</span></span><br><span class="line"><span class="comment"># keys和values是字典的键和值的迭代器方法。虽然键值对没有顺序，这两个方法可以用相同的顺序输出键和值：</span></span><br><span class="line">list(d1.keys()) <span class="comment"># ['a', 'b', 7]</span></span><br><span class="line">list(d1.values()) <span class="comment"># ['some value', [1, 2, 3, 4], 'an integer']</span></span><br><span class="line"><span class="comment"># update方法可以将一个字典与另一个融合</span></span><br><span class="line">d1.update(&#123;<span class="string">'b'</span> : <span class="string">'foo'</span>, <span class="string">'c'</span> : <span class="number">12</span>&#125;) <span class="comment"># 键'b'对应的值会改变</span></span><br><span class="line"><span class="comment"># update方法是原地改变字典，任何传递给update的键的旧的值都会被舍弃。</span></span><br></pre></td></tr></table></figure>
<h5 id="用序列创建字典"><a href="#用序列创建字典" class="headerlink" title="用序列创建字典"></a>用序列创建字典</h5><p>将两个序列配对组合成字典</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mapping = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> zip(key_list, value_list):</span><br><span class="line">    mapping[key] = val</span><br></pre></td></tr></table></figure>
<p>字典本质上是2元元组的集合，所以dict可以接受2元元组的列表</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mapping = dict(zip(range(<span class="number">5</span>), reversed(range(<span class="number">5</span>))))</span><br></pre></td></tr></table></figure>
<h5 id="默认值"><a href="#默认值" class="headerlink" title="默认值"></a>默认值</h5><p>dict的方法get和pop可以取默认值进行返回。get默认会返回None，如果不存在键，pop会抛出一个例外。</p>
<p><code>value = some_dict.get(key, default_value)</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">words = [<span class="string">'apple'</span>, <span class="string">'bat'</span>, <span class="string">'bar'</span>, <span class="string">'atom'</span>, <span class="string">'book'</span>]</span><br><span class="line">by_letter = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    letter = word[<span class="number">0</span>]</span><br><span class="line">    by_letter.setdefault(letter, []).append(word)</span><br></pre></td></tr></table></figure>
<p><code>collections</code>模块有一个很有用的类，<code>defaultdict</code>，它可以进一步简化上面。传递类型或函数以生成每个位置的默认值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line">by_letter = defaultdict(list)</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    by_letter[word[<span class="number">0</span>]].append(word)</span><br></pre></td></tr></table></figure>
<h5 id="有效的键对类型"><a href="#有效的键对类型" class="headerlink" title="有效的键对类型"></a>有效的键对类型</h5><p>字典的值可以是任意Python对象，而键通常是不可变的标量类型（整数、浮点型、字符串）或元组（元组中的对象必须是不可变的）。这被称为<strong>“可哈希性”</strong> 。可以用<code>hash</code>函数检测一个对象是否是可哈希的（可被用作字典的键）：</p>
<h4 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h4><p>无序的不可重复的元素的集合。可看成只有键没有值的字典。可以通过set函数或使用尖括号set语句创建集合：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">set([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>]) <span class="comment"># &#123;1, 2, 3&#125;</span></span><br><span class="line">&#123;<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>&#125; <span class="comment"># &#123;1, 2, 3&#125;</span></span><br></pre></td></tr></table></figure>
<p>集合支持合并、交集、差分和对称差等数学集合运算。</p>
<h5 id="合并（union方法，或者-运算符）"><a href="#合并（union方法，或者-运算符）" class="headerlink" title="合并（union方法，或者|运算符）"></a>合并（<code>union</code>方法，或者<code>|</code>运算符）</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a.union(b) <span class="comment"># &#123;1, 2, 3, 4, 5, 6, 7, 8&#125;</span></span><br><span class="line">a | b <span class="comment"># &#123;1, 2, 3, 4, 5, 6, 7, 8&#125;</span></span><br></pre></td></tr></table></figure>
<h5 id="交集（intersection或-amp-运算符）"><a href="#交集（intersection或-amp-运算符）" class="headerlink" title="交集（intersection或&amp;运算符）"></a>交集（<code>intersection</code>或<code>&amp;</code>运算符）</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a.intersection(b) <span class="comment"># &#123;3, 4, 5&#125;</span></span><br><span class="line">a &amp; b <span class="comment"># &#123;3, 4, 5&#125;</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-980efe5d98ecc4d6.png?imageMogr2/auto-orient/strip|imageView2/2/w/695/format/webp" alt="img"></p>
<p>所有逻辑集合操作都有另外的原地实现方法，可以直接用结果替代集合的内容，对于大的集合，这么做效率更高：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line">b = &#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>&#125;</span><br><span class="line">c = a.copy()  <span class="comment"># 硬copy</span></span><br><span class="line">c |= b</span><br><span class="line">d = a.copy()</span><br><span class="line">d &amp;= b</span><br></pre></td></tr></table></figure>
<p>与字典的键类似，集合元素通常都是不可变的。要获得类似列表的元素，必须转换成元组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">my_data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">my_set = &#123;tuple(my_data)&#125;</span><br><span class="line"><span class="comment"># 直接 my_set = &#123;[1, 2, 3, 4]&#125; 会报错</span></span><br></pre></td></tr></table></figure>
<h5 id="列表，集合和字典推导式"><a href="#列表，集合和字典推导式" class="headerlink" title="列表，集合和字典推导式"></a>列表，集合和字典推导式</h5><p>该特性允许用户从一个集合过滤元素，形成列表，集合或字典，在传递参数的过程中还可以修改元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 列表推导式</span></span><br><span class="line">[expr <span class="keyword">for</span> value <span class="keyword">in</span> collection <span class="keyword">if</span> condition]</span><br><span class="line"><span class="comment"># 字典推导式</span></span><br><span class="line">dict_comp = &#123;key-expr : value-expr <span class="keyword">for</span> value <span class="keyword">in</span> collection <span class="keyword">if</span> condition&#125;</span><br><span class="line"><span class="comment"># 例子</span></span><br><span class="line">loc_mapping = &#123;val : index <span class="keyword">for</span> index, val <span class="keyword">in</span> enumerate(strings)&#125;</span><br><span class="line"><span class="comment"># 集合推导式</span></span><br><span class="line">set_comp = &#123;expr <span class="keyword">for</span> value <span class="keyword">in</span> collection <span class="keyword">if</span> condition&#125;</span><br><span class="line"><span class="comment"># map函数</span></span><br><span class="line">strings = [<span class="string">'a'</span>, <span class="string">'as'</span>, <span class="string">'bat'</span>, <span class="string">'car'</span>, <span class="string">'dove'</span>, <span class="string">'python'</span>]</span><br><span class="line">unique_lengths = &#123;len(x) <span class="keyword">for</span> x <span class="keyword">in</span> strings&#125;</span><br><span class="line">set(map(len, strings)) <span class="comment"># map 返回可迭代器，也可以list(map(len,strings))</span></span><br></pre></td></tr></table></figure>
<h5 id="嵌套列表推导式"><a href="#嵌套列表推导式" class="headerlink" title="嵌套列表推导式"></a>嵌套列表推导式</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">all_data = [[<span class="string">'John'</span>, <span class="string">'Emily'</span>, <span class="string">'Michael'</span>, <span class="string">'Mary'</span>, <span class="string">'Steven'</span>],[<span class="string">'Maria'</span>, <span class="string">'Juan'</span>, <span class="string">'Javier'</span>, <span class="string">'Natalia'</span>, <span class="string">'Pilar'</span>]]</span><br><span class="line">result = [name <span class="keyword">for</span> names <span class="keyword">in</span> all_data <span class="keyword">for</span> name <span class="keyword">in</span> names <span class="keyword">if</span> name.count(<span class="string">'e'</span>) &gt;= <span class="number">2</span>]</span><br><span class="line"><span class="comment"># 将一个整数元组的列表扁平化成了一个整数列表</span></span><br><span class="line">some_tuples = [(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>), (<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)]</span><br><span class="line">flattened = [x <span class="keyword">for</span> tup <span class="keyword">in</span> some_tuples <span class="keyword">for</span> x <span class="keyword">in</span> tup]</span><br><span class="line">[[x <span class="keyword">for</span> x <span class="keyword">in</span> tup] <span class="keyword">for</span> tup <span class="keyword">in</span> some_tuples] <span class="comment"># 这样产生一个列表</span></span><br><span class="line"><span class="comment"># for表达式的顺序是与嵌套for循环的顺序一样</span></span><br><span class="line">flattened = []</span><br><span class="line"><span class="keyword">for</span> tup <span class="keyword">in</span> some_tuples:</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> tup:</span><br><span class="line">        flattened.append(x)</span><br></pre></td></tr></table></figure>
<h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>函数是Python中最主要也是最重要的<strong>代码组织和复用手段</strong> 。如果要<strong>重复使用相同或非常类似的代码</strong>，就需要写一个函数。通过给函数起一个名字，还可以提高代码的可读性。</p>
<p>函数使用<code>def</code>关键字声明，用<code>return</code>关键字返回值：可以同时拥有多条return语句。如果到达函数末尾时没有遇到任何一条return语句，则返回None。</p>
<p>位置参数（positional）和一些关键字参数（keyword）。关键字参数通常用于指定默认值或可选参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_function</span><span class="params">(x, y, z=<span class="number">1.5</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> z &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> z * (x + y)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> z / (x + y)</span><br><span class="line"><span class="comment"># z是关键字参数</span></span><br><span class="line">my_function(<span class="number">5</span>, <span class="number">6</span>, z=<span class="number">0.7</span>)</span><br><span class="line">my_function(<span class="number">3.14</span>, <span class="number">7</span>, <span class="number">3.5</span>)</span><br><span class="line">my_function(<span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line"><span class="comment"># 关键字参数必须位于位置参数（如果有的话）之后，关键字参数顺序可以随便</span></span><br></pre></td></tr></table></figure>
<h4 id="命名空间、作用域和局部函数"><a href="#命名空间、作用域和局部函数" class="headerlink" title="命名空间、作用域和局部函数"></a>命名空间、作用域和局部函数</h4><p>函数可以访问两种不同作用域中的变量：全局（global）和局部（local）</p>
<p>Python中命名空间（namespace）用于描述变量作用域的名称。任何在函数中赋值的变量默认都被分配到局部命名空间（local namespace）中。局部命名空间是在函数被调用时创建的，函数参数会立即填入该命名空间。在函数执行完毕之后，局部命名空间就会被销毁。</p>
<h4 id="返回多个值"><a href="#返回多个值" class="headerlink" title="返回多个值"></a>返回多个值</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">()</span>:</span></span><br><span class="line">    a = <span class="number">5</span></span><br><span class="line">    b = <span class="number">6</span></span><br><span class="line">    c = <span class="number">7</span></span><br><span class="line">    <span class="keyword">return</span> a, b, c</span><br><span class="line">    <span class="comment">#return &#123;'a' : a, 'b' : b, 'c' : c&#125; #也可以返回字典</span></span><br></pre></td></tr></table></figure>
<p>该函数其实只返回了一个对象，也就是一个元组，最后该元组会被拆包到各个结果变量中。</p>
<h4 id="函数也是对象"><a href="#函数也是对象" class="headerlink" title="函数也是对象"></a>函数也是对象</h4><p>数据清洗：</p>
<p>为了得到一组能用于分析工作的格式统一的字符串，需要做很多事情：去除空白符、删除各种标点符号、正确的大写格式等。做法之一是使用内建的字符串方法和正则表达式<code>re</code>模块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 方法一</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_strings</span><span class="params">(strings)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> strings:</span><br><span class="line">        value = value.strip()</span><br><span class="line">        value = re.sub(<span class="string">'[!#?]'</span>, <span class="string">''</span>, value)</span><br><span class="line">        value = value.title()</span><br><span class="line">        result.append(value)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line">clean_strings(states)</span><br><span class="line"><span class="comment"># 方法二</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_punctuation</span><span class="params">(value)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> re.sub(<span class="string">'[!#?]'</span>, <span class="string">''</span>, value)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_strings</span><span class="params">(strings, ops)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> strings:</span><br><span class="line">        <span class="keyword">for</span> function <span class="keyword">in</span> ops:</span><br><span class="line">            value = function(value)</span><br><span class="line">        result.append(value)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">clean_ops = [str.strip, remove_punctuation, str.title]</span><br><span class="line">clean_strings(states, clean_ops)</span><br></pre></td></tr></table></figure>
<h4 id="匿名（lambda）函数"><a href="#匿名（lambda）函数" class="headerlink" title="匿名（lambda）函数"></a>匿名（lambda）函数</h4><p>Python支持一种被称为匿名函数（lambda函数，这种函数对象本身是没有提供名称<strong>name</strong>属性）。仅由单条语句组成，该语句的结果就是返回值。通过lambda关键字定义的，该关键字没有含义，仅仅表明“正在声明的是一个匿名函数”。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply_to_list</span><span class="params">(some_list, f)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [f(x) <span class="keyword">for</span> x <span class="keyword">in</span> some_list]</span><br><span class="line"></span><br><span class="line">ints = [<span class="number">4</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">apply_to_list(ints, <span class="keyword">lambda</span> x: x * <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h4 id="柯里化：部分参数应用"><a href="#柯里化：部分参数应用" class="headerlink" title="柯里化：部分参数应用"></a>柯里化：部分参数应用</h4><p>柯里化（currying）是一个计算机科学术语，是指通过“部分参数应用”（partial argument application）从现有函数派生出新函数的技术。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 有一个执行两数相加的简单函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_numbers</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x + y</span><br><span class="line"><span class="comment"># 通过这个函数，可以派生出一个新的只有一个参数的函数</span></span><br><span class="line">add_five = <span class="keyword">lambda</span> y: add_numbers(<span class="number">5</span>, y)</span><br><span class="line"><span class="comment"># add_numbers的第二个参数称为“柯里化的”（curried）</span></span><br></pre></td></tr></table></figure>
<p>本质上是定义了一个可以调用现有函数的新函数而已。内置的functools模块可以用partial函数将此过程简化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line">add_five = partial(add_numbers, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h4 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h4><p>Python可以以一种一致的方式对序列进行迭代（比如列表中的对象或文件中的行）。这是通过一种叫做迭代器协议（iterator protocol，它是一种使对象可迭代的通用方式）的方式实现的，是一个原生的使对象可迭代的方法。</p>
<p>迭代器是一种特殊对象，它可以在诸如for循环之类的上下文中向Python解释器输送对象。大部分能接受列表之类的对象的方法也都可以接受任何可迭代对象。比如min、max、sum等内置方法以及list、tuple等类型构造器。</p>
<p>生成器（generator）是构造新的可迭代对象的一种简单方式。一般的函数执行之后只会返回单个值，而生成器则是以延迟的方式返回一个值序列，即每返回一个值之后暂停，直到下一个值被请求时再继续。要创建一个生成器，只需将函数中的return替换为yeild即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squares</span><span class="params">(n=<span class="number">10</span>)</span>:</span></span><br><span class="line">    print(<span class="string">'Generating squares from 1 to &#123;0&#125;'</span>.format(n ** <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">yield</span> i ** <span class="number">2</span></span><br><span class="line">              </span><br><span class="line"><span class="comment"># 调用该生成器时，没有任何代码会被立即执行</span></span><br><span class="line">gen = squares()</span><br><span class="line"><span class="comment"># 直到从该生成器中请求元素时，它才会开始执行其代码</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> gen:</span><br><span class="line">    print(x,end=<span class="string">' '</span> )</span><br></pre></td></tr></table></figure>
<h5 id="生成器表达式（generator-expression）"><a href="#生成器表达式（generator-expression）" class="headerlink" title="生成器表达式（generator expression）"></a>生成器表达式（generator expression）</h5><p>另一种更简洁的构造生成器的方法。类似于列表、字典、集合推导式的生成器。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 其创建方式为，把列表推导式两端的方括号改成圆括号</span></span><br><span class="line">gen = (x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">100</span>))</span><br><span class="line"><span class="comment"># 等价于：</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_make_gen</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">yield</span> x ** <span class="number">2</span></span><br><span class="line">gen = _make_gen()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成器表达式也可以取代列表推导式，作为函数参数</span></span><br><span class="line">sum(x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">100</span>))</span><br><span class="line">dict((i, i **<span class="number">2</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>))</span><br></pre></td></tr></table></figure>
<h5 id="itertools模块"><a href="#itertools模块" class="headerlink" title="itertools模块"></a>itertools模块</h5><p>标准库itertools模块中有一组用于许多常见数据算法的生成器。例如，groupby可以接受任何序列和一个函数。它根据函数的返回值对序列中的<strong>连续元素进行分组</strong> 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">first_letter = <span class="keyword">lambda</span> x: x[<span class="number">0</span>]</span><br><span class="line">names = [<span class="string">'Alan'</span>, <span class="string">'Adam'</span>, <span class="string">'Wes'</span>, <span class="string">'Will'</span>, <span class="string">'Albert'</span>, <span class="string">'Steven'</span>]</span><br><span class="line"><span class="keyword">for</span> letter, names <span class="keyword">in</span> itertools.groupby(names, first_letter):</span><br><span class="line">    print(letter, list(names)) <span class="comment"># names is a generator</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-111823d8767a104d.png?imageMogr2/auto-orient/strip|imageView2/2/w/696/format/webp" alt="img"></p>
<h4 id="错误和异常处理"><a href="#错误和异常处理" class="headerlink" title="错误和异常处理"></a>错误和异常处理</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># something</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="comment"># another thing</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 只想处理ValueError，其他错误可能是合理的bug    </span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># something</span></span><br><span class="line"><span class="keyword">except</span> TypeError:</span><br><span class="line">    <span class="comment"># another thing  </span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 可以用元组包含多个异常    </span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># something</span></span><br><span class="line"><span class="keyword">except</span> (TypeError, ValueError):</span><br><span class="line">    <span class="comment"># another thing</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##  不想抑制异常，无论try部分的代码是否成功，都执行一段代码   </span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># something</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    <span class="comment"># another thing</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 例子</span></span><br><span class="line">f = open(path, <span class="string">'w'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    write_to_file(f)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">'Failed'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">'Succeeded'</span>)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure>
<h4 id="IPython的异常"><a href="#IPython的异常" class="headerlink" title="IPython的异常"></a>IPython的异常</h4><p>在%run一个脚本或一条语句时抛出异常，IPython默认会打印完整的调用栈（traceback），在栈的每个点都会有几行上下文。</p>
<p>IPython中以用魔术命令<code>%xmode</code>，从Plain（与Python标准解释器相同）到Verbose（带有函数的参数值）控制文本显示的数量。发生错误之后，（用%debug或%pdb magics）可以进入stack进行事后调试。</p>
<h3 id="文件和操作系统"><a href="#文件和操作系统" class="headerlink" title="文件和操作系统"></a>文件和操作系统</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">path = <span class="string">'examples/segismundo.txt'</span></span><br><span class="line">f = open(path)</span><br></pre></td></tr></table></figure>
<p>默认情况下，文件是以只读模式（’r’）打开的。然后，可以像处理列表那样来处理文件句柄f，比如对行进行迭代：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 还可以</span></span><br><span class="line">lines = [x.rstrip() <span class="keyword">for</span> x <span class="keyword">in</span> open(path)]</span><br></pre></td></tr></table></figure>
<p>从文件中取出的行都带有完整的行结束符（EOL）。</p>
<p>使用open创建文件对象，一定要用close关闭。关闭文件可以返回操作系统资源。</p>
<p>用with语句可以在退出代码块时，自动关闭文件，更容易地清理打开的文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> open(path) <span class="keyword">as</span> f:</span><br><span class="line">    lines = [x.rstrip() <span class="keyword">for</span> x <span class="keyword">in</span> f]</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-28274484129f0ea7.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="常用方法-read、seek、tell"><a href="#常用方法-read、seek、tell" class="headerlink" title="常用方法 read、seek、tell"></a>常用方法 read、seek、tell</h4><p>read会从文件返回字符。字符的内容是由文件的编码决定的（如UTF-8），如果是二进制模式打开的就是原始字节：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">f = open(path)</span><br><span class="line">f.read(<span class="number">10</span>) <span class="comment"># 'Sueña el r'</span></span><br><span class="line"></span><br><span class="line">f2 = open(path, <span class="string">'rb'</span>)  <span class="comment"># Binary mode</span></span><br><span class="line">f2.read(<span class="number">10</span>) <span class="comment"># b'Sue\xc3\xb1a el '</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#read模式会将文件句柄的位置提前，提前的数量是读取的字节数。tell可以给出当前的位置：</span></span><br><span class="line">f.tell() <span class="comment"># 11</span></span><br><span class="line">f2.tell() <span class="comment"># 10</span></span><br><span class="line"><span class="comment"># seek将文件位置更改为文件中的指定字节</span></span><br><span class="line">f.seek(<span class="number">3</span>) <span class="comment"># 3</span></span><br><span class="line">f.read(<span class="number">1</span>) <span class="comment"># ñ</span></span><br></pre></td></tr></table></figure>
<p>向文件写入，可以使用文件的write或writelines方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'tmp.txt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> handle:</span><br><span class="line">    handle.writelines(x <span class="keyword">for</span> x <span class="keyword">in</span> open(path) <span class="keyword">if</span> len(x) &gt; <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 创建一个无空行版文件</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-d25bd6e730afeb39.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="文件的字节和Unicode"><a href="#文件的字节和Unicode" class="headerlink" title="文件的字节和Unicode"></a>文件的字节和Unicode</h4><p>Python文件的默认操作是“文本模式”，即处理Python的字符串（即Unicode）。二进制模式需要在文件模式后加一个b。</p>
<p>UTF-8是长度可变的Unicode编码，当从文件请求一定数量的字符时，Python会从文件读取足够多（可能少至10或多至40字节）的字节进行解码。如果以“rb”模式打开文件，则读取确切的请求字节数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> open(path) <span class="keyword">as</span> f:</span><br><span class="line">    chars = f.read(<span class="number">10</span>)  <span class="comment"># 'Sueña el r'</span></span><br><span class="line"><span class="keyword">with</span> open(path, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = f.read(<span class="number">10</span>)   <span class="comment"># b'Sue\xc3\xb1a el '</span></span><br><span class="line"><span class="comment"># 可以将字节解码为str对象，但只有当每个编码的Unicode字符都完全成形时才能这么做：</span></span><br><span class="line">    data.decode(<span class="string">'utf8'</span>) <span class="comment"># 'Sueña el '</span></span><br><span class="line"><span class="comment"># 不要在二进制模式中使用seek。如果文件位置位于定义Unicode字符的字节的中间位置，读取后面会产生错误：</span></span><br></pre></td></tr></table></figure>
<h2 id="第4章-NumPy基础：数组和矢量计算"><a href="#第4章-NumPy基础：数组和矢量计算" class="headerlink" title="第4章 NumPy基础：数组和矢量计算"></a>第4章 NumPy基础：数组和矢量计算</h2><p>NumPy（Numerical Python的简称）是Python数值计算最重要的基础包。大多数提供科学计算的包都是用NumPy的数组作为构建基础。</p>
<p>NumPy可以高效处理大数组的数据。这是因为：</p>
<ul>
<li>NumPy是在一个连续的内存块中存储数据，独立于其他Python内置对象。NumPy的C语言编写的算法库可以操作内存，而不必进行类型检查或其它前期工作。比起Python的内置序列，NumPy数组使用的内存更少。</li>
<li>NumPy可以在整个数组上执行复杂的计算，而不需要Python的for循环。</li>
</ul>
<h3 id="多维数组对象ndarray"><a href="#多维数组对象ndarray" class="headerlink" title="多维数组对象ndarray"></a>多维数组对象ndarray</h3><p>ndarray是一个通用的同构数据多维容器，所有元素必须是相同类型的。</p>
<h4 id="创建ndarray"><a href="#创建ndarray" class="headerlink" title="创建ndarray"></a>创建ndarray</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用np.array函数创建。它接受一切序列型的对象（包括其他数组），然后产生一个新的含有传入数据的NumPy数组</span></span><br><span class="line">data1 = [<span class="number">6</span>, <span class="number">7.5</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">arr1 = np.array(data1)</span><br><span class="line"><span class="comment"># 嵌套序列（比如由一组等长列表组成的列表）将会被转换为一个多维数组：</span></span><br><span class="line">data2 = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]]</span><br><span class="line">arr2 = np.array(data2)</span><br><span class="line"><span class="comment"># 属性：dtype，shape，ndim</span></span><br></pre></td></tr></table></figure>
<p>zeros, ones和empty可以创建指定长度或形状的全0，全1或者一个没有任何具体值的数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.zeros(<span class="number">10</span>)</span><br><span class="line">np.zeros((<span class="number">3</span>, <span class="number">6</span>))</span><br><span class="line">np.empty((<span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p>arange是Python内置函数range的数组版</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.arange(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-78ab11f67e7077a6.png?imageMogr2/auto-orient/strip|imageView2/2/w/696/format/webp" alt="img"></p>
<p>如果没有特别指定，数据类型基本都是float64（浮点数）。</p>
<h4 id="ndarray的数据类型"><a href="#ndarray的数据类型" class="headerlink" title="ndarray的数据类型"></a>ndarray的数据类型</h4><p>dtype（数据类型）是一个特殊的对象，它含有ndarray将一块内存解释为特定数据类型所需的信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr1 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=np.float64)</span><br><span class="line">arr2 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=np.int32)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-2f2d7406a8bc076c.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-5cc31115615737b7.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>可以通过ndarray的<code>astype</code>方法将一个数组从一个dtype转换成另一个dtype</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">arr.dtype <span class="comment"># dtype('int64')</span></span><br><span class="line">float_arr = arr.astype(np.float64) <span class="comment"># 也可以写float，NumPy会将Python类型映射到等价的dtype上。也可用简洁类型代码表示dtype，f4</span></span><br><span class="line"><span class="comment"># 如果将浮点数转换成整数，则小数部分将会被截取删除</span></span><br><span class="line"><span class="comment"># 如果某字符串数组表示的全是数字，也可以用astype将其转换为数值形式</span></span><br><span class="line">numeric_strings = np.array([<span class="string">'1.25'</span>, <span class="string">'-9.6'</span>, <span class="string">'42'</span>], dtype=np.string_)</span><br><span class="line">numeric_strings.astype(float)</span><br></pre></td></tr></table></figure>
<h4 id="NumPy数组的运算"><a href="#NumPy数组的运算" class="headerlink" title="NumPy数组的运算"></a>NumPy数组的运算</h4><p>不编写循环，使用数组即可对数据执行批量运算。NumPy用户称其为<strong>矢量化（vectorization）</strong> </p>
<ul>
<li>大小相等的数组之间的任何算术运算都会将运算应用到元素级</li>
<li>数组与标量的算术运算会将标量值传播到各个元素</li>
<li>大小相同的数组之间的比较会生成布尔值数组</li>
<li>不同大小的数组之间的运算叫做<strong>广播（broadcasting）</strong> </li>
</ul>
<h4 id="基本的索引和切片"><a href="#基本的索引和切片" class="headerlink" title="基本的索引和切片"></a>基本的索引和切片</h4><h5 id="一维数组"><a href="#一维数组" class="headerlink" title="一维数组"></a>一维数组</h5><p>一维数组和列表最重要的区别在于：数组切片是原始数组的视图，即数据不会被复制，视图上的任何修改都会直接反映到源数组上。这是因为NumPy的设计目的是处理大数据，假如NumPy坚持要将数据复制会产生性能和内存问题。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 将一个标量值赋值给一个切片时，该值会自动传播（即“广播”）到整个选区</span></span><br><span class="line">arr[<span class="number">5</span>:<span class="number">8</span>] = <span class="number">12</span>  <span class="comment"># array([ 0,  1,  2,  3,  4, 12, 12, 12,  8,  9])</span></span><br><span class="line"><span class="comment"># 切片[ : ]会给数组中的所有值赋值</span></span><br><span class="line"><span class="comment"># 数组切片是原始数组的视图</span></span><br><span class="line">arr_slice = arr[<span class="number">5</span>:<span class="number">8</span>]</span><br><span class="line">arr_slice[<span class="number">1</span>] = <span class="number">12345</span> <span class="comment"># arr也会发生变化</span></span><br><span class="line"><span class="comment"># 如果想要得到ndarray切片的副本而非视图</span></span><br><span class="line">arr[<span class="number">5</span>:<span class="number">8</span>].copy()</span><br></pre></td></tr></table></figure>
<h5 id="高维度数组"><a href="#高维度数组" class="headerlink" title="高维度数组"></a>高维度数组</h5><p><strong>二维数组</strong> 中，各索引位置上的元素不是标量而是一维数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr2d = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="comment"># 对各个元素进行递归访问</span></span><br><span class="line">arr2d[<span class="number">0</span>][<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 传入一个以逗号隔开的索引列表来选取单个元素</span></span><br><span class="line">arr2d[<span class="number">0</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-0a641536f73f560e.png?imageMogr2/auto-orient/strip|imageView2/2/w/745/format/webp" alt="img"></p>
<p>在<strong>多维数组</strong> 中，如果省略了后面的索引，则返回对象会是一个维度低一点的ndarray（它含有高一级维度上的所有数据）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr3d = np.array([[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]], [[<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]])</span><br><span class="line"><span class="comment"># 标量值和数组都可以被赋值给arr3d[0]：</span></span><br><span class="line">old_values = arr3d[<span class="number">0</span>].copy()</span><br><span class="line">arr3d[<span class="number">0</span>] = <span class="number">42</span></span><br><span class="line">arr3d[<span class="number">0</span>] = old_values</span><br></pre></td></tr></table></figure>
<h5 id="切片索引"><a href="#切片索引" class="headerlink" title="切片索引"></a>切片索引</h5><p>一维ndarray的切片语法跟Python列表差不多。</p>
<p>二维ndarray的切片方式稍显不同。切片是沿着一个轴向选取元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr2d = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line">arr2d[:<span class="number">2</span>]</span><br><span class="line"><span class="comment"># array([[1, 2, 3],   # 第一个轴切片，取了前两行</span></span><br><span class="line"><span class="comment">#       [4, 5, 6]])</span></span><br><span class="line">arr2d[:<span class="number">2</span>, <span class="number">1</span>:]</span><br><span class="line"><span class="comment"># array([[2, 3],   # 第一个轴切片，再第二个轴切片</span></span><br><span class="line"><span class="comment">#       [5, 6]])</span></span><br></pre></td></tr></table></figure>
<p>这样切片只能得到相同维数的数组视图。通过将整数索引和切片混合，可以得到低维度的切片。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr2d[<span class="number">1</span>, :<span class="number">2</span>]  <span class="comment"># array([4, 5])</span></span><br><span class="line">arr2d[:<span class="number">2</span>, <span class="number">2</span>]  <span class="comment"># array([3, 6])</span></span><br></pre></td></tr></table></figure>
<p><strong>“只有冒号”表示选取整个轴</strong> </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr2d[:, :<span class="number">1</span>]</span><br><span class="line"><span class="comment"># array([[1],</span></span><br><span class="line"><span class="comment">#       [4],</span></span><br><span class="line"><span class="comment">#       [7]])</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9da32d2f4629c304.png?imageMogr2/auto-orient/strip|imageView2/2/w/867/format/webp" alt="img"></p>
<p><strong>对切片表达式的赋值操作也会被扩散到整个选区</strong></p>
<h5 id="布尔型索引"><a href="#布尔型索引" class="headerlink" title="布尔型索引"></a>布尔型索引</h5><p>布尔型数组的长度必须跟被索引的轴长度一致</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">names = np.array([<span class="string">'Bob'</span>, <span class="string">'Joe'</span>, <span class="string">'Will'</span>, <span class="string">'Bob'</span>, <span class="string">'Will'</span>, <span class="string">'Joe'</span>, <span class="string">'Joe'</span>])</span><br><span class="line">data = np.random.randn(<span class="number">7</span>, <span class="number">4</span>)</span><br><span class="line">data[names == <span class="string">'Bob'</span>]  <span class="comment"># 可以选出对名字"Bob"对应的所有行</span></span><br><span class="line"><span class="comment"># 布尔型数组可以和切片、整数（或整数序列）混合使用</span></span><br><span class="line">data[names == <span class="string">'Bob'</span>, <span class="number">2</span>:]  <span class="comment"># array([[ 0.769 ,  1.2464], [-0.5397,  0.477 ]])</span></span><br><span class="line">data[names == <span class="string">'Bob'</span>, <span class="number">3</span>]   <span class="comment"># array([ 1.2464,  0.477 ])</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可以使用不等于符号（!=），或通过~对条件进行否定</span></span><br><span class="line">data[~(names == <span class="string">'Bob'</span>)]</span><br><span class="line">data[names != <span class="string">'Bob'</span>]</span><br><span class="line"><span class="comment"># 使用&amp;（和）、|（或）之类的布尔算术运算符</span></span><br><span class="line">data[mask = (names == <span class="string">'Bob'</span>) | (names == <span class="string">'Will'</span>)]</span><br><span class="line"><span class="comment"># 通过布尔型数组设置值。例如将data中的所有负值都设置为0</span></span><br><span class="line">data[data &lt; <span class="number">0</span>] = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<ul>
<li>布尔型索引选取数组中的数据，总是创建数据的副本。</li>
<li>Python关键字and和or在布尔型数组中无效。要使用&amp;与|。</li>
<li>这类二维数据的操作也可以用pandas</li>
</ul>
<h5 id="花式索引"><a href="#花式索引" class="headerlink" title="花式索引"></a>花式索引</h5><p>花式索引（Fancy indexing）是一个NumPy术语，是指利用整数数组进行索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.empty((<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">     arr[i] = i</span><br><span class="line"><span class="comment"># 可以传入一个用于指定顺序的整数列表或ndarray，特定顺序选取行子集</span></span><br><span class="line">arr[[<span class="number">4</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">6</span>]]</span><br><span class="line"><span class="comment"># 使用负数索引将会从末尾开始选取行</span></span><br><span class="line">arr[[<span class="number">-3</span>, <span class="number">-5</span>, <span class="number">-7</span>]]</span><br></pre></td></tr></table></figure>
<ul>
<li>无论数组是多少维的，花式索引总是一维的</li>
<li>花式索引总是将数据复制到新数组中</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一次传入多个索引数组的返回是一个一维数组</span></span><br><span class="line">arr = np.arange(<span class="number">32</span>).reshape((<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line">arr[[<span class="number">1</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>]] <span class="comment"># array([ 4, 23, 29, 10])</span></span><br><span class="line"><span class="comment"># 要想的到矩阵</span></span><br><span class="line">arr[[<span class="number">1</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">2</span>]][:, [<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>]]</span><br></pre></td></tr></table></figure>
<h4 id="数组转置和轴兑换"><a href="#数组转置和轴兑换" class="headerlink" title="数组转置和轴兑换"></a>数组转置和轴兑换</h4><ul>
<li>转置是重塑的一种特殊形式，返回源数据的视图（不会进行任何复制操作）。</li>
</ul>
<p>数组不仅有transpose方法，还有一个特殊的T属性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">15</span>).reshape((<span class="number">3</span>, <span class="number">5</span>))</span><br><span class="line">arr.T</span><br><span class="line">arr.transpose()</span><br></pre></td></tr></table></figure>
<p>对于高维数组，transpose需要得到一个由轴编号组成的元组才能对这些轴进行转置.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">16</span>).reshape((<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>))</span><br><span class="line">arr.transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 第一个轴被换成了第二个，第二个轴被换成了第一个，最后一个轴不变</span></span><br><span class="line">arr.swapaxes(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># swapaxes方法，它需要接受一对轴编号</span></span><br></pre></td></tr></table></figure>
<ul>
<li>swapaxes也是返回源数据的视图（不会进行任何复制操作）</li>
</ul>
<h3 id="通用函数：快速的元素级数组函数"><a href="#通用函数：快速的元素级数组函数" class="headerlink" title="通用函数：快速的元素级数组函数"></a>通用函数：快速的元素级数组函数</h3><p>通用函数（即ufunc）是一种对ndarray中的数据执行元素级运算的函数。可以看做简单函数（接受一个或多个标量值，并产生一个或多个标量值）的<strong>矢量化包装器</strong>。</p>
<ul>
<li><p>一元（unary）ufunc,如sqrt和exp,返回一个结果数组</p>
</li>
<li><p>二元（binary）ufunc，如add或maximum接受2个数组,并返回一个结果数组</p>
</li>
<li><p>有些ufunc可以返回多个数组，例如mod（Python内置函数divmod的矢量化版本），返回浮点数数组的小数和整数部分</p>
</li>
<li><p>Ufuncs可以接受一个out可选参数，这样就能在数组原地进行操作。</p>
</li>
<li><p>```python<br>arr = array([-3.2623, -6.0915, -6.663 ,  5.3731,  3.6182,  3.45  ,  5.0077])<br>np.sqrt(arr)</p>
<h1 id="array-nan-nan-nan-2-318-1-9022-1-8574-2-2378"><a href="#array-nan-nan-nan-2-318-1-9022-1-8574-2-2378" class="headerlink" title="array([    nan,     nan,     nan,  2.318 ,  1.9022,  1.8574,  2.2378])"></a>array([    nan,     nan,     nan,  2.318 ,  1.9022,  1.8574,  2.2378])</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">![img](https:&#x2F;&#x2F;upload-images.jianshu.io&#x2F;upload_images&#x2F;7178691-1d494e73b61c7ced.png?imageMogr2&#x2F;auto-orient&#x2F;strip|imageView2&#x2F;2&#x2F;w&#x2F;1200&#x2F;format&#x2F;webp)</span><br><span class="line"></span><br><span class="line">![img](https:&#x2F;&#x2F;upload-images.jianshu.io&#x2F;upload_images&#x2F;7178691-2be79faf68ab6ff8.png?imageMogr2&#x2F;auto-orient&#x2F;strip|imageView2&#x2F;2&#x2F;w&#x2F;1200&#x2F;format&#x2F;webp)</span><br><span class="line"></span><br><span class="line">![img](https:&#x2F;&#x2F;upload-images.jianshu.io&#x2F;upload_images&#x2F;7178691-4e38d02a66481530.png?imageMogr2&#x2F;auto-orient&#x2F;strip|imageView2&#x2F;2&#x2F;w&#x2F;1200&#x2F;format&#x2F;webp)</span><br><span class="line"></span><br><span class="line">![img](https:&#x2F;&#x2F;upload-images.jianshu.io&#x2F;upload_images&#x2F;7178691-eff1e61e5464159f.png?imageMogr2&#x2F;auto-orient&#x2F;strip|imageView2&#x2F;2&#x2F;w&#x2F;1200&#x2F;format&#x2F;webp)</span><br><span class="line"></span><br><span class="line">![img](https:&#x2F;&#x2F;upload-images.jianshu.io&#x2F;upload_images&#x2F;7178691-236dba83b6a420cc.png?imageMogr2&#x2F;auto-orient&#x2F;strip|imageView2&#x2F;2&#x2F;w&#x2F;1200&#x2F;format&#x2F;webp)</span><br><span class="line"></span><br><span class="line">### 利用数组进行数据处理</span><br><span class="line"></span><br><span class="line">用数组表达式代替循环的做法，通常被称为**矢量化**。一般来说，矢量化数组运算要比等价的纯Python方式快上一两个数量级（甚至更多）。</span><br><span class="line"></span><br><span class="line">#### 将条件逻辑表述为数组运算</span><br><span class="line"></span><br><span class="line">&#96;numpy.where&#96;函数是三元表达式&#96;x if condition else y&#96;的矢量化版本</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">xarr &#x3D; np.array([1.1, 1.2, 1.3, 1.4, 1.5])</span><br><span class="line">yarr &#x3D; np.array([2.1, 2.2, 2.3, 2.4, 2.5])</span><br><span class="line">cond &#x3D; np.array([True, False, True, True, False])</span><br><span class="line"># 根据cond中的值选取xarr和yarr的值：当cond中的值为True时，选取xarr的值，否则从yarr中选取。</span><br><span class="line"># 列表推导式的写法  缺点：1, 对大数组的处理速度不是很快。2,无法用于多维数组</span><br><span class="line">result &#x3D; [(x if c else y) for x, y, c in zip(xarr, yarr, cond)]</span><br><span class="line">#</span><br><span class="line">result &#x3D; np.where(cond, xarr, yarr)</span><br><span class="line"># 第二个和第三个参数也可以是标量值</span><br><span class="line">arr &#x3D; np.random.randn(4, 4)</span><br><span class="line">np.where(arr &gt; 0, 2, -2) # set positive values to 2, negative values to -2.</span><br><span class="line"># 可以将标量和数组结合起来</span><br><span class="line">np.where(arr &gt; 0, 2, arr) # set only positive values to 2</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="数学和统计方法"><a href="#数学和统计方法" class="headerlink" title="数学和统计方法"></a>数学和统计方法</h4><p>通过数组上的一组数学函数对整个数组或某个轴向的数据进行统计计算</p>
<p>sum、mean, 标准差std等聚合计算（aggregation，通常叫做约简（reduction））既可以当做数组的实例方法调用，也可以当做顶级NumPy函数使用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.random.randn(<span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">arr.mean()</span><br><span class="line">np.mean(arr)</span><br><span class="line"><span class="comment"># mean和sum这类的函数可以接受一个axis选项参数，用于计算该轴向上的统计值，最终结果是一个低一维的数组</span></span><br><span class="line">arr.mean(axis=<span class="number">1</span>) <span class="comment"># 算行的平均值</span></span><br><span class="line">arr.sum(axis=<span class="number">0</span>) <span class="comment"># 计算每列的和</span></span><br></pre></td></tr></table></figure>
<p>其他如cumsum（累加）和cumprod（累乘）之类的方法则不聚合，而是产生一个由中间结果组成的数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>])</span><br><span class="line">arr.cumsum()  <span class="comment"># array([ 0,  1,  3,  6, 10, 15, 21, 28])</span></span><br><span class="line"><span class="comment"># 多维数组，返回同样大小的数组，每个低维的切片沿着标记轴计算部分聚类</span></span><br><span class="line">arr = np.array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">arr.cumsum(axis=<span class="number">0</span>) <span class="comment"># 列上累加</span></span><br><span class="line">arr.cumprod(axis=<span class="number">1</span>) <span class="comment"># 行上累乘</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-a6c6df3ca8e0b98e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-866fcde885b1d357.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="用于布尔型数组的方法"><a href="#用于布尔型数组的方法" class="headerlink" title="用于布尔型数组的方法"></a>用于布尔型数组的方法</h4><p>在上面这些方法中，布尔值会被强制转换为1（True）和0（False）</p>
<ul>
<li><p>sum经常被用来对布尔型数组中的True值计数：</p>
</li>
<li><p>```python<br>arr = np.random.randn(100)<br>(arr &gt; 0).sum()</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+ any用于测试数组中是否存在一个或多个True</span><br><span class="line"></span><br><span class="line">+ all则检查数组中所有值是否都是True</span><br><span class="line"></span><br><span class="line">+ any,all 用于非布尔型数组时，所有非0元素将会被当做True</span><br><span class="line"></span><br><span class="line">#### 排序</span><br><span class="line"></span><br><span class="line">多维数组可以在任何一个轴向上进行排序，只需将轴编号传给sort即可</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">arr &#x3D; np.random.randn(5, 3)</span><br><span class="line">arr.sort(1)  # 安行排序，地排序则会修改数组本身</span><br><span class="line">np.sum(arr,1) # 返回的是数组的已排序副本</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="唯一化以及其它的集合逻辑"><a href="#唯一化以及其它的集合逻辑" class="headerlink" title="唯一化以及其它的集合逻辑"></a>唯一化以及其它的集合逻辑</h4><p>NumPy提供了一些针对一维ndarray的基本集合运算。</p>
<ul>
<li>np.unique用于找出数组中的唯一值并返回已排序的结果：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">names = np.array([<span class="string">'Bob'</span>, <span class="string">'Joe'</span>, <span class="string">'Will'</span>, <span class="string">'Bob'</span>, <span class="string">'Will'</span>, <span class="string">'Joe'</span>, <span class="string">'Joe'</span>])</span><br><span class="line">np.unique(names)  <span class="comment"># array(['Bob', 'Joe', 'Will'], dtype='&lt;U4')</span></span><br><span class="line"><span class="comment"># 纯python代码也可以</span></span><br><span class="line">sorted(set(names)) <span class="comment"># ['Bob', 'Joe', 'Will']</span></span><br></pre></td></tr></table></figure>
<ul>
<li>np.in1d用于测试一个数组中的值在另一个数组中的成员资格，返回一个布尔型数组</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">values = np.array([<span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">np.in1d(values, [<span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>]) <span class="comment"># array([ True, False, False,  True,  True, False,  True], dtype=bool)</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-80e85ae6b9c89ada.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="用于数组的文件输入输出"><a href="#用于数组的文件输入输出" class="headerlink" title="用于数组的文件输入输出"></a>用于数组的文件输入输出</h3><p>NumPy的内置二进制格式，使用pandas或其它工具加载文本或表格数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 保存，default：数组以未压缩的原始二进制格式保存在扩展名为.npy的文件中，如果文件路径末尾没有扩展名.npy，则该扩展名会被自动加上。</span></span><br><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line">np.save(<span class="string">'some_array'</span>, arr)</span><br><span class="line"><span class="comment"># 读取</span></span><br><span class="line">np.load(<span class="string">'some_array.npy'</span>)</span><br><span class="line"><span class="comment"># 将多个数组保存到一个未压缩文件中，将数组以关键字参数的形式传入</span></span><br><span class="line">np.savez(<span class="string">'array_archive.npz'</span>, a=arr, b=arr)</span><br><span class="line"><span class="comment"># 加载.npz文件时，得到一个类似字典的对象</span></span><br><span class="line">arch = np.load(<span class="string">'array_archive.npz'</span>)</span><br><span class="line">arch[<span class="string">'b'</span>] <span class="comment"># array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span></span><br><span class="line"><span class="comment"># 数据压缩</span></span><br><span class="line">np.savez_compressed(<span class="string">'arrays_compressed.npz'</span>, a=arr, b=arr)</span><br></pre></td></tr></table></figure>
<h3 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h3><p>线性代数（如矩阵乘法、矩阵分解、行列式以及其他方阵数学等）是任何数组库的重要组成部分。</p>
<p>点积np.dot(a,y)或者x.dot(y)，@符用作中缀运算符，进行矩阵乘法</p>
<p><strong>numpy.linalg模块</strong> ：标准的矩阵分解运算包括求逆和行列式之类，使用行业标准线性代数库，如BLAS、LAPACK、Intel MKL（Math Kernel Library，可能有，取决于NumPy版本）等。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-dcdb66e49e5f70ea.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="伪随机数生成"><a href="#伪随机数生成" class="headerlink" title="伪随机数生成"></a>伪随机数生成</h3><p><strong>numpy.random模块</strong>:对Python内置的random进行了补充，增加了一些用于高效生成多种概率分布的样本值的函数</p>
<p>都是通过算法基于随机数生成器种子，在确定性的条件下生成的伪随机数。可以用NumPy的np.random.seed更改随机数生成种子</p>
<p>numpy.random的数据生成函数使用全局随机种子。使用numpy.random.RandomState 创建一个与其它隔离的随机数生成器,避免全局状态</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-97ba09c96dab93a2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-6ed04fae3d1178e2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="示例：随机漫步"><a href="#示例：随机漫步" class="headerlink" title="示例：随机漫步"></a>示例：随机漫步</h3><p>简单的随机漫步的例子：从0开始，步长1和－1出现的概率相等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">position = <span class="number">0</span></span><br><span class="line">walk = [position]</span><br><span class="line">steps = <span class="number">1000</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(steps):</span><br><span class="line">    step = <span class="number">1</span> <span class="keyword">if</span> random.randint(<span class="number">0</span>, <span class="number">1</span>) <span class="keyword">else</span> <span class="number">-1</span></span><br><span class="line">    position += step</span><br><span class="line">    walk.append(position)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用一个数组运算来实现</span></span><br><span class="line">nsteps = <span class="number">1000</span></span><br><span class="line">draws = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=nsteps)</span><br><span class="line">steps = np.where(draws &gt; <span class="number">0</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">walk = steps.cumsum()</span><br><span class="line">walk.min()</span><br><span class="line">walk.max()</span><br></pre></td></tr></table></figure>
<p>统计首次穿越时间，即随机漫步过程中第一次到达某个特定值的时间。假设想要知道本次随机漫步需要多久才能距离初始0点至少10步远（任一方向均可）。</p>
<p>np.abs(walk)&gt;=10可以得到一个布尔型数组，它表示的是距离是否达到或超过10，而我们想要知道的是第一个10或－10的索引。</p>
<p>可以用argmax来解决这个问题，它返回的是该布尔型数组第一个最大值的索引（True就是最大值）：<code>(np.abs(walk) &gt;= 10).argmax()</code></p>
<ul>
<li>注意，这里使用argmax并不是很高效，因为它无论如何都会对数组进行完全扫描。在本例中，只要发现了一个True，那我们就知道它是个最大值了。</li>
</ul>
<h4 id="一次模拟多个随机漫步"><a href="#一次模拟多个随机漫步" class="headerlink" title="一次模拟多个随机漫步"></a>一次模拟多个随机漫步</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 模拟5000个随机漫步过程</span></span><br><span class="line">nwalks = <span class="number">5000</span></span><br><span class="line">nsteps = <span class="number">1000</span></span><br><span class="line">draws = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=(nwalks, nsteps)) <span class="comment"># 0 or 1</span></span><br><span class="line">steps = np.where(draws &gt; <span class="number">0</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">walks = steps.cumsum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算30或－30的最小穿越时间</span></span><br><span class="line">hits30 = (np.abs(walks) &gt;= <span class="number">30</span>).any(<span class="number">1</span>)  <span class="comment"># 按照行来查询，一行中只要有一个true，则为true</span></span><br><span class="line">hits30.sum()  <span class="comment"># 5000个随机过程中，有多少个达到30，sum布尔值时，True为1</span></span><br><span class="line">crossing_times = (np.abs(walks[hits30]) &gt;= <span class="number">30</span>).argmax(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="第5章-pandas入门"><a href="#第5章-pandas入门" class="headerlink" title="第5章 pandas入门"></a>第5章 pandas入门</h2><p>pandas是专门为处理表格和混杂数据设计的，而NumPy更适合处理统一的数值数组数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> Series, DataFrame</span><br></pre></td></tr></table></figure>
<h3 id="pandas的数据结构介绍"><a href="#pandas的数据结构介绍" class="headerlink" title="pandas的数据结构介绍"></a>pandas的数据结构介绍</h3><h4 id="Series"><a href="#Series" class="headerlink" title="Series"></a>Series</h4><p>一种类似于一维数组的对象，它由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成</p>
<p>可以将Series看成是一个定长的有序字典，因为它是索引值到数据值的一个映射。它可以用在许多原本需要字典参数的函数中</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">obj = pd.Series([<span class="number">4</span>, <span class="number">7</span>, <span class="number">-5</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 可以通过Series 的values和index属性获取其数组表示形式和索引对象</span></span><br><span class="line">obj.values <span class="comment"># array([ 4,  7, -5,  3])</span></span><br><span class="line">obj.index  <span class="comment"># like range(4)  RangeIndex(start=0, stop=4, step=1)</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">obj2 = pd.Series([<span class="number">4</span>, <span class="number">7</span>, <span class="number">-5</span>, <span class="number">3</span>], index=[<span class="string">'d'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>])</span><br><span class="line"><span class="comment"># 直接通过这个字典来创建Series</span></span><br><span class="line">sdata = &#123;<span class="string">'Ohio'</span>: <span class="number">35000</span>, <span class="string">'Texas'</span>: <span class="number">71000</span>, <span class="string">'Oregon'</span>: <span class="number">16000</span>, <span class="string">'Utah'</span>: <span class="number">5000</span>&#125;</span><br><span class="line">obj3 = pd.Series(sdata)</span><br><span class="line"><span class="comment"># </span></span><br><span class="line">states = [<span class="string">'California'</span>, <span class="string">'Ohio'</span>, <span class="string">'Oregon'</span>, <span class="string">'Texas'</span>]</span><br><span class="line">obj4 = pd.Series(sdata, index=states)</span><br><span class="line"><span class="comment"># sdata中跟states索引相匹配的那3个值会被找出来并放到相应的位置上，但由于"California"所对应的sdata值找不到，所以其结果就为NaN（即“非数字”（not a number），在pandas中，它用于表示缺失或NA值）。因为‘Utah’不在states中，它被从结果中除去。</span></span><br><span class="line">pd.isnull(obj4)  <span class="comment"># pandas的isnull和notnull函数可用于检测缺失数据</span></span><br><span class="line">pd.notnull(obj4)</span><br><span class="line">obj4.isnull()   <span class="comment"># Series也有类似的实例方法</span></span><br></pre></td></tr></table></figure>
<p>Series最重要的一个功能是，它会根据运算的索引标签自动对齐数据，类似数据库的join的操作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">37</span>]: obj3 + obj4</span><br><span class="line">Out[<span class="number">37</span>]: </span><br><span class="line">California         NaN</span><br><span class="line">Ohio           <span class="number">70000.0</span></span><br><span class="line">Oregon         <span class="number">32000.0</span></span><br><span class="line">Texas         <span class="number">142000.0</span></span><br><span class="line">Utah               NaN</span><br><span class="line"><span class="comment"># Series对象本身及其索引都有一个name属性</span></span><br><span class="line">obj4.name = <span class="string">'population'</span></span><br><span class="line">obj4.index.name = <span class="string">'state'</span></span><br></pre></td></tr></table></figure>
<h4 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h4><p>一个<strong>表格型的数据结构</strong>，含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。DataFrame既有行索引也有列索引，可以看做由Series组成的字典（共用同一个索引）。DataFrame中的数据是以一个或多个二维块存放的（而不是列表、字典或别的一维数据结构）。</p>
<p>pandas中许多高级数据处理功能的关键要素，<strong>层次化索引的表格型结构</strong>  </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">data = &#123;<span class="string">'state'</span>: [<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>],</span><br><span class="line">        <span class="string">'year'</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2003</span>],</span><br><span class="line">        <span class="string">'pop'</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>, <span class="number">3.2</span>]&#125;</span><br><span class="line">frame = pd.DataFrame(data)</span><br><span class="line"><span class="comment"># 按照指定顺序进行排列</span></span><br><span class="line">pd.DataFrame(data, columns=[<span class="string">'year'</span>, <span class="string">'state'</span>, <span class="string">'pop'</span>]) </span><br><span class="line"><span class="comment"># 传入的列在数据中找不到，就会在结果中产生缺失值</span></span><br><span class="line">frame2 = pd.DataFrame(data, columns=[<span class="string">'year'</span>, <span class="string">'state'</span>, <span class="string">'pop'</span>, <span class="string">'debt'</span>],index=[<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>, <span class="string">'four'</span>,<span class="string">'five'</span>, <span class="string">'six'</span>])</span><br><span class="line"><span class="comment"># 通过类似字典标记的方式或属性的方式，可以将DataFrame的列获取为一个Series</span></span><br><span class="line">frame2[<span class="string">'state'</span>]</span><br><span class="line">frame2.year</span><br><span class="line"><span class="comment"># 行也可以通过位置或名称的方式进行获取，比如用loc属性</span></span><br><span class="line">frame2.loc[<span class="string">'three'</span>]</span><br><span class="line"><span class="comment"># 列可以通过赋值的方式进行修改</span></span><br><span class="line">frame2[<span class="string">'debt'</span>] = <span class="number">16.5</span></span><br><span class="line">frame2[<span class="string">'debt'</span>] = np.arange(<span class="number">6.</span>)</span><br><span class="line">val = pd.Series([<span class="number">-1.2</span>, <span class="number">-1.5</span>, <span class="number">-1.7</span>], index=[<span class="string">'two'</span>, <span class="string">'four'</span>, <span class="string">'five'</span>])</span><br><span class="line">frame2[<span class="string">'debt'</span>] = val</span><br><span class="line"><span class="comment"># 根据state是否为'Ohio'，添加一个新的布尔值的列</span></span><br><span class="line">frame2[<span class="string">'eastern'</span>] = frame2.state == <span class="string">'Ohio'</span></span><br><span class="line"><span class="comment"># 关键字del用于删除列</span></span><br><span class="line"><span class="keyword">del</span> frame2[<span class="string">'eastern'</span>] </span><br><span class="line"><span class="comment"># 方法</span></span><br><span class="line">frame.head() <span class="comment"># 前五行</span></span><br></pre></td></tr></table></figure>
<ul>
<li>frame2[column]适用于任何列的名，但是frame2.column只有在列名是一个合理的Python变量名时才适用。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 嵌套字典</span></span><br><span class="line">pop = &#123;<span class="string">'Nevada'</span>: &#123;<span class="number">2001</span>: <span class="number">2.4</span>, <span class="number">2002</span>: <span class="number">2.9</span>&#125;,<span class="string">'Ohio'</span>: &#123;<span class="number">2000</span>: <span class="number">1.5</span>, <span class="number">2001</span>: <span class="number">1.7</span>, <span class="number">2002</span>: <span class="number">3.6</span>&#125;&#125;</span><br><span class="line">frame3 = pd.DataFrame(pop)</span><br><span class="line"><span class="comment"># 对DataFrame进行转置（交换行和列）</span></span><br><span class="line">frame3.T</span><br><span class="line"><span class="comment"># 由Series组成的字典</span></span><br><span class="line">pdata = &#123;<span class="string">'Ohio'</span>: frame3[<span class="string">'Ohio'</span>][:<span class="number">-1</span>],<span class="string">'Nevada'</span>: frame3[<span class="string">'Nevada'</span>][:<span class="number">2</span>]&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-106835b28c0cea5a.png?imageMogr2/auto-orient/strip|imageView2/2/w/1075/format/webp" alt="img"></p>
<p>如果设置了DataFrame的index和columns的name属性，则这些信息也会被显示出来:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame3.index.name = <span class="string">'year'</span>; frame3.columns.name = <span class="string">'state'</span></span><br></pre></td></tr></table></figure>
<h4 id="索引对象"><a href="#索引对象" class="headerlink" title="索引对象"></a>索引对象</h4><h4 id="重新索引"><a href="#重新索引" class="headerlink" title="重新索引"></a>重新索引</h4><p>在对Series或DataFrame重新索引时，也可以指定一个填充值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df1.reindex(columns=df2.columns, fill_value=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="丢弃指定轴上的项"><a href="#丢弃指定轴上的项" class="headerlink" title="丢弃指定轴上的项"></a>丢弃指定轴上的项</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认删除行（index）</span></span><br><span class="line">data.drop([<span class="string">'Colorado'</span>, <span class="string">'Ohio'</span>])</span><br><span class="line"><span class="comment"># 通过传递axis=1或axis='columns'可以删除列的值</span></span><br><span class="line">data.drop(<span class="string">'two'</span>, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 就地修改对象，不会返回新的对象</span></span><br><span class="line">obj.drop(<span class="string">'c'</span>, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="索引、选取和过滤"><a href="#索引、选取和过滤" class="headerlink" title="索引、选取和过滤"></a>索引、选取和过滤</h4><p>Series：利用标签的切片运算与普通的Python切片运算不同，其末端是包含的。</p>
<p>DataFrame：默认列标签的索引</p>
<h4 id="用loc和iloc进行选取"><a href="#用loc和iloc进行选取" class="headerlink" title="用loc和iloc进行选取"></a>用loc和iloc进行选取</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先行后列</span></span><br><span class="line">data.loc[<span class="string">'Colorado'</span>, [<span class="string">'two'</span>, <span class="string">'three'</span>]] <span class="comment">#行是必须的</span></span><br><span class="line">data.iloc[<span class="number">2</span>, [<span class="number">3</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line"><span class="comment"># 切片</span></span><br><span class="line">data.loc[:<span class="string">'Utah'</span>, <span class="string">'two'</span>]</span><br><span class="line">data.iloc[:, :<span class="number">3</span>][data.three &gt; <span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-64354f2ab777bd8c.png?imageMogr2/auto-orient/strip|imageView2/2/w/929/format/webp" alt="img"></p>
<h4 id="整数索引"><a href="#整数索引" class="headerlink" title="整数索引"></a>整数索引</h4><p>loc和iloc</p>
<h4 id="算术运算和数据对齐"><a href="#算术运算和数据对齐" class="headerlink" title="算术运算和数据对齐"></a>算术运算和数据对齐</h4><p>pandas最重要的一个功能是，它可以对不同索引的对象进行算术运算。在将对象相加时，如果存在不同的索引对，则结果的索引就是该索引对的并集。</p>
<p>自动的数据对齐操作在不重叠的索引处引入了NA值。缺失值会在算术运算过程中传播</p>
<h4 id="在算术方法中填充值"><a href="#在算术方法中填充值" class="headerlink" title="在算术方法中填充值"></a>在算术方法中填充值</h4><p>两个DataFrame相加时，没有重叠的位置就会产生NA值，可以使用add方法填充一个特殊值（比如0）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df1.add(df2, fill_value=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-16857a1021f98d1f.png?imageMogr2/auto-orient/strip|imageView2/2/w/388/format/webp" alt="img"></p>
<ul>
<li>以字母r开头，它会翻转参数。</li>
</ul>
<h4 id="DataFrame和Series之间的运算"><a href="#DataFrame和Series之间的运算" class="headerlink" title="DataFrame和Series之间的运算"></a>DataFrame和Series之间的运算</h4><p>广播（broadcasting）</p>
<p>默认情况下，DataFrame和Series之间的算术运算会将Series的索引匹配到DataFrame的列，然后沿着行一直向下广播。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame = pd.DataFrame(np.arange(<span class="number">12.</span>).reshape((<span class="number">4</span>, <span class="number">3</span>)),columns=list(<span class="string">'bde'</span>),index=[<span class="string">'Utah'</span>, <span class="string">'Ohio'</span>, <span class="string">'Texas'</span>, <span class="string">'Oregon'</span>])</span><br><span class="line">series = frame.iloc[<span class="number">0</span>]</span><br><span class="line">frame - series</span><br><span class="line"><span class="string">""" output</span></span><br><span class="line"><span class="string">          b    d    e</span></span><br><span class="line"><span class="string">Utah    0.0  0.0  0.0</span></span><br><span class="line"><span class="string">Ohio    3.0  3.0  3.0</span></span><br><span class="line"><span class="string">Texas   6.0  6.0  6.0</span></span><br><span class="line"><span class="string">Oregon  9.0  9.0  9.0</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<p>如果某个索引值在DataFrame的列或Series的索引中找不到，则参与运算的两个对象就会被重新索引以形成并集。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">series2 = pd.Series(range(<span class="number">3</span>), index=[<span class="string">'b'</span>, <span class="string">'e'</span>, <span class="string">'f'</span>])</span><br><span class="line">frame + series2</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">          b   d     e   f</span></span><br><span class="line"><span class="string">Utah    0.0 NaN   3.0 NaN</span></span><br><span class="line"><span class="string">Ohio    3.0 NaN   6.0 NaN</span></span><br><span class="line"><span class="string">Texas   6.0 NaN   9.0 NaN</span></span><br><span class="line"><span class="string">Oregon  9.0 NaN  12.0 NaN</span></span><br><span class="line"><span class="string">"</span></span><br></pre></td></tr></table></figure>
<p>可以使用算术运算方法匹配行且在列上广播。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame.sub(series3, axis=<span class="string">'index'</span>) <span class="comment"># 或者 axis=0</span></span><br></pre></td></tr></table></figure>
<h4 id="函数应用和映射"><a href="#函数应用和映射" class="headerlink" title="函数应用和映射"></a>函数应用和映射</h4><p>DataFrame的apply方法可以将函数应用到由各列或行所形成的一维数组上。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame = pd.DataFrame(np.random.randn(<span class="number">4</span>, <span class="number">3</span>), columns=list(<span class="string">'bde'</span>),index=[<span class="string">'Utah'</span>, <span class="string">'Ohio'</span>, <span class="string">'Texas'</span>, <span class="string">'Oregon'</span>])</span><br><span class="line">f = <span class="keyword">lambda</span> x: x.max() - x.min()</span><br><span class="line">frame.apply(f) <span class="comment"># 每列</span></span><br><span class="line">frame.apply(f, axis=<span class="string">'columns'</span>) <span class="comment"># 每行</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> pd.Series([x.min(), x.max()], index=[<span class="string">'min'</span>, <span class="string">'max'</span>])</span><br><span class="line">frame.apply(f)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">            b         d         e</span></span><br><span class="line"><span class="string">min -0.555730  0.281746 -1.296221</span></span><br><span class="line"><span class="string">max  1.246435  1.965781  1.393406</span></span><br><span class="line"><span class="string">"</span></span><br></pre></td></tr></table></figure>
<p>DataFrame的applymap方法可以使用元素级的Python函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">format = <span class="keyword">lambda</span> x: <span class="string">'%.2f'</span> % x</span><br><span class="line">frame.applymap(format)</span><br></pre></td></tr></table></figure>
<p>Series有一个用于应用元素级函数的map方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame[<span class="string">'e'</span>].map(format)</span><br></pre></td></tr></table></figure>
<h4 id="排序和排名"><a href="#排序和排名" class="headerlink" title="排序和排名"></a>排序和排名</h4><p>DataFrame和Series中的sort_index方法对行或列索引进行排序（按字典顺序，默认升序），返回一个已排序的新对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">obj = pd.Series(range(<span class="number">4</span>), index=[<span class="string">'d'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>])</span><br><span class="line">obj.sort_index()</span><br><span class="line">frame = pd.DataFrame(np.arange(<span class="number">8</span>).reshape((<span class="number">2</span>, <span class="number">4</span>)),index=[<span class="string">'three'</span>, <span class="string">'one'</span>], columns=[<span class="string">'d'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>])</span><br><span class="line">frame.sort_index()  <span class="comment"># index</span></span><br><span class="line">frame.sort_index(axis=<span class="number">1</span>, ascending=<span class="literal">False</span>) <span class="comment"># columns</span></span><br></pre></td></tr></table></figure>
<p>若要按值对Series进行排序，可使用其sort_values方法,任何缺失值默认都会被放到Series的末尾。</p>
<p>DataFrame排序时，可以根据一个或多个列中的值进行排序。将一个或多个列的名字传递给sort_values的by选项即可达到该目的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame = pd.DataFrame(&#123;<span class="string">'b'</span>: [<span class="number">4</span>, <span class="number">7</span>, <span class="number">-3</span>, <span class="number">2</span>], <span class="string">'a'</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]&#125;)</span><br><span class="line">frame.sort_values(by=<span class="string">'b'</span>)</span><br><span class="line">frame.sort_values(by=[<span class="string">'a'</span>, <span class="string">'b'</span>])</span><br></pre></td></tr></table></figure>
<p><strong>Series和DataFrame的rank方法</strong></p>
<p>默认情况下，rank是通过“为各组分配一个平均排名”的方式破坏平级关系的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">obj = pd.Series([<span class="number">7</span>, <span class="number">-5</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">4</span>])</span><br><span class="line">obj.rank() <span class="comment"># 排名并列会平均</span></span><br><span class="line">obj.rank(method=<span class="string">'first'</span>) <span class="comment"># 排名并列会选择小的数值</span></span><br><span class="line">obj.rank(ascending=<span class="literal">False</span>, method=<span class="string">'max'</span>) <span class="comment"># 排名并列选择大的数值</span></span><br><span class="line"></span><br><span class="line">frame = pd.DataFrame(&#123;<span class="string">'b'</span>: [<span class="number">4.3</span>, <span class="number">7</span>, <span class="number">-3</span>, <span class="number">2</span>], <span class="string">'a'</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>], <span class="string">'c'</span>: [<span class="number">-2</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">-2.5</span>]&#125;) </span><br><span class="line">frame.rank(axis=<span class="string">'columns'</span>) <span class="comment"># 即axis=1， 默认axis=0</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-7edfab5b4a147581.png?imageMogr2/auto-orient/strip|imageView2/2/w/653/format/webp" alt="img"></p>
<h4 id="带有重复标签的轴索引"><a href="#带有重复标签的轴索引" class="headerlink" title="带有重复标签的轴索引"></a>带有重复标签的轴索引</h4><p>pandas函数（如reindex）都要求标签唯一，但这不是强制性的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">obj = pd.Series(range(<span class="number">5</span>), index=[<span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>])</span><br><span class="line"><span class="comment"># 检查标签是否唯一</span></span><br><span class="line">obj.index.is_unique</span><br><span class="line"><span class="comment"># 如果某个索引对应多个值，则返回一个Series</span></span><br><span class="line"><span class="comment"># 对DataFrame的行进行索引时，返回DataFrame</span></span><br></pre></td></tr></table></figure>
<h3 id="汇总和计算描述统计"><a href="#汇总和计算描述统计" class="headerlink" title="汇总和计算描述统计"></a>汇总和计算描述统计</h3><p><img src="https://upload-images.jianshu.io/upload_images/7178691-af35e3809278410e.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>有些方法（如idxmin和idxmax）返回的是间接统计（比如达到最小值或最大值的索引），另一些方法则是累计型的。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-11fa967f658ac314.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="相关系数与协方差"><a href="#相关系数与协方差" class="headerlink" title="相关系数与协方差"></a>相关系数与协方差</h4><h4 id="唯一值、值计数以及成员资格"><a href="#唯一值、值计数以及成员资格" class="headerlink" title="唯一值、值计数以及成员资格"></a>唯一值、值计数以及成员资格</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">obj = pd.Series([<span class="string">'c'</span>, <span class="string">'a'</span>, <span class="string">'d'</span>, <span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'c'</span>])</span><br><span class="line">uniques = obj.unique()</span><br><span class="line">obj.value_counts()</span><br><span class="line"><span class="comment"># isin用于判断矢量化集合的成员资格</span></span><br><span class="line">mask = obj.isin([<span class="string">'b'</span>, <span class="string">'c'</span>])</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b53c4a9d65a2db32.png?imageMogr2/auto-orient/strip|imageView2/2/w/848/format/webp" alt="img"></p>
<h2 id="第6章-数据加载、存储与文件格式"><a href="#第6章-数据加载、存储与文件格式" class="headerlink" title="第6章 数据加载、存储与文件格式"></a>第6章 数据加载、存储与文件格式</h2><h3 id="读写文本格式的数据"><a href="#读写文本格式的数据" class="headerlink" title="读写文本格式的数据"></a>读写文本格式的数据</h3><p><img src="https://upload-images.jianshu.io/upload_images/7178691-958f849e6067b19b.png?imageMogr2/auto-orient/strip|imageView2/2/w/778/format/webp" alt="img"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'examples/ex1.csv'</span>)</span><br><span class="line">pd.read_table(<span class="string">'examples/ex1.csv'</span>, sep=<span class="string">','</span>)</span><br><span class="line"><span class="comment"># 如果文件没有标题行</span></span><br><span class="line">pd.read_csv(<span class="string">'examples/ex2.csv'</span>, header=<span class="literal">None</span>)</span><br><span class="line">pd.read_csv(<span class="string">'examples/ex2.csv'</span>, names=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'message'</span>])</span><br><span class="line"><span class="comment"># 将某列设置为索引</span></span><br><span class="line">names = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'message'</span>]</span><br><span class="line">pd.read_csv(<span class="string">'examples/ex2.csv'</span>, names=names, index_col=<span class="string">'message'</span>)</span><br><span class="line"><span class="comment"># 层次化索引</span></span><br><span class="line">parsed = pd.read_csv(<span class="string">'examples/csv_mindex.csv'</span>, index_col=[<span class="string">'key1'</span>, <span class="string">'key2'</span>])</span><br><span class="line"><span class="comment"># 正则表达式作为分隔</span></span><br><span class="line">result = pd.read_table(<span class="string">'examples/ex3.txt'</span>, sep=<span class="string">'\s+'</span>)</span><br><span class="line"><span class="comment"># 用skiprows跳过文件的指定行</span></span><br><span class="line">pd.read_csv(<span class="string">'examples/ex4.csv'</span>, skiprows=[<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<p>缺失值处理是文件解析任务中的一个重要组成部分。缺失数据经常是要么没有（空字符串），要么用某个标记值表示。默认情况下，pandas会用一组经常出现的标记值进行识别，比如NA及NULL：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># na_values可以用一个列表或集合的字符串表示缺失值</span></span><br><span class="line">result = pd.read_csv(<span class="string">'examples/ex5.csv'</span>, na_values=[<span class="string">'NULL'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: !cat examples/ex5.csv</span><br><span class="line">something,a,b,c,d,message</span><br><span class="line">one,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,NA</span><br><span class="line">two,<span class="number">5</span>,<span class="number">6</span>,,<span class="number">8</span>,world</span><br><span class="line">three,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>,foo</span><br><span class="line">In [<span class="number">26</span>]: result = pd.read_csv(<span class="string">'examples/ex5.csv'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-082daf4a00ed9494.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-f2bcc0a703c7236f.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-597327ade3e94c7a.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="逐块读取文本文件"><a href="#逐块读取文本文件" class="headerlink" title="逐块读取文本文件"></a>逐块读取文本文件</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置pandas显示地更紧些</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">10</span></span><br><span class="line"><span class="comment"># 只读取几行</span></span><br><span class="line">pd.read_csv(<span class="string">'examples/ex6.csv'</span>, nrows=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 要逐块读取文件</span></span><br><span class="line">chunker = pd.read_csv(<span class="string">'ch06/ex6.csv'</span>, chunksize=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p>返回可迭代的TextParser对象</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tot = pd.Series([])</span><br><span class="line"><span class="keyword">for</span> piece <span class="keyword">in</span> chunker:</span><br><span class="line">    tot = tot.add(piece[<span class="string">'key'</span>].value_counts(), fill_value=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">tot = tot.sort_values(ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h4 id="将数据写出到文本格式"><a href="#将数据写出到文本格式" class="headerlink" title="将数据写出到文本格式"></a>将数据写出到文本格式</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data.to_csv(<span class="string">'examples/out.csv'</span>)</span><br><span class="line">data.to_csv(sys.stdout, sep=<span class="string">'|'</span>) <span class="comment"># 写出到sys.stdout，仅仅打印出文本结果</span></span><br><span class="line"><span class="comment"># 默认缺失值在输出结果中会被表示为空字符串</span></span><br><span class="line">data.to_csv(sys.stdout, na_rep=<span class="string">'NULL'</span>)</span><br><span class="line"><span class="comment"># 默认写出行和列的标签</span></span><br><span class="line">data.to_csv(sys.stdout, index=<span class="literal">False</span>, header=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 只写出一部分</span></span><br><span class="line">data.to_csv(sys.stdout, index=<span class="literal">False</span>, columns=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>])</span><br><span class="line"><span class="comment"># Series也有一个to_csv方法</span></span><br><span class="line">dates = pd.date_range(<span class="string">'1/1/2000'</span>, periods=<span class="number">7</span>)</span><br><span class="line">ts = pd.Series(np.arange(<span class="number">7</span>), index=dates)</span><br><span class="line">ts.to_csv(<span class="string">'examples/tseries.csv'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="处理分隔符格式"><a href="#处理分隔符格式" class="headerlink" title="处理分隔符格式"></a>处理分隔符格式</h4><p>手动处理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">54</span>]: !cat examples/ex7.csv</span><br><span class="line"><span class="string">"a"</span>,<span class="string">"b"</span>,<span class="string">"c"</span></span><br><span class="line"><span class="string">"1"</span>,<span class="string">"2"</span>,<span class="string">"3"</span></span><br><span class="line"><span class="string">"1"</span>,<span class="string">"2"</span>,<span class="string">"3"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接使用Python内置的csv模块</span></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line">f = open(<span class="string">'examples/ex7.csv'</span>)</span><br><span class="line">reader = csv.reader(f)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> reader:</span><br><span class="line">    print(line)</span><br><span class="line"><span class="comment"># 读取文件到一个多行的列表中</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'examples/ex7.csv'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    lines = list(csv.reader(f))</span><br><span class="line"><span class="comment"># 将这些行分为标题行和数据行    </span></span><br><span class="line">header, values = lines[<span class="number">0</span>], lines[<span class="number">1</span>:]</span><br><span class="line"><span class="comment"># 用字典构造式和zip(*values)，后者将行转置为列，创建数据列的字典</span></span><br><span class="line">data_dict = &#123;h: v <span class="keyword">for</span> h, v <span class="keyword">in</span> zip(header, zip(*values))&#125;</span><br></pre></td></tr></table></figure>
<p>CSV文件的形式有很多。只需定义csv.Dialect的一个子类即可定义出新格式（如专门的分隔符、字符串引用约定、行结束符等）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">my_dialect</span><span class="params">(csv.Dialect)</span>:</span></span><br><span class="line">    lineterminator = <span class="string">'\n'</span></span><br><span class="line">    delimiter = <span class="string">';'</span></span><br><span class="line">    quotechar = <span class="string">'"'</span></span><br><span class="line">    quoting = csv.QUOTE_MINIMAL</span><br><span class="line">reader = csv.reader(f, dialect=my_dialect)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-7a1cee622459072b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1187/format/webp" alt="img"></p>
<h4 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h4><p>通过json.loads即可将JSON字符串转换成Python形式</p>
<p>json.dumps则将Python对象转换成JSON格式</p>
<p>JSON对象转换为DataFrame：向DataFrame构造器传入一个字典的列表（就是原先的JSON对象），并选取数据字段的子集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = json.loads(obj)</span><br><span class="line">siblings = pd.DataFrame(result[<span class="string">'siblings'</span>], columns=[<span class="string">'name'</span>, <span class="string">'age'</span>])</span><br></pre></td></tr></table></figure>
<p>pandas.read_json可以自动将特别格式的JSON数据集转换为Series或DataFrame</p>
<p>将数据从pandas输出到JSON，可以使用to_json方法</p>
<h4 id="XML和HTML：Web信息收集"><a href="#XML和HTML：Web信息收集" class="headerlink" title="XML和HTML：Web信息收集"></a>XML和HTML：Web信息收集</h4><p>pandas有一个内置的功能，read_html，它可以使用lxml和Beautiful Soup自动将HTML文件中的表格解析为DataFrame对象。</p>
<h3 id="二进制数据格式"><a href="#二进制数据格式" class="headerlink" title="二进制数据格式"></a>二进制数据格式</h3><p>实现数据的高效二进制格式存储最简单的办法之一是使用Python内置的pickle序列化</p>
<p>read_pickle和to_pickle</p>
<ul>
<li>pickle仅建议用于短期存储格式。其原因是很难保证该格式永远是稳定的</li>
</ul>
<p>pandas内置支持两个二进制数据格式：HDF5和MessagePack。</p>
<p>pandas或NumPy数据的其它存储格式有：</p>
<ul>
<li>bcolz：一种可压缩的列存储二进制格式，基于Blosc压缩库。</li>
<li>Feather：一种跨语言的列存储文件格式。Feather使用了Apache Arrow的列式内存格式。</li>
</ul>
<h4 id="HDF5格式"><a href="#HDF5格式" class="headerlink" title="HDF5格式"></a>HDF5格式</h4><p>HDF5是一种存储大规模科学数组数据的非常好的文件格式。</p>
<p>HDF5可以高效地分块读写</p>
<p>可以用PyTables或h5py库直接访问HDF5文件，pandas提供了更为高级的接口</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame = pd.DataFrame(&#123;<span class="string">'a'</span>: np.random.randn(<span class="number">100</span>)&#125;)</span><br><span class="line">store[<span class="string">'obj1'</span>] = frame</span><br><span class="line">store[<span class="string">'obj1_col'</span>] = frame[<span class="string">'a'</span>]</span><br><span class="line">store = pd.HDFStore(<span class="string">'mydata.h5'</span>)</span><br><span class="line"><span class="comment"># HDFStore支持两种存储模式，'fixed'和'table'。后者通常会更慢，但是支持使用特殊语法进行查询操作：</span></span><br><span class="line">store.put(<span class="string">'obj2'</span>, frame, format=<span class="string">'table'</span>)</span><br><span class="line">store.select(<span class="string">'obj2'</span>, where=[<span class="string">'index &gt;= 10 and index &lt;= 15'</span>])</span><br><span class="line"></span><br><span class="line">frame.to_hdf(<span class="string">'mydata.h5'</span>, <span class="string">'obj3'</span>, format=<span class="string">'table'</span>)</span><br><span class="line">pd.read_hdf(<span class="string">'mydata.h5'</span>, <span class="string">'obj3'</span>, where=[<span class="string">'index &lt; 5'</span>])</span><br></pre></td></tr></table></figure>
<h4 id="读取Microsoft-Excel文件"><a href="#读取Microsoft-Excel文件" class="headerlink" title="读取Microsoft Excel文件"></a>读取Microsoft Excel文件</h4><p>pandas的ExcelFile类或pandas.read_excel函数支持读取存储在Excel 2003（或更高版本）中的表格型数据。这两个工具分别使用扩展包xlrd和openpyxl读取XLS和XLSX文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取</span></span><br><span class="line">xlsx = pd.ExcelFile(<span class="string">'examples/ex1.xlsx'</span>)</span><br><span class="line">pd.read_excel(xlsx, <span class="string">'Sheet1'</span>)</span><br><span class="line">frame = pd.read_excel(<span class="string">'examples/ex1.xlsx'</span>, <span class="string">'Sheet1'</span>)</span><br><span class="line"><span class="comment"># 写入</span></span><br><span class="line">writer = pd.ExcelWriter(<span class="string">'examples/ex2.xlsx'</span>)</span><br><span class="line">frame.to_excel(writer, <span class="string">'Sheet1'</span>)</span><br><span class="line">writer.save()</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">frame.to_excel(<span class="string">'examples/ex2.xlsx'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="Web-APIs交互"><a href="#Web-APIs交互" class="headerlink" title="Web APIs交互"></a>Web APIs交互</h3><h3 id="数据库交互"><a href="#数据库交互" class="headerlink" title="数据库交互"></a>数据库交互</h3><p>将数据从SQL加载到DataFrame的过程很简单，此外pandas还有一些能够简化该过程的函数。例如，我将使用SQLite数据库（通过Python内置的sqlite3驱动器）</p>
<p>。<a href="http://www.sqlalchemy.org/" target="_blank" rel="noopener">SQLAlchemy项目</a>是一个流行的Python SQL工具，它抽象出了SQL数据库中的许多常见差异。pandas有一个read_sql函数，可以让你轻松的从SQLAlchemy连接读取数据。</p>
<h2 id="第7章-数据清洗和准备"><a href="#第7章-数据清洗和准备" class="headerlink" title="第7章 数据清洗和准备"></a>第7章 数据清洗和准备</h2><h3 id="处理缺失数据"><a href="#处理缺失数据" class="headerlink" title="处理缺失数据"></a>处理缺失数据</h3><p>对于数值数据，pandas使用浮点值NaN（Not a Number）表示缺失数据，称其为哨兵值，可以方便的检测出来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">string_data = pd.Series([<span class="string">'aardvark'</span>, <span class="string">'artichoke'</span>, np.nan, <span class="string">'avocado'</span>])</span><br><span class="line">string_data.isnull()</span><br><span class="line">string_data[<span class="number">0</span>] = <span class="literal">None</span></span><br><span class="line">string_data.isnull()</span><br></pre></td></tr></table></figure>
<p>pandas采用了R语言中的惯用法，即将缺失值表示为NA，它表示不可用not available。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-1a0f73e5bb26ea21.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="滤除缺失数据"><a href="#滤除缺失数据" class="headerlink" title="滤除缺失数据"></a>滤除缺失数据</h4><p>通过pandas.isnull或布尔索引的手工方法，或者dropna。对于一个Series，dropna返回一个仅含非空数据和索引值的Series</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> nan <span class="keyword">as</span> NA</span><br><span class="line">data = pd.Series([<span class="number">1</span>, NA, <span class="number">3.5</span>, NA, <span class="number">7</span>]) </span><br><span class="line">data.dropna()</span><br><span class="line"><span class="comment"># 等价于</span></span><br><span class="line">data[data.notnull()]</span><br></pre></td></tr></table></figure>
<p>对于DataFrame对象，dropna默认丢弃任何含有缺失值的行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.DataFrame([[<span class="number">1.</span>, <span class="number">6.5</span>, <span class="number">3.</span>], [<span class="number">1.</span>, NA, NA], [NA, NA, NA], [NA, <span class="number">6.5</span>, <span class="number">3.</span>]])</span><br><span class="line">cleaned = data.dropna()</span><br><span class="line"><span class="comment"># 丢弃全为NA的那些行</span></span><br><span class="line">data.dropna(how=<span class="string">'all'</span>)</span><br><span class="line"><span class="comment"># 丢弃列</span></span><br><span class="line">data.dropna(axis=<span class="number">1</span>, how=<span class="string">'all'</span>)</span><br><span class="line"><span class="comment"># 滤除DataFrame行的问题涉及时间序列数据，至滤除符合条件的前两行</span></span><br><span class="line">df.dropna(thresh=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h4 id="填充缺失数据"><a href="#填充缺失数据" class="headerlink" title="填充缺失数据"></a>填充缺失数据</h4><p>fillna函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.fillna(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 实现对不同的列填充不同的值</span></span><br><span class="line">df.fillna(&#123;<span class="number">1</span>: <span class="number">0.5</span>, <span class="number">2</span>: <span class="number">0</span>&#125;)</span><br><span class="line"><span class="comment"># 对现有对象进行就地修改</span></span><br><span class="line"> _ = df.fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#对reindexing有效的那些插值方法也可用于fillna    </span></span><br><span class="line">df.fillna(method=<span class="string">'ffill'</span>)</span><br><span class="line">df.fillna(method=<span class="string">'ffill'</span>, limit=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 传入平均值</span></span><br><span class="line">data.fillna(data.mean())</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-0bf235386a64c3b5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4edd39e68f4dc530.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h3><h4 id="移除重复数据"><a href="#移除重复数据" class="headerlink" title="移除重复数据"></a>移除重复数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.DataFrame(&#123;<span class="string">'k1'</span>: [<span class="string">'one'</span>, <span class="string">'two'</span>] * <span class="number">3</span> + [<span class="string">'two'</span>],<span class="string">'k2'</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>]&#125;)</span><br><span class="line"><span class="comment"># duplicated方法返回一个布尔型Series，表示各行是否和前面出现过的行重复</span></span><br><span class="line">data.duplicated()</span><br><span class="line"><span class="comment"># drop_duplicates方法，返回一个DataFrame，重复的数组会标为False</span></span><br><span class="line">data.drop_duplicates()</span><br><span class="line"><span class="comment"># 指定部分列进行重复项判断</span></span><br><span class="line">data.drop_duplicates([<span class="string">'k1'</span>])</span><br><span class="line"><span class="comment"># duplicated和drop_duplicates默认保留的是第一个出现的值组合。传入keep='last'则保留最后一个</span></span><br><span class="line">data.drop_duplicates([<span class="string">'k1'</span>, <span class="string">'k2'</span>], keep=<span class="string">'last'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="利用函数或映射进行数据转换"><a href="#利用函数或映射进行数据转换" class="headerlink" title="利用函数或映射进行数据转换"></a>利用函数或映射进行数据转换</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.DataFrame(&#123;<span class="string">'food'</span>: [<span class="string">'bacon'</span>, <span class="string">'pulled pork'</span>, <span class="string">'bacon'</span>,</span><br><span class="line"><span class="string">'Pastrami'</span>, <span class="string">'corned beef'</span>, <span class="string">'Bacon'</span>,<span class="string">'pastrami'</span>, <span class="string">'honey ham'</span>, <span class="string">'nova lox'</span>],<span class="string">'ounces'</span>: [<span class="number">4</span>, <span class="number">3</span>, <span class="number">12</span>, <span class="number">6</span>, <span class="number">7.5</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>]&#125;)</span><br><span class="line"><span class="comment"># 添加一列表示该肉类食物来源的动物类型</span></span><br><span class="line"><span class="comment"># 编写一个不同肉类到动物的映射</span></span><br><span class="line">meat_to_animal = &#123;</span><br><span class="line">  <span class="string">'bacon'</span>: <span class="string">'pig'</span>,</span><br><span class="line">  <span class="string">'pulled pork'</span>: <span class="string">'pig'</span>,</span><br><span class="line">  <span class="string">'pastrami'</span>: <span class="string">'cow'</span>,</span><br><span class="line">  <span class="string">'corned beef'</span>: <span class="string">'cow'</span>,</span><br><span class="line">  <span class="string">'honey ham'</span>: <span class="string">'pig'</span>,</span><br><span class="line">  <span class="string">'nova lox'</span>: <span class="string">'salmon'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 先将字母转换为小写</span></span><br><span class="line">lowercased = data[<span class="string">'food'</span>].str.lower()</span><br><span class="line">data[<span class="string">'animal'</span>] = lowercased.map(meat_to_animal)</span><br><span class="line"><span class="comment"># 传入一个能够完成全部这些工作的函数：</span></span><br><span class="line">data[<span class="string">'food'</span>].map(<span class="keyword">lambda</span> x: meat_to_animal[x.lower()])</span><br></pre></td></tr></table></figure>
<h4 id="替换值"><a href="#替换值" class="headerlink" title="替换值"></a>替换值</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.Series([<span class="number">1.</span>, <span class="number">-999.</span>, <span class="number">2.</span>, <span class="number">-999.</span>, <span class="number">-1000.</span>, <span class="number">3.</span>])</span><br><span class="line">data.replace(<span class="number">-999</span>, np.nan)</span><br><span class="line"><span class="comment"># 传入多个值</span></span><br><span class="line">data.replace([<span class="number">-999</span>, <span class="number">-1000</span>], np.nan)</span><br><span class="line">data.replace([<span class="number">-999</span>, <span class="number">-1000</span>], [np.nan, <span class="number">0</span>])</span><br><span class="line"><span class="comment"># 也可以传入字典</span></span><br><span class="line">data.replace(&#123;<span class="number">-999</span>: np.nan, <span class="number">-1000</span>: <span class="number">0</span>&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li>data.replace方法与data.str.replace不同，后者做的是字符串的元素级替换</li>
</ul>
<h4 id="重命名轴索引"><a href="#重命名轴索引" class="headerlink" title="重命名轴索引"></a>重命名轴索引</h4><p>轴标签可以通过函数或映射进行转换，从而得到一个新的不同标签的对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.DataFrame(np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>, <span class="number">4</span>)), index=[<span class="string">'Ohio'</span>, <span class="string">'Colorado'</span>, <span class="string">'New York'</span>], columns=[<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'three'</span>, <span class="string">'four'</span>])</span><br><span class="line">transform = <span class="keyword">lambda</span> x: x[:<span class="number">4</span>].upper()</span><br><span class="line">data.index.map(transform)</span><br><span class="line"><span class="comment"># 对DataFrame就地修改</span></span><br><span class="line">data.index = data.index.map(transform)</span><br><span class="line"><span class="comment"># 用rename方法创建数据集的转换版（而不是修改原始数据）</span></span><br><span class="line">data.rename(index=str.title, columns=str.upper)</span><br><span class="line"><span class="comment"># rename可以结合字典型对象实现对部分轴标签的更新</span></span><br><span class="line">data.rename(index=&#123;<span class="string">'OHIO'</span>: <span class="string">'INDIANA'</span>&#125;,columns=&#123;<span class="string">'three'</span>: <span class="string">'peekaboo'</span>&#125;)</span><br><span class="line"><span class="comment"># 就地修改</span></span><br><span class="line">data.rename(index=&#123;<span class="string">'OHIO'</span>: <span class="string">'INDIANA'</span>&#125;, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="离散化和面元划分"><a href="#离散化和面元划分" class="headerlink" title="离散化和面元划分"></a>离散化和面元划分</h4><p>为了便于分析，连续数据常常被离散化或拆分为“面元”（bin）。</p>
<p>cut函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 年龄分组</span></span><br><span class="line">ages = [<span class="number">20</span>, <span class="number">22</span>, <span class="number">25</span>, <span class="number">27</span>, <span class="number">21</span>, <span class="number">23</span>, <span class="number">37</span>, <span class="number">31</span>, <span class="number">61</span>, <span class="number">45</span>, <span class="number">41</span>, <span class="number">32</span>]</span><br><span class="line">bins = [<span class="number">18</span>, <span class="number">25</span>, <span class="number">35</span>, <span class="number">60</span>, <span class="number">100</span>]</span><br><span class="line">cats = pd.cut(ages, bins)</span><br><span class="line"><span class="comment"># 返回的是一个特殊的Categorical对象</span></span><br><span class="line">cats.codes <span class="comment"># array([0, 0, 0, 1, 0, 0, 2, 1, 3, 2, 2, 1], dtype=int8)</span></span><br><span class="line">cats.categories </span><br><span class="line"><span class="string">""" IntervalIndex([(18, 25], (25, 35], (35, 60], (60, 100]]</span></span><br><span class="line"><span class="string">              closed='right',</span></span><br><span class="line"><span class="string">              dtype='interval[int64]')"""</span></span><br><span class="line"><span class="comment"># pd.value_counts(cats)是pandas.cut结果的面元计数</span></span><br><span class="line">pd.value_counts(cats)</span><br><span class="line"></span><br><span class="line">pd.cut(ages, [<span class="number">18</span>, <span class="number">26</span>, <span class="number">36</span>, <span class="number">61</span>, <span class="number">100</span>], right=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 可以通过传递一个列表或数组到labels，设置面元名称</span></span><br><span class="line">group_names = [<span class="string">'Youth'</span>, <span class="string">'YoungAdult'</span>, <span class="string">'MiddleAged'</span>, <span class="string">'Senior'</span>]</span><br><span class="line">pd.cut(ages, bins, labels=group_names)</span><br><span class="line"><span class="comment"># 向cut传入的是面元的数量</span></span><br><span class="line">data = np.random.rand(<span class="number">20</span>)</span><br><span class="line">pd.cut(data, <span class="number">4</span>, precision=<span class="number">2</span>) <span class="comment"># 选项precision=2，限定小数只有两位</span></span><br></pre></td></tr></table></figure>
<p>qcut非常类似cut，它可以根据样本分位数对数据进行面元划分。根据数据的分布情况，cut可能无法使各个面元中含有相同数量的数据点。而qcut由于使用的是样本分位数，因此可以得到大小基本相等的面元：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = np.random.randn(<span class="number">1000</span>)</span><br><span class="line">cats = pd.qcut(data, <span class="number">4</span>)</span><br><span class="line"><span class="comment"># 可以传递自定义的分位数（0到1之间的数值，包含端点）</span></span><br><span class="line">pd.qcut(data, [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.9</span>, <span class="number">1.</span>])</span><br></pre></td></tr></table></figure>
<h4 id="检测和过滤异常值"><a href="#检测和过滤异常值" class="headerlink" title="检测和过滤异常值"></a>检测和过滤异常值</h4><p>过滤或变换异常值（outlier）在很大程度上就是运用数组运算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.DataFrame(np.random.randn(<span class="number">1000</span>, <span class="number">4</span>))</span><br><span class="line">data.describe()</span><br><span class="line"><span class="comment"># 找出某列中绝对值大小超过3的值</span></span><br><span class="line">col = data[<span class="number">2</span>] <span class="comment"># 第二列</span></span><br><span class="line">col[np.abs(col) &gt; <span class="number">3</span>]</span><br><span class="line"><span class="comment"># 选出全部含有“超过3或－3的值”的行</span></span><br><span class="line">data[(np.abs(data) &gt; <span class="number">3</span>).any(<span class="number">1</span>)]</span><br><span class="line">data[np.abs(data) &gt; <span class="number">3</span>] = np.sign(data) * <span class="number">3</span></span><br><span class="line"><span class="comment"># 根据数据的值是正还是负，np.sign(data)可以生成1和-1：</span></span><br><span class="line">np.sign(data).head()</span><br></pre></td></tr></table></figure>
<h4 id="排列和随机采样"><a href="#排列和随机采样" class="headerlink" title="排列和随机采样"></a>排列和随机采样</h4><p>利用numpy.random.permutation函数可以实现对Series或DataFrame的列的排列工作（permuting，随机重排序）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.DataFrame(np.arange(<span class="number">5</span> * <span class="number">4</span>).reshape((<span class="number">5</span>, <span class="number">4</span>)))</span><br><span class="line">sampler = np.random.permutation(<span class="number">5</span>)</span><br><span class="line">df.take(sampler)</span><br><span class="line"><span class="comment"># 可以在Series和DataFrame上使用sample方法</span></span><br><span class="line">df.sample(n=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 要通过替换的方式产生样本（允许重复选择），可以传递replace=True到sample</span></span><br><span class="line">choices = pd.Series([<span class="number">5</span>, <span class="number">7</span>, <span class="number">-1</span>, <span class="number">6</span>, <span class="number">4</span>])</span><br><span class="line">draws = choices.sample(n=<span class="number">10</span>, replace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="计算指标-哑变量"><a href="#计算指标-哑变量" class="headerlink" title="计算指标/哑变量"></a>计算指标/哑变量</h4><p>另一种常用于统计建模或机器学习的转换方式是：将分类变量（categorical variable）转换为“哑变量”或“指标矩阵”。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">'key'</span>: [<span class="string">'b'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>],<span class="string">'data1'</span>: range(<span class="number">6</span>)&#125;)</span><br><span class="line"><span class="comment"># 给指标DataFrame的列加上一个前缀，以便能够跟其他数据进行合并</span></span><br><span class="line">dummies = pd.get_dummies(df[<span class="string">'key'</span>], prefix=<span class="string">'key'</span>)</span><br><span class="line">df_with_dummy = df[[<span class="string">'data1'</span>]].join(dummies)</span><br><span class="line"><span class="comment"># 如果DataFrame中的某行同属于多个分类，则事情就会有点复杂</span></span><br></pre></td></tr></table></figure>
<p>另一个例子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">12345</span>)</span><br><span class="line">values = np.random.rand(<span class="number">10</span>)</span><br><span class="line">bins = [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">1</span>]</span><br><span class="line">pd.get_dummies(pd.cut(values, bins))</span><br></pre></td></tr></table></figure>
<h3 id="字符串操作"><a href="#字符串操作" class="headerlink" title="字符串操作"></a>字符串操作</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">val = <span class="string">'a,b,  guido'</span></span><br><span class="line">pieces = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> val.split(<span class="string">','</span>)]</span><br><span class="line"><span class="string">'::'</span>.join(pieces) <span class="comment"># 等价于 first + '::' + second + '::' + third</span></span><br><span class="line"><span class="comment"># 子串定位</span></span><br><span class="line"><span class="string">'guido'</span> <span class="keyword">in</span> val</span><br><span class="line">val.index(<span class="string">','</span>) <span class="comment"># 找不到字符串，index将会引发一个异常</span></span><br><span class="line">val.find(<span class="string">':'</span>)  <span class="comment"># 找不到返回-1</span></span><br><span class="line">val.count(<span class="string">','</span>)</span><br><span class="line">val.replace(<span class="string">','</span>, <span class="string">'::'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-087fe67bf6db0701.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-d1f0d4ed3e895016.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h4><p>re模块的函数可以分为三个大类：模式匹配、替换以及拆分。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">text = <span class="string">"foo    bar\t baz  \tqux"</span></span><br><span class="line">re.split(<span class="string">'\s+'</span>, text)</span><br><span class="line"><span class="comment"># 调用re.split('\s+',text)时，正则表达式会先被编译，然后再在text上调用其split方法。</span></span><br><span class="line"><span class="comment"># 如果打算对许多字符串应用同一条正则表达式，强烈建议通过re.compile创建regex对象。这样将可以节省大量的CPU时间。</span></span><br><span class="line">regex = re.compile(<span class="string">'\s+'</span>)</span><br><span class="line">regex.split(text)</span><br><span class="line">regex.findall(text)</span><br><span class="line"><span class="comment"># findall返回字符串中所有的匹配项，search返回第一个匹配项。match只匹配字符串的首部</span></span><br><span class="line">text = <span class="string">"""Dave dave@google.com</span></span><br><span class="line"><span class="string">Steve steve@gmail.com</span></span><br><span class="line"><span class="string">Rob rob@gmail.com</span></span><br><span class="line"><span class="string">Ryan ryan@yahoo.com</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">pattern = <span class="string">r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]&#123;2,4&#125;'</span></span><br><span class="line"><span class="comment"># re.IGNORECASE makes the regex case-insensitive</span></span><br><span class="line">regex = re.compile(pattern, flags=re.IGNORECASE)</span><br><span class="line"></span><br><span class="line">regex.findall(text)</span><br><span class="line">m = regex.search(text)</span><br><span class="line"><span class="comment"># &lt;_sre.SRE_Match object; span=(5, 20), match='dave@google.com'&gt;</span></span><br><span class="line">text[m.start():m.end()]</span><br><span class="line">regex.match(text) <span class="comment"># 结果为None,只匹配出现在字符串开头的模式</span></span><br><span class="line">regex.sub(<span class="string">'REDACTED'</span>, text)</span><br><span class="line"><span class="comment"># 分段的模式</span></span><br><span class="line">pattern = <span class="string">r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]&#123;2,4&#125;)'</span></span><br><span class="line">m = regex.match(<span class="string">'wesm@bright.net'</span>)</span><br><span class="line">m.groups()</span><br><span class="line"><span class="comment"># ('wesm', 'bright', 'net')</span></span><br><span class="line">regex.findall(text) <span class="comment"># 对于带有分组功能的模式，findall返回一个元组列表</span></span><br><span class="line"><span class="comment"># sub能通过诸如\1、\2之类的特殊符号访问各匹配项中的分组</span></span><br><span class="line">regex.sub(<span class="string">r'Username: \1, Domain: \2, Suffix: \3'</span>, text)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-efbb80a793759fc0.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="pandas的矢量化字符串函数"><a href="#pandas的矢量化字符串函数" class="headerlink" title="pandas的矢量化字符串函数"></a>pandas的矢量化字符串函数</h4><p>通过data.map，所有字符串和正则表达式方法都能被应用于（传入lambda表达式或其他函数）各个值，但是如果存在NA（null）就会报错。</p>
<p>含有字符串的列有时还含有缺失数据,为了解决这个问题，Series有一些能够跳过NA值的面向数组方法，进行字符串操作。通过Series的str属性即可访问这些方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data.str.contains(<span class="string">'gmail'</span>)</span><br><span class="line">data.str.findall(pattern, flags=re.IGNORECASE)</span><br><span class="line">matches = data.str.match(pattern, flags=re.IGNORECASE)</span><br><span class="line">data.str[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-a634364ed6d5d5c5.png?imageMogr2/auto-orient/strip|imageView2/2/w/870/format/webp" alt="img"></p>
<h2 id="第8章-数据规整：聚合、合并和重塑"><a href="#第8章-数据规整：聚合、合并和重塑" class="headerlink" title="第8章 数据规整：聚合、合并和重塑"></a>第8章 数据规整：聚合、合并和重塑</h2><h3 id="层次化索引"><a href="#层次化索引" class="headerlink" title="层次化索引"></a>层次化索引</h3><p>层次化索引（hierarchical indexing）是pandas的一项重要功能，在一个轴上拥有多个（两个以上）索引级别，以低维度形式处理高维度数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.Series(np.random.randn(<span class="number">9</span>),index=[[<span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'d'</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line"><span class="comment"># 外层操作</span></span><br><span class="line">data[<span class="string">'b'</span>]</span><br><span class="line"><span class="comment"># 内层操作</span></span><br><span class="line">data.loc[:, <span class="number">2</span>]</span><br><span class="line"><span class="comment"># 通过unstack方法将这段数据重新安排到一个DataFrame中</span></span><br><span class="line">data.unstack()</span><br><span class="line">data.unstack().stack()</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">对于一个DataFrame，每条轴都可以有分层索引：</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">frame = pd.DataFrame(np.arange(<span class="number">12</span>).reshape((<span class="number">4</span>, <span class="number">3</span>)),index=[[<span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'b'</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>]],columns=[[<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Colorado'</span>],[<span class="string">'Green'</span>, <span class="string">'Red'</span>, <span class="string">'Green'</span>]])</span><br><span class="line"><span class="comment"># 各层都可以有名字</span></span><br><span class="line">frame.index.names = [<span class="string">'key1'</span>, <span class="string">'key2'</span>]</span><br><span class="line">frame.columns.names = [<span class="string">'state'</span>, <span class="string">'color'</span>]</span><br><span class="line"><span class="comment"># </span></span><br><span class="line">frame[<span class="string">'Ohio'</span>]</span><br><span class="line">frame.loc[<span class="string">'a'</span>]</span><br></pre></td></tr></table></figure>
<h4 id="重排与分级排序"><a href="#重排与分级排序" class="headerlink" title="重排与分级排序"></a>重排与分级排序</h4><p>swaplevel接受两个级别编号或名称，并返回一个互换了级别的新对象（但数据不会发生变化）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame.index.names = [<span class="string">'key1'</span>, <span class="string">'key2'</span>]</span><br><span class="line">frame.columns.names = [<span class="string">'state'</span>, <span class="string">'color'</span>]</span><br><span class="line"><span class="comment"># sort_index则根据单个级别中的值对数据进行排序</span></span><br><span class="line">frame.sort_index(level=<span class="number">1</span>)</span><br><span class="line">frame.swaplevel(<span class="number">0</span>, <span class="number">1</span>).sort_index(level=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="根据级别汇总统计"><a href="#根据级别汇总统计" class="headerlink" title="根据级别汇总统计"></a>根据级别汇总统计</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 根据行或列上的级别来进行求和</span></span><br><span class="line">frame.sum(level=<span class="string">'key2'</span>)</span><br><span class="line">frame.sum(level=<span class="string">'color'</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="使用DataFrame的列进行索引"><a href="#使用DataFrame的列进行索引" class="headerlink" title="使用DataFrame的列进行索引"></a>使用DataFrame的列进行索引</h4><p>DataFrame的set_index函数会将其一个或多个列转换为行索引，并创建一个新的DataFrame</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">frame = pd.DataFrame(&#123;<span class="string">'a'</span>: range(<span class="number">7</span>), <span class="string">'b'</span>: range(<span class="number">7</span>, <span class="number">0</span>, <span class="number">-1</span>),<span class="string">'c'</span>: [<span class="string">'one'</span>, <span class="string">'one'</span>, <span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'two'</span>, <span class="string">'two'</span>, <span class="string">'two'</span>], <span class="string">'d'</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;)</span><br><span class="line">frame2 = frame.set_index([<span class="string">'c'</span>, <span class="string">'d'</span>])</span><br><span class="line"><span class="comment"># 默认情况下，那些列会从DataFrame中移除，但也可以将其保留下来</span></span><br><span class="line">frame.set_index([<span class="string">'c'</span>, <span class="string">'d'</span>], drop=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># reset_index的功能跟set_index刚好相反，层次化索引的级别会被转移到列里面</span></span><br><span class="line">frame2.reset_index()</span><br></pre></td></tr></table></figure>
<h3 id="合并数据集"><a href="#合并数据集" class="headerlink" title="合并数据集"></a>合并数据集</h3><p>pandas对象中的数据可以通过一些方式进行合并：</p>
<ul>
<li>pandas.merge可根据一个或多个键将不同DataFrame中的行连接起来。</li>
<li>pandas.concat可以沿着一条轴将多个对象堆叠到一起。</li>
<li>实例方法combine_first可以将重复数据拼接在一起，用一个对象中的值填充另一个对象中的缺失值。</li>
</ul>
<h4 id="数据库风格的DataFrame合并"><a href="#数据库风格的DataFrame合并" class="headerlink" title="数据库风格的DataFrame合并"></a>数据库风格的DataFrame合并</h4><p>数据集的合并（merge）或连接（join）运算是通过一个或多个键将行连接起来的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df1 = pd.DataFrame(&#123;<span class="string">'key'</span>: [<span class="string">'b'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>],<span class="string">'data1'</span>: range(<span class="number">7</span>)&#125;)</span><br><span class="line">df2 = pd.DataFrame(&#123;<span class="string">'key'</span>: [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'d'</span>],<span class="string">'data2'</span>: range(<span class="number">3</span>)&#125;)</span><br><span class="line"><span class="comment"># 多对一的合并</span></span><br><span class="line"><span class="comment"># 默认情况下，merge会将重叠列的列名当做键</span></span><br><span class="line">pd.merge(df1, df2)</span><br><span class="line"><span class="comment"># 列名可以指定</span></span><br><span class="line">pd.merge(df1, df2, on=<span class="string">'key'</span>)</span><br><span class="line"><span class="comment">#如果两个对象的列名不同，也可以分别进行指定</span></span><br><span class="line">pd.merge(df3, df4, left_on=<span class="string">'lkey'</span>, right_on=<span class="string">'rkey'</span>)</span><br><span class="line"><span class="comment"># 默认情况下，merge做的是“内连接”；结果中的键是交集</span></span><br><span class="line"><span class="comment"># 他方式还有"left"、"right"以及"outer"。外连接求取的是键的并集，组合了左连接和右连接的效果</span></span><br><span class="line">pd.merge(df1, df2, how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e49b3341f4a3c90e.png?imageMogr2/auto-orient/strip|imageView2/2/w/739/format/webp" alt="img"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 多对多的合并</span></span><br><span class="line">df1 = pd.DataFrame(&#123;<span class="string">'key'</span>: [<span class="string">'b'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>], <span class="string">'data1'</span>: range(<span class="number">6</span>)&#125;)</span><br><span class="line">df2 = pd.DataFrame(&#123;<span class="string">'key'</span>: [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'d'</span>],<span class="string">'data2'</span>: range(<span class="number">5</span>)&#125;)</span><br><span class="line">pd.merge(df1, df2, on=<span class="string">'key'</span>, how=<span class="string">'left'</span>)</span><br><span class="line"><span class="comment"># 多对多连接产生的是行的笛卡尔积</span></span><br><span class="line"><span class="comment"># 由于左边的DataFrame有3个"b"行，右边的有2个，所以最终结果中就有6个"b"行。</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 根据多个键进行合并，传入一个由列名组成的列表</span></span><br><span class="line">left = pd.DataFrame(&#123;<span class="string">'key1'</span>: [<span class="string">'foo'</span>, <span class="string">'foo'</span>, <span class="string">'bar'</span>], <span class="string">'key2'</span>: [<span class="string">'one'</span>, <span class="string">'two'</span>, <span class="string">'one'</span>], <span class="string">'lval'</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]&#125;)</span><br><span class="line">right = pd.DataFrame(&#123;<span class="string">'key1'</span>: [<span class="string">'foo'</span>, <span class="string">'foo'</span>, <span class="string">'bar'</span>, <span class="string">'bar'</span>],<span class="string">'key2'</span>: [<span class="string">'one'</span>, <span class="string">'one'</span>, <span class="string">'one'</span>, <span class="string">'two'</span>],<span class="string">'rval'</span>: [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]&#125;)</span><br><span class="line">pd.merge(left, right, on=[<span class="string">'key1'</span>, <span class="string">'key2'</span>], how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure>
<p>合并运算对重复列名的处理：merge有一个更实用的suffixes选项，用于指定附加到左右两个DataFrame对象的重叠列名上的字符串</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.merge(left, right, on=<span class="string">'key1'</span>)</span><br><span class="line">pd.merge(left, right, on=<span class="string">'key1'</span>, suffixes=(<span class="string">'_left'</span>, <span class="string">'_right'</span>))</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-35ca716a4f1b8475.png?imageMogr2/auto-orient/strip|imageView2/2/w/1180/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-c86672e733ceccd9.png?imageMogr2/auto-orient/strip|imageView2/2/w/1180/format/webp" alt="img"></p>
<h4 id="索引上的合并"><a href="#索引上的合并" class="headerlink" title="索引上的合并"></a>索引上的合并</h4><p>有时候，DataFrame中的连接键位于其索引中。在这种情况下，你可以传入left_index=True或right_index=True（或两个都传）以说明索引应该被用作连接键</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">left1 = pd.DataFrame(&#123;<span class="string">'key'</span>: [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>],<span class="string">'value'</span>: range(<span class="number">6</span>)&#125;)</span><br><span class="line">right1 = pd.DataFrame(&#123;<span class="string">'group_val'</span>: [<span class="number">3.5</span>, <span class="number">7</span>]&#125;, index=[<span class="string">'a'</span>, <span class="string">'b'</span>])</span><br><span class="line">pd.merge(left1, right1, left_on=<span class="string">'key'</span>, right_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>对于层次化索引的数据，索引的合并默认是多键合并</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lefth = pd.DataFrame(&#123;<span class="string">'key1'</span>: [<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>],<span class="string">'key2'</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>], <span class="string">'data'</span>: np.arange(<span class="number">5.</span>)&#125;)</span><br><span class="line">righth = pd.DataFrame(np.arange(<span class="number">12</span>).reshape((<span class="number">6</span>, <span class="number">2</span>)),index=[[<span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>,<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>],[<span class="number">2001</span>, <span class="number">2000</span>, <span class="number">2000</span>, <span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>]],  columns=[<span class="string">'event1'</span>, <span class="string">'event2'</span>])</span><br><span class="line"><span class="comment"># 以列表的形式指明用作合并键的多个列</span></span><br><span class="line">pd.merge(lefth, righth, left_on=[<span class="string">'key1'</span>, <span class="string">'key2'</span>], right_index=<span class="literal">True</span>)</span><br><span class="line">pd.merge(lefth, righth, left_on=[<span class="string">'key1'</span>, <span class="string">'key2'</span>], right_index=<span class="literal">True</span>,how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure>
<p>DataFrame还有一个便捷的join实例方法，它能更为方便地实现按索引合并。它还可用于合并多个带有相同或相似索引的DataFrame对象，但要求没有重叠的列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 同时使用合并双方的索引</span></span><br><span class="line">pd.merge(left2, right2, how=<span class="string">'outer'</span>, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># join默认使用的是左连接，保留左边表的行索引</span></span><br><span class="line">left2.join(right2, how=<span class="string">'outer'</span>)</span><br><span class="line"><span class="comment"># 支持在调用的DataFrame的列上，连接传递的DataFrame索引</span></span><br><span class="line">left1.join(right1, on=<span class="string">'key'</span>)</span><br><span class="line"><span class="comment"># 相当于</span></span><br><span class="line">pd.merge(left1,right1, left_on=<span class="string">'key'</span>, right_index=<span class="literal">True</span>,how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="轴向连接"><a href="#轴向连接" class="headerlink" title="轴向连接"></a>轴向连接</h4><p>连接（concatenation）、绑定（binding）或堆叠（stacking）。NumPy的concatenation函数可以用NumPy数组来做</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">np.concatenate([arr, arr], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>对于pandas对象（如Series和DataFrame），还需要考虑以下这些情况：</p>
<ul>
<li>如果对象在其它轴上的索引不同，应该合并这些轴的不同元素还是只使用交集？</li>
<li>连接的数据集是否需要在结果对象中可识别？</li>
<li>连接轴中保存的数据是否需要保留？许多情况下，DataFrame默认的整数标签最好在连接时删掉。</li>
</ul>
<p>pandas的concat函数提供了一种能够解决这些问题的可靠方式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s1 = pd.Series([<span class="number">0</span>, <span class="number">1</span>], index=[<span class="string">'a'</span>, <span class="string">'b'</span>])</span><br><span class="line">s2 = pd.Series([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], index=[<span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>])</span><br><span class="line">s3 = pd.Series([<span class="number">5</span>, <span class="number">6</span>], index=[<span class="string">'f'</span>, <span class="string">'g'</span>])</span><br><span class="line">pd.concat([s1, s2, s3])</span><br><span class="line"><span class="comment"># 默认情况下，concat是在axis=0上工作的，最终产生一个新的Series。如果传入axis=1，则结果就会变成一个DataFrame（axis=1是列）</span></span><br><span class="line">s4 = pd.concat([s1, s3])</span><br><span class="line">pd.concat([s1, s4], axis=<span class="number">1</span>)</span><br><span class="line">pd.concat([s1, s4], axis=<span class="number">1</span>, join=<span class="string">'inner'</span>)</span><br><span class="line">pd.concat([s1, s4], axis=<span class="number">1</span>, join_axes=[[<span class="string">'a'</span>, <span class="string">'c'</span>, <span class="string">'b'</span>, <span class="string">'e'</span>]])</span><br><span class="line"><span class="comment"># 在连接轴上创建一个层次化索引</span></span><br><span class="line">result = pd.concat([s1, s1, s3], keys=[<span class="string">'one'</span>,<span class="string">'two'</span>, <span class="string">'three'</span>])</span><br><span class="line">pd.concat([s1, s2, s3], axis=<span class="number">1</span>, keys=[<span class="string">'one'</span>,<span class="string">'two'</span>, <span class="string">'three'</span>])</span><br><span class="line"><span class="comment"># 如果传入的不是列表而是一个字典，则字典的键就会被当做keys选项的值</span></span><br><span class="line">pd.concat(&#123;<span class="string">'level1'</span>: df1, <span class="string">'level2'</span>: df2&#125;, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 可以用names参数命名创建的轴级别</span></span><br><span class="line">pd.concat([df1, df2], axis=<span class="number">1</span>, keys=[<span class="string">'level1'</span>, <span class="string">'level2'</span>],names=[<span class="string">'upper'</span>, <span class="string">'lower'</span>])</span><br><span class="line"><span class="comment"># DataFrame的行索引不包含任何相关数据，直接合并index</span></span><br><span class="line">pd.concat([df1, df2], ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-339436563b519415.png?imageMogr2/auto-orient/strip|imageView2/2/w/1167/format/webp" alt="img"></p>
<h4 id="合并重叠数据"><a href="#合并重叠数据" class="headerlink" title="合并重叠数据"></a>合并重叠数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = pd.Series([np.nan, <span class="number">2.5</span>, np.nan, <span class="number">3.5</span>, <span class="number">4.5</span>, np.nan], index=[<span class="string">'f'</span>, <span class="string">'e'</span>, <span class="string">'d'</span>, <span class="string">'c'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>])</span><br><span class="line">b = pd.Series(np.arange(len(a), dtype=np.float64), index=[<span class="string">'f'</span>, <span class="string">'e'</span>, <span class="string">'d'</span>, <span class="string">'c'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>])</span><br></pre></td></tr></table></figure>
<h2 id="第11章-时间序列"><a href="#第11章-时间序列" class="headerlink" title="第11章 时间序列"></a>第11章 时间序列</h2><p>时间序列数据的意义取决于具体的应用场景，主要有以下几种：</p>
<ul>
<li>时间戳（timestamp），特定的时刻。</li>
<li>固定时期（period），如2007年1月或2010年全年。</li>
<li>时间间隔（interval），由起始和结束时间戳表示。时期（period）可以被看做间隔（interval）的特例。</li>
<li>实验或过程时间，每个时间点都是相对于特定起始时间的一个度量。例如，从放入烤箱时起，每秒钟饼干的直径。</li>
</ul>
<h3 id="日期和时间数据类型及工具"><a href="#日期和时间数据类型及工具" class="headerlink" title="日期和时间数据类型及工具"></a>日期和时间数据类型及工具</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="comment"># 以毫秒形式存储日期和时间</span></span><br><span class="line">now = datetime.now() <span class="comment"># datetime.datetime(2017, 9, 25, 14, 5, 52, 72973)</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line">start = datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">7</span>)</span><br><span class="line">datetime.timedelta(<span class="number">926</span>, <span class="number">56700</span>) <span class="comment"># day and second</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4af261a305a70aeb.png?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp" alt="img"></p>
<h4 id="字符串和datetime的相互转换"><a href="#字符串和datetime的相互转换" class="headerlink" title="字符串和datetime的相互转换"></a>字符串和datetime的相互转换</h4><p><code>datetime.strptime</code>是通过已知格式进行日期解析的最佳方式，但是每次都要编写格式定义。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">stamp = datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">str(stamp) <span class="comment"># '2011-01-03 00:00:00'</span></span><br><span class="line">stamp.strftime(<span class="string">'%Y-%m-%d'</span>) <span class="comment">#'2011-01-03'</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-50c751823754df58.png?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-de0181e1f6b45eaf.png?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp" alt="img"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">value = <span class="string">'2011-01-03'</span></span><br><span class="line">datetime.strptime(value, <span class="string">'%Y-%m-%d'</span>) <span class="comment"># datetime.datetime(2011, 1, 3, 0, 0)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> dateutil.parser <span class="keyword">import</span> parse</span><br><span class="line">parse(<span class="string">'2011-01-03'</span>) <span class="comment"># datetime.datetime(2011, 1, 3, 0, 0)</span></span><br><span class="line">parse(<span class="string">'Jan 31, 1997 10:45 PM'</span>)</span><br><span class="line">parse(<span class="string">'6/12/2011'</span>, dayfirst=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>一些常见的日期格式可以用dateutil这个第三方包中的parser.parse方法。</p>
<p>pandas通常是用于处理成组日期的，不管这些日期是DataFrame的轴索引还是列。to_datetime方法可以解析多种不同的日期表示形式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">datestrs = [<span class="string">'2011-07-06 12:00:00'</span>, <span class="string">'2011-08-06 00:00:00'</span>]</span><br><span class="line">pd.to_datetime(datestrs) <span class="comment"># DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00'], dtype='datetime64[ns]', freq=None)</span></span><br></pre></td></tr></table></figure>
<p>NaT（Not a Time）是pandas中时间戳数据的null值。</p>
<ul>
<li><p>注意：dateutil.parser是一个实用但不完美的工具。比如说，它会把一些原本不是日期的字符串认作是日期（比如”42”会被解析为2042年的今天）。</p>
<p>特定于当前环境（位于不同国家或使用不同语言的系统）的日期格式</p>
</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-cf0119398273e2b0.png?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp" alt="img"></p>
<h3 id="时间序列基础"><a href="#时间序列基础" class="headerlink" title="时间序列基础"></a>时间序列基础</h3><p>pandas用NumPy的datetime64数据类型以纳秒形式存储时间戳。</p>
<p>datetime对象用作index时，实际上被放在一个DatetimeIndex中，其中的各个标量值是pandas的Timestamp对象。</p>
<h4 id="索引、选取、子集构造"><a href="#索引、选取、子集构造" class="headerlink" title="索引、选取、子集构造"></a>索引、选取、子集构造</h4><p>根据标签索引选取数据时，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">stamp = ts.index[<span class="number">2</span>] </span><br><span class="line">ts[stamp]</span><br><span class="line"><span class="comment"># 下面这种格式也可以</span></span><br><span class="line">ts[<span class="string">'1/10/2011'</span>]</span><br><span class="line">ts[<span class="string">'20110110'</span>]</span><br><span class="line"><span class="comment"># 对于较长的时间序列，只需传入“年”或“年月”即可轻松选取数据的切片</span></span><br><span class="line">longer_ts = pd.Series(np.random.randn(<span class="number">1000</span>),index=pd.date_range(<span class="string">'1/1/2000'</span>, periods=<span class="number">1000</span>))</span><br><span class="line">longer_ts[<span class="string">'2001'</span>]</span><br><span class="line">longer_ts[<span class="string">'2001-05'</span>]</span><br><span class="line"><span class="comment"># 使用datetime对象进行切片</span></span><br><span class="line">ts[datetime(<span class="number">2011</span>, <span class="number">1</span>, <span class="number">7</span>):]</span><br><span class="line"><span class="comment"># 也可以用不存在于该时间序列中的时间戳对其进行切片（即范围查询）</span></span><br><span class="line">ts[<span class="string">'1/6/2011'</span>:<span class="string">'1/11/2011'</span>] <span class="comment"># 产生的是原时间序列的视图</span></span><br><span class="line">ts.truncate(after=<span class="string">'1/9/2011'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="带有重复索引的时间序列"><a href="#带有重复索引的时间序列" class="headerlink" title="带有重复索引的时间序列"></a>带有重复索引的时间序列</h4><p>多个观测数据落在同一个时间点上</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dates = pd.DatetimeIndex([<span class="string">'1/1/2000'</span>, <span class="string">'1/2/2000'</span>, <span class="string">'1/2/2000'</span>,<span class="string">'1/2/2000'</span>, <span class="string">'1/3/2000'</span>])</span><br><span class="line">dup_ts = pd.Series(np.arange(<span class="number">5</span>), index=dates)</span><br><span class="line">dup_ts.index.is_unique</span><br><span class="line"><span class="comment"># 对具有非唯一时间戳的数据进行聚合</span></span><br><span class="line">grouped = dup_ts.groupby(level=<span class="number">0</span>)</span><br><span class="line">grouped.mean()</span><br><span class="line">grouped.count()</span><br></pre></td></tr></table></figure>
<h3 id="日期的范围、频率以及移动"><a href="#日期的范围、频率以及移动" class="headerlink" title="日期的范围、频率以及移动"></a>日期的范围、频率以及移动</h3><p>pandas中的原生时间序列没有固定的频率,一般被认为是不规则的。但pandas有一整套标准时间序列频率以及用于重采样、频率推断、生成固定频率日期范围的工具。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">resampler = ts.resample(<span class="string">'D'</span>)</span><br><span class="line"><span class="comment"># 字符串“D”是每天的意思</span></span><br></pre></td></tr></table></figure>
<h4 id="生成日期范围"><a href="#生成日期范围" class="headerlink" title="生成日期范围"></a>生成日期范围</h4><p><code>pandas.date_range</code>可用于根据指定的频率生成指定长度的DatetimeIndex.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.date_range(<span class="string">'2012-04-01'</span>, <span class="string">'2012-06-01'</span>)</span><br><span class="line">pd.date_range(start=<span class="string">'2012-04-01'</span>, periods=<span class="number">20</span>)</span><br><span class="line">pd.date_range(end=<span class="string">'2012-06-01'</span>, periods=<span class="number">20</span>)</span><br><span class="line"><span class="comment"># 生成一个由每月最后一个工作日组成的日期索引</span></span><br><span class="line">pd.date_range(<span class="string">'2000-01-01'</span>, <span class="string">'2000-12-01'</span>, freq=<span class="string">'BM'</span>) <span class="comment">#"BM"频率business end of month</span></span><br></pre></td></tr></table></figure>
<p>date_range默认会保留起始和结束时间戳的时间信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.date_range(<span class="string">'2012-05-02 12:56:31'</span>, periods=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 每个日期都有12:56:31,可以关掉</span></span><br><span class="line">pd.date_range(<span class="string">'2012-05-02 12:56:31'</span>, periods=<span class="number">5</span>, normalize=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="频率和日期偏移量"><a href="#频率和日期偏移量" class="headerlink" title="频率和日期偏移量"></a>频率和日期偏移量</h4><p>pandas中的频率是由一个基础频率（base frequency）和一个乘数组成的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.tseries.offsets <span class="keyword">import</span> Hour, Minute</span><br><span class="line">hour = Hour()</span><br><span class="line">four_hours = Hour(<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 可以使用别名"H"或"4H"</span></span><br><span class="line">pd.date_range(<span class="string">'2000-01-01'</span>, <span class="string">'2000-01-03 23:59'</span>, freq=<span class="string">'4h'</span>)</span><br><span class="line"><span class="comment"># 偏移量对象都可通过加法进行连接</span></span><br><span class="line">Hour(<span class="number">2</span>) + Minute(<span class="number">30</span>) <span class="comment"># &lt;150 * Minutes&gt;</span></span><br><span class="line"><span class="comment"># 传入频率字符串</span></span><br><span class="line">pd.date_range(<span class="string">'2000-01-01'</span>, periods=<span class="number">10</span>, freq=<span class="string">'1h30min'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-c8614ddbd10793ca.png?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-8da46ba96544b071.png?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-3ca410609195edc4.png?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp" alt="img"></p>
<h4 id="WOM日期"><a href="#WOM日期" class="headerlink" title="WOM日期"></a>WOM日期</h4><p>WOM（Week Of Month）是一种非常实用的频率类，获得诸如“每月第3个星期五”之类的日期。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rng = pd.date_range(<span class="string">'2012-01-01'</span>, <span class="string">'2012-09-01'</span>, freq=<span class="string">'WOM-3FRI'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="移动（超前和滞后）数据"><a href="#移动（超前和滞后）数据" class="headerlink" title="移动（超前和滞后）数据"></a>移动（超前和滞后）数据</h4><p>移动（shifting）指的是沿着时间轴将数据前移或后移。Series和DataFrame都有shift方法用于执行单纯的前移或后移操作，<strong>保持索引不变</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts = pd.Series(np.random.randn(<span class="number">4</span>),index=pd.date_range(<span class="string">'1/1/2000'</span>, periods=<span class="number">4</span>, freq=<span class="string">'M'</span>))</span><br><span class="line"><span class="comment"># 数据位移，会在时间序列的前面或后面产生缺失数据</span></span><br><span class="line">ts.shift(<span class="number">2</span>)</span><br><span class="line">ts.shift(<span class="number">-2</span>)</span><br><span class="line"><span class="comment"># 实现对时间戳进行位移而不是对数据进行简单位移</span></span><br><span class="line">ts.shift(<span class="number">2</span>, freq=<span class="string">'M'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="通过偏移量对日期进行位移"><a href="#通过偏移量对日期进行位移" class="headerlink" title="通过偏移量对日期进行位移"></a>通过偏移量对日期进行位移</h4><p>pandas的日期偏移量还可以用在datetime或Timestamp对象上</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.tseries.offsets <span class="keyword">import</span> Day, MonthEnd</span><br><span class="line">now = datetime(<span class="number">2011</span>, <span class="number">11</span>, <span class="number">17</span>)</span><br><span class="line">now + <span class="number">3</span> * Day() <span class="comment"># Timestamp('2011-11-20 00:00:00')</span></span><br><span class="line"><span class="comment"># 使用锚点偏移量</span></span><br><span class="line">now + MonthEnd() <span class="comment"># Timestamp('2011-12-31 00:00:00')</span></span><br><span class="line"><span class="comment"># 通过锚点偏移量的rollforward和rollback方法，可明确地将日期向前或向后“滚动”</span></span><br><span class="line">offset = MonthEnd()</span><br><span class="line">offset.rollforward(now) <span class="comment"># Timestamp('2011-11-30 00:00:00')</span></span><br><span class="line">offset.rollback(now) <span class="comment"># Timestamp('2011-10-31 00:00:00')</span></span><br></pre></td></tr></table></figure>
<h3 id="时区处理"><a href="#时区处理" class="headerlink" title="时区处理"></a>时区处理</h3><h4 id="时区本地化和转换"><a href="#时区本地化和转换" class="headerlink" title="时区本地化和转换"></a>时区本地化和转换</h4><p>在Python中，时区信息来自第三方库pytz，它使Python可以使用Olson数据库（汇编了世界时区信息）。pandas包装了pytz的功能。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pytz</span><br><span class="line">pytz.common_timezones[<span class="number">-5</span>:]<span class="comment"># ['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']</span></span><br><span class="line">tz = pytz.timezone(<span class="string">'America/New_York'</span>) <span class="comment"># &lt;DstTzInfo 'America/New_York' LMT-1 day, 19:04:00 STD&gt;</span></span><br></pre></td></tr></table></figure>
<p>默认情况下，pandas中的时间序列是单纯（naive）的时区,其索引的tz字段为None。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rng = pd.date_range(<span class="string">'3/9/2012 9:30'</span>, periods=<span class="number">6</span>, freq=<span class="string">'D'</span>)</span><br><span class="line">ts = pd.Series(np.random.randn(len(rng)), index=rng)</span><br><span class="line">print(ts.index.tz) <span class="comment"># None</span></span><br><span class="line"><span class="comment"># 可以指定时区</span></span><br><span class="line">pd.date_range(<span class="string">'3/9/2012 9:30'</span>, periods=<span class="number">10</span>, freq=<span class="string">'D'</span>, tz=<span class="string">'UTC'</span>)</span><br><span class="line"><span class="comment"># 通过tz_localize方法从单纯转换到本地化</span></span><br><span class="line">ts_utc = ts.tz_localize(<span class="string">'UTC'</span>)</span><br><span class="line"><span class="comment"># 被本地化到某个特定时区，就可以用tz_convert将其转换到别的时区</span></span><br><span class="line">ts_utc.tz_convert(<span class="string">'America/New_York'</span>)</span><br><span class="line"><span class="comment"># 独立的Timestamp对象也能被从单纯型（naive）本地化为时区意识型（time zone-aware）</span></span><br><span class="line">stamp = pd.Timestamp(<span class="string">'2011-03-12 04:00'</span>)</span><br><span class="line">stamp_utc = stamp.tz_localize(<span class="string">'utc'</span>)</span><br><span class="line">stamp_utc.tz_convert(<span class="string">'America/New_York'</span>)</span><br></pre></td></tr></table></figure>
<p>如果两个时间序列的时区不同，在将它们合并到一起时，最终结果就会是UTC</p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rng = pd.date_range(<span class="string">'3/7/2012 9:30'</span>, periods=<span class="number">10</span>, freq=<span class="string">'B'</span>)</span><br><span class="line">ts = pd.Series(np.random.randn(len(rng)), index=rng)</span><br><span class="line">ts1 = ts[:<span class="number">7</span>].tz_localize(<span class="string">'Europe/London'</span>)</span><br><span class="line">ts2 = ts1[<span class="number">2</span>:].tz_convert(<span class="string">'Europe/Moscow'</span>)</span><br><span class="line">result = ts1 + ts2</span><br></pre></td></tr></table></figure>
<h3 id="时期及其算术运算"><a href="#时期及其算术运算" class="headerlink" title="时期及其算术运算"></a>时期及其算术运算</h3><p>时期（period）表示的是时间区间，比如数日、数月、数季、数年等。Period类所表示的就是这种数据类型，其构造函数需要用到一个字符串或整数，以及频率符号</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">p = pd.Period(<span class="number">2007</span>, freq=<span class="string">'A-DEC'</span>) <span class="comment">#表示的是从2007年1月1日到2007年12月31日之间的整段时间</span></span><br><span class="line"><span class="comment"># 对Period对象加上或减去一个整数即可达到根据其频率进行位移的效果</span></span><br><span class="line">p + <span class="number">5</span>  <span class="comment"># Period('2012', 'A-DEC')</span></span><br><span class="line"><span class="comment"># period_range函数可用于创建规则的时期范围</span></span><br><span class="line">rng = pd.period_range(<span class="string">'2000-01-01'</span>, <span class="string">'2000-06-30'</span>, freq=<span class="string">'M'</span>) <span class="comment"># 返回PeriodIndex对象</span></span><br><span class="line"><span class="comment"># 字符串数组，可以使用PeriodIndex类：</span></span><br><span class="line">values = [<span class="string">'2001Q3'</span>, <span class="string">'2002Q2'</span>, <span class="string">'2003Q1'</span>]</span><br><span class="line">index = pd.PeriodIndex(values, freq=<span class="string">'Q-DEC'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="时期的频率转换"><a href="#时期的频率转换" class="headerlink" title="时期的频率转换"></a>时期的频率转换</h4><p>Period和PeriodIndex对象都可以通过其asfreq方法被转换成别的频率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">p = pd.Period(<span class="string">'2007'</span>, freq=<span class="string">'A-DEC'</span>)<span class="comment"># Period('2007', 'A-DEC')</span></span><br><span class="line">p.asfreq(<span class="string">'M'</span>, how=<span class="string">'start'</span>)<span class="comment"># Period('2007-01', 'M')</span></span><br><span class="line">p.asfreq(<span class="string">'M'</span>, how=<span class="string">'end'</span>)<span class="comment">#  Period('2007-12', 'M')</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">p = pd.Period(<span class="string">'2007'</span>, freq=<span class="string">'A-JUN'</span>)</span><br><span class="line">p.asfreq(<span class="string">'M'</span>, <span class="string">'start'</span>)  <span class="comment"># Period('2006-07', 'M')</span></span><br><span class="line">p.asfreq(<span class="string">'M'</span>, <span class="string">'end'</span>) <span class="comment"># Period('2007-06', 'M')</span></span><br><span class="line"><span class="comment"># 完整的PeriodIndex或TimeSeries的频率转换方式也是如此</span></span><br><span class="line">rng = pd.period_range(<span class="string">'2006'</span>, <span class="string">'2009'</span>, freq=<span class="string">'A-DEC'</span>)</span><br><span class="line">ts = pd.Series(np.random.randn(len(rng)), index=rng)</span><br><span class="line">ts.asfreq(<span class="string">'M'</span>, how=<span class="string">'start'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-d201200d0e65676f.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="按季度计算的时期频率"><a href="#按季度计算的时期频率" class="headerlink" title="按季度计算的时期频率"></a>按季度计算的时期频率</h4><p>时期”2012Q4”根据财年末的不同会有不同的含义。pandas支持12种可能的季度型频率，即Q-JAN到Q-DEC.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 以1月结束的财年中，2012Q4是从11月到1月（将其转换为日型频率就明白了）</span></span><br><span class="line">p = pd.Period(<span class="string">'2012Q4'</span>, freq=<span class="string">'Q-JAN'</span>) <span class="comment"># Period('2012Q4', 'Q-JAN')</span></span><br><span class="line">p.asfreq(<span class="string">'D'</span>, <span class="string">'start'</span>) <span class="comment"># Period('2011-11-01', 'D')</span></span><br><span class="line">p.asfreq(<span class="string">'D'</span>, <span class="string">'end'</span>) <span class="comment"># Period('2012-01-31', 'D')</span></span><br><span class="line"><span class="comment"># 获取该季度倒数第二个工作日下午4点的时间戳</span></span><br><span class="line">p4pm = (p.asfreq(<span class="string">'B'</span>, <span class="string">'e'</span>) - <span class="number">1</span>).asfreq(<span class="string">'T'</span>, <span class="string">'s'</span>) + <span class="number">16</span> * <span class="number">60</span> <span class="comment"># Period('2012-01-30 16:00', 'T')</span></span><br><span class="line">p4pm.to_timestamp() <span class="comment"># Timestamp('2012-01-30 16:00:00')</span></span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e2e1d52c9766f6ff.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="将Timestamp转换为Period（及其反向过程）"><a href="#将Timestamp转换为Period（及其反向过程）" class="headerlink" title="将Timestamp转换为Period（及其反向过程）"></a>将Timestamp转换为Period（及其反向过程）</h4><p>to_period方法，可以将由时间戳索引的Series和DataFrame对象转换为以时期索引，要转换回时间戳，使用to_timestamp》</p>
<h4 id="通过数组创建PeriodIndex"><a href="#通过数组创建PeriodIndex" class="headerlink" title="通过数组创建PeriodIndex"></a>通过数组创建PeriodIndex</h4>]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL和MySQL</title>
    <url>/2020/09/07/SQL%E5%92%8CMySQL/</url>
    <content><![CDATA[<h1 id="结构化查询语言（SQL）"><a href="#结构化查询语言（SQL）" class="headerlink" title="结构化查询语言（SQL）"></a>结构化查询语言（SQL）</h1><p>结构化查询语言（Structured Query Language）简称 SQL，是一种数据库查询语言。用于存取数据、查询、更新和管理关系数据库系统。</p>
<a id="more"></a>
<h2 id="SQL-是一种声明性语言"><a href="#SQL-是一种声明性语言" class="headerlink" title="SQL 是一种声明性语言"></a>SQL 是一种声明性语言</h2><p>简单地说，SQL 语言声明的是结果集的属性，计算机会根据 SQL 所声明的内容来从数据库中挑选出符合声明的数据，而不是像传统编程思维去指示计算机如何操作。</p>
<h2 id="SQL-的语法并不按照语法顺序执行"><a href="#SQL-的语法并不按照语法顺序执行" class="headerlink" title="SQL 的语法并不按照语法顺序执行"></a>SQL 的语法并不按照语法顺序执行</h2><p>SQL 语句的语法顺序是：</p>
<ul>
<li>SELECT[DISTINCT]</li>
<li>FROM</li>
<li>WHERE</li>
<li>GROUP BY</li>
<li>HAVING</li>
<li>UNION</li>
<li>ORDER BY</li>
</ul>
<p>执行顺序为：</p>
<ul>
<li>FROM</li>
<li>WHERE</li>
<li>GROUP BY</li>
<li>HAVING</li>
<li>SELECT</li>
<li>DISTINCT</li>
<li>UNION</li>
<li>ORDER BY</li>
</ul>
<ol>
<li>FROM 是 SQL 语句执行的第一步，而非 SELECT 。数据库在执行 SQL 语句的第一步是将数据从硬盘加载到数据缓冲区中，以便对这些数据进行操作。</li>
<li>SELECT 是在大部分语句执行了之后才执行的，严格说是在 FROM 和 GROUP BY 之后执行的。所以不能在 WHERE 中使用在 SELECT 中设定别名字段作为判断条件。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT A.x + A.y AS z FROM A</span><br><span class="line">WHERE z &#x3D; 10 -- z 在此处不可用，因为SELECT是最后执行的语句！</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT A.x + A.y AS z FROM A </span><br><span class="line">WHERE (A.x + A.y) &#x3D; 10 -- 正确用法</span><br></pre></td></tr></table></figure>
<ol>
<li>无论在语法上还是在执行顺序上， UNION 总是排在在 ORDER BY 之前。尽管某些数据库允许 SQL 语句对子查询（subqueries）或者派生表（derived tables）进行排序，但是这并不说明这个排序在 UNION 操作过后仍保持排序后的顺序。</li>
</ol>
<blockquote>
<p>并非所有的数据库对 SQL 语句使用相同的解析方式。如 MySQL、PostgreSQL和 SQLite 中就不会按照上面第二点中所说的方式执行。</p>
</blockquote>
<h2 id="SQL-语言的核心是对表的引用（table-references）"><a href="#SQL-语言的核心是对表的引用（table-references）" class="headerlink" title="SQL 语言的核心是对表的引用（table references）"></a>SQL 语言的核心是对表的引用（table references）</h2><p>根据 SQL 标准，FROM 语句被定义为：</p>
<p><code>&lt;from clause&gt; ::= FROM &lt;table reference&gt; [ { &lt;comma&gt; &lt;table reference&gt; }... ]</code></p>
<p>FROM 语句的“输出”是一张联合表，来自于所有引用的表在某一维度上的联合。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">FROM a, b</span><br></pre></td></tr></table></figure>
<p>上面这句 FROM 语句的输出了一张联合表，联合了表 a 和表 b 。如果 a 表有三个字段， b 表有 5 个字段，那么这个“输出表”就有 8 （ =5+3）个字段。联合表里的数据是 a*b，<strong>即 a 和 b 的笛卡尔积</strong>。 a 表中的每一条数据都要跟 b 表中的每一条数据配对。如果 a 表有3 条数据， b 表有 5 条数据，那么联合表就会有 15 （ =5*3）条数据。</p>
<blockquote>
<p>从集合论（关系代数）的角度来看，一张数据库的表就是一组数据元的关系，而每个 SQL 语句会改变一种或数种关系，从而产生出新的数据元的关系（即产生新的表）</p>
</blockquote>
<h2 id="SQL-语句中的表连接"><a href="#SQL-语句中的表连接" class="headerlink" title="SQL 语句中的表连接"></a>SQL 语句中的表连接</h2><p><strong>SQL 是对表的引用， JOIN 则是一种引用表的复杂方式</strong> 。严格的说 JOIN 语句并非是 SELECT 中的一部分，而是<strong>一种特殊的表引用语句</strong>。SQL 语言标准中表的连接定义如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;table reference&gt; ::&#x3D;</span><br><span class="line">    &lt;table name&gt;</span><br><span class="line">  | &lt;derived table&gt;</span><br><span class="line">  | &lt;joined table&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">FROM a1 JOIN a2 ON a1.id = a2.id, b</span><br></pre></td></tr></table></figure>
<p> JOIN 是构建连接表的关键词，并不是 SELECT 语句的一部分。有一些数据库允许在 INSERT 、 UPDATE 、 DELETE 中使用 JOIN 。</p>
<p>使用 JOIN 语句的好处在于：</p>
<ul>
<li>安全。JOIN 和要连接的表离得非常近，这样就能避免错误。</li>
<li>更多连接的方式，JOIN 语句能去区分出来外连接和内连接等。</li>
</ul>
<h2 id="SQL-语句中不同的连接操作"><a href="#SQL-语句中不同的连接操作" class="headerlink" title="SQL 语句中不同的连接操作"></a><strong>SQL 语句中不同的连接操作</strong></h2><p>SQL 语句中，表连接的方式从根本上分为五种：</p>
<ul>
<li>EQUI JOIN</li>
<li>SEMI JOIN</li>
<li>ANTI JOIN</li>
<li>CROSS JOIN</li>
<li>DIVISION</li>
</ul>
<h3 id="EQUI-JOIN"><a href="#EQUI-JOIN" class="headerlink" title="EQUI JOIN"></a><strong>EQUI JOIN</strong></h3><p>包含两种连接方式：</p>
<ul>
<li>INNER JOIN（或者是 JOIN ）</li>
<li>OUTER JOIN（包括：LEFT 、 RIGHT、 FULL OUTER JOIN）</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- This table reference contains authors and their books.</span></span><br><span class="line"><span class="comment">-- There is one record for each book and its author.</span></span><br><span class="line"><span class="comment">-- authors without books are NOT included</span></span><br><span class="line">author JOIN book ON author.id = book.author_id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- This table reference contains authors and their books</span></span><br><span class="line"><span class="comment">-- There is one record for each book and its author.</span></span><br><span class="line"><span class="comment">-- ... OR there is an "empty" record for authors without books</span></span><br><span class="line"><span class="comment">-- ("empty" meaning that all book columns are NULL)</span></span><br><span class="line">author LEFT OUTER JOIN book ON author.id = book.author_id</span><br></pre></td></tr></table></figure>
<h3 id="SEMI-JOIN"><a href="#SEMI-JOIN" class="headerlink" title="SEMI JOIN"></a>SEMI JOIN</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Using IN</span></span><br><span class="line">FROM author WHERE author.id IN (<span class="keyword">SELECT</span> book.author_id <span class="keyword">FROM</span> book)</span><br><span class="line"><span class="comment">-- Using EXISTS</span></span><br><span class="line"><span class="keyword">FROM</span> author <span class="keyword">WHERE</span> <span class="keyword">EXISTS</span> (<span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">FROM</span> book <span class="keyword">WHERE</span> book.author_id = author.id)</span><br></pre></td></tr></table></figure>
<ul>
<li>IN比 EXISTS 的可读性更好</li>
<li>EXISTS 比IN 的表达性更好（更适合复杂的语句）</li>
<li>二者之间性能没有差异（但对于某些数据库来说性能差异会非常大）</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Find only those authors who also have books</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> first_name, last_name</span><br><span class="line"><span class="keyword">FROM</span> author <span class="keyword">JOIN</span> book <span class="keyword">ON</span> author.id = book.author_id</span><br></pre></td></tr></table></figure>
<p>这是一种很糟糕的写法，原因如下：</p>
<ul>
<li>SQL 语句性能低下：因为去重操作（ DISTINCT ）需要数据库重复从硬盘中读取数据到内存中。</li>
<li>这么写并非完全正确：尽管也许现在这么写不会出现问题，但是随着 SQL 语句变得越来越复杂，想要去重得到正确的结果就变得十分困难。</li>
</ul>
<h3 id="ANTI-JOIN"><a href="#ANTI-JOIN" class="headerlink" title="ANTI JOIN"></a><strong>ANTI JOIN</strong></h3><p>这种连接的关系跟 SEMI JOIN 刚好相反。在 IN 或者 EXISTS 前加一个 NOT 关键字就能使用这种连接。举个例子来说，我们列出书名表里没有书的作者：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Using IN</span></span><br><span class="line">FROM author WHERE author.id NOT IN (<span class="keyword">SELECT</span> book.author_id <span class="keyword">FROM</span> book)</span><br><span class="line"><span class="comment">-- Using EXISTS</span></span><br><span class="line"><span class="keyword">FROM</span> author <span class="keyword">WHERE</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> (<span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">FROM</span> book <span class="keyword">WHERE</span> book.author_id = author.id)</span><br></pre></td></tr></table></figure>
<h3 id="CROSS-JOIN"><a href="#CROSS-JOIN" class="headerlink" title="CROSS JOIN"></a><strong>CROSS JOIN</strong></h3><p>这个连接过程就是<strong>两个连接的表的乘积</strong>：即将第一张表的每一条数据分别对应第二张表的每条数据。这就是逗号在 FROM 语句中的用法。在实际的应用中，很少有地方能用到 CROSS JOIN，一旦用上，可以用这样的 SQL语句表达：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Combine every author with every book</span></span><br><span class="line">author CROSS JOIN book</span><br><span class="line"><span class="comment">-- 等同于</span></span><br><span class="line">FROM author, book</span><br></pre></td></tr></table></figure>
<h3 id="DIVISION"><a href="#DIVISION" class="headerlink" title="DIVISION"></a><strong>DIVISION</strong></h3><p>DIVISION 比较奇怪。简而言之，如果 JOIN 是一个乘法运算，那么 DIVISION 就是 JOIN 的逆过程。DIVISION 的关系很难用 SQL 表达出来。</p>
<h2 id="SQL-中的派生表"><a href="#SQL-中的派生表" class="headerlink" title="SQL 中的派生表"></a><strong>SQL 中的派生表</strong></h2><p>派生表就是在括号之中的子查询：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- A derived table</span></span><br><span class="line">FROM (<span class="keyword">SELECT</span> * <span class="keyword">FROM</span> author)</span><br><span class="line"><span class="comment">-- 我们可以给派生表定义一个相关名（即别名）</span></span><br><span class="line"><span class="comment">-- A derived table with an alias</span></span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">SELECT</span> * <span class="keyword">FROM</span> author) a</span><br></pre></td></tr></table></figure>
<p>派生表可以有效的避免由于 SQL 逻辑而产生的问题。</p>
<p>想重用一个用 SELECT 和 WHERE 语句查询出的结果：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Get authors' first and last names, and their age in days</span></span><br><span class="line"><span class="keyword">SELECT</span> first_name, last_name, age</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span> first_name, last_name, <span class="keyword">current_date</span> - date_of_birth age</span><br><span class="line">  <span class="keyword">FROM</span> author</span><br><span class="line">)</span><br><span class="line"><span class="comment">-- If the age is greater than 10000 days</span></span><br><span class="line"><span class="keyword">WHERE</span> age &gt; <span class="number">10000</span></span><br></pre></td></tr></table></figure>
<p>在有些数据库，以及 SQL ：1990 标准中，派生表被归为下一级——通用表语句（ common table experssion）。允许在一个 SELECT 语句中对派生表多次重用。上面的例子就（几乎）等价于下面的语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WITH</span> a <span class="keyword">AS</span> (</span><br><span class="line">  <span class="keyword">SELECT</span> first_name, last_name, <span class="keyword">current_date</span> - date_of_birth age</span><br><span class="line">  <span class="keyword">FROM</span> author</span><br><span class="line">)</span><br><span class="line"><span class="keyword">SELECT</span> *</span><br><span class="line"><span class="keyword">FROM</span> a</span><br><span class="line"><span class="keyword">WHERE</span> age &gt; <span class="number">10000</span></span><br></pre></td></tr></table></figure>
<h3 id="SQL-语句中-GROUP-BY"><a href="#SQL-语句中-GROUP-BY" class="headerlink" title="SQL 语句中 GROUP BY"></a><strong>SQL 语句中 GROUP BY</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> A.x, A.y, <span class="keyword">SUM</span>(A.z)</span><br><span class="line"><span class="keyword">FROM</span> A</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> A.x, A.y</span><br></pre></td></tr></table></figure>
<h3 id="SQL-语句中的-SELECT-实质上是对关系的映射"><a href="#SQL-语句中的-SELECT-实质上是对关系的映射" class="headerlink" title="SQL 语句中的 SELECT 实质上是对关系的映射"></a><strong>SQL 语句中的 SELECT 实质上是对关系的映射</strong></h3><p>SELECT 语句就像一个“投影仪”，可以将其理解成一个将源表中的数据按照一定的逻辑转换成目标表数据的函数。</p>
<p>通过 SELECT语句，可以对每一个字段进行操作，通过复杂的表达式生成所需要的数据。</p>
<p>SELECT 语句有很多特殊的规则：</p>
<ul>
<li><p>仅能够使用能通过表引用而得来的字段；</p>
</li>
<li><p>如果有 GROUP BY 语句，只能够使用 GROUP BY 语句后面的字段或者聚合函数；</p>
</li>
<li><p>当语句中没有 GROUP BY 的时候，可以使用开窗函数代替聚合函数；</p>
</li>
<li><p>当语句中没有 GROUP BY 的时候，不能同时使用聚合函数和其它函数；</p>
<blockquote>
<p>在既有聚合函数又有普通函数的 SQL 语句中，如果没有 GROUP BY 进行分组，SQL 语句默认视整张表为一个分组，当聚合函数对某一字段进行聚合统计的时候，引用的表中的每一条 record 就失去了意义，全部的数据都聚合为一个统计值，你此时对每一条 record 使用其它函数是没有意义的</p>
</blockquote>
</li>
<li><p>有一些方法可以将普通函数封装在聚合函数中</p>
</li>
</ul>
<h3 id="DISTINCT-，-UNION-，-ORDER-BY-和-OFFSET"><a href="#DISTINCT-，-UNION-，-ORDER-BY-和-OFFSET" class="headerlink" title="DISTINCT ， UNION ， ORDER BY 和 OFFSET"></a><strong>DISTINCT ， UNION ， ORDER BY 和 OFFSET</strong></h3><h4 id="集合运算（-DISTINCT-和-UNION-）"><a href="#集合运算（-DISTINCT-和-UNION-）" class="headerlink" title="集合运算（ DISTINCT 和 UNION ）"></a>集合运算（ DISTINCT 和 UNION ）</h4><p>集合运算主要操作在于集合上，事实上指的就是对表的一种操作。</p>
<ul>
<li>DISTINCT 在映射之后对数据进行去重</li>
<li>UNION 将两个子查询拼接起来并去重</li>
<li>UNION ALL 将两个子查询拼接起来但不去重</li>
<li>EXCEPT 将第二个字查询中的结果从第一个子查询中去掉</li>
<li>INTERSECT 保留两个子查询中都有的结果并去重</li>
</ul>
<h4 id="排序运算（-ORDER-BY，OFFSET…FETCH）"><a href="#排序运算（-ORDER-BY，OFFSET…FETCH）" class="headerlink" title="排序运算（ ORDER BY，OFFSET…FETCH）"></a>排序运算（ ORDER BY，OFFSET…FETCH）</h4><p>排序运算跟逻辑关系无关。这是一个 SQL 特有的功能。排序运算不仅在 SQL 语句的最后，而且在 SQL 语句运行的过程中也是最后执行的。使用 ORDER BY 和 OFFSET…FETCH 是保证数据能够按照顺序排列的最有效的方式。</p>
<p>OFFSET…SET是一个没有统一确定语法的语句，不同的数据库有不同的表达方式，如 MySQL 和 PostgreSQL 的 LIMIT…OFFSET、SQL Server 和 Sybase 的 TOP…START AT 等。</p>
<h1 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h1><p>MySQL是一种开放源代码的关系型数据库管理系统（Relational Database Management System，RDBMS），由瑞典 MySQL AB 公司开发，属于 Oracle 旗下产品，使用最常用的数据库管理语言–结构化查询语言（SQL）进行数据库管理。</p>
<h2 id="连接数据库："><a href="#连接数据库：" class="headerlink" title="连接数据库："></a>连接数据库：</h2><p><code>mysql  -u user -p</code></p>
<p>退出连接：<code>QUIT 或者 Ctrl+D</code></p>
<h2 id="查看，创建，使用数据库"><a href="#查看，创建，使用数据库" class="headerlink" title="查看，创建，使用数据库:"></a>查看，创建，使用数据库:</h2><p><code>show databases;</code></p>
<p>默认数据库：</p>
<figure class="highlight plain"><figcaption><span>- 用户权限相关数据</span></figcaption><table><tr><td class="code"><pre><span class="line">mysql - 用户权限相关数据保存在mysql数据库的user表中</span><br><span class="line">test - 用于用户测试数据</span><br><span class="line">information_schema - MySQL本身架构相关数据</span><br></pre></td></tr></table></figure>
<p>创建数据库：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create database db1 DEFAULT CHARSET utf8 COLLATE utf8_general_ci; # utf8编码</span><br><span class="line">create database db1 DEFAULT CHARACTER SET gbk COLLATE gbk_chinese_ci; # gbk编码</span><br></pre></td></tr></table></figure>
<p>使用数据库：<code>use db1;</code></p>
<p>显示当前使用的数据库中所有表：<code>SHOW TABLES;</code></p>
<h2 id="用户管理"><a href="#用户管理" class="headerlink" title="用户管理"></a>用户管理</h2><p>创建用户：<code>create user &#39;用户名&#39;@&#39;IP地址&#39; identified by &#39;密码&#39;;</code></p>
<p>修改用户：<code>rename user &#39;用户名&#39;@&#39;IP地址&#39;; to &#39;新用户名&#39;@&#39;IP地址&#39;;</code></p>
<p>删除用户：<code>drop user &#39;用户名&#39;@&#39;IP地址&#39;;</code></p>
<p>修改密码：<code>set password for &#39;用户名&#39;@&#39;IP地址&#39; = Password(&#39;新密码&#39;);</code></p>
<h2 id="权限管理"><a href="#权限管理" class="headerlink" title="权限管理"></a>权限管理</h2><p>mysql对于权限这块有以下限制：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">all privileges：除grant外的所有权限</span><br><span class="line">select：仅查权限</span><br><span class="line">select,insert：查和插入权限</span><br><span class="line">...</span><br><span class="line">usage：无访问权限</span><br><span class="line">alter：使用alter table</span><br><span class="line">alter routine：使用alter procedure和drop procedure</span><br><span class="line">create：使用create table</span><br><span class="line">create routine：使用create procedure</span><br><span class="line">create temporary tables：使用create temporary tables</span><br><span class="line">create user：使用create user、drop user、rename user和revoke  all privileges</span><br><span class="line">create view：使用create view</span><br><span class="line">delete：使用delete</span><br><span class="line">drop：使用drop table</span><br><span class="line">execute：使用call和存储过程</span><br><span class="line">file：使用select into outfile 和 load data infile</span><br><span class="line">grant option：使用grant 和 revoke</span><br><span class="line">index：使用index</span><br><span class="line">insert：使用insert</span><br><span class="line">lock tables：使用lock table</span><br><span class="line">process：使用show full processlist</span><br><span class="line">select：使用select</span><br><span class="line">show databases：使用show databases</span><br><span class="line">show view：使用show view</span><br><span class="line">update：使用update</span><br><span class="line">reload：使用flush</span><br><span class="line">shutdown：使用mysqladmin shutdown(关闭MySQL)</span><br><span class="line">super：使用change master、kill、logs、purge、master和set global。还允许mysqladmin调试登陆</span><br><span class="line">replication client：服务器位置的访问</span><br><span class="line">replication slave：由复制从属使用</span><br></pre></td></tr></table></figure>
<p>对于数据库及内部其他权限如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">数据库名.*            数据库中的所有</span><br><span class="line">数据库名.表           指定数据库中的某张表</span><br><span class="line">数据库名.存储过程      指定数据库中的存储过程</span><br><span class="line">*.*                   所有数据库</span><br></pre></td></tr></table></figure>
<p>对于用户和IP的权限如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用户名@IP地址        用户只能在改IP下才能访问</span><br><span class="line">用户名@192.168.1.%   用户只能在改IP段下才能访问(通配符%表示任意)</span><br><span class="line">用户名@%             用户可以再任意IP下访问(默认IP地址为%)</span><br></pre></td></tr></table></figure>
<p>1、查看权限：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show grants for &#39;用户&#39;@&#39;IP地址&#39;</span><br></pre></td></tr></table></figure>
<p>2、授权</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grant  权限 on 数据库.表 to   &#39;用户&#39;@&#39;IP地址&#39;</span><br></pre></td></tr></table></figure>
<p>3、取消授权</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">revoke 权限 on 数据库.表 from &#39;用户名&#39;@&#39;IP地址&#39;</span><br></pre></td></tr></table></figure>
<p>授权实例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grant all privileges on db1.tb1 TO &#39;用户名&#39;@&#39;IP&#39;</span><br><span class="line"></span><br><span class="line">grant select on db1.* TO &#39;用户名&#39;@&#39;IP&#39;</span><br><span class="line"></span><br><span class="line">grant select,insert on *.* TO &#39;用户名&#39;@&#39;IP&#39;</span><br><span class="line"></span><br><span class="line">revoke select on db1.tb1 from &#39;用户名&#39;@&#39;IP&#39;</span><br></pre></td></tr></table></figure>
<h2 id="MySQL表操作"><a href="#MySQL表操作" class="headerlink" title="MySQL表操作"></a>MySQL表操作</h2><h3 id="查看表"><a href="#查看表" class="headerlink" title="查看表"></a>查看表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show tables; # 查看数据库全部表</span><br><span class="line">select * from 表名; # 查看表所有内容</span><br></pre></td></tr></table></figure>
<h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table 表名(</span><br><span class="line">    列名  类型  是否可以为空，</span><br><span class="line">    列名  类型  是否可以为空</span><br><span class="line">)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8</span><br></pre></td></tr></table></figure>
<p>例如</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE &#96;tab1&#96; (</span><br><span class="line">  &#96;nid&#96; int(11) NOT NULL auto_increment,</span><br><span class="line">  &#96;name&#96; varchar(255) DEFAULT zhangyanlin,</span><br><span class="line">  &#96;email&#96; varchar(255),</span><br><span class="line">  PRIMARY KEY (&#96;nid&#96;) </span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>默认值，创建列时可以指定默认值，当插入数据时如果未主动设置，则自动添加默认值。</p>
</li>
<li><p>自增，如果为某列设置自增列，插入数据时无需设置此列，默认将自增（表中只能有一个自增列）</p>
<blockquote>
<p>注意：</p>
<p>1、自增列，必须是索引（含主键）</p>
<p>2、自增可以设置步长和起始值。</p>
</blockquote>
</li>
<li><p>主键，一种特殊的唯一索引，不允许有空值，如果主键使用单个列，则它的值必须唯一，如果是多列，则其组合必须唯一。</p>
</li>
</ul>
<h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drop table 表名</span><br></pre></td></tr></table></figure>
<h3 id="清空表内容"><a href="#清空表内容" class="headerlink" title="清空表内容"></a>清空表内容</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">delete from 表名</span><br><span class="line">truncate table 表名</span><br></pre></td></tr></table></figure>
<h3 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">添加列：   </span><br><span class="line">alter table 表名 add 列名 类型</span><br><span class="line">删除列：   </span><br><span class="line">alter table 表名 drop column 列名</span><br><span class="line">修改列：      </span><br><span class="line">alter table 表名 modify column 列名 类型;  -- 类型</span><br><span class="line">alter table 表名 change 原列名 新列名 类型; -- 列名，类型</span><br><span class="line">添加主键：       </span><br><span class="line">alter table 表名 add primary key(列名);</span><br><span class="line">删除主键：         </span><br><span class="line">alter table 表名 drop primary key;</span><br><span class="line">alter table 表名  modify  列名 int, drop primary key;</span><br><span class="line">添加外键： </span><br><span class="line">alter table 从表 add constraint 外键名称（形如：FK_从表_主表） foreign key 从表(外键字段) references 主表(主键字段);</span><br><span class="line">删除外键： </span><br><span class="line">alter table 表名 drop foreign key 外键名称</span><br><span class="line">修改默认值：</span><br><span class="line">ALTER TABLE testalter_tbl ALTER i SET DEFAULT 1000;</span><br><span class="line">删除默认值：</span><br><span class="line">ALTER TABLE testalter_tbl ALTER i DROP DEFAULT;</span><br></pre></td></tr></table></figure>
<h3 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h3><p>MySQL的数据类型大致分为：<strong>数值、时间和字符串</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bit[(M)]</span><br><span class="line">            二进制位（101001），m表示二进制位的长度（1-64），默认m＝1</span><br><span class="line">tinyint[(m)] [unsigned] [zerofill]</span><br><span class="line">            小整数，数据类型用于保存一些范围的整数数值范围：</span><br><span class="line">            有符号：</span><br><span class="line">                -128 ～ 127.</span><br><span class="line">            无符号：</span><br><span class="line">                0 ～ 255</span><br><span class="line">            特别的： MySQL中无布尔值，使用tinyint(1)构造。</span><br><span class="line">int[(m)][unsigned][zerofill]</span><br><span class="line">            整数，数据类型用于保存一些范围的整数数值范围：</span><br><span class="line">                有符号：</span><br><span class="line">                    -2147483648 ～ 2147483647</span><br><span class="line">                无符号：</span><br><span class="line">                    0 ～ 4294967295</span><br><span class="line">            特别的：整数类型中的m仅用于显示，对存储范围无限制。例如： int(5),当插入数据2时，select 时数据显示为：00002</span><br><span class="line">bigint[(m)][unsigned][zerofill]</span><br><span class="line">            大整数，数据类型用于保存一些范围的整数数值范围：</span><br><span class="line">                有符号：</span><br><span class="line">                    -9223372036854775808 ～ 9223372036854775807</span><br><span class="line">                无符号：</span><br><span class="line">                    0  ～  18446744073709551615</span><br><span class="line">decimal[(m[,d])] [unsigned] [zerofill]</span><br><span class="line">            准确的小数值，m是数字总个数（负号不算），d是小数点后个数。 m最大值为65，d最大值为30。</span><br><span class="line">            特别的：对于精确数值计算时需要用此类型</span><br><span class="line">                   decaimal能够存储精确值的原因在于其内部按照字符串存储。</span><br><span class="line">FLOAT[(M,D)] [UNSIGNED] [ZEROFILL]          </span><br><span class="line">            单精度浮点数（非准确小数值），m是数字总个数，d是小数点后个数。</span><br><span class="line">                无符号：</span><br><span class="line">                    -3.402823466E+38 to -1.175494351E-38,</span><br><span class="line">                    0</span><br><span class="line">                    1.175494351E-38 to 3.402823466E+38</span><br><span class="line">                有符号：</span><br><span class="line">                    0</span><br><span class="line">                    1.175494351E-38 to 3.402823466E+38</span><br><span class="line">            **** 数值越大，越不准确 ****</span><br><span class="line">DOUBLE[(M,D)] [UNSIGNED] [ZEROFILL]</span><br><span class="line">            双精度浮点数（非准确小数值），m是数字总个数，d是小数点后个数。</span><br><span class="line">                无符号：</span><br><span class="line">                    -1.7976931348623157E+308 to -2.2250738585072014E-308</span><br><span class="line">                    0</span><br><span class="line">                    2.2250738585072014E-308 to 1.7976931348623157E+308</span><br><span class="line">                有符号：</span><br><span class="line">                    0</span><br><span class="line">                    2.2250738585072014E-308 to 1.7976931348623157E+308</span><br><span class="line">            **** 数值越大，越不准确 ****</span><br><span class="line">char (m)</span><br><span class="line">            char数据类型用于表示固定长度的字符串，可以包含最多达255个字符。其中m代表字符串的长度。</span><br><span class="line">            PS: 即使数据小于m长度，也会占用m长度          </span><br><span class="line">varchar(m)</span><br><span class="line">            varchars数据类型用于变长的字符串，可以包含最多达255个字符。其中m代表该数据类型所允许保存的字符串的最大长度，只要长度小于该最大值的字符串都可以被保存在该数据类型中。</span><br><span class="line"></span><br><span class="line">            注：虽然varchar使用起来较为灵活，但是从整个系统的性能角度来说，char数据类型的处理速度更快，有时甚至可以超出varchar处理速度的50%。因此，用户在设计数据库时应当综合考虑各方面的因素，以求达到最佳的平衡</span><br><span class="line">text</span><br><span class="line">            text数据类型用于保存变长的大字符串，可以组多到65535 (2**16 − 1)个字符。</span><br><span class="line">mediumtext</span><br><span class="line">            A TEXT column with a maximum length of 16,777,215 (2**24 − 1) characters.</span><br><span class="line">longtext</span><br><span class="line">            A TEXT column with a maximum length of 4,294,967,295 or 4GB (2**32 − 1) characters.</span><br><span class="line">enum</span><br><span class="line">            枚举类型，</span><br><span class="line">            An ENUM column can have a maximum of 65,535 distinct elements. (The practical limit is less than 3000.)</span><br><span class="line">            示例：</span><br><span class="line">                CREATE TABLE shirts (</span><br><span class="line">                    name VARCHAR(40),</span><br><span class="line">                    size ENUM(&#39;x-small&#39;, &#39;small&#39;, &#39;medium&#39;, &#39;large&#39;, &#39;x-large&#39;)</span><br><span class="line">                );</span><br><span class="line">                INSERT INTO shirts (name, size) VALUES (&#39;dress shirt&#39;,&#39;large&#39;), (&#39;t-shirt&#39;,&#39;medium&#39;),(&#39;polo shirt&#39;,&#39;small&#39;);</span><br><span class="line">set</span><br><span class="line">            集合类型</span><br><span class="line">            A SET column can have a maximum of 64 distinct members.</span><br><span class="line">            示例：</span><br><span class="line">                CREATE TABLE myset (col SET(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;));</span><br><span class="line">                INSERT INTO myset (col) VALUES (&#39;a,d&#39;), (&#39;d,a&#39;), (&#39;a,d,a&#39;), (&#39;a,d,d&#39;), (&#39;d,a,d&#39;);</span><br><span class="line"></span><br><span class="line">DATE          </span><br><span class="line">            YYYY-MM-DD（1000-01-01&#x2F;9999-12-31）</span><br><span class="line">TIME</span><br><span class="line">            HH:MM:SS（&#39;-838:59:59&#39;&#x2F;&#39;838:59:59&#39;）</span><br><span class="line">YEAR</span><br><span class="line">            YYYY（1901&#x2F;2155）</span><br><span class="line">DATETIME</span><br><span class="line">            YYYY-MM-DD HH:MM:SS（1000-01-01 00:00:00&#x2F;9999-12-31 23:59:59    Y）</span><br><span class="line">TIMESTAMP</span><br><span class="line">            YYYYMMDD HHMMSS（1970-01-01 00:00:00&#x2F;2037 年某时）</span><br></pre></td></tr></table></figure>
<h2 id="MySQL表内容操作"><a href="#MySQL表内容操作" class="headerlink" title="MySQL表内容操作"></a>MySQL表内容操作</h2><p>表内容操包括<strong>增删改查</strong>，最多的是查</p>
<h3 id="增"><a href="#增" class="headerlink" title="增"></a>增</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">insert into 表 (列名,列名...) values (值,值,...)</span><br><span class="line">insert into 表 (列名,列名...) values (值,值,...),(值,值,值...)</span><br><span class="line">insert into 表 (列名,列名...) select (列名,列名...) from 表</span><br><span class="line">例：</span><br><span class="line">    insert into tab1(name,email) values(&#39;zhangyanlin&#39;,&#39;zhangyanlin8851@163.com&#39;)</span><br></pre></td></tr></table></figure>
<h3 id="删"><a href="#删" class="headerlink" title="删"></a>删</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">delete from 表   # 删除表里全部数据</span><br><span class="line">delete from 表 where id＝1 and name＝&#39;zhangyanlin&#39; # 删除ID &#x3D;1 和name&#x3D;&#39;zhangyanlin&#39; 那一行数据</span><br></pre></td></tr></table></figure>
<h3 id="改"><a href="#改" class="headerlink" title="改"></a>改</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">update 表 set name ＝ &#39;zhangyanlin&#39; where id&gt;1</span><br></pre></td></tr></table></figure>
<h3 id="查"><a href="#查" class="headerlink" title="查"></a>查</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from 表</span><br><span class="line">select * from 表 where id &gt; 1</span><br><span class="line">select nid,name,gender as gg from 表 where id &gt; 1</span><br></pre></td></tr></table></figure>
<h4 id="条件判断where"><a href="#条件判断where" class="headerlink" title="条件判断where"></a>条件判断where</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from 表 where id &gt; 1 and name !&#x3D; &#39;aylin&#39; and num &#x3D; 12;</span><br><span class="line">select * from 表 where id between 5 and 16;</span><br><span class="line">select * from 表 where id in (11,22,33)</span><br><span class="line">select * from 表 where id not in (11,22,33)</span><br><span class="line">select * from 表 where id in (select nid from 表)</span><br></pre></td></tr></table></figure>
<h4 id="通配符like"><a href="#通配符like" class="headerlink" title="通配符like"></a>通配符like</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from 表 where name like &#39;zhang%&#39;  # zhang开头的所有（多个字符串）</span><br><span class="line">select * from 表 where name like &#39;zhang_&#39;  # zhang开头的所有（一个字符）</span><br></pre></td></tr></table></figure>
<h4 id="限制limit"><a href="#限制limit" class="headerlink" title="限制limit"></a>限制limit</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from 表 limit 5;            - 前5行</span><br><span class="line">select * from 表 limit 4,5;          - 从第4行开始的5行</span><br><span class="line">select * from 表 limit 5 offset 4    - 从第4行开始的5行</span><br></pre></td></tr></table></figure>
<h4 id="排序asc，desc"><a href="#排序asc，desc" class="headerlink" title="排序asc，desc"></a>排序asc，desc</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from 表 order by 列 asc              - 根据 “列” 从小到大排列</span><br><span class="line">select * from 表 order by 列 desc             - 根据 “列” 从大到小排列</span><br><span class="line">select * from 表 order by 列1 desc,列2 asc    - 根据 “列1” 从大到小排列，如果相同则按列2从小到大排序</span><br></pre></td></tr></table></figure>
<h4 id="分组group-by"><a href="#分组group-by" class="headerlink" title="分组group by"></a>分组group by</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select num from 表 group by num</span><br><span class="line">select num,nid from 表 group by num,nid</span><br><span class="line">select num,nid from 表  where nid &gt; 10 group by num,nid order nid desc</span><br><span class="line">select num,nid,count(*),sum(score),max(score),min(score) from 表 group by num,nid</span><br><span class="line">select num from 表 group by num having max(id) &gt; 10</span><br><span class="line"></span><br><span class="line">特别的：group by 必须在where之后，order by之前</span><br></pre></td></tr></table></figure>
<p><a href="https://mp.weixin.qq.com/s/ha_tlD0H_HrrdbmoB7NlzA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/ha_tlD0H_HrrdbmoB7NlzA</a></p>
]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Typora使用</title>
    <url>/2020/09/04/Typora%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="插入大纲目录"><a href="#插入大纲目录" class="headerlink" title="插入大纲目录"></a>插入大纲目录</h2><p>使用 <code>[TOC]</code>可以在顶部显示目录，但是hexo不能渲染</p>
<h2 id="左侧大纲视图折叠"><a href="#左侧大纲视图折叠" class="headerlink" title="左侧大纲视图折叠"></a>左侧大纲视图折叠</h2><p>Typora 中 shift+ctrl+O 可以在左侧显示大纲视图，但是当目录很长，默认展开时，</p>
<p>文件 ⇒ 偏好设置 ⇒ 侧边栏 ⇒  选中侧边栏的大纲视图允许折叠和展开。</p>
<p>参考：<a href="https://www.cnblogs.com/tian-ci/p/10543088.html" target="_blank" rel="noopener">https://www.cnblogs.com/tian-ci/p/10543088.html</a></p>
]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>Typora</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统</title>
    <url>/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h2 id="认识操作系统"><a href="#认识操作系统" class="headerlink" title="认识操作系统"></a>认识操作系统</h2><p><img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600217528868.png" alt="1600217528868"></p>
<a id="more"></a>
<h3 id="x86-系统的结构"><a href="#x86-系统的结构" class="headerlink" title="x86 系统的结构"></a>x86 系统的结构</h3><p><img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600160298027.png" alt="1600160298027"></p>
<h4 id="PCI-E"><a href="#PCI-E" class="headerlink" title="PCI-E"></a>PCI-E</h4><p>PCIe (Peripheral Component Interconnect Express，PCI-Express)一种高速串行计算机扩展总线标准，PCIe属于高速串行点对点双通道高带宽传输，所连接的设备分配独享通道带宽，不共享总线带宽，主要支持主动电源管理，错误报告，端对端的可靠性传输，热插拔以及服务质量(<a href="https://baike.baidu.com/item/QOS" target="_blank" rel="noopener">QOS</a>)等功能。</p>
<p>PCIe Sizes：x16 vs x8 vs x4 vs x1</p>
<p>x后面的数字表示PCIe卡或插槽的物理大小，x16是最大的，x1是最小的。以下是各种尺寸的形状：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>-</th>
<th>Number of Pins（引脚的数量）</th>
<th>Length</th>
</tr>
</thead>
<tbody>
<tr>
<td>PCI Express x1</td>
<td>18</td>
<td>25毫米</td>
</tr>
<tr>
<td>PCI Express x4</td>
<td>32</td>
<td>39毫米</td>
</tr>
<tr>
<td>PCI Express x8</td>
<td>49</td>
<td>56毫米</td>
</tr>
<tr>
<td>PCI Express x16</td>
<td>82</td>
<td>89毫米</td>
</tr>
</tbody>
</table>
</div>
<p>不管PCIe插槽或卡片的大小是多少，关键的凹槽，卡或槽中的小空间，总是在大头针11上。</p>
<p>PCIe卡片适合于主板上的任何PCIe插槽，它的大小至少和它一样大。例如，PCIe x1卡将适用于任何PCIe x4、PCIe x8或PCIe x16插槽。</p>
<p><img src="https://img-blog.csdn.net/20180718153127412?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JqYXJuZUNwcA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<h4 id="MDI"><a href="#MDI" class="headerlink" title="MDI"></a>MDI</h4><p>Medium Dependent Interface ，介质相关接口。在 hub 或 switch 中有两种接口，分别叫 MDI port和 MDI-X port， MDI port 也叫做级联端口（ uplink port ），是 hub 或 switch 之间相互连接的端口。 </p>
<p>MDI port和 MDI-X port 之间最大的区别在于， MDI port内部发送数据线和接收数据线没交叉， 而MDI-X port 内部发送数据线和接收数据线是交叉的，这个X代表交叉的意思。</p>
<p><img src="https://bkimg.cdn.bcebos.com/pic/9345d688d43f8794964ce0bdd31b0ef41ad53af5?x-bce-process=image/resize,m_lfit,w_250,h_250,limit_1" alt="img"></p>
<p>计算机和交换机的连接要用直通线，交换机和交换机之间的连接要用交叉线，</p>
<h4 id="DMI"><a href="#DMI" class="headerlink" title="DMI"></a>DMI</h4><p>DMI是指Direct Media Interface(直接媒体接口)，用于连接主板南北桥的总线，取代了以前的Hub-Link总线。它基于<a href="https://baike.baidu.com/item/PCI-Express" target="_blank" rel="noopener">PCI-Express</a>总线，跟随PCI-E总线的换代而换代。DMI采用点对点的连接方式，时钟频率为100MHz。</p>
<h4 id="USB"><a href="#USB" class="headerlink" title="USB"></a>USB</h4><p>USB(Univversal Serial Bus) 连接慢速 I/O 设备和计算机。USB 1.0 ：12 Mb/s，USB 2.0 总线速度 480Mb/s，USB 3.0不小于 5Gb/s。USB连接不需要重启计算机。</p>
<h4 id="SCSI"><a href="#SCSI" class="headerlink" title="SCSI"></a>SCSI</h4><p>SCSI(Small Computer System Interface) 总线是一种高速总线，用在高速硬盘，扫描仪和其他需要较大带宽的设备上。现在，它们主要用在服务器和工作站中，速度可以达到640MB/s。</p>
<h3 id="存储器"><a href="#存储器" class="headerlink" title="存储器"></a>存储器</h3><h4 id="RAM"><a href="#RAM" class="headerlink" title="RAM"></a>RAM</h4><h4 id="ROM"><a href="#ROM" class="headerlink" title="ROM"></a>ROM</h4><blockquote>
<ol>
<li><p>rom最初不能编程，出厂什么内容就永远什么内容，不灵活。</p>
</li>
<li><p>后来出现了prom，可以自己写入一次，要是写错了，只能换一片。</p>
</li>
<li><p>人类文明不断进步，终于出现了可多次擦除写入的EPROM，每次擦除要把芯片拿到紫外线上照一下.</p>
</li>
<li><p>历史的车轮不断前进，伟大的EEPROM出现了，拯救了一大批程序员，终于可以随意的修改rom中的内容了。</p>
<p>ROM—PROM—EPROM—EEPROM的进化！</p>
</li>
</ol>
</blockquote>
<h4 id="EEPROM"><a href="#EEPROM" class="headerlink" title="EEPROM"></a>EEPROM</h4><p>全称是“电可擦除可编程只读存储器，即Electrically Erasable Programmable Read-Only Memory。是相对于紫外擦除的rom来讲的。但是今天已经存在多种EEPROM的变种，变成了一类存储器的统称。</p>
<h4 id="Flash"><a href="#Flash" class="headerlink" title="Flash"></a>Flash</h4><p>狭义的EEPROM：这种rom的特点是可以随机访问和修改任何一个字节，可以往每个bit中写入0或者1。这是最传统的一种EEPROM，掉电后数据不丢失，可以保存100年，可以擦写100w次。具有较高的可靠性，但是电路复杂/成本也高。因此目前的EEPROM都是几十千字节到几百千字节的，绝少有超过512K的。</p>
<p>Flash属于广义的EEPROM，也是电擦除的rom。但擦除时不再以字节为单位，而是以块为单位，一次简化了电路，数据密度更高，降低了成本。上M的rom一般都是flash。</p>
<p>flash分为nor flash和nand flash。</p>
<blockquote>
<ol>
<li>nor flash数据线和地址线分开，可以实现ram一样的随机寻址功能，可以读取任何一个字节。但是擦除仍要按块来擦。</li>
<li>nand flash同样是按块擦除，但是数据线和地址线复用，不能利用地址线随机寻址。读取只能按页来读取。（nandflash按块来擦除，按页来读，norflash没有页）</li>
<li>由于nandflash引脚上复用，因此读取速度比nor flash慢一点，但是擦除和写入速度比nor flash快很多。nand flash内部电路更简单，因此数据密度大，体积小，成本也低。因此大容量的flash都是nand型的。小容量的2～12M的flash多是nor型的。</li>
<li>使用寿命上，nand flash的擦除次数是nor的数倍。而且nand flash可以标记坏块，从而使软件跳过坏块。nor flash 一旦损坏便无法再用。</li>
<li>因为nor flash可以进行字节寻址，所以程序可以在nor flash中运行。嵌入式系统多用一个小容量的nor flash存储引导代码，用一个大容量的nand flash存放文件系统和内核。</li>
</ol>
</blockquote>
<p>参考：<a href="https://www.cnblogs.com/Pual623548198/p/7085319.html" target="_blank" rel="noopener">https://www.cnblogs.com/Pual623548198/p/7085319.html</a></p>
<h3 id="主板"><a href="#主板" class="headerlink" title="主板"></a>主板</h3><h4 id="基本输入输出系统-Basic-Input-Output-System-BIOS"><a href="#基本输入输出系统-Basic-Input-Output-System-BIOS" class="headerlink" title="基本输入输出系统(Basic Input Output System, BIOS)"></a>基本输入输出系统(Basic Input Output System, BIOS)</h4><p>保存在闪存中，非易失性。</p>
<p>有底层I/0软件：读键盘，写屏幕，磁盘I/O。</p>
<p>计算机启动时，检查设备，通过尝试存储在CMOS存储器中的设备清单尝试启动设备。</p>
<p>决定从外部（CD-ROM，USB）还是硬盘启动。</p>
<h4 id="互补金属氧化物半导体-Complementary-Metal-Oxide-Semiconductor-CMOS"><a href="#互补金属氧化物半导体-Complementary-Metal-Oxide-Semiconductor-CMOS" class="headerlink" title="互补金属氧化物半导体(Complementary Metal Oxide Semiconductor , CMOS)"></a>互补金属氧化物半导体(Complementary Metal Oxide Semiconductor , CMOS)</h4><p>电脑主板上的一块可读写的RAM芯片。用来保存BIOS设置完电脑硬件参数后的数据。</p>
<h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><h4 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h4><p>大型机操作系统</p>
<p>服务器操作系统：典型的服务器操作系统有Solaris， FreeBSD，Linux，Windows Server 201x</p>
<p>多处理器操作系统：将多个CPU连接到一个系统中，并行计算机（多核处理器）</p>
<p>个人计算机系统：Linux，FreeBSD，Windows 7，Windows 8 ， OS X</p>
<p>掌上计算机：Abdroid和IOS</p>
<p>嵌入式操作系统：</p>
<p>传感器节点操作系统：</p>
<p>实时操作系统：硬实时系统和软实时系统</p>
<p>智能卡操作系统：信用卡</p>
<h4 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h4><p>本质是操作系统执行的一个程序。</p>
<h5 id="地址空间："><a href="#地址空间：" class="headerlink" title="地址空间："></a>地址空间：</h5><p>32位有2^32字节的地址空间，64位有2^64字节的地址空间。</p>
<p>通常，每个进程有一些可以使用的地址集合，典型值从0开始到某个最大值，一个进程可拥有的最大地址空间小于主存，这种情况下，即使进程用完其地址空间，内存也会有足够的内存运行该进程。</p>
<blockquote>
<p>如果进程的地址空间比主存还大，可以把部分地址空间装入主存，部分留在磁盘，并在需要时来回交换（虚拟内存）</p>
</blockquote>
<p>磁芯映像 core image</p>
<p>资源集：寄存器（程序计数器和堆栈指针），打开文件的清单等 （这些都在进程表中）</p>
<p>进程表：与一个进程相关的所有信息，除了该进程自身空间的内容以外，均存放在操作系统的一张表中。是数组或者链表结构，当前存在每一个进程都占据其中的一项。</p>
<p>进程间通信：合作完成某些作业的相关进程需要彼此通信</p>
<h4 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h4><p>读写之前，检查访问权限，若权限许可，系统返回一个小整数（文件描述符），若禁止访问，系统返回一个错误码。</p>
<p>UNIX的特殊文件：为了使系统向调用读写文件一样调用I/O设备</p>
<p>块特殊文件：可随机存取的块组成的设备，比如磁盘</p>
<p>字符特殊文件：用于打印机，调制解调器和其他接受或输出字符流的设备。</p>
<p>管道：一种虚文件，可以用来连接两个进程。</p>
<h4 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h4><p>提供应用程序抽象：创建，写入，读取和删除文件。</p>
<p>管理计算资源：</p>
<h4 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h4><p>以系统调用read(fd, buffer, nbytes)为例</p>
<p><img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600168907591.png" alt="1600168907591"></p>
<p>首先把参数压入栈堆：1. C和C++编译器使用逆序 2. 第二个参数通过引用传递，即传递的是缓冲区的地址 &amp;</p>
<p>TRAP指令：将用户态切换到内核态。</p>
<p>完成调用之后，操作系统需要清除用户堆栈，增加堆栈指针（increment stackpointer）</p>
<h5 id="用于进程管理的系统调用"><a href="#用于进程管理的系统调用" class="headerlink" title="用于进程管理的系统调用"></a>用于进程管理的系统调用</h5><p>fork创建原有进程的副本，包括所有的文件描述，寄存器等。fork调用返回一个值，在子进程中为0，在父进程中等于子进程的进程标识符（Process IDentified，PID）。</p>
<h5 id="用于文件管理的系统调用"><a href="#用于文件管理的系统调用" class="headerlink" title="用于文件管理的系统调用"></a>用于文件管理的系统调用</h5><p>O_RDONLY O_WRONLY O_RDWR</p>
<p>iseek(fd,offset,whence)</p>
<h5 id="用于目录管理的系统调用"><a href="#用于目录管理的系统调用" class="headerlink" title="用于目录管理的系统调用"></a>用于目录管理的系统调用</h5><p>mkdir   rmdir</p>
<p>link(name1,name2) 允许同一个文件以两个或者多个名称出现。</p>
<p>每个文件都独一无二，i-number 是inodes表的索引。目录是一系列（i-编号，ASCII名称）的集合。</p>
<p>link利用某个已有文件的i-编号，穿件一个新的目录项。</p>
<p>mount(specila, name, flag)将两个文件系统合并为一个。<img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600174254344.png" alt="1600174254344"></p>
<h5 id="其他系统调用"><a href="#其他系统调用" class="headerlink" title="其他系统调用"></a>其他系统调用</h5><p>chdir    chmod   kill</p>
<h3 id="Win-32-API"><a href="#Win-32-API" class="headerlink" title="Win 32 API"></a>Win 32 API</h3><p>UNIX程序由执行某些操作或执行其他操作的代码组成，进行系统调用以执行某些服务。</p>
<p>Windows应用程序通常是由事件驱动的，主程序等待一些时间发生，然后调用程序去处理。</p>
<p>win中函数库的调用和实际的系统调用几乎是不对应的。</p>
<p><img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600174669528.png" alt="1600174669528"></p>
<p>windows中没有类似UNIX中的进程层次，不存在父进程和子进程的概念。</p>
<h3 id="操作系统结构"><a href="#操作系统结构" class="headerlink" title="操作系统结构"></a>操作系统结构</h3><h4 id="单体系统"><a href="#单体系统" class="headerlink" title="单体系统"></a>单体系统</h4><p>内核态以单一程序的方式运行</p>
<p><img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600216350126.png" alt="1600216350126"></p>
<p>除了核心操作系统外，操作系统还支持扩展：I/O设备驱动和文件系统。UNIX中叫做<strong>共享库（shared library）</strong>，windows中叫做**动态链接库（Dynamic Link Library，DLL）</p>
<h4 id="分层系统"><a href="#分层系统" class="headerlink" title="分层系统"></a>分层系统</h4><p>使用层来分隔不同的功能单元，每一层只与该层的上层和下层通信。上层软件都是在下层软件的基础之上构建的。</p>
<p><img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600216585570.png" alt="1600216585570"></p>
<p><img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600216594038.png" alt="1600216594038"></p>
<h4 id="微内核"><a href="#微内核" class="headerlink" title="微内核"></a>微内核</h4><p>在分层方式中，确定哪里划分内核-用户的分界。</p>
<p>MINIX3</p>
<p><img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600217029845.png" alt="1600217029845"></p>
<p>微内核中机制与策略分离，内核均值寻找最高的优先级进程并运行，策略（赋予进程优先级）可以在用户态中的进程完成。</p>
<h4 id="客户-服务器模式"><a href="#客户-服务器模式" class="headerlink" title="客户-服务器模式"></a>客户-服务器模式</h4><p>当策略将进程分为两大类：服务器（提供服务）和客户端（使用服务）——客户-服务模式。</p>
<h2 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h2><p><img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600217767997.png" alt="1600217767997"></p>
<h3 id="进程-1"><a href="#进程-1" class="headerlink" title="进程"></a>进程</h3><p>进程是对正在运行中的程序的一个抽象。即使CPU只有一个，也支持（伪）并发操作（将单独的CPU抽象为多个虚拟机的CPU）</p>
<p>伪并行（pseudoparallelism）：单核或多核处理器同时执行多个进程，从而使程序更快，通过以非常有限的时间间隔在程序之间快速切换CPU产生并行感。</p>
<h4 id="进程模型"><a href="#进程模型" class="headerlink" title="进程模型"></a>进程模型</h4><p>进程包括：程序计数器，寄存器，变量当前值。</p>
<h4 id="进程的创建"><a href="#进程的创建" class="headerlink" title="进程的创建"></a>进程的创建</h4><ul>
<li><p>系统初始化（init）: 启动阶段穿件进程</p>
<blockquote>
<p>前台进程（numerous process）：同用户进行交互并完成工作</p>
<p>守护进程（daemons）：运行在后台，不与特定用户进行交互</p>
</blockquote>
</li>
<li><p>正在运行的程序执行了创建进程的系统调用（fork）</p>
<blockquote>
<p>​</p>
</blockquote>
</li>
<li><p>用户请求创建新进程</p>
<blockquote>
<p>交互式系统中，输入命令或者双击启动程序</p>
</blockquote>
</li>
<li><p>初始化一个批处理工作</p>
<blockquote>
<p>大型机的批处理系统</p>
<p>在UNIX中，系统调用(fork)后，创建一个与调用进程相关的副本，子进程有何父进程相同的内存映像，环境字符创和打开文件，子进程执行<code>execve</code>或者简单的系统调用来改变内存映像并运行一个新程序。</p>
<p>例如 shell中输入sort命令，shell会fork一个子进程，然后执行sort命令</p>
<p>Win32中，<code>CreateProcess</code>处理流程创建并将正确的程序加载到新的进程中。</p>
</blockquote>
</li>
</ul>
<h4 id="进程的终止"><a href="#进程的终止" class="headerlink" title="进程的终止"></a>进程的终止</h4><ul>
<li><p>正常退出(自愿)</p>
<blockquote>
<p>编译器完成给定程序的编译后，编译器执行一个系统调用告诉操作系统完成了工作</p>
<p>UNIX：<code>exit</code>  Windows: <code>ExitProcess</code></p>
<p>界面化的软件有可以点击关闭的按钮，用来通知进程删除其打开的临时文件，然后终止。</p>
</blockquote>
</li>
<li><p>错误退出(自愿)</p>
<blockquote>
<p>发出声明，给出错误参数，并退出</p>
<p>面向屏幕的交互式进程通常并不会直接退出</p>
</blockquote>
</li>
<li><p>严重错误（非自愿）</p>
<blockquote>
<p>进程引起的错误，通常由于程序中的错误导致，UNIX中，进程会受到信号（中断）</p>
<p>例如，执行一条非法指令，引用不存在的内存，或者除数为0</p>
</blockquote>
</li>
<li><p>被其他进程杀死（非自愿）</p>
<blockquote>
<p>UNIX kill；Win32中TerminateProcess</p>
</blockquote>
</li>
</ul>
<h4 id="进程的层次结构"><a href="#进程的层次结构" class="headerlink" title="进程的层次结构"></a>进程的层次结构</h4><ul>
<li><p>UNIX</p>
<p>进程和其所有子进程以及子进程的子进程共同组成一个进程组。</p>
</li>
<li><p>Windows</p>
<p>没有进程层次的概念。父进程可以得到一个特别的令牌（句柄），用来控制子进程，但该令牌可以移交给别的操作系统。UNIX中不能剥夺其子进程的进程权。</p>
</li>
</ul>
<h4 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat chapter1 chapter2 chapter3 | grep tree</span><br></pre></td></tr></table></figure>
<p>当grep就绪，但输入进程还没能完成时，必须阻塞grep进程，直到输入完毕。</p>
<p><img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600220979244.png" alt="1600220979244"></p>
<ul>
<li>运行态：进程实际占用CPU时间片</li>
<li>就绪态：可运行，但因其他进程正在运行而处于就绪状态</li>
<li>阻塞态：除非某种外部时间发生，否则进程不能运行</li>
</ul>
<p>程序调度：决定哪个进程优先被运行和运行多久。</p>
<img src="/2020/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1600225430669.png" class width="1600225430669">
<p>顺序进程（sequential process）</p>
<p>操作系统最底层是调度程序（中断和调度处理），之上是顺序进程。</p>
<h4 id="进程的实现"><a href="#进程的实现" class="headerlink" title="进程的实现"></a>进程的实现</h4>]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title>网络相关知识</title>
    <url>/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h2 id="HTTP知识"><a href="#HTTP知识" class="headerlink" title="HTTP知识"></a>HTTP知识</h2><h3 id="安全和幂等的概念"><a href="#安全和幂等的概念" class="headerlink" title="安全和幂等的概念"></a>安全和幂等的概念</h3><p>在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。<br>所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。</p>
<a id="more"></a>
<p><strong>GET 方法是安全且幂等的</strong>，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。<br><strong>POST </strong>因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全</strong>的，且多次提交数据就会创建多个资源，所以<strong>不是幂等</strong>的。</p>
<h3 id="HTTP的优缺点"><a href="#HTTP的优缺点" class="headerlink" title="HTTP的优缺点"></a>HTTP的优缺点</h3><p>HTTP 最凸出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。</p>
<p>HTTP 协议缺点是「无状态、明文传输」，同时还有一大缺点「不安全」。</p>
<blockquote>
<ol>
<li><p>无状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。</p>
<p>无状态的坏处，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。</p>
<p><strong>可以通过cookie解决</strong></p>
</li>
<li><p>明文意味着在传输过程中的信息，是可方便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。<br>但HTTP 的所有信息都暴露在了光天化日下，相当于信息裸奔。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息，那你号没了。</p>
</li>
<li><p>HTTP 比较严重的缺点就是不安全：</p>
<ul>
<li><p>通信使用明文（不加密），内容可能会被窃听。比如，账号信息容易泄漏，那你号没了。</p>
</li>
<li><p>不验证通信方的身份，因此有可能遭遇伪装。比如，访问假的淘宝、拼多多，那你钱没了。</p>
</li>
<li><p>无法证明报文的完整性，所以有可能已遭篡改。比如，网页上植入垃圾广告，视觉污染，眼没了。</p>
<p><strong>通过HTTPS解决：在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚至把 TCP 层换成了基于 UDP 的 QUIC。</strong></p>
</li>
</ul>
</li>
</ol>
</blockquote>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599625816283.png" alt="1599625816283"></p>
<h2 id="IP知识"><a href="#IP知识" class="headerlink" title="IP知识"></a>IP知识</h2><h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>IP 在 TCP/IP 参考模型中处于第三层，也就是网络层。<br>网络层的主要作用是：实现主机与主机之间的通信，也叫点对点（end to end）通信。</p>
<p>IP 地址（IPv4 地址）由 32 位正整数来表示，IP 地址在计算机是以二进制的方式处理的。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599626314741.png" alt="1599626314741"></p>
<p>IP地址最大$2^{32}$ ，大约43亿，IP 地址并不是根据主机台数来配置的，而是以网卡。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599626438580.png" alt="1599626438580"></p>
<h3 id="IP-地址的分类"><a href="#IP-地址的分类" class="headerlink" title="IP 地址的分类"></a>IP 地址的分类</h3><p>IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599626499535.png" alt="1599626499535"></p>
<p>D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于多播，E 类是预留的分类，暂时未使用。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599626848504.png" alt="1599626848504"></p>
<p>多播用于将包发送给特定组内的所有主机。由于广播无法穿透路由，若想给其他网段发送同样的包，就可以使用可以穿透路由的多播。</p>
<ul>
<li>224.0.0.0 ~ 224.0.0.255 为预留的组播地址，只能在局域网中，路由器是不会进行转发的。</li>
<li>224.0.1.0 ~ 238.255.255.255 为用户可用的组播地址，可以用于 Internet 上。</li>
<li>239.0.0.0 ~ 239.255.255.255 为本地管理组播地址，可供内部网在内部使用，仅在特定的本地范围内有效。</li>
</ul>
<p>对于 A、B、C 类主要分为两个部分，分别是网络号和主机号。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599626543682.png" alt="1599626543682"></p>
<p>在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和 全为 0 地址。</p>
<ul>
<li>主机号全为 1 指定某个网络下的所有主机，用于广播（广播地址用于在同一个链路中相互连接的主机之间发送数据包）</li>
<li>主机号全为 0 指定某个网络</li>
</ul>
<p>广播地址可以分为本地广播和直接广播：</p>
<ul>
<li>在本网络内广播的叫做本地广播。例如网络地址为 192.168.0.0/24 的情况下，广播地址是192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0/24 以外的其他链路上。</li>
<li>在不同网络之间的广播叫做直接广播。例如网络地址为 192.168.0.0/24 的主机向192.168.1.255/24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0/24，从而使得所有 192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有一定的安全问题，多数情况下会在路由器上设置为不转发。） 。</li>
</ul>
<h3 id="IP分类的优缺点"><a href="#IP分类的优缺点" class="headerlink" title="IP分类的优缺点"></a>IP分类的优缺点</h3><ol>
<li>同一网络下没有地址层次，比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性。</li>
<li>A、B、C类有个尴尬处境，就是不能很好的与现实网络匹配。C 类地址能包含的最大主机数量实在太少了，只有 254 个。而 B 类地址能包含的最大主机数量又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。</li>
</ol>
<h3 id="无分类地址-CIDR"><a href="#无分类地址-CIDR" class="headerlink" title="无分类地址 CIDR"></a>无分类地址 CIDR</h3><p>32 比特的 IP 地址被划分为两部分，前面是网络号，后面是主机号。表示形式 a.b.c.d/x ，其中 /x 表示前 x 位属于网络号， x 的范围是 0 ~ 32 ，这就使得 IP 地址更加具有灵活性。</p>
<p>另一种划分网络号与主机号形式，那就是子网掩码，掩码的意思就是掩盖掉主机号，剩余的就是网络号。将子网掩码和 IP 地址按位计算 AND，就可得到网络号。</p>
<blockquote>
<p>两台计算机要通讯，首先要判断是否处于同一个广播域内，即网络地址是否相同。如果网络地址相同，表明接受方在本网络上，那么可以把数据包直接发送到目标主机。</p>
</blockquote>
<h3 id="子网划分"><a href="#子网划分" class="headerlink" title="子网划分"></a>子网划分</h3><p>子网掩码的另一个作用，子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址。</p>
<h3 id="公有-IP-地址与私有-IP-地址"><a href="#公有-IP-地址与私有-IP-地址" class="headerlink" title="公有 IP 地址与私有 IP 地址"></a>公有 IP 地址与私有 IP 地址</h3><p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599629584305.png" alt="1599629584305"></p>
<p>私有 IP 地址允许组织内部的 IT人员自己管理、自己分配，而且可以重复。</p>
<p>公有 IP 地址是由 ICANN 组织管理，中文叫「互联网名称与数字地址分配机构」。IANA 是 ICANN 的其中一个机构，它负责分配互联网 IP 地址，是按州的方式层层分配。在中国是由 CNNIC 的机构进行管理，它是中国国内唯一指定的全局 IP 地址管理的组织。<br><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599629683644.png" alt="1599629683644"></p>
<h3 id="IP-地址与路由控制"><a href="#IP-地址与路由控制" class="headerlink" title="IP 地址与路由控制"></a>IP 地址与路由控制</h3><p>IP地址的网络地址这一部分是用于进行路由控制。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599629833778.png" alt="1599629833778"></p>
<h3 id="环回地址"><a href="#环回地址" class="headerlink" title="环回地址"></a>环回地址</h3><p>环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。</p>
<p>计算机使用一个特殊的 IP 地址 127.0.0.1 作为环回地址。与该地址具有相同意义的是一个叫做localhost 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。</p>
<h3 id="IP-分片与重组"><a href="#IP-分片与重组" class="headerlink" title="IP 分片与重组"></a>IP 分片与重组</h3><p>每种数据链路的最大传输单元 MTU 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是1500 字节等。</p>
<p>那么当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片。经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。</p>
<h3 id="IPv6-基本认识"><a href="#IPv6-基本认识" class="headerlink" title="IPv6 基本认识"></a>IPv6 基本认识</h3><p>IPv6 地址长度是 128 位，是以每 16 位作为一组，每组用冒号 「:」 隔开。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599631076301.png" alt="1599631076301"></p>
<h3 id="IPv6-的优点"><a href="#IPv6-的优点" class="headerlink" title="IPv6 的优点"></a>IPv6 的优点</h3><blockquote>
<p>IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址，即插即用。</p>
<p>IPv6 包头包首部长度采用固定的值 40 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大提高了传输的性能。</p>
<p>IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大提升了安全性。</p>
</blockquote>
<h3 id="IPv6-地址的类型"><a href="#IPv6-地址的类型" class="headerlink" title="IPv6 地址的类型"></a>IPv6 地址的类型</h3><ol>
<li><p>单播地址，用于一对一的通信</p>
<blockquote>
<ul>
<li>在同一链路单播通信，不经过路由器，可以使用链路本地单播地址，IPv4 没有此类型</li>
<li>在内网里单播通信，可以使用唯一本地地址，相当于 IPv4 的私有 IP</li>
<li>在互联网通信，可以使用全局单播地址，相当于 IPv4 的公有 IP</li>
</ul>
</blockquote>
</li>
<li><p>组播地址，用于一对多的通信</p>
</li>
<li><p>任播地址，用于通信最近的节点，最近的节点是由路由协议决定</p>
</li>
<li><p>没有广播地址</p>
</li>
</ol>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599631155764.png" alt="1599631155764"></p>
<h3 id="IPv4-首部与-IPv6-首部"><a href="#IPv4-首部与-IPv6-首部" class="headerlink" title="IPv4 首部与 IPv6 首部"></a>IPv4 首部与 IPv6 首部</h3><p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599631291826.png" alt="1599631291826"></p>
<h3 id="IP（网络层）-和-MAC-（数据链路层）之间的区别和关系"><a href="#IP（网络层）-和-MAC-（数据链路层）之间的区别和关系" class="headerlink" title="IP（网络层） 和 MAC （数据链路层）之间的区别和关系"></a>IP（网络层） 和 MAC （数据链路层）之间的区别和关系</h3><p>IP 的作用是主机之间通信用的，而 MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599626206478.png" alt="1599626206478"></p>
<p>在网络中数据包传输中，源IP地址和目标IP地址在传输过程中是不会变化的，只有 MAC 地址和目标 MAC 一直在变化。</p>
<h3 id="ARP"><a href="#ARP" class="headerlink" title="ARP"></a>ARP</h3><p>在DNS解析域名后，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下一跳。</p>
<p>由于主机的路由表中可以找到下一跳的 IP 地址，所以可以通过 ARP 协议，求得下一跳的 MAC 地址。</p>
<blockquote>
<ul>
<li>主机会通过广播发送 ARP 请求，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。</li>
<li>当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 ARP 响应包返回给主机。</li>
</ul>
</blockquote>
<h3 id="RARP"><a href="#RARP" class="headerlink" title="RARP"></a>RARP</h3><p>已知 MAC 地址求 IP 地址。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。</p>
<h3 id="DHCP"><a href="#DHCP" class="headerlink" title="DHCP"></a>DHCP</h3><p>通过 DHCP 动态获取 IP 地址，大大省去了配IP 信息繁琐的过程。</p>
<p>DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。DHCP 交互中，全程使用 UDP 广播通信。</p>
<h3 id="NAT"><a href="#NAT" class="headerlink" title="NAT"></a>NAT</h3><p>网络地址转换 NAT 的方法，缓解了 IPv4 地址耗尽的问题。</p>
<p>简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。</p>
<p>可以把 IP 地址 + 端口号一起进行转换，这种转换技术就叫网络地址与端口转换 NAPT。</p>
<h3 id="ICMP（互联网控制报文协议）"><a href="#ICMP（互联网控制报文协议）" class="headerlink" title="ICMP（互联网控制报文协议）"></a>ICMP（互联网控制报文协议）</h3><p>ICMP 全称是 Internet Control Message Protocol，也就是互联网控制报文协议。主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599632892092.png" alt="1599632892092"></p>
<p>3：IP 路由器无法将 IP 数据包发送给目标地址时，会给发送端主机返回一个目标不可达的 ICMP 消息，并在这个消息中显示不可达的具体原因，<strong>原因记录在 ICMP 包头的代码字段。</strong></p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599642681552.png" alt="1599642681552"></p>
<p>4：原点抑制消息（ICMP Source Quench Message），当路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向 IP 包的源地址发送一个 ICMP 原点抑制消息。</p>
<p>5：路由器发现发送端主机使用了「不是最优」的路径发送数据，那么它会返回一个 ICMP 重定向消息给这个主机。</p>
<p>11：IP 包中有一个字段叫做 TTL （ Time To Live ，生存周期），它的值随着每经过一次路由器就会减1，直到减到 0 时该 IP 包会被丢弃。设置 IP 包生存周期的主要目的，是为了在路由控制遇到问题发生循环状况时，避免 IP 包无休止地在网络上被转发。</p>
<h3 id="IGMP（因特网组管理协议）"><a href="#IGMP（因特网组管理协议）" class="headerlink" title="IGMP（因特网组管理协议）"></a>IGMP（因特网组管理协议）</h3><p>IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间，</p>
<p>D 类地址，也就是组播地址，只有一组的主机能收到数据包，不在一组的主机不能收到数组包。</p>
<h2 id="Ping命令"><a href="#Ping命令" class="headerlink" title="Ping命令"></a>Ping命令</h2><p>ping 是基于 ICMP 协议工作的。</p>
<p>ICMP 报文是封装在 IP 包里面，它工作在网络层，是 IP 协议的助手。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599633694899.png" alt="1599633694899"></p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599633743475.png" alt="1599633743475"></p>
<p>可以向对端主机发送回送请求的消息（ ICMP Echo Request Message ，类型 8 ），也可以接收对端主机发回来的回送应答消息（ ICMP Echo Reply Message ，类型 0 ）。</p>
<h3 id="ping-的发送和接收过程"><a href="#ping-的发送和接收过程" class="headerlink" title="ping 的发送和接收过程"></a>ping 的发送和接收过程</h3><p>同个子网下的主机 A 和 主机 B，主机 A 执行 ping 主机 B 后，我们来看看其间发送了什么</p>
<ol>
<li><p>构建一个 ICMP 回送请求消息数据包。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599643761263.png" alt="1599643761263"></p>
</li>
<li><p>构建一个 IP 数据包</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599643783667.png" alt="1599643783667"></p>
</li>
<li><p>加入 MAC头</p>
</li>
</ol>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599643796582.png" alt="1599643796582"></p>
<ol>
<li><p>主机 B 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。主机 B 会构建一个 ICMP 回送响应消息数据包</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599646372406.png" alt="1599646372406"></p>
</li>
</ol>
<h2 id="访问网址"><a href="#访问网址" class="headerlink" title="访问网址"></a>访问网址</h2><h3 id="URL解析"><a href="#URL解析" class="headerlink" title="URL解析"></a>URL解析</h3><p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599646805689.png" alt="1599646805689"></p>
<p>当没有路径名时，就代表访问根目录下事先设置的默认文件，也就是 /index.html 或者 /default.html</p>
<h3 id="生产-HTTP-请求信息"><a href="#生产-HTTP-请求信息" class="headerlink" title="生产 HTTP 请求信息"></a>生产 HTTP 请求信息</h3><p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599646862552.png" alt="1599646862552"></p>
<h3 id="查询真实IP地址"><a href="#查询真实IP地址" class="headerlink" title="查询真实IP地址"></a>查询真实IP地址</h3><p>查询服务器域名对应的 IP 地址，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。</p>
<p>DNS 服务器专门保存了 Web 服务器域名与 IP 的对应关系。</p>
<h3 id="协议栈"><a href="#协议栈" class="headerlink" title="协议栈"></a>协议栈</h3><p>把 HTTP 的传输工作交给操作系统中的协议栈，协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599647032468.png" alt="1599647032468"></p>
<h3 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h3><h4 id="基础知识-1"><a href="#基础知识-1" class="headerlink" title="基础知识"></a>基础知识</h4><p>TCP 是面向连接（一对一，UDP可以一对多）的、可靠的、基于字节流的传输层通信协议。</p>
<p>TCP连接，包括Socket、序列号和窗口大小，用于保证可靠性和流量控制维护的某些状态信息。</p>
<ul>
<li>Socket：由 IP 地址和端口号组成</li>
<li>序列号：用来解决乱序问题等</li>
<li>窗口大小：用来做流量控制</li>
</ul>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599650022884.png" alt="1599650022884"></p>
<p>TCP 四元组可以唯一的确定一个连接，端口在TCP头部中，地址在IP头部中。</p>
<h4 id="UDP和TCP"><a href="#UDP和TCP" class="headerlink" title="UDP和TCP"></a>UDP和TCP</h4><p>UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。<br>UDP 协议非常简单，头部只有 8 个字节（ 64 位），UDP 的头部格式如下：</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599650138256.png" alt="1599650138256"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>TCP</th>
<th>UDP</th>
</tr>
</thead>
<tbody>
<tr>
<td>连接</td>
<td>向连接的传输层协议，传输数据前先要建立连接。</td>
<td>不需要连接，即刻传输数据</td>
</tr>
<tr>
<td>服务对象</td>
<td>一对一的两点服务，即一条连接只有两个端点</td>
<td>支持一对一、一对多、多对多的交互通信</td>
</tr>
<tr>
<td>可靠性</td>
<td>是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。</td>
<td>尽最大努力交付，不保证可靠交付数据。</td>
</tr>
<tr>
<td>拥塞控制、流量控制</td>
<td>有拥塞控制和流量控制机制，保证数据传输的安全性。</td>
<td>即使网络非常拥堵了，也不会影响 UDP 的发送速率。</td>
</tr>
<tr>
<td>首部开销</td>
<td>首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使</td>
<td>首部只有 8 个字节，并且是固定不变的，开销较小。</td>
</tr>
<tr>
<td>传输方式</td>
<td>流式传输，没有边界，但保证顺序和可靠。</td>
<td>是一个包一个包的发送，是有边界的，但可能会丢包和乱序。</td>
</tr>
<tr>
<td>分片不同</td>
<td>数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输</td>
<td>数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了一个分片，则就需要重传所有的数据包，这样传输</td>
</tr>
<tr>
<td>应用场景</td>
<td>FTP 文件传输 HTTP / HTTPS</td>
<td>包总量较少的通信，如 DNS 、SNMP 等，视频、音频等多媒体通信</td>
</tr>
</tbody>
</table>
</div>
<p>IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。TCP 是一个工作在传输层的可靠数据传输的服务，它能确保接收端接收的网络包是无损坏、无间隔、非冗余和按序的。</p>
<h4 id="TCP-报文头部的格式"><a href="#TCP-报文头部的格式" class="headerlink" title="TCP 报文头部的格式:"></a>TCP 报文头部的格式:</h4><p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599647186623.png" alt="1599647186623"></p>
<ol>
<li><p>源端口号和目标端口号是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。</p>
</li>
<li><p>序号，在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一<br>次数据，就「累加」一次该「数据字节数」的大小。解决包乱序的问题。</p>
</li>
<li><p>确认号，指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序<br>号以前的数据都已经被正常接收，为了解决不丢包的问题。</p>
</li>
<li><p>控制位。</p>
<blockquote>
<ol>
<li><p>SYN 该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。</p>
<blockquote>
<p>RFC1948 中提出了一个较好的初始化序列号 ISN 随机生成算法。<br>ISN = M + F (localhost, localport, remotehost, remoteport)<br>M 是一个计时器，这个计时器每隔 4 毫秒加 1。<br>F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。</p>
</blockquote>
</li>
<li><p>ACK 该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN包之外该位必须设置为 1 。</p>
</li>
<li><p>RST 该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。</p>
</li>
<li><p>FIN 该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。</p>
<p>TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>窗口大小。TCP 要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，也别发的太慢。</p>
</li>
</ol>
<h4 id="三次握手连接"><a href="#三次握手连接" class="headerlink" title="三次握手连接"></a>三次握手连接</h4><p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599647353466.png" alt="1599647353466"></p>
<ol>
<li>客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN状态。</li>
<li>客户端主动发起连接 SYN ，之后处于 SYN-SENT 状态。</li>
<li>服务端收到发起的连接，返回 SYN ，并且 ACK 客户端的 SYN ，之后处于 SYN-RCVD 状态。</li>
<li>客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK ，之后处于ESTABLISHED 状态，因为它一发一收成功了。</li>
<li>服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。</li>
</ol>
<p>第三次握手是可以携带数据的，前两次握手是不可以携带数据的，</p>
<h4 id="三次握手的原因"><a href="#三次握手的原因" class="headerlink" title="三次握手的原因"></a>三次握手的原因</h4><ol>
<li><p>防止旧的重复连接初始化造成混乱。</p>
<blockquote>
<p>在网络拥堵情况下：<br>一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端；<br>那么此时服务端就会回一个 SYN + ACK 报文给客户端；<br>客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户<br>端就会发送 RST 报文给服务端，表示中止这一次连接。</p>
</blockquote>
</li>
<li><p>同步双方初始序列号</p>
<blockquote>
<p>序列号是可靠传输的一个关键因素，它的作用：<br>接收方可以去除重复的数据；<br>接收方可以根据数据包的序列号按序接收；<br>可以标识发送出去的数据包中， 哪些是已经被对方收到的；</p>
</blockquote>
</li>
<li><p>避免资源浪费</p>
<blockquote>
<p>「两次握手」：如果客户端的 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。</p>
<p>无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；</p>
</blockquote>
</li>
</ol>
<h4 id="TCP四次挥手"><a href="#TCP四次挥手" class="headerlink" title="TCP四次挥手"></a>TCP四次挥手</h4><p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599657284840.png" alt="1599657284840"></p>
<p>等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态</p>
<p><strong>为什么会有四次</strong></p>
<p>服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。</p>
<p><strong>TIME_WAIT 等待的时间是 2MSL</strong></p>
<p>MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。</p>
<p>MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL消耗为 0 的时间，以确保报文已被自然消亡。</p>
<p>TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。</p>
<p><strong>TIME-WAIT的原因</strong></p>
<ol>
<li><p>防止旧连接的数据包</p>
<blockquote>
<p>经过 2MSL 这个时间，足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。</p>
</blockquote>
</li>
<li><p>保证连接正确关闭</p>
<blockquote>
<p>TIME-WAIT 作用是等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</p>
</blockquote>
</li>
</ol>
<h4 id="TCP的重传机制"><a href="#TCP的重传机制" class="headerlink" title="TCP的重传机制"></a>TCP的重传机制</h4><p>TCP 实现可靠传输的方式之一，是通过序列号与确认应答。</p>
<p>TCP 针对数据包丢失的情况，会用重传机制解决。</p>
<h5 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h5><p>在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据</p>
<p>TCP 会在以下两种情况发生超时重传：</p>
<ul>
<li>数据包丢失</li>
<li>确认应答丢失</li>
</ul>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599658362894.png" alt="1599658362894"></p>
<p>RTT （Round-Trip Time 往返时延）：是数据从网络一端传送到另一端所需的时间，也就是包的往返时间。</p>
<p>超时重传时间是以 RTO （Retransmission Timeout 超时重传时间）表示，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。</p>
<h5 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h5><p>快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。不以时间为驱动，而是以数据驱动重传。只解决了超时时间的问题，面临着另外一个问题。就是重传的时候，是重传之前的一个，还是重传所有的问题。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599701097569.png" alt="1599701097569"></p>
<h5 id="SACK-方法"><a href="#SACK-方法" class="headerlink" title="SACK 方法"></a>SACK 方法</h5><p>Selective Acknowledgment 选择性确认</p>
<p>在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。</p>
<h5 id="Duplicate-SACK"><a href="#Duplicate-SACK" class="headerlink" title="Duplicate SACK"></a>Duplicate SACK</h5><p>使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。</p>
<h4 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h4><p>TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。缺点：数据包的往返时间越长，通信的效率就越低。</p>
<p>窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。</p>
<p><strong>发送方的滑动窗口</strong></p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599701589673.png" alt="1599701589673"></p>
<p>TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。</p>
<p><strong>接收方的滑动窗口</strong></p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599701705091.png" alt="1599701705091"></p>
<h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h4><p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。</p>
<p><strong>窗口关闭，潜在死锁</strong></p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599702117779.png" alt="1599702117779"></p>
<p>TCP 为每个连接设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。如果持续计时器超时，就会发送窗口探测 ( Window probe ) 报文，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。</p>
<p>窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 RST 报文来中断连接。</p>
<p><strong>糊涂窗口综合症</strong></p>
<p>如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症。TCP + IP 头有 40 个字节，为了传输那几个字节的数据，要达上这么大的开销，这太不经济了。</p>
<ul>
<li>让接收方不通告小窗口给发送方</li>
<li>让发送方避免发送小数据</li>
</ul>
<h4 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h4><p>避免「发送方」的数据填满整个网络。</p>
<p>拥塞控制主要是四个算法：</p>
<ul>
<li><p>慢启动：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。（是指数性的增长）</p>
</li>
<li><p>拥塞避免：拥塞避免算法：每当收到一个 ACK 时，cwnd 增加 1/cwnd（线性增长）</p>
</li>
<li><p>拥塞发生：（会发生数据包重传）</p>
<blockquote>
<p>超时重传：ssthresh 设为 cwnd/2；cwnd 重置为 1，重新进入慢启动</p>
<p>快速重传：cwnd = cwnd/2 ，也就是设置为原来的一半;ssthresh = cwnd ;进入快速恢复算法</p>
</blockquote>
</li>
<li><p>快速恢复</p>
<blockquote>
<p>拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）；<br>重传丢失的数据包；<br>如果再收到重复的 ACK，那么 cwnd 增加 1；<br>如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新<br>的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的<br>状态了，也即再次进入拥塞避免状态；</p>
</blockquote>
</li>
</ul>
<h4 id="TCP半连接队和全连接队"><a href="#TCP半连接队和全连接队" class="headerlink" title="TCP半连接队和全连接队"></a>TCP半连接队和全连接队</h4><ul>
<li>半连接队列，也称 SYN 队列；</li>
<li>全连接队列，也称 accepet 队列；</li>
</ul>
<h4 id="TCP分割数据"><a href="#TCP分割数据" class="headerlink" title="TCP分割数据"></a>TCP分割数据</h4><p>MTU ：一个网络包的最大长度，以太网中一般为 1500 字节；<br>MSS ：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599647484820.png" alt="1599647484820"></p>
<p>如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。</p>
<p><strong>如果使用IP分片</strong></p>
<p>IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。</p>
<p>当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。</p>
<h4 id="TCP报文生成"><a href="#TCP报文生成" class="headerlink" title="TCP报文生成"></a>TCP报文生成</h4><p>TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 80 ， HTTPS 默认端口号是 443 ）。</p>
<p>网络包：</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599647574610.png" alt="1599647574610"></p>
<h4 id="SYN-攻击"><a href="#SYN-攻击" class="headerlink" title="SYN 攻击"></a>SYN 攻击</h4><p>假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务。</p>
<p><strong>解决办法</strong></p>
<ol>
<li><p>通过修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理。</p>
<blockquote>
<p>当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。</p>
<p>SYN_RCVD 状态连接的最大个数：</p>
<p>超出处理能时，对新的 SYN 直接回报 RST，丢弃连接：</p>
</blockquote>
</li>
</ol>
<h3 id="IP-报文头部"><a href="#IP-报文头部" class="headerlink" title="IP 报文头部"></a>IP 报文头部</h3><p>TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成网络包发送给通信对象。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599647663399.png" alt="1599647663399"></p>
<p>HTTP 是经过 TCP 传输的，所以在 IP 包头的协议号，要填写为 06 （十六进制），表示协议为TCP。</p>
<p>当存在多个网卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。</p>
<p>目标地址和子网掩码都是 0.0.0.0 ，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器， Gateway 即是路由器的 IP 地址。</p>
<h3 id="MAC头部"><a href="#MAC头部" class="headerlink" title="MAC头部"></a>MAC头部</h3><p>在 MAC 包头里需要发送方 MAC 地址和接收方目标 MAC 地址，用于两点之间的传输。<br>一般在 TCP/IP 通信里，MAC 包头的协议类型只使用：</p>
<ul>
<li>0800 ： IP 协议</li>
<li>0806 ： ARP 协议</li>
</ul>
<p>MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。</p>
<h3 id="网卡"><a href="#网卡" class="headerlink" title="网卡"></a>网卡</h3><p>IP 生成的网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，需要<strong>将数字信息转换为电信号</strong>，才能在网线上传输，负责执行这一操作的是<strong>网卡，要控制网卡还需要靠网卡驱动程序。</strong></p>
<p>网卡驱动从 IP 模块获取到包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上<strong>报头和起始帧分界符</strong>，在末尾加上<strong>用于检测错误的帧校验序列</strong>。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599648804365.png" alt="1599648804365"></p>
<p>网卡会将包转为电信号，通过网线发送出去</p>
<h3 id="交换机"><a href="#交换机" class="headerlink" title="交换机"></a>交换机</h3><p>交换机的设计是将网络包原样转发到目的地。交换机工作在MAC 层，也称为二层网络设备。</p>
<p>交换机的端口不具有 MAC 地址，直接接收所有的包并存放到缓冲区中，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录。根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。</p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599648944157.png" alt="1599648944157"></p>
<h3 id="路由器"><a href="#路由器" class="headerlink" title="路由器"></a>路由器</h3><p>网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。</p>
<ul>
<li>因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；</li>
<li>而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。</li>
</ul>
<p>完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。<br>MAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。</p>
<p><strong>查询路由表判断转发目标</strong></p>
<p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599649188561.png" alt="1599649188561"></p>
<h3 id="服务器和客户端"><a href="#服务器和客户端" class="headerlink" title="服务器和客户端"></a>服务器和客户端</h3><p><img src="/2020/09/09/%E7%BD%91%E7%BB%9C%E5%B8%B8%E8%A7%81%E7%9F%A5%E8%AF%86/1599649299268.png" alt="1599649299268"></p>
<h3 id="路由器和交换机"><a href="#路由器和交换机" class="headerlink" title="路由器和交换机"></a>路由器和交换机</h3><p>现在家里的路由器其实有了交换机的功能了。交换机可以简单理解成一个设备，三台电脑网线接到这个设备，这三台电脑就可以互相通信了，交换机嘛，交换数据这么理解就可以。</p>
<h2 id="TCP三次握手，四次挥手"><a href="#TCP三次握手，四次挥手" class="headerlink" title="TCP三次握手，四次挥手"></a>TCP三次握手，四次挥手</h2>]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>tcp</tag>
        <tag>IP</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo-如何支持数学公式</title>
    <url>/2020/09/04/hexo-%E5%A6%82%E4%BD%95%E6%94%AF%E6%8C%81%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</url>
    <content><![CDATA[<p>最近在学习hands on sklearn这本书，用Typora做笔记时有大量公式，今天发现hexo默认不支持数学公式。</p>
<h2 id="前因"><a href="#前因" class="headerlink" title="前因"></a>前因</h2><p>Hexo默认使用<code>hexo-renderer-marked</code>引擎渲染网页，该引擎会把一些特殊的markdown符号转换为相应的html标签，比如下划线’_’会被渲染引擎处理为<code>&lt;em&gt;</code>标签,这样MathJax引擎就认为该公式有语法错误，因此不会渲染。</p>
<a id="more"></a>
<p>类似的语义冲突的符号还包括’*’, ‘{‘, ‘}’, ‘\’等。</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><h3 id="使用hexo-renderer-kramed引擎渲染"><a href="#使用hexo-renderer-kramed引擎渲染" class="headerlink" title="使用hexo-renderer-kramed引擎渲染"></a>使用<code>hexo-renderer-kramed</code>引擎渲染</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure>
<p>但<code>hexo-renderer-kramed</code>引擎也有语义冲突（行内公式，{问题）：</p>
<p>接下来到博客根目录下，找到<code>node_modules\kramed\lib\rules\inline.js</code>，修改如下两处</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">//  escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,</span><br><span class="line">  escape: /^\\([`*\[\]()#$+\-.!_&gt;])/</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">//  em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br><span class="line">  em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/</span><br></pre></td></tr></table></figure>
<h3 id="在主题文件中开启mathjax开关"><a href="#在主题文件中开启mathjax开关" class="headerlink" title="在主题文件中开启mathjax开关"></a>在主题文件中开启mathjax开关</h3><p>进入主题目录，打开<code>_config.yml</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Math Formulas Render Support</span></span><br><span class="line">math:</span><br><span class="line">  per_page: true</span><br><span class="line">  engine: mathjax   </span><br><span class="line">  mathjax:</span><br><span class="line">    enable: true    </span><br><span class="line">    mhchem: true</span><br></pre></td></tr></table></figure>
<h3 id="在Front-matter中打开mathjax开关"><a href="#在Front-matter中打开mathjax开关" class="headerlink" title="在Front-matter中打开mathjax开关"></a>在Front-matter中打开mathjax开关</h3><p>因为之前配置文件中设置了<code>per_page: true</code>，意味着：</p>
<blockquote>
<p>Default (true) will load mathjax / katex script on demand.</p>
<p>That is it only render those page which has <code>mathjax: true</code> in Front-matter.</p>
<p>If you set it to false, it will load mathjax / katex srcipt EVERY PAGE.</p>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: </span><br><span class="line">date: </span><br><span class="line">tags:</span><br><span class="line">category: </span><br><span class="line">mathjax: true</span><br><span class="line">--</span><br></pre></td></tr></table></figure>
<p>但我把<code>per_page: false</code>，尝试不在front-matter中加上 <code>mathjax: true</code> ，没有效果。</p>
<hr>
<p>参考：</p>
<p><a href="https://blog.csdn.net/ssjdoudou/article/details/103318019" target="_blank" rel="noopener">https://blog.csdn.net/ssjdoudou/article/details/103318019</a></p>
<p><a href="https://www.jianshu.com/p/7ab21c7f0674" target="_blank" rel="noopener">https://www.jianshu.com/p/7ab21c7f0674</a></p>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo-next主题设置</title>
    <url>/2020/09/04/hexo-next%E4%B8%BB%E9%A2%98%E8%AE%BE%E7%BD%AE/</url>
    <content><![CDATA[<h2 id="NexT主题开启文章目录"><a href="#NexT主题开启文章目录" class="headerlink" title="NexT主题开启文章目录"></a>NexT主题开启文章目录</h2><p>参考这篇<a href="https://blog.csdn.net/wugenqiang/article/details/88609066" target="_blank" rel="noopener">博客</a></p>
<h3 id="修改样式文件"><a href="#修改样式文件" class="headerlink" title="修改样式文件"></a>修改样式文件</h3><a id="more"></a>
<p>在<code>custom.styl</code>文件（位于<code>themes/next/source/css/_custom下</code>）后添加</p>
<p>文章目录展开</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">//文章目录默认展开</span><br><span class="line">.post-toc .nav .nav-child &#123; display: block; &#125;</span><br></pre></td></tr></table></figure>
<p>以及目录字体大小调整</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">.post-toc ol &#123;  </span><br><span class="line">  font-size : <span class="number">13</span>px;     </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>打开主题的配置文件<code>_config.yml</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">toc:</span><br><span class="line">  enable: true</span><br><span class="line">  <span class="comment"># Automatically add list number to toc.</span></span><br><span class="line">  number: false</span><br><span class="line">  <span class="comment"># If true, all words will placed on next lines if header width longer then sidebar width.</span></span><br><span class="line">  wrap: false</span><br><span class="line">  <span class="comment"># If true, all level of TOC in a post will be displayed, rather than the activated part of it.</span></span><br><span class="line">  expand_all: false</span><br><span class="line">  <span class="comment"># Maximum heading depth of generated toc.</span></span><br><span class="line">  max_depth: <span class="number">4</span></span><br></pre></td></tr></table></figure>
<p>PS: 我的主题目录下没有·custom.styl·这个文件（<code>themes/next/source/css/_custom</code>），但最终也能生成目录ORZ。</p>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库知识点大总结</title>
    <url>/2020/09/07/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9F%A5%E8%AF%86%E5%A4%A7%E7%9B%98%E7%82%B9/</url>
    <content><![CDATA[<p>转载来源：<a href="https://blog.csdn.net/wugenqiang/article/details/106501338" target="_blank" rel="noopener">数据库面试题</a></p>
<h2 id="数据库基本知识"><a href="#数据库基本知识" class="headerlink" title="数据库基本知识"></a>数据库基本知识</h2><h3 id="范式的定义"><a href="#范式的定义" class="headerlink" title="范式的定义"></a>范式的定义</h3><p>改造关系模式，通过分解关系模型来消除其中不合适的数据依赖，以决绝插入异常，删除异常，数据用余。</p>
<a id="more"></a>
<h3 id="数据库三大范式是什么"><a href="#数据库三大范式是什么" class="headerlink" title="数据库三大范式是什么"></a>数据库三大范式是什么</h3><p>第一范式（1NF）：关系模式 R 中每个列都不可以再拆分。</p>
<p>第二范式（2NF）：在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分。</p>
<p>第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键。</p>
<p>在设计数据库结构的时候，要尽量遵守三范式，如果不遵守，必须有足够的理由。比如性能。</p>
<h3 id="mysql有关权限的表"><a href="#mysql有关权限的表" class="headerlink" title="mysql有关权限的表"></a>mysql有关权限的表</h3><p>MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别user，db，table_priv，columns_priv和host。下面分别介绍一下这些表的结构和内容：</p>
<ul>
<li>user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。</li>
<li>db权限表：记录各个帐号在各个数据库上的操作权限。</li>
<li>table_priv权限表：记录数据表级的操作权限。</li>
<li>columns_priv权限表：记录数据列级的操作权限。</li>
<li>host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。</li>
</ul>
<h3 id="MySQL的binlog的3种录入格式"><a href="#MySQL的binlog的3种录入格式" class="headerlink" title="MySQL的binlog的3种录入格式"></a>MySQL的binlog的3种录入格式</h3><p>有三种格式，statement，row和mixed。</p>
<ul>
<li>statement模式下，每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。</li>
<li>row级别下，不记录sql语句上下文相关信息，仅保存哪条记录被修改。记录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存的信息太多，日志量太大。</li>
<li>mixed，一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。</li>
</ul>
<p>此外，新版的MySQL中对row级别也做了一些优化，当表结构发生变化的时候，会记录语句而不是逐行记录。</p>
<h3 id="⭐什么是数据字典"><a href="#⭐什么是数据字典" class="headerlink" title="⭐什么是数据字典"></a>⭐什么是数据字典</h3><p>数据字典是关系数据库管理系统内部的一组系统表，它<strong>记录了数据库中所有的定义信息</strong>，包括关系模式定义、视图定义、索引定义、完整性约束定义、各类用户对数据库的操作权限、统计信息等。<strong>关系数据库管理系统在执行 SQL 的数据定义语句时，实际上就是在更新数据字典中的相应信息</strong></p>
<h2 id="关系数据库"><a href="#关系数据库" class="headerlink" title="关系数据库"></a>关系数据库</h2><h3 id="关系型数据库和非关系型数据库比较"><a href="#关系型数据库和非关系型数据库比较" class="headerlink" title="关系型数据库和非关系型数据库比较"></a>关系型数据库和非关系型数据库比较</h3><h4 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库:"></a>关系型数据库:</h4><ul>
<li>采用了关系模型来组织数据的数据库，以行和列形式存储数据，以便于用户理解。</li>
<li>通用的 SQL 语言使得操作关系型数据库非常方便。</li>
<li>关系型数据库遵循 ACID 原则。</li>
<li>常见的关系型数据库比如 MySQL，Oracle</li>
</ul>
<p><strong>关系型数据库存在的问题</strong>：</p>
<ul>
<li>网站的用户并发性非常高，往往达到每秒上万次读写请求，对于传统关系型数据库来说，硬盘 I/O 是一个很大的瓶颈</li>
<li>网站每天产生的数据量是巨大的，对于关系型数据库来说，在一张包含海量数据的表中查询，效率是非常低的。因此，关系型数据不适合持久存储海量数据</li>
<li>很难进行横向扩展（增加服务器），也就是说想要提高数据处理能力，要使用性能更好的计算机（纵向扩展）</li>
<li>性能欠佳：导致关系型数据库性能欠佳的最主要原因就是多表的关联查询，为了保证数据库的ACID特性，必须尽量按照范式要求设计数据库，关系数据库中的表存储的往往是一个固定的、格式化的数据结构</li>
</ul>
<p>而非关系型数据库就可以很好的解决关系型数据库很难解决的大数据问题</p>
<h4 id="非关系型数据库-NoSQL"><a href="#非关系型数据库-NoSQL" class="headerlink" title="非关系型数据库 NoSQL"></a>非关系型数据库 NoSQL</h4><ul>
<li>非关系型数据库以键值对存储，且结构不固定，每一个元组可以有不一样的字段，每个元组可以根据需要增加一些自己的键值对，不局限于固定的结构，可以减少一些时间和空间的开销。</li>
<li>支持分布式存储，容易进行横向扩展</li>
<li>不遵循 ACID 特性（不提供对事务的处理）</li>
<li>常见的非关系型数据库比如 Redis、MongoDB、Elasticsearch</li>
</ul>
<h3 id="数据库连接池"><a href="#数据库连接池" class="headerlink" title="数据库连接池"></a>数据库连接池</h3><h4 id="①-概述"><a href="#①-概述" class="headerlink" title="① 概述"></a>① 概述</h4><p>数据库连接池是负责分配、管理和释放数据库连接，它<strong>允许应用程序重复使用一个现有的数据库连接</strong>，而不是每次访问数据库的时候都需要重新建立一次连接。</p>
<h4 id="②-为什么要使用连接池"><a href="#②-为什么要使用连接池" class="headerlink" title="② 为什么要使用连接池"></a>② 为什么要使用连接池</h4><p><strong> 数据库连接是一种关键的有限的昂贵的资源</strong> ，这一点在多用户的网页应用程序中体现得尤为突出。 一个数据库连接对象均对应一个物理数据库连接，每次操作都打开一个物理连接，使用完都关闭连接，这样造成系统的性能低下。</p>
<p>数据库连接池的解决方案是在应用程序启动时建立足够的数据库连接，并将这些连接组成一个连接池，由应用程序动态地对池中的连接进行申请、使用和释放。对于多于连接池中连接数的并发请求，应该在请求队列中排队等待。并且应用程序可以根据池中连接的使用率，动态增加或减少池中的连接数。</p>
<p>连接池技术尽可能多地重用了消耗内存地资源，大大节省了内存，提高了服务器地服务效率，能够支持更多的客户服务。通过使用连接池，将大大提高程序运行效率，同时，我们可以通过其自身的管理机制来监视数据库连接的数量、使用情况等。</p>
<h4 id="③-传统的连接机制与连接池运行机制区别"><a href="#③-传统的连接机制与连接池运行机制区别" class="headerlink" title="③ 传统的连接机制与连接池运行机制区别"></a>③ 传统的连接机制与连接池运行机制区别</h4><p>执行一个 SQL 命令</p>
<p><strong>不使用数据库连接池的步骤</strong>：</p>
<ul>
<li>TCP建立连接三次握手</li>
<li>MySQL认证三次握手</li>
<li>真正的SQL执行</li>
<li>MySQL关闭</li>
<li>TCP四次挥手关闭</li>
</ul>
<p>可以看到，为了执行一条SQL，却多了非常多网络交互，应用需要频繁的创建连接和关闭连接。</p>
<p><strong>使用数据库连接池的步骤</strong>：</p>
<p>第一次访问的时候，需要建立连接。 但是之后的访问，均会复用之前创建的连接，直接执行SQL语句。</p>
<h3 id="超键、候选键、主键、外键分别是什么"><a href="#超键、候选键、主键、外键分别是什么" class="headerlink" title="超键、候选键、主键、外键分别是什么"></a>超键、候选键、主键、外键分别是什么</h3><ul>
<li><strong>⭐超键</strong>：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。</li>
<li><strong>⭐候选键</strong>：即最小超键，即没有冗余元素的超键。候选键中的元素称为<strong>主属性</strong></li>
<li><strong>主键</strong>：候选键中选出一个作为主键，一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。</li>
<li><strong>外键</strong>：在一个表中存在的另一个表的主键称此表的外键。</li>
</ul>
<h4 id="主键和外键的区别"><a href="#主键和外键的区别" class="headerlink" title="主键和外键的区别"></a>主键和外键的区别</h4><p>主键在本表中是唯一的、不可为空的，外键可以重复可以为空；外键和另一张表的主键关联，不能创建对应表中不存在的外键。</p>
<h3 id="主码和外码"><a href="#主码和外码" class="headerlink" title="主码和外码"></a>主码和外码</h3><p>若关系中某一属性组的值能唯一地标识一个元组，而其子集不能，则称该属性组为<strong>候选码</strong>，若一个关系有多个候选码，则选定其中一个为<strong>主码</strong>。</p>
<p>如果F是基本关系R的一个或一组属性，但不是关系R的码，Ks是基本关系S的主码。如果F与Ks相对应，则称F是R的<strong>外码</strong>。</p>
<blockquote>
<p>类似外键：F不是R的主键，但是是另一个关系S的主键，则F是R的外键</p>
</blockquote>
<h3 id="⭐完整性约束"><a href="#⭐完整性约束" class="headerlink" title="⭐完整性约束"></a>⭐完整性约束</h3><p>数据库的完整性是指<strong>数据的正确性和相容性</strong>。</p>
<ul>
<li>数据的正确性是指数据是符合现实世界语义、反映当前实际状况的。</li>
<li>数据的相容性是指数据库同一对象在不同关系表中的数据是符合逻辑的。</li>
</ul>
<p>l <strong>实体完整性</strong>：若属性A是基本关系B的主属性，则A不能取空值（所谓空值是指不知道，不存在，无意义的值）</p>
<p>l <strong>参照完整性</strong>：若属性F是基本关系R的外码，它与基本关系S的主码Ks相对应，则对于R中每个元组在F上的值必须：</p>
<p>² 或者取空值（F的每个属性值均为空值）</p>
<p>² 或者等于S中某个元组的主码值</p>
<p>（某个同学班长属性可以是尚为选出班长，也可以是本关系中某个元组的学号值）</p>
<p>l <strong>用户定义完整性</strong>：针对某一具体关系数据库的约束条件，反映某一具体应用涉及的数据必须满足的语义要求（如某个属性必须取唯一值，某个非主属性不能取空值）</p>
<h2 id="常用SQL语句"><a href="#常用SQL语句" class="headerlink" title="常用SQL语句"></a>常用SQL语句</h2><h3 id="SQL-的四个组成部分-⭐"><a href="#SQL-的四个组成部分-⭐" class="headerlink" title="SQL 的四个组成部分 ⭐"></a>SQL 的四个组成部分 ⭐</h3><ol>
<li>数据库模式定义语言DDL：create用来创建数据库中的各种对象——表、视图、索引、同义词、聚簇等</li>
<li>数据查询语言dql：基本结构是由SELECT子句，FROM子句和WHERE子句组成的查询块</li>
<li>数据操纵语言dml：插入INSERT、更新UPDATE和删除DELETE</li>
<li>数据控制语言dcl：用来授予或回收访问数据库的某种特权，并控制数据库操纵事物发生的时间和效果，对数据库实行监视等</li>
</ol>
<h3 id="SQL-约束"><a href="#SQL-约束" class="headerlink" title="SQL 约束"></a>SQL 约束</h3><ul>
<li>NOT NULL: 用于控制字段的内容一定不能为空（NULL）。</li>
<li>UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。</li>
<li>PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。</li>
<li>FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。</li>
<li>CHECK: 用于控制字段的值范围。</li>
</ul>
<h3 id="六种关联查询"><a href="#六种关联查询" class="headerlink" title="六种关联查询"></a>六种关联查询</h3><ul>
<li><p>交叉连接（CROSS JOIN）</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM A,B(,C)或者SELECT * FROM A CROSS JOIN B (CROSS JOIN C)#没有任何关联条件，结果是笛卡尔积，结果集会很大，没有意义，很少使用</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>内连接（INNER JOIN）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT * FROM A,B WHERE A.id&#x3D;B.id </span><br><span class="line">SELECT * FROM A INNER JOIN B ON A.id&#x3D;B.id #多表中同时符合某种条件的数据记录的集合，INNER JOIN可以缩写为JOIN</span><br></pre></td></tr></table></figure>
<blockquote>
<p>等值连接：ON A.id=B.id</p>
<p>不等值连接：ON A.id &gt; B.id</p>
<p>自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid</p>
</blockquote>
</li>
<li><p>外连接（LEFT JOIN/RIGHT JOIN）</p>
<blockquote>
<p>左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN<br>右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN</p>
</blockquote>
</li>
<li><p>联合查询（UNION与UNION ALL）</p>
<blockquote>
<p>把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并<br>如果使用UNION ALL，不会合并重复的记录行<br>效率 UNION 高于 UNION ALL</p>
</blockquote>
</li>
<li><p>全连接（FULL JOIN）</p>
<blockquote>
<p>MySQL不支持全连接<br>可以使用LEFT JOIN 和UNION和RIGHT JOIN联合使用</p>
</blockquote>
</li>
</ul>
<h3 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h3><blockquote>
<ol>
<li>条件：一条SQL语句的查询结果做为另一条查询语句的条件或查询结果</li>
<li>嵌套：多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。</li>
</ol>
</blockquote>
<h3 id="子查询的三种情况"><a href="#子查询的三种情况" class="headerlink" title="子查询的三种情况"></a>子查询的三种情况</h3><ul>
<li>子查询是单行单列的情况：结果集是一个值，父查询使用：=、 &lt;、 &gt; 等运算符</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 查询工资最高的员工是谁？ </span><br><span class="line">select  * from employee where salary&#x3D;(select max(salary) from employee);</span><br></pre></td></tr></table></figure>
<ul>
<li>子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select id from Stduent where id in (select id from SC);</span><br></pre></td></tr></table></figure>
<ul>
<li>子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 1) 查询出2011年以后入职的员工信息</span><br><span class="line">-- 2) 查询所有的部门信息，与上面的虚拟表中的信息比对，找出所有部门ID相等的员工。</span><br><span class="line">select * from dept d,  (select * from employee where join_date &gt; &#39;2011-1-1&#39;) e where e.dept_id &#x3D;  d.id;    </span><br><span class="line"></span><br><span class="line">-- 使用表连接：</span><br><span class="line">select d.*, e.* from  dept d inner join employee e on d.id &#x3D; e.dept_id where e.join_date &gt;  &#39;2011-1-1&#39;</span><br></pre></td></tr></table></figure>
<h3 id="in-和-exists-的区别"><a href="#in-和-exists-的区别" class="headerlink" title="in 和 exists 的区别"></a>in 和 exists 的区别</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select id from Student where id exists (select id from SC);</span><br><span class="line">select id from Stduent where id in (select id from SC);</span><br></pre></td></tr></table></figure>
<ul>
<li><p>in 先进行子查询 select id from SC，再进行外查询 select id from Student</p>
<p>exists 先执行外查询，再执行子查询</p>
</li>
<li><p>in 语句是把外表和内表作连接</p>
<p>而 exists 语句是对外表作循环，每次循环再对内表进行查询</p>
</li>
<li><p>exists 适合子查询的表比外查询大的查询语句</p>
<p>如果内表和外表差不多大，那么 in 和 exists 的效率差别不大</p>
</li>
</ul>
<h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3VnZW5xaWFuZy9QaWN0dXJlQmVkL3Jhdy9tYXN0ZXIvQ1MtTm90ZXMvMjAyMDA0MjkxMDAwMzcucG5n?x-oss-process=image/format,png" alt="image-20200429100036635"></p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3VnZW5xaWFuZy9QaWN0dXJlQmVkL3Jhdy9tYXN0ZXIvQ1MtTm90ZXMvMjAyMDA0MjkxMDAxMDAucG5n?x-oss-process=image/format,png" alt="image-20200429100059106"></p>
<h4 id="整数类型"><a href="#整数类型" class="headerlink" title="整数类型"></a>整数类型</h4><p>TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。</p>
<p>长度：整数类型可以被指定长度，例如：INT(11)表示长度为11的INT类型。长度在大多数场景是没有意义的，它不会限制值的合法范围，只会影响显示字符的个数，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。</p>
<p>例子，假定类型设定为INT(5)，属性为UNSIGNED ZEROFILL，如果用户插入的数据为12的话，那么数据库实际存储数据为00012。仍占4字节存储，存储范围不变，不影响内部存储。</p>
<h4 id="实数类型"><a href="#实数类型" class="headerlink" title="实数类型"></a>实数类型</h4><p>FLOAT（存储至多8位十进制数，4字节）、DOUBLE（存储至多18位十进制数，8字节）、DECIMAL。</p>
<p>DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。<br>而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算。<br>计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。</p>
<h4 id="日期和时间类型"><a href="#日期和时间类型" class="headerlink" title="日期和时间类型"></a>日期和时间类型</h4><p>year, date, time, datetime, timestep</p>
<p>尽量使用timestamp，空间效率高于datetime，<br>用整数保存时间戳通常不方便处理。</p>
<h4 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h4><p>VARCHAR、CHAR、TEXT、BLOB</p>
<p>CHAR是定长的，根据定义的字符串长度分配足够的空间，会根据需要使用空格进行填充方便比较，适合存储很短的字符串，或者所有值都接近同一个长度。存储的内容超出设置的长度时，内容会被截断。</p>
<p>VARCHAR用于存储可变长字符串，列长度小于255字节时，使用1字节表示，否则使用2字节表示，存储的内容超出设置的长度时，内容会被截断，比定长类型更节省空间。使用额外1或2个字节存储字符串长度。</p>
<p>varchar(50)中50的表示最多存放50个字符，varchar(50)和(200)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计算col长度(memory引擎也一样)。在早期 MySQL 版本中， 50 代表字节数，现在代表字符数。</p>
<p><strong>使用策略：</strong><br>对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片。<br>对于非常短的列，CHAR比VARCHAR在存储空间上更有效率。<br>使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。<br>尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。</p>
<h4 id="枚举类型（ENUM）"><a href="#枚举类型（ENUM）" class="headerlink" title="枚举类型（ENUM）"></a>枚举类型（ENUM）</h4><p>把不重复的数据存储为一个预定义的集合。</p>
<p>有时可以使用ENUM代替常用的字符串类型。<br>ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。<br>ENUM在内部存储时，其实存的是整数。<br>尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。<br>排序是按照内部存储的整数</p>
<h3 id="drop、delete与truncate的区别"><a href="#drop、delete与truncate的区别" class="headerlink" title="drop、delete与truncate的区别"></a>drop、delete与truncate的区别</h3><p>三者都表示删除，但是三者有一些差别：</p>
<h4 id="delete"><a href="#delete" class="headerlink" title="delete"></a>delete</h4><p>1、delete是DML，执行delete操作时，每次从表中删除一行，并且同时将该行的的删除操作记录在redo和undo表空间中以便进行回滚（rollback）和重做操作，但要注意表空间要足够大，需要手动提交（commit）操作才能生效，可以通过rollback撤消操作。</p>
<p>2、delete可根据条件删除表中满足条件的数据，如果不指定where子句，那么删除表中所有记录。</p>
<p>3、delete语句不影响表所占用的extent，高水线(high watermark)保持原位置不变。</p>
<h4 id="truncate"><a href="#truncate" class="headerlink" title="truncate"></a>truncate</h4><p>1、truncate是DDL，会隐式提交，所以，不能回滚，不会触发触发器。</p>
<p>2、truncate会删除表中所有记录，并且将重新设置高水线和所有的索引，缺省情况下将空间释放到minextents个extent，除非使用reuse storage，。不会记录日志，所以执行速度很快，但不能通过rollback撤消操作（如果一不小心把一个表truncate掉，也是可以恢复的，只是不能通过rollback来恢复）。</p>
<p>3、对于外键（foreignkey ）约束引用的表，不能使用 truncate table，而应使用不带 where 子句的 delete 语句。</p>
<p>4、truncatetable不能用于参与了索引视图的表。</p>
<h4 id="drop"><a href="#drop" class="headerlink" title="drop"></a>drop</h4><p>1、drop是DDL，会隐式提交，所以，不能回滚，不会触发触发器。</p>
<p>2、drop语句删除表结构及所有数据，并将表所占用的空间全部释放。</p>
<p>3、drop语句将删除表的结构所依赖的约束，触发器，索引，依赖于该表的存储过程/函数将保留,但是变为invalid状态。</p>
<h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p>1、在速度上，一般来说，drop&gt; truncate &gt; delete。</p>
<p>2、在使用drop和truncate时一定要注意，虽然可以恢复，但为了减少麻烦，还是要慎重。</p>
<p>3、如果想删除部分数据用delete，注意带上where子句，回滚段要足够大；</p>
<p>   如果想删除表，当然用drop； </p>
<p>   如果想保留表而将所有数据删除，如果和事务无关，用truncate即可；</p>
<p>   如果和事务有关，或者想触发trigger，还是用delete；</p>
<p>   如果是整理表内部的碎片，可以用truncate跟上reuse stroage，再重新导入/插入数据。</p>
<h3 id="SQL-的生命周期"><a href="#SQL-的生命周期" class="headerlink" title="SQL 的生命周期"></a>SQL 的生命周期</h3><ol>
<li>应用服务器与数据库服务器建立一个连接</li>
<li>数据库进程拿到请求sql</li>
<li>解析并生成执行计划，执行</li>
<li>读取数据到内存并进行逻辑处理</li>
<li>通过步骤一的连接，发送结果到客户端</li>
<li>关掉连接，释放资源</li>
</ol>
<h3 id="在数据库中查询语句速度很慢，应如何优化"><a href="#在数据库中查询语句速度很慢，应如何优化" class="headerlink" title="在数据库中查询语句速度很慢，应如何优化"></a>在数据库中查询语句速度很慢，应如何优化</h3><ol>
<li>建索引</li>
<li>减少表之间的关联</li>
<li>优化 SQL，尽量让 SQL 很快定位数据，不要让 SQL 做全表查询，应该走索引，把数据量大的表排在前面</li>
<li>简化查询字段，没用的字段不要，已经对返回结果的控制，尽量返回少量数据</li>
<li>尽量用 Prepared Statement 来查询，不要用 Statement</li>
</ol>
<h3 id="超大分页怎么处理？"><a href="#超大分页怎么处理？" class="headerlink" title="超大分页怎么处理？"></a>超大分页怎么处理？</h3><p>超大的分页一般从两个方向上来解决.</p>
<ul>
<li><p>数据库层面：核心减少load的数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 下面第一条语句需要load1000000数据，只取10条，基本上全部丢弃,所以很慢</span><br><span class="line">select * from table where age &gt; 20 limit 1000000,10</span><br><span class="line">select * from table where id in (select id from table where age &gt; 20 limit 1000000,10)</span><br><span class="line"></span><br><span class="line">select * from table where id &gt; 1000000 limit 10</span><br></pre></td></tr></table></figure>
</li>
<li><p>从需求的角度减少这种请求：不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击.</p>
</li>
</ul>
<h3 id="Union-和-Union-All-有什么不同"><a href="#Union-和-Union-All-有什么不同" class="headerlink" title="Union 和 Union All 有什么不同"></a>Union 和 Union All 有什么不同</h3><p>UNION 在进行表链接后会筛选掉重复的记录，所以在表链接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。实际大部分应用中是不会产生重复的记录，最常见的是过程表与历史表 UNION。 </p>
<p>UNION ALL 只是简单的将两个结果合并后就返回。 </p>
<p>从效率上说，UNION ALL 要比 UNION 快很多，如果可以确认合并的两个结果集中不包含重复的数据的话，那么就使用 UNION ALL。</p>
<h3 id="order-by-和-group-by-的区别"><a href="#order-by-和-group-by-的区别" class="headerlink" title="order by 和 group by 的区别"></a>order by 和 group by 的区别</h3><p>order by 排序查询、asc 升序、desc 降序 </p>
<p>group by 分组查询、having 只能用于 group by 子句，作用于组内，having 条件子句可以直接跟函数表达式。使用 group by 子句的查询语句需要使用聚合函数。</p>
<h3 id="什么是-PL-SQL"><a href="#什么是-PL-SQL" class="headerlink" title="什么是 PL / SQL"></a>什么是 PL / SQL</h3><p>PL / SQL 是一种程序语言，叫做过程化 SQL 语言（Procedural Language/SQL）。PL / SQL 是 Oracle 数据库对 SQL 语句的扩展。在普通 SQL 语句的使用上增加了编程语言的特点，所以 PL / SQL 把数据操作和查询语句组织在 PL / SQL 代码的过程性单元中，通过逻辑判断、循环等操作实现复杂的功能或者计算。</p>
<p>PL / SQL 只有 Oracle 数据库有。 MySQL 目前不支持 PL / SQL 的。</p>
<h2 id="引擎"><a href="#引擎" class="headerlink" title="引擎"></a>引擎</h2><p>存储引擎Storage engine：数据、索引以及其他对象是如何存储的，是一套文件系统的实现。</p>
<p>常用的存储引擎有以下：</p>
<ol>
<li>Innodb引擎：提供了对数据库ACID事务的支持，还提供了行级锁和外键的约束。它的设计目标就是处理大数据容量的数据库系统。</li>
<li>MyIASM引擎(原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。</li>
<li>MEMORY引擎：所有的数据都在内存中，数据的处理速度快，但是安全性不高。</li>
</ol>
<h3 id="MySQL存储引擎MyISAM与InnoDB区别"><a href="#MySQL存储引擎MyISAM与InnoDB区别" class="headerlink" title="MySQL存储引擎MyISAM与InnoDB区别"></a>MySQL存储引擎MyISAM与InnoDB区别</h3><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3VnZW5xaWFuZy9QaWN0dXJlQmVkL3Jhdy9tYXN0ZXIvQ1MtTm90ZXMvMjAyMDA0MjkxMDA2MjkucG5n?x-oss-process=image/format,png" alt="image-20200429100628653"></p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3VnZW5xaWFuZy9QaWN0dXJlQmVkL3Jhdy9tYXN0ZXIvQ1MtTm90ZXMvMjAyMDA0MjkxMDA2NTgucG5n?x-oss-process=image/format,png" alt="image-20200429100657751"></p>
<blockquote>
<p>InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。<br>InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。<br>MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。<br>InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。</p>
</blockquote>
<h3 id="InnoDB引擎的4大特性"><a href="#InnoDB引擎的4大特性" class="headerlink" title="InnoDB引擎的4大特性"></a>InnoDB引擎的4大特性</h3><blockquote>
<ul>
<li>插入缓冲（insert buffer)</li>
<li>二次写(double write)</li>
<li>自适应哈希索引(ahi)</li>
<li>预读(read ahead)</li>
</ul>
</blockquote>
<h3 id="存储引擎选择"><a href="#存储引擎选择" class="headerlink" title="存储引擎选择"></a>存储引擎选择</h3><blockquote>
<p>如果没有特别的需求，使用默认的<code>Innodb</code>即可。</p>
<p>MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。</p>
<p>Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。</p>
</blockquote>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="什么是索引"><a href="#什么是索引" class="headerlink" title="什么是索引"></a>什么是索引</h3><ul>
<li>索引是一种特殊的文件（InnoDB 数据表上的索引是表空间的一个组成部分），包含对数据表里所有记录的引用指针。</li>
<li>索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用 B 树及其变种 B + 树。</li>
<li>索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。索引是一个文件，需要占据物理空间。</li>
</ul>
<h3 id="索引的作用"><a href="#索引的作用" class="headerlink" title="索引的作用"></a>索引的作用</h3><p>索引就一种特殊的查询表，数据库的搜索可以利用它加速对数据的检索。如果没有索引，一般来说执行查询时遍历整张表。</p>
<h3 id="添加索引目的"><a href="#添加索引目的" class="headerlink" title="添加索引目的"></a>添加索引目的</h3><p>提高数据查询的效率</p>
<h3 id="聚集索引和非聚集索引-⭐"><a href="#聚集索引和非聚集索引-⭐" class="headerlink" title="聚集索引和非聚集索引 ⭐"></a>聚集索引和非聚集索引 ⭐</h3><p>物理存储顺序与逻辑顺序相同，即聚集索引（InnoDB）</p>
<p>物理存储顺序与索引顺序不一致，即非聚集索引（MyISAM）</p>
<h3 id="索引的优缺点"><a href="#索引的优缺点" class="headerlink" title="索引的优缺点"></a>索引的优缺点</h3><p>优点</p>
<ul>
<li>加快数据的检索速度，这也是创建索引的最主要的原因。</li>
<li>通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。</li>
</ul>
<p>缺点</p>
<ul>
<li>时间方面：创建索引和维护索引要耗费时间，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；</li>
<li>空间方面：索引需要占物理空间。</li>
</ul>
<h3 id="什么样的字段适合建索引"><a href="#什么样的字段适合建索引" class="headerlink" title="什么样的字段适合建索引"></a>什么样的字段适合建索引</h3><p>唯一、不为空、经常被查询的字段</p>
<h3 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a>索引类型</h3><p>主键索引: 数据列不允许重复，不允许为NULL，一个表只能有一个主键。</p>
<p>唯一索引: 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。</p>
<ul>
<li>可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯一索引</li>
<li>可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创建唯一组合索引</li>
</ul>
<p>普通索引: 基本的索引类型，没有唯一性的限制，允许为NULL值。</p>
<ul>
<li>可以通过ALTER TABLE table_name ADD INDEX index_name (column);创建普通索引</li>
<li>可以通过ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);创建组合索引</li>
</ul>
<p>全文索引： 是目前搜索引擎使用的一种关键技术。（InnoDB不支持，MyISAM支持）</p>
<ul>
<li>可以通过ALTER TABLE table_name ADD FULLTEXT (column);创建全文索引</li>
</ul>
<h3 id="索引的数据结构"><a href="#索引的数据结构" class="headerlink" title="索引的数据结构"></a>索引的数据结构</h3><h3 id="索引的基本原理"><a href="#索引的基本原理" class="headerlink" title="索引的基本原理"></a>索引的基本原理</h3><p>索引的原理就是把无序的数据变成有序的查询，把创建了索引的列的内容进行排序，对排序结果生成倒排表，在倒排表内容上拼上数据地址链。在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据。</p>
<h3 id="索引算法"><a href="#索引算法" class="headerlink" title="索引算法"></a>索引算法</h3><h4 id="B树索引"><a href="#B树索引" class="headerlink" title="B树索引"></a>B树索引</h4><p>Mysql数据库中最常用的索引算法，基本所有存储引擎都支持BTree索引。（实际是用B+树实现的，因为在查看表索引时，mysql一律打印BTREE，所以简称为B树索引）。不仅可以被用在=,&gt;,&gt;=,&lt;,&lt;=和between这些比较操作符上，还可以用于like操作符，只要它的查询条件是一个不以通配符开头的常量， 例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-- 只要它的查询条件是一个不以通配符开头的常量</span><br><span class="line">select * from user where name like &#39;jack%&#39;; </span><br><span class="line">-- 如果一通配符开头，或者没有使用常量，则不会使用索引，例如： </span><br><span class="line">select * from user where name like &#39;%jack&#39;;</span><br></pre></td></tr></table></figure>
<p><strong>B+ tree性质：</strong></p>
<ol>
<li>n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。</li>
<li>所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。</li>
<li>所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。</li>
<li>B+ 树中，数据对象的插入和删除仅在叶节点上进行。</li>
<li>B+ 树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。</li>
</ol>
<h4 id="B树和B-树的区别"><a href="#B树和B-树的区别" class="headerlink" title="B树和B+树的区别"></a>B树和B+树的区别</h4><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>B tree</th>
<th>B+ tree</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td><strong>内部节点和叶子节点存放键和值</strong>    把频繁访问的数据放在靠近根节点的地方可以提高热点数据的查询效率。</td>
<td><strong>内部节点都是键，没有值，叶子节点同时存放键和值 </strong>    因此一次读取可以在内存页中获取更多的键，有利于更快地缩小查找范围,空间利用率更高，可减少I/O次数，磁盘读写代价更低（因为索引本身很大，不可能全部存储在内存中，往往以索引文件的形式存储的磁盘上）</td>
</tr>
<tr>
<td></td>
<td><strong>叶子节点各自独立</strong>  遍历时需要对树的每一层进行遍历，需要更多的内存置换次数，花费更多的时间</td>
<td><strong>叶子节点有一条链相连</strong>    当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。</td>
</tr>
<tr>
<td></td>
<td>只适合随机检索</td>
<td>同时支持随机检索和顺序检索</td>
</tr>
<tr>
<td></td>
<td>B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td><strong>查询效率更加稳定</strong>    顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。</td>
</tr>
</tbody>
</table>
</div>
<h4 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h4><p>类似于数据结构中简单实现的HASH表（散列表）一样，在mysql中用哈希索引时，主要就是通过Hash算法（常见的Hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。</p>
<p>Hash索引只能用于对等比较，例如=,&lt;=&gt;（相当于=）操作符。由于是一次定位数据，不像BTree索引需要从根节点到枝节点，最后才能访问到页节点这样多次IO访问，所以检索效率远高于B Tree索引。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>item</th>
<th>Hash</th>
<th>B+ tree</th>
</tr>
</thead>
<tbody>
<tr>
<td>底层实现原理</td>
<td>hash索引底层就是hash表，进行查找时，调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据。</td>
<td>B+树底层实现是多路平衡查找树。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。</td>
</tr>
<tr>
<td></td>
<td>hash索引进行等值查询更快(一般情况下)，但是却无法进行范围查询。</td>
<td></td>
</tr>
<tr>
<td></td>
<td>经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。不支持使用索引进行排序， 不支持模糊查询以及多列索引的最左前缀匹配（因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。）</td>
<td></td>
</tr>
<tr>
<td></td>
<td>hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。</td>
<td>B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低</td>
</tr>
</tbody>
</table>
</div>
<h3 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h3><p>语法：index(field(10))，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。</p>
<p>前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。</p>
<p>实操的难度：在于前缀截取的长度。</p>
<p>可以利用<code>select count(*)/count(distinct left(password,prefixLen))</code>;，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录）</p>
<h3 id="最左前缀原则-amp-最左匹配原则"><a href="#最左前缀原则-amp-最左匹配原则" class="headerlink" title="最左前缀原则&amp;最左匹配原则"></a>最左前缀原则&amp;最左匹配原则</h3><p>最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。</p>
<p>最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式</p>
<h3 id="创建索引的原则"><a href="#创建索引的原则" class="headerlink" title="创建索引的原则"></a>创建索引的原则</h3><ol>
<li>最左前缀匹配原则：组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)停止匹配</li>
<li>较频繁作为查询条件的字段才去创建索引, 对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。</li>
<li>更新频繁字段不适合创建索引</li>
<li>不能有效区分数据的列不适合做索引列(如性别，男女未知，最多也就三种，区分度实在太低)</li>
<li>尽量扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。</li>
<li>定义有外键的数据列一定要建立索引。</li>
<li>对于定义为text、image和bit的数据类型的列不要建立索引。</li>
</ol>
<h3 id="创建，删除索引"><a href="#创建，删除索引" class="headerlink" title="创建，删除索引"></a>创建，删除索引</h3><h4 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h4><ul>
<li>非空字段：应该指定列为NOT NULL，除非想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。应该用0、一个特殊的值或者一个空串代替空值；</li>
<li>取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多，字段的离散程度高；</li>
<li>索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。</li>
</ul>
<h5 id="在执行CREATE-TABLE时创建索引"><a href="#在执行CREATE-TABLE时创建索引" class="headerlink" title="在执行CREATE TABLE时创建索引"></a>在执行CREATE TABLE时创建索引</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE user_index2 (</span><br><span class="line">	id INT auto_increment PRIMARY KEY,</span><br><span class="line">	first_name VARCHAR (16),</span><br><span class="line">	last_name VARCHAR (16),</span><br><span class="line">	id_card VARCHAR (18),</span><br><span class="line">	information text,</span><br><span class="line">	KEY name (first_name, last_name),</span><br><span class="line">	FULLTEXT KEY (information),</span><br><span class="line">	UNIQUE KEY (id_card)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h5 id="使用ALTER-TABLE命令去增加索引"><a href="#使用ALTER-TABLE命令去增加索引" class="headerlink" title="使用ALTER TABLE命令去增加索引"></a>使用ALTER TABLE命令去增加索引</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ALTER TABLE table_name ADD INDEX index_name (column_list);</span><br></pre></td></tr></table></figure>
<p>ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。</p>
<p>其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。</p>
<p>索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。</p>
<h5 id="使用CREATE-INDEX命令创建"><a href="#使用CREATE-INDEX命令创建" class="headerlink" title="使用CREATE INDEX命令创建"></a>使用CREATE INDEX命令创建</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE INDEX index_name ON table_name (column_list);</span><br></pre></td></tr></table></figure>
<p>CREATE INDEX可对表增加普通索引或UNIQUE索引。（但是，不能创建PRIMARY KEY索引）</p>
<h4 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h4><p>根据索引名删除普通索引、唯一索引、全文索引：<code>alter table 表名 drop KEY 索引名</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table user_index drop KEY name;</span><br><span class="line">alter table user_index drop KEY id_card;</span><br><span class="line">alter table user_index drop KEY information;</span><br></pre></td></tr></table></figure>
<p>删除主键索引：<code>alter table 表名 drop primary key</code>（因为主键只有一个）。这里值得注意的是，如果主键自增长，那么不能直接执行此操作（自增长依赖于主键索引），需要取消自增长再行删除：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table user_index</span><br><span class="line">-- 重新定义字段</span><br><span class="line">MODIFY id int,</span><br><span class="line">drop PRIMARY KEY</span><br></pre></td></tr></table></figure>
<p>但通常不会删除主键，因为设计主键一定与业务逻辑无关。</p>
<h3 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h3><h4 id="使用索引查询一定能提高查询的性能吗？"><a href="#使用索引查询一定能提高查询的性能吗？" class="headerlink" title="使用索引查询一定能提高查询的性能吗？"></a>使用索引查询一定能提高查询的性能吗？</h4><p>通常，通过索引查询数据比全表扫描要快。但是它也有代价。</p>
<p>索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，不必要的索引反而会使查询反应时间变慢。</p>
<p>使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况:</p>
<ul>
<li>基于一个范围的检索，一般查询返回结果集小于表中记录数的30%</li>
<li>基于非唯一性索引的检索</li>
</ul>
<h4 id="如何删除百万级别或以上的数据"><a href="#如何删除百万级别或以上的数据" class="headerlink" title="如何删除百万级别或以上的数据"></a>如何删除百万级别或以上的数据</h4><p>对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。</p>
<p>要删除百万数据时</p>
<ol>
<li>先删除索引（此时大概耗时三分多钟）</li>
<li>删除其中无用数据（此过程需要不到两分钟）</li>
<li>重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。</li>
</ol>
<h4 id="聚簇索引与非聚簇索引"><a href="#聚簇索引与非聚簇索引" class="headerlink" title="聚簇索引与非聚簇索引"></a>聚簇索引与非聚簇索引</h4><p>聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据<br>非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因。</p>
<p>B+树在满足聚簇索引和覆盖索引的时候不需要回表查询数据，</p>
<h4 id="非聚簇索引一定会回表查询吗？"><a href="#非聚簇索引一定会回表查询吗？" class="headerlink" title="非聚簇索引一定会回表查询吗？"></a>非聚簇索引一定会回表查询吗？</h4><p>不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。</p>
<p>举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行<code>select age from employee where age &lt; 20</code>的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。</p>
<h4 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h4><p>MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。</p>
<h4 id="为什么需要注意联合索引中的顺序？"><a href="#为什么需要注意联合索引中的顺序？" class="headerlink" title="为什么需要注意联合索引中的顺序？"></a>为什么需要注意联合索引中的顺序？</h4><p>MySQL使用索引时需要索引有序，假设现在建立了”name，age，school”的联合索引，那么索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。</p>
<p>当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。</p>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><h3 id="什么是事务"><a href="#什么是事务" class="headerlink" title="什么是事务"></a>什么是事务</h3><p>事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。</p>
<p>事务是指一个单元的工作，要么全做，要么全不做，事务是逻辑上的一组操作，保证一组数据的修改要么全部执行，要么全部不执行。</p>
<blockquote>
<p>举例：事务最经典也经常被拿出来说例子就是转账了。</p>
<p>假如小明要给小红转账 1000 元，这个转账会涉及到两个关键操作就是：将小明的余额减少 1000 元，将小红的余额增加 1000 元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。</p>
</blockquote>
<h3 id="事物的四大特性-ACID"><a href="#事物的四大特性-ACID" class="headerlink" title="事物的四大特性(ACID)"></a>事物的四大特性(ACID)</h3><p>关系性数据库需要遵循ACID规则，具体内容如下：</p>
<ul>
<li>原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</li>
<li>一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；</li>
<li>隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</li>
<li>持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li>
</ul>
<h3 id="脏读，幻读，不可重复读"><a href="#脏读，幻读，不可重复读" class="headerlink" title="脏读，幻读，不可重复读"></a>脏读，幻读，不可重复读</h3><ul>
<li>脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。</li>
<li>幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。</li>
<li>不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。</li>
</ul>
<h3 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><p>SQL 标准定义了四个隔离级别：</p>
<ol>
<li>READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。</li>
<li>READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。</li>
<li>REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。</li>
<li>SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。</li>
</ol>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="什么是锁"><a href="#什么是锁" class="headerlink" title="什么是锁"></a>什么是锁</h3><p>在所有的 DBMS 中，<strong>锁是实现事务的关键，锁可以保证事务的完整性和并发性</strong>。与现实生活中锁一样，它可以是某些数据的拥有者，在某段时间内不能使用某些数据或数据结构。当然锁还分级别的。</p>
<h3 id="隔离级别与锁的关系"><a href="#隔离级别与锁的关系" class="headerlink" title="隔离级别与锁的关系"></a>隔离级别与锁的关系</h3><ol>
<li>在Read Uncommitted级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突</li>
<li>在Read Committed级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁；</li>
<li>在Repeatable Read级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。</li>
<li>SERIALIZABLE 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成。</li>
</ol>
<h3 id="锁的分类"><a href="#锁的分类" class="headerlink" title="锁的分类"></a>锁的分类</h3><h4 id="按照锁的粒度划分"><a href="#按照锁的粒度划分" class="headerlink" title="按照锁的粒度划分"></a>按照锁的粒度划分</h4><p>在关系型数据库中，按照锁的粒度把数据库锁分为<strong>行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。</strong></p>
<p>MyISAM采用表级锁(table-level locking)<br>InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>行级锁</th>
<th>表级锁</th>
<th>页级锁</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁</td>
<td>MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。</td>
<td>MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。</td>
</tr>
<tr>
<td>开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</td>
<td>开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。</td>
<td>开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</td>
</tr>
</tbody>
</table>
</div>
<h4 id="按照锁的类别划分"><a href="#按照锁的类别划分" class="headerlink" title="按照锁的类别划分"></a>按照锁的类别划分</h4><p><strong>共享锁</strong>: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。</p>
<p><strong>排他锁</strong>: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。</p>
<p>用上面的例子来说就是用户的行为有两种，一种是来看房，多个用户一起看房是可以接受的。 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房的都不可以。</p>
<h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。</p>
<p>常见的解决死锁的方法</p>
<ol>
<li>如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。</li>
<li>在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；</li>
<li>对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；</li>
<li>如果业务处理不好可以用分布式事务锁或者使用乐观锁</li>
</ol>
<h3 id="数据库的乐观锁和悲观锁"><a href="#数据库的乐观锁和悲观锁" class="headerlink" title="数据库的乐观锁和悲观锁"></a>数据库的乐观锁和悲观锁</h3><p>数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。<strong>乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。</strong></p>
<p><strong>悲观锁</strong>：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制</p>
<blockquote>
<p>多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。</p>
</blockquote>
<p><strong>乐观锁</strong>：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：一般会使用版本号机制或CAS算法实现。</p>
<blockquote>
<p>乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。</p>
</blockquote>
<h3 id="问题：-1"><a href="#问题：-1" class="headerlink" title="问题："></a>问题：</h3><h4 id="MySQL中InnoDB引擎的行锁"><a href="#MySQL中InnoDB引擎的行锁" class="headerlink" title="MySQL中InnoDB引擎的行锁"></a>MySQL中InnoDB引擎的行锁</h4><p>InnoDB是基于索引来完成行锁</p>
<p>例: <code>select * from tab_with_index where id = 1 for update;</code></p>
<p>for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不是索引键那么InnoDB将完成表锁，并发将无从谈起。</p>
<h4 id="InnoDB存储引擎的锁的算法"><a href="#InnoDB存储引擎的锁的算法" class="headerlink" title="InnoDB存储引擎的锁的算法"></a>InnoDB存储引擎的锁的算法</h4><ul>
<li><p>Record lock：单个行记录上的锁</p>
<blockquote>
<p>当查询的索引含有唯一属性时，将next-key lock降级为record key</p>
</blockquote>
</li>
<li><p>Gap lock：间隙锁，锁定一个范围，不包括记录本身</p>
<blockquote>
<p>Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，这会导致幻读问题<br>有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock）</p>
<p> A. 将事务隔离级别设置为RC </p>
<p>B. 将参数innodb_locks_unsafe_for_binlog设置为1</p>
</blockquote>
</li>
<li><p>Next-key lock：record+gap 锁定一个范围，包含记录本身</p>
<blockquote>
<p>Next-locking keying为了解决Phantom Problem幻读问题</p>
<p>innodb对于行的查询使用next-key lock</p>
</blockquote>
</li>
</ul>
<h2 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h2><h3 id="什么是视图"><a href="#什么是视图" class="headerlink" title="什么是视图"></a>什么是视图</h3><p>视图本质上是一种虚拟表，在物理上是不存在的，具有和物理表相同的功能，其内容与真实的表相似，包含一系列带有名称的列和行数据，可以对视图进行增，改，查，操作，但是，视图并不在数据库中以储存的数据值形式存在。行和列数据来自定义视图的查询所引用基本表，并且在具体引用视图时动态生成。</p>
<h3 id="为什么要使用视图"><a href="#为什么要使用视图" class="headerlink" title="为什么要使用视图"></a>为什么要使用视图</h3><p>为了提高复杂 SQL 语句的复用性和表操作的安全性，数据库管理系统提供了视图特性。视图使得开发者只关心感兴趣的某些特定数据和所负责的特定任务，只能看到视图中所定义的数据，而不是视图所引用表中的数据，从而提高了数据库中数据的安全性。</p>
<h3 id="视图有哪些特点"><a href="#视图有哪些特点" class="headerlink" title="视图有哪些特点"></a>视图有哪些特点</h3><ol>
<li>视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。</li>
<li>视图是由基本表(实表)产生的表(虚表)。</li>
<li>视图的建立和删除不影响基本表。</li>
<li>对视图内容的更新(添加，删除和修改)直接影响基本表。</li>
<li>当视图来自多个基本表时，不允许添加和删除数据。</li>
<li>视图的操作包括创建视图，查看视图，删除视图和修改视图。</li>
</ol>
<h3 id="视图的优缺点"><a href="#视图的优缺点" class="headerlink" title="视图的优缺点"></a>视图的优缺点</h3><h4 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h4><ol>
<li>查询简单化：视图能简化用户的操作</li>
<li>数据安全性：视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护</li>
<li>逻辑数据独立性：视图对重构数据库提供了一定程度的逻辑独立性</li>
</ol>
<h4 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h4><ol>
<li>性能：数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所定义，那么，即使是视图的一个简单查询，数据库也把它变成一个复杂的结合体，需要花费一定的时间。</li>
<li>修改限制：当用户试图修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改。事实上，当从视图中插入或者删除时，情况也是这样。对于简单视图来说，这是很方便的，但是，对于比较复杂的视图，可能是不可修改的。</li>
</ol>
<h3 id="问题：-2"><a href="#问题：-2" class="headerlink" title="问题："></a>问题：</h3><h4 id="视图的使用场景有哪些"><a href="#视图的使用场景有哪些" class="headerlink" title="视图的使用场景有哪些"></a>视图的使用场景有哪些</h4><p>视图根本用途：简化 SQL 查询，提高开发效率。兼容老的表结构。</p>
<p>常见使用场景：</p>
<ol>
<li>重用 SQL 语句；</li>
<li>简化复杂的 SQL 操作。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；</li>
<li>使用表的组成部分而不是整个表；</li>
<li>保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；</li>
<li>更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。</li>
</ol>
<h4 id="表和视图的关系"><a href="#表和视图的关系" class="headerlink" title="表和视图的关系"></a>表和视图的关系</h4><p>视图其实就是一条查询 SQL 语句，用于显示一个或多个表或其他视图中的相关数据。 </p>
<p>表是关系数据库中实际存储数据用的。</p>
<h4 id="什么是游标"><a href="#什么是游标" class="headerlink" title="什么是游标"></a>什么是游标</h4><p>游标是系统为用户开设的一个数据缓冲区，存放 SQL 语句的执行结果，每个游标区都有一个名字。用户可以通过游标逐一获取记录并赋给主变量，交由主语言进一步处理。</p>
<h2 id="存储过程与函数"><a href="#存储过程与函数" class="headerlink" title="存储过程与函数"></a>存储过程与函数</h2><h3 id="什么是存储过程"><a href="#什么是存储过程" class="headerlink" title="什么是存储过程"></a>什么是存储过程</h3><p>存储过程是一个预编译的 SQL 语句，优点是允许模块化的设计，就是说只需要创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次 SQL，使用存储过程比单纯 SQL 语句执行要快。</p>
<h3 id="存储过程用什么来调用"><a href="#存储过程用什么来调用" class="headerlink" title="存储过程用什么来调用"></a>存储过程用什么来调用</h3><ul>
<li>可以用一个命令对象来调用存储过程。</li>
<li>可以供外部程序调用，比如：Java 程序。</li>
</ul>
<h3 id="存储过程的优缺点"><a href="#存储过程的优缺点" class="headerlink" title="存储过程的优缺点"></a>存储过程的优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol>
<li>存储过程是预编译过的，执行效率高。</li>
<li>存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。</li>
<li>安全性高，执行存储过程需要有一定权限的用户。</li>
<li>存储过程可以重复使用，减少数据库开发人员的工作量。</li>
</ol>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol>
<li>调试麻烦，但是用 PL/SQL Developer 调试很方便。</li>
<li>移植性差，数据库端代码当然是与数据库相关的。但如果是工程型项目，基本不存在移植问题。</li>
<li>重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（也可以设置成运行时刻自动编译）。</li>
<li>如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，如果用户很难维护该系统</li>
</ol>
<h3 id="存储过程与函数的区别"><a href="#存储过程与函数的区别" class="headerlink" title="存储过程与函数的区别"></a>存储过程与函数的区别</h3><div class="table-container">
<table>
<thead>
<tr>
<th>存储过程</th>
<th>函数</th>
</tr>
</thead>
<tbody>
<tr>
<td>用于在数据库中完成特定的操作或者任务（如插入、删除等）</td>
<td>用于特定的数据（如选择）</td>
</tr>
<tr>
<td>程序头部声明用 procedure</td>
<td>程序头部声明用 function</td>
</tr>
<tr>
<td>程序头部声明时不需描述返回类型</td>
<td>程序头部声明时要描述返回类型，而且 PL / SQL 块中至少要包括一个有效的 return 语句</td>
</tr>
<tr>
<td>可以使用 in / out / in out 三种模式的参数</td>
<td>可以使用 in / out /in out 三种模式的参数</td>
</tr>
<tr>
<td>可作为一个独立的 PL / SQL 语句来执行</td>
<td>不能独立执行，必须作为表达式的一部分调用</td>
</tr>
<tr>
<td>可以通过 out / in out 返回零个或多个值</td>
<td>通过 return 语句返回一个值，且改值要与声明部分一致，也可以是通过 out 类型的参数带出的变量</td>
</tr>
<tr>
<td>SQL 语句( DML 或 SELECT )中不可调用存储过程</td>
<td>SQL 语句( DML 或 SELECT )中可以调用函数</td>
</tr>
</tbody>
</table>
</div>
<h2 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h2><h3 id="什么是触发器"><a href="#什么是触发器" class="headerlink" title="什么是触发器"></a>什么是触发器</h3><p>触发器是<strong>用户定义在关系表上的一类由事件驱动的特殊的存储过程</strong>，触发器是指一段代码，当触发某个事件时，自动执行这些代码。</p>
<p>主要是通过事件来触发而被执行的。可以强化约束，来维护数据的完整性和一致性，可以跟踪数据库内的操作从而不允许未经许可的更新和变化。可以联级运算。如某表上的触发器上包含对另一个表的数据操作，而该操作又会导致该表触发器被触发。</p>
<h3 id="触发器的使用场景"><a href="#触发器的使用场景" class="headerlink" title="触发器的使用场景"></a>触发器的使用场景</h3><p>可以通过数据库中的相关表实现级联更改。<br>实时监控某张表中的某个字段的更改而需要做出相应的处理。例如可以生成某些业务的编号。</p>
<h3 id="MySQL中的触发器"><a href="#MySQL中的触发器" class="headerlink" title="MySQL中的触发器"></a>MySQL中的触发器</h3><p>在 MySQL 数据库中有如下六种触发器：</p>
<ul>
<li>Before Insert</li>
<li>After Insert</li>
<li>Before Update</li>
<li>After Update</li>
<li>Before Delete</li>
<li>After Delete</li>
</ul>
<h3 id="事前触发和事后触发的区别"><a href="#事前触发和事后触发的区别" class="headerlink" title="事前触发和事后触发的区别"></a>事前触发和事后触发的区别</h3><p>事前触发器运行于触发事件发生之前，事后触发器运行于触发事件发生之后。</p>
<p>通常事前触发器可以获取事件之前和新的字段值。</p>
<h3 id="语句级触发和行级触发有何区别"><a href="#语句级触发和行级触发有何区别" class="headerlink" title="语句级触发和行级触发有何区别"></a>语句级触发和行级触发有何区别</h3><p>语句级触发器可以在语句执行前或后执行，而行级触发在触发器所影响的每一行触发一次。</p>
]]></content>
      <categories>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo-插入本地图片</title>
    <url>/2020/09/16/Hexo%E6%8F%92%E5%85%A5%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87/</url>
    <content><![CDATA[<h2 id="前因"><a href="#前因" class="headerlink" title="前因"></a>前因</h2><p>记笔记时经常使用微信截图，直接粘贴到Typora中，在本地显示没有问题，但是如果不小心删除微信缓存，或者换电脑浏览图片显示就会出错。</p>
<p>PS：微信暂时不支持自定义截图存储位置</p>
<a id="more"></a>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><p>Typora设置：文件→偏好设置→图片→设置复制图片到文件夹</p>

<p>如果选择<code>对网络位置的图片应用上述规则</code>应该会将图片保存到assets文件夹下。</p>
<p>但是完成设置后仅仅可以在Typro中显示，在主页不能显示。</p>
<h2 id="博客不能显示图片"><a href="#博客不能显示图片" class="headerlink" title="博客不能显示图片"></a>博客不能显示图片</h2><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><ol>
<li><p>安装插件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install hexo-asset-image --save</span><br></pre></td></tr></table></figure>
<p>将node_modules/hexo-asset-image/index.js中的内容替换为<a href="https://blog.csdn.net/xjm850552586/article/details/84101345" target="_blank" rel="noopener">CSDN一篇博客-hexo引用本地图片无法显示</a>中的代码。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="meta">'use strict'</span>;</span><br><span class="line"><span class="keyword">var</span> cheerio = <span class="built_in">require</span>(<span class="string">'cheerio'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-string</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getPosition</span>(<span class="params">str, m, i</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> str.split(m, i).join(m).length;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> version = <span class="built_in">String</span>(hexo.version).split(<span class="string">'.'</span>);</span><br><span class="line">hexo.extend.filter.register(<span class="string">'after_post_render'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> config = hexo.config;</span><br><span class="line">  <span class="keyword">if</span>(config.post_asset_folder)&#123;</span><br><span class="line">    	<span class="keyword">var</span> link = data.permalink;</span><br><span class="line">	<span class="keyword">if</span>(version.length &gt; <span class="number">0</span> &amp;&amp; <span class="built_in">Number</span>(version[<span class="number">0</span>]) == <span class="number">3</span>)</span><br><span class="line">	   <span class="keyword">var</span> beginPos = getPosition(link, <span class="string">'/'</span>, <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">	   <span class="keyword">var</span> beginPos = getPosition(link, <span class="string">'/'</span>, <span class="number">3</span>) + <span class="number">1</span>;</span><br><span class="line">	<span class="comment">// In hexo 3.1.1, the permalink of "about" page is like ".../about/index.html".</span></span><br><span class="line">	<span class="keyword">var</span> endPos = link.lastIndexOf(<span class="string">'/'</span>) + <span class="number">1</span>;</span><br><span class="line">    link = link.substring(beginPos, endPos);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> toprocess = [<span class="string">'excerpt'</span>, <span class="string">'more'</span>, <span class="string">'content'</span>];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; toprocess.length; i++)&#123;</span><br><span class="line">      <span class="keyword">var</span> key = toprocess[i];</span><br><span class="line"> </span><br><span class="line">      <span class="keyword">var</span> $ = cheerio.load(data[key], &#123;</span><br><span class="line">        ignoreWhitespace: <span class="literal">false</span>,</span><br><span class="line">        xmlMode: <span class="literal">false</span>,</span><br><span class="line">        lowerCaseTags: <span class="literal">false</span>,</span><br><span class="line">        decodeEntities: <span class="literal">false</span></span><br><span class="line">      &#125;);</span><br><span class="line"></span><br><span class="line">      $(<span class="string">'img'</span>).each(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">		<span class="keyword">if</span> ($(<span class="keyword">this</span>).attr(<span class="string">'src'</span>))&#123;</span><br><span class="line">			<span class="comment">// For windows style path, we replace '\' to '/'.</span></span><br><span class="line">			<span class="keyword">var</span> src = $(<span class="keyword">this</span>).attr(<span class="string">'src'</span>).replace(<span class="string">'\\'</span>, <span class="string">'/'</span>);</span><br><span class="line">			<span class="keyword">if</span>(!<span class="regexp">/http[s]*.*|\/\/.*/</span>.test(src) &amp;&amp;</span><br><span class="line">			   !<span class="regexp">/^\s*\//</span>.test(src)) &#123;</span><br><span class="line">			  <span class="comment">// For "about" page, the first part of "src" can't be removed.</span></span><br><span class="line">			  <span class="comment">// In addition, to support multi-level local directory.</span></span><br><span class="line">			  <span class="keyword">var</span> linkArray = link.split(<span class="string">'/'</span>).filter(<span class="function"><span class="keyword">function</span>(<span class="params">elem</span>)</span>&#123;</span><br><span class="line">				<span class="keyword">return</span> elem != <span class="string">''</span>;</span><br><span class="line">			  &#125;);</span><br><span class="line">			  <span class="keyword">var</span> srcArray = src.split(<span class="string">'/'</span>).filter(<span class="function"><span class="keyword">function</span>(<span class="params">elem</span>)</span>&#123;</span><br><span class="line">				<span class="keyword">return</span> elem != <span class="string">''</span> &amp;&amp; elem != <span class="string">'.'</span>;</span><br><span class="line">			  &#125;);</span><br><span class="line">			  <span class="keyword">if</span>(srcArray.length &gt; <span class="number">1</span>)</span><br><span class="line">				srcArray.shift();</span><br><span class="line">			  src = srcArray.join(<span class="string">'/'</span>);</span><br><span class="line">			  $(<span class="keyword">this</span>).attr(<span class="string">'src'</span>, config.root + link + src);</span><br><span class="line">			  <span class="built_in">console</span>.info&amp;&amp;<span class="built_in">console</span>.info(<span class="string">"update link as:--&gt;"</span>+config.root + link + src);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			<span class="built_in">console</span>.info&amp;&amp;<span class="built_in">console</span>.info(<span class="string">"no src attr, skipped..."</span>);</span><br><span class="line">			<span class="built_in">console</span>.info&amp;&amp;<span class="built_in">console</span>.info($(<span class="keyword">this</span>));</span><br><span class="line">		&#125;</span><br><span class="line">      &#125;);</span><br><span class="line">      data[key] = $.html();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>该插件可以在信件文章时自动生成和文章名相同的文件夹。</p>
</li>
<li><p>按照<a href="https://hexo.io/zh-cn/docs/asset-folders.html" target="_blank" rel="noopener">Hexo-资源文件夹</a>中的设置：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">_config.yml</span></span><br><span class="line"><span class="attr">post_asset_folder:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">marked:</span></span><br><span class="line">  <span class="attr">prependRoot:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">postAsset:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>可以<code>![](image.jpg)</code>，直接添加，会自动渲染添加路径。</p>
</li>
<li><p>将filename.assets文件夹重命名为filename</p>
<p>或者将图片拷到filename文件夹下</p>
<p>因为hexo自动渲染的路径是相对应的post路径</p>
</li>
</ol>
<h3 id="可能的改进"><a href="#可能的改进" class="headerlink" title="可能的改进"></a>可能的改进</h3><ol>
<li>onedrive+oneindex部署，创建图床。</li>
<li>typora自动创建的资源文件夹名字和hexo自动创建的资源文件夹名字应该可以更改</li>
</ol>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>Typora</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
