<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="https:&#x2F;&#x2F;www.cntofu.com&#x2F;book&#x2F;27&#x2F;docs&#x2F;2.一个完整的机器学习项目.md https:&#x2F;&#x2F;github.com&#x2F;ageron&#x2F;handson-ml2 https:&#x2F;&#x2F;github.com&#x2F;apachecn&#x2F;hands-on-ml-zh&#x2F;blob&#x2F;master&#x2F;docs&#x2F; https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;3470a6efbe8d">
<meta property="og:type" content="article">
<meta property="og:title" content="《Scikit-Learn与TensorFlow机器学习实用指南》">
<meta property="og:url" content="http://yoursite.com/2020/08/25/%E3%80%8AScikit-Learn%E4%B8%8ETensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97%E3%80%8B/index.html">
<meta property="og:site_name" content="Ringinmay&#39;s Blog">
<meta property="og:description" content="https:&#x2F;&#x2F;www.cntofu.com&#x2F;book&#x2F;27&#x2F;docs&#x2F;2.一个完整的机器学习项目.md https:&#x2F;&#x2F;github.com&#x2F;ageron&#x2F;handson-ml2 https:&#x2F;&#x2F;github.com&#x2F;apachecn&#x2F;hands-on-ml-zh&#x2F;blob&#x2F;master&#x2F;docs&#x2F; https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;3470a6efbe8d">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/apachecn/hands-on-ml-zh/raw/master/images/chapter_1/1-13.png">
<meta property="og:image" content="https://img-blog.csdn.net/20170824103329707?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemVhbGZvcnk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="https://img-blog.csdn.net/20170824103423352?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemVhbGZvcnk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-4.PNG">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-5.PNG">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-9.PNG">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-6.PNG">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-11.PNG">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E8%A1%A84-1.PNG">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-15.PNG">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-16.PNG">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-17.PNG">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-18.PNG">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-93eea6b5c197bbc8d7be8b4c14e9f8f3.gif">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-4b43b0aee35624cd95b910189b3dc231.gif">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-e4da079f692fe35778bbdf1fdf120d99.gif">
<meta property="og:image" content="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-20.PNG">
<meta property="article:published_time" content="2020-08-25T11:26:00.000Z">
<meta property="article:modified_time" content="2020-08-29T10:44:18.497Z">
<meta property="article:author" content="QQAI">
<meta property="article:tag" content="sklearn">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/apachecn/hands-on-ml-zh/raw/master/images/chapter_1/1-13.png">

<link rel="canonical" href="http://yoursite.com/2020/08/25/%E3%80%8AScikit-Learn%E4%B8%8ETensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97%E3%80%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>《Scikit-Learn与TensorFlow机器学习实用指南》 | Ringinmay's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ringinmay's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Home is behind, the world ahead</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/25/%E3%80%8AScikit-Learn%E4%B8%8ETensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97%E3%80%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.jpg">
      <meta itemprop="name" content="QQAI">
      <meta itemprop="description" content="Home is behind, the world ahead">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ringinmay's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          《Scikit-Learn与TensorFlow机器学习实用指南》
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-25 19:26:00" itemprop="dateCreated datePublished" datetime="2020-08-25T19:26:00+08:00">2020-08-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-29 18:44:18" itemprop="dateModified" datetime="2020-08-29T18:44:18+08:00">2020-08-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" itemprop="url" rel="index">
                    <span itemprop="name">数据分析</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><a href="https://www.cntofu.com/book/27/docs/2.%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE.md" target="_blank" rel="noopener">https://www.cntofu.com/book/27/docs/2.一个完整的机器学习项目.md</a></p>
<p><a href="https://github.com/ageron/handson-ml2" target="_blank" rel="noopener">https://github.com/ageron/handson-ml2</a></p>
<p><a href="https://github.com/apachecn/hands-on-ml-zh/blob/master/docs/1.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88.md" target="_blank" rel="noopener">https://github.com/apachecn/hands-on-ml-zh/blob/master/docs/</a></p>
<p><a href="https://www.jianshu.com/p/3470a6efbe8d" target="_blank" rel="noopener">https://www.jianshu.com/p/3470a6efbe8d</a></p>
<a id="more"></a>

<h2 id="《Scikit-Learn与TensorFlow机器学习实用指南》"><a href="#《Scikit-Learn与TensorFlow机器学习实用指南》" class="headerlink" title="《Scikit-Learn与TensorFlow机器学习实用指南》"></a>《Scikit-Learn与TensorFlow机器学习实用指南》</h2><h3 id="第01章-机器学习概览"><a href="#第01章-机器学习概览" class="headerlink" title="第01章 机器学习概览"></a>第01章 机器学习概览</h3><ol>
<li><p>os.makedirs(IMAGES_PATH, exist_ok=True)</p>
</li>
<li><p>pd.merge(left=oecd_bli, right=gdp_per_capita, left_index=True, right_index=True)</p>
<p>left_index和right_index：指定是否以索引为参考进行合并</p>
<p>​</p>
<h4 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h4><ol>
<li>如何定义机器学习？</li>
</ol>
<blockquote>
<p>机器学习是通过编程让计算机从数据中进行学习的科学（和艺术）。</p>
<p><strong>更广义的概念：</strong></p>
<p>机器学习是让计算机具有学习的能力，无需进行明确编程。 —— 亚瑟·萨缪尔，1959</p>
<p><strong>工程性的概念：</strong></p>
<p>计算机程序利用经验 E 学习任务 T，性能是 P，如果针对任务 T 的性能 P 随着经验 E 不断增长，则称为机器学习。 —— 汤姆·米切尔，1997</p>
</blockquote>
<ol start="2">
<li>机器学习可以解决的四类问题？</li>
</ol>
<blockquote>
<p>分类，回归，聚类，降维</p>
<p>机器学习可以根据训练时监督的量和类型进行分类。主要有四类：监督学习、非监督学习、半监督学习和强化学习。</p>
</blockquote>
<ol start="3">
<li>什么是带标签的训练集？</li>
</ol>
<blockquote>
<p>在监督学习中，用来训练算法的训练数据包含了答案，称为标签。</p>
</blockquote>
<ol start="4">
<li>最常见的两个监督任务是什么？</li>
</ol>
<blockquote>
<ol>
<li>分类：例如垃圾邮件过滤器：用许多带有归类（垃圾邮件或普通邮件）的邮件样本进行训练，过滤器必须还能对新邮件进行分类。</li>
<li>回归：预测目标数值，例如给出一些特征（里程数、车龄、品牌等等）称作预测值，来预测一辆汽车的价格。。要训练这个系统，需要给出大量汽车样本，包括它们的预测值和标签（即，它们的价格）。</li>
</ol>
</blockquote>
<ol start="5">
<li>指出四个常见的非监督任务？</li>
</ol>
<blockquote>
<ol>
<li><strong>聚类算法</strong> ，检测相似访客的分组。假设有一份关于博客访客的大量数据，不告诉算法某个访客属于哪一类：它会自己找出关系，无需帮助。例如，算法可能注意到 40% 的访客是喜欢漫画书的男性，通常是晚上访问，20% 是科幻爱好者，他们是在周末访问等等。如果使用<strong>层次聚类分析</strong> ，它可能还会细分每个分组为更小的组。这可以帮助你为每个分组定位博文。</li>
<li><strong>可视化算法</strong> ：给算法大量复杂的且不加标签的数据，算法输出数据的2D或3D图像。算法会试图保留数据的结构（即尝试保留输入的独立聚类，避免在图像中重叠），这样就可以明白数据是如何组织起来的，也许还能发现隐藏的规律。</li>
<li><strong>降维</strong> ：降维的目的是简化数据、但是不能失去大部分信息。做法之一是合并若干相关的特征。例如，汽车的里程数与车龄高度相关，降维算法就会将它们合并成一个，表示汽车的磨损。这叫做<strong>特征提取</strong> 。</li>
<li><strong>异常检测（anomaly detection）</strong> ：例如，检测异常的信用卡转账以防欺诈，检测制造缺陷，或者在训练之前自动从训练数据集去除异常值。异常检测的系统使用正常值训练的，当它碰到一个新实例，它可以判断这个新实例是像正常值还是异常值。</li>
</ol>
</blockquote>
<ol start="6">
<li>要让一个机器人能在各种未知地形行走，你会采用什么机器学习算法？</li>
</ol>
<blockquote>
<p>强化学习：</p>
</blockquote>
<ol start="7">
<li>要对你的顾客进行分组，你会采用哪类算法？</li>
</ol>
<blockquote>
<p>非监督学习</p>
</blockquote>
<ol start="8">
<li>垃圾邮件检测是监督学习问题，还是非监督学习问题？</li>
</ol>
<blockquote>
<p>监督学习：因为有标签</p>
</blockquote>
<ol start="9">
<li>什么是在线学习系统？</li>
</ol>
<blockquote>
<p>从导入的数据流进行持续学习</p>
<p>在在线学习中，是用数据实例持续地进行训练，可以一次一个或一次几个实例（称为小批量）。每个学习步骤都很快且廉价，所以系统可以动态地学习收到的最新数据</p>
<p><img src="https://github.com/apachecn/hands-on-ml-zh/raw/master/images/chapter_1/1-13.png" alt="img"></p>
</blockquote>
<ol start="10">
<li>什么是核外学习？</li>
</ol>
<blockquote>
<p>在线学习算法也适用于在超大数据集（一台计算机不足以用于存储它）上训练系统（这称作核外学习，<em>out-of-core</em> learning）。算法每次只加载部分数据，用这些数据进行训练，然后重复这个过程，直到使用完所有数据</p>
</blockquote>
<ol start="11">
<li>什么学习算法是用相似度做预测？</li>
</ol>
<blockquote>
<p>基于实例学习：系统先用记忆学习案例，然后使用相似度测量推广到新的例子</p>
<p>例如，垃圾邮件检测器，不仅能标记和已知的垃圾邮件相同的邮件，也要能标记类似垃圾邮件的邮件。需要测量两封邮件的相似性。一个（简单的）相似度测量方法是统计两封邮件包含的相同单词的数量。如果一封邮件含有许多垃圾邮件中的词，就会被标记为垃圾邮件。</p>
</blockquote>
<ol start="12">
<li>模型参数和学习算法的超参数的区别是什么？</li>
</ol>
<blockquote>
<p>学习算法搜寻模型参数值，使代价函数最小</p>
<p>超参数（hyperparameter）是一个学习算法的参数（而不是模型的），控制正则化的度。</p>
</blockquote>
<ol start="13">
<li>基于模型学习的算法搜寻的是什么？最成功的策略是什么？基于模型学习如何做预测？</li>
</ol>
<blockquote>
<p>搜寻使得代价函数（测量线性模型的预测值和训练样本之间的距离差）最小的模型参数</p>
<p>线性回归算法</p>
<p>研究数据-选择模型-用训练数据进行训练（学习算法搜寻模型参数值，使得代价函数最小）-使用模型对新案例进行预测（这称作推断）</p>
</blockquote>
<ol start="14">
<li>机器学习的四个主要挑战是什么？</li>
</ol>
<blockquote>
<p>训练数据量不足</p>
<p>没有代表性的训练数据</p>
<p>低质量数据</p>
<p>不相关的特征</p>
<p>过拟合</p>
<p>欠拟合</p>
</blockquote>
<ol start="15">
<li>如果模型在训练集上表现好，但推广到新实例表现差，问题是什么？给出三个可能的解决方案。</li>
</ol>
<blockquote>
<p>过拟合：利用超参数正则化</p>
<p>不相关特征：</p>
<ul>
<li>特征选择：在所有存在的特征中选取最有用的特征进行训练。</li>
<li>特征提取：组合存在的特征，生成一个更有用的特征（如前面看到的，可以使用降维算法）。</li>
<li>收集新数据创建新特征。</li>
</ul>
<p>低质量数据：如果训练集中的错误、异常值和噪声（错误测量引入的）太多，系统检测出潜在规律的难度就会变大，性能就会降低。</p>
<ul>
<li>如果一些实例是明显的异常值，最好删掉它们或尝试手工修改错误；</li>
<li>如果一些实例缺少特征（比如，你的 5% 的顾客没有说明年龄），你必须决定是否忽略这个属性、忽略这些实例、填入缺失值（比如，年龄中位数），或者训练一个含有这个特征的模型和一个不含有这个特征的模型，等等。</li>
</ul>
</blockquote>
<ol start="16">
<li>什么是测试集，为什么要使用它？</li>
</ol>
<blockquote>
<p>测试集：用来训练模型的数据集</p>
</blockquote>
<ol start="17">
<li>验证集的目的是什么？</li>
</ol>
<blockquote>
<p>验证集：数据中分出来，对模型进行测试的数据集。</p>
<p>评估模型推广到新样本的效果（即对新样本的性能），可以将模型部署到生产环境，观察它的性能。这么做可以，但如果模型的性能很差，就会引起用户抱怨。更好的选项是将数据分成训练集和测试集。用训练集进行训练，用测试集进行测试。对新样本的错误率称作<strong>推广错误（或样本外错误）</strong> ，通过模型对测试集的评估，可以预估这个错误。这个值可以我们模型对新样本的性能。</p>
</blockquote>
<ol start="18">
<li>如果用测试集调节超参数，会发生什么？</li>
</ol>
<blockquote>
<p>过拟合</p>
<p>在测试集上多次测量了推广误差率，调整了模型和超参数，以使模型最适合这个集合。这意味着模型对新数据的性能不会高。</p>
</blockquote>
<ol start="19">
<li>什么是交叉验证，为什么它比验证集好？</li>
</ol>
<blockquote>
<p>交叉验证：训练集分成互补的子集，每个模型用不同的子集训练，再用剩下的子集验证。一旦确定模型类型和超参数，最终的模型使用这些超参数和全部的训练集进行训练，用测试集得到推广误差率。</p>
<p>而使用验证集：用训练集和多个超参数训练多个模型，选择在验证集上有最佳性能的模型和超参数。当对模型满意时，用测试集再做最后一次测试，以得到推广误差率的预估，会“浪费”过多训练数据在验证集上。</p>
</blockquote>
</li>
</ol>
<h3 id="第02章-一个完整的机器学习项目"><a href="#第02章-一个完整的机器学习项目" class="headerlink" title="第02章 一个完整的机器学习项目"></a>第02章 一个完整的机器学习项目</h3><p>[Python API：crc32函数 计算CRC校验值](<a href="https://b" target="_blank" rel="noopener">https://b</a></p>
<p><a href="https://blog.csdn.net/liuyu60305002/article/details/6307152" target="_blank" rel="noopener">模2运算</a></p>
<p><a href="https://blog.csdn.net/sparkliang/article/details/5671510" target="_blank" rel="noopener">CRC32算法详细推导</a></p>
<blockquote>
<p>crc32用于计算 <em>data</em> 的 CRC (A cyclic redundancy check 32，循环冗余校验) 值。计算的结果是一个 32 位的整数。本质是<strong>模2除法模2运算包括模2加、模2减、模2乘、模2除四种二进制运算，不考虑进位和借位）</strong>， 的余数，采用的除数不同，CRC的类型也就不一样。通常，CRC的除数用生成多项式来表示。</p>
<p>此算法没有加密强度，不应用于身份验证和数字签名。仅<strong>为验证数据的正确性</strong> ，不适合作为通用散列算法。</p>
<h4 id="特点：检错能力极强，开销小等"><a href="#特点：检错能力极强，开销小等" class="headerlink" title="特点：检错能力极强，开销小等"></a>特点：检错能力极强，开销小等</h4><h4 id="本质"><a href="#本质" class="headerlink" title="本质"></a>本质</h4><p>CRC 算法是以 GF(2) 多项式算术为数学基础的， GF(2) 多项式中只有一个变量 x ，其系数也只有 0 和 1 ，比如：</p>
<p>​    1 <em>x^6 + 0</em>x^5 + 1<em>x^4 + 0</em>x^3 + 0<em>x^2 +1</em>x^1 + 1*x^0</p>
<p>​       = x^6 + x^4 + x + 1</p>
<p>加减运算不考虑进位和退位。说白了就是下面的运算规则：</p>
<p>​    0 + 0 = 0    0 - 0 = 0</p>
<p>​    0 + 1 = 1    0 - 1 = 1</p>
<p>​    1 + 0 = 1    1 - 0 = 1</p>
<p>​    1 + 1 = 0    1 - 1 = 0<br>看看这个规则，其实就是一个<strong>异或运算</strong> 。</p>
<p>每个生成多项式的系数只能是 0 或 1 ，因此可以把它转化为二进制形式表示， 比如 g(x)=x^4 + x + 1 ，那么 g(x) 对应的二进制形式就是 10011 ， 于是把 GF(2) 多项式的除法转换成了二进制形式，和普通除法没有区别，只是加减运算没有进位和退位。</p>
<p>比如基于上述规则计算 11010/1001 ，那么商是 11 ，余数就是 1。</p>
<h4 id="CRC-校验的基本过程"><a href="#CRC-校验的基本过程" class="headerlink" title="CRC 校验的基本过程"></a>CRC 校验的基本过程</h4><p>采用 CRC 校验时，发送方和接收方用同一个生成多项式 g(x) ， g(x) 是一个 GF(2) 多项式，并且 g(x) 的首位和最后一位的系数必须为 1 。</p>
<p>CRC 的处理方法是：发送方用发送数据的二进制多项式 t(x) 除以 g(x) ，得到余数 y(x) 作为 CRC 校验码。校验时，以计算的校正结果是否为 0 为据，判断数据帧是否出错。设生成多项式是 r 阶的（最高位是 x^r ）具体步骤如下面的描述。</p>
<p>发送方：</p>
<p>1 ）在发送的 m 位数据的二进制多项式 t(x) 后添加 r 个 0 ，扩张到 m+ r 位，以容纳 r 位的校验码，追加 0 后的二进制多项式为  T(x) ；</p>
<p>2 ）用 T(x) 除以生成多项式 g(x) ，得到 r 位的余数 y(x) ，它就是 CRC 校验码；</p>
<p>3 ）把 y(x) 追加到 t(x) 后面，此时的数据 s(x) 就是包含了 CRC 校验码的待发送字符串；由于 s(x) = t(x) y(x) ，因此 s(x) 肯定能被 g(x) 除尽。</p>
<p>接收方：</p>
<p>1 ）接收数据 n(x) ，这个 n(x) 就是包含了 CRC 校验码的 m+r 位数据；</p>
<p>2 ）计算 n(x) 除以 g(x) ，如果余数为 0 则表示传输过程没有错误，否则表示有错误。从 n(x) 去掉尾部的 r 位数据，得到的就是原始数据。</p>
<p>生成多项式不是随意选择的，以下是一些标准的 CRC 算法的生成多项式：</p>
<table>
<thead>
<tr>
<th>标准</th>
<th>生成多项式</th>
<th>16 进制表示</th>
</tr>
</thead>
<tbody><tr>
<td>CRC12</td>
<td>x^12 + x^11 + x^3 + x^2 + x + 1</td>
<td>0x80F</td>
</tr>
<tr>
<td>CRC16</td>
<td>x^16 + x^15 + x^2 + 1</td>
<td>0x8005</td>
</tr>
<tr>
<td>CRC16-CCITT</td>
<td>x^16 + x^12 + x^5 + 1</td>
<td>0x1021</td>
</tr>
<tr>
<td>CRC32</td>
<td>x^32 + x^26 + x^23 + x^22 + x^16 + x^12 + x^11+ x^10 + x^8 + x^7 + x^5 + x^4 + x^2 + x + 1</td>
<td>0x04C11DB7</td>
</tr>
</tbody></table>
<p>在python 3.0 之后: 返回值永远是无符号数。要在所有的 Python 版本和平台上获得相同的值，请使用 <strong>crc32(data) &amp; 0xffffffff</strong>。</p>
</blockquote>
<p><strong>问题：</strong> </p>
<p>使用本章的房产数据集：</p>
<ol>
<li>尝试一个支持向量机回归器（<code>sklearn.svm.SVR</code>），使用多个超参数，比如<code>kernel=&quot;linear&quot;</code>（多个超参数<code>C</code>值）。现在不用担心这些超参数是什么含义。最佳的<code>SVR</code>预测表现如何？</li>
</ol>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;<span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line"></span><br><span class="line">&gt;svm_reg = SVR(kernel=<span class="string">"linear"</span>)</span><br><span class="line">&gt;svm_reg.fit(housing_prepared, housing_labels)</span><br><span class="line">&gt;housing_predictions = svm_reg.predict(housing_prepared)</span><br><span class="line">&gt;svm_mse = mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line">&gt;svm_rmse = np.sqrt(svm_mse)</span><br><span class="line">&gt;svm_rmse <span class="comment"># output: 111094.6308539982</span></span><br></pre></td></tr></table></figure>

<p>结果不好。</p>
</blockquote>
<ol start="2">
<li>尝试用<code>RandomizedSearchCV</code>替换<code>GridSearchCV</code>。</li>
</ol>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line">&gt;<span class="keyword">from</span> scipy.stats <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line">&gt;param_distribs = &#123;</span><br><span class="line">       <span class="string">'n_estimators'</span>: randint(low=<span class="number">1</span>, high=<span class="number">200</span>),</span><br><span class="line">       <span class="string">'max_features'</span>: randint(low=<span class="number">1</span>, high=<span class="number">8</span>),</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&gt;forest_reg = RandomForestRegressor(random_state=<span class="number">42</span>)</span><br><span class="line">&gt;rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,</span><br><span class="line">                               n_iter=<span class="number">10</span>, cv=<span class="number">5</span>, scoring=<span class="string">'neg_mean_squared_error'</span>, random_state=<span class="number">42</span>)</span><br><span class="line">&gt;rnd_search.fit(housing_prepared, housing_labels)</span><br></pre></td></tr></table></figure>
</blockquote>
<ol start="3">
<li>尝试在准备流水线中添加一个只选择最重要属性的转换器。</li>
</ol>
<blockquote>
<p>​</p>
</blockquote>
<ol start="4">
<li>尝试创建一个单独的可以完成数据准备和最终预测的流水线。</li>
</ol>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;full_pipeline_with_predictor = Pipeline([</span><br><span class="line">       (<span class="string">"preparation"</span>, full_pipeline),</span><br><span class="line">       (<span class="string">"linear"</span>, LinearRegression())</span><br><span class="line">   ])</span><br><span class="line"></span><br><span class="line">&gt;full_pipeline_with_predictor.fit(housing, housing_labels)</span><br><span class="line">&gt;full_pipeline_with_predictor.predict(some_data)</span><br></pre></td></tr></table></figure>
</blockquote>
<ol start="5">
<li>使用<code>GridSearchCV</code>自动探索一些准备过程中的候选项。</li>
</ol>
<h3 id="第03章-分类"><a href="#第03章-分类" class="headerlink" title="第03章 分类"></a>第03章 分类</h3><p><a href="https://blog.csdn.net/weixin_38145317/article/details/79650188" target="_blank" rel="noopener">SVM、SVC、SVR</a> </p>
<p>####练习</p>
<ol>
<li><p>尝试在 MNIST 数据集上建立一个分类器，使它在测试集上的精度超过 97%。提示：<code>KNeighborsClassifier</code>非常适合这个任务。你只需要找出一个好的超参数值（试一下对权重和超参数<code>n_neighbors</code>进行网格搜索）。</p>
<p>​</p>
</li>
<li><p>写一个函数可以是 MNIST 中的图像任意方向移动（上下左右）一个像素。然后，对训练集上的每张图片，复制四个移动后的副本（每个方向一个副本），把它们加到训练集当中去。最后在扩展后的训练集上训练你最好的模型，并且在测试集上测量它的精度。你应该会观察到你的模型会有更好的表现。这种人工扩大训练集的方法叫做数据增强，或者训练集扩张。</p>
<p>​</p>
</li>
<li><p>拿 Titanic 数据集去捣鼓一番。开始这个项目有一个很棒的平台：Kaggle</p>
<p>​</p>
</li>
<li><p>建立一个垃圾邮件分类器（这是一个更有挑战性的练习）：</p>
</li>
</ol>
<ul>
<li>下载垃圾邮件和非垃圾邮件的样例数据。地址是<a href="https://spamassassin.apache.org/publiccorpus/" target="_blank" rel="noopener">Apache SpamAssassin 的公共数据集</a></li>
<li>解压这些数据集，并且熟悉它的数据格式。</li>
<li>将数据集分成训练集和测试集</li>
<li>写一个数据准备的流水线，将每一封邮件转换为特征向量。你的流水线应该将一封邮件转换为一个稀疏向量，对于所有可能的词，这个向量标志哪个词出现了，哪个词没有出现。举例子，如果所有邮件只包含了<code>&quot;Hello&quot;,&quot;How&quot;,&quot;are&quot;, &quot;you&quot;</code>这四个词，那么一封邮件（内容是：<code>&quot;Hello you Hello Hello you&quot;</code>）将会被转换为向量<code>[1, 0, 0, 1]</code>(意思是：<code>&quot;Hello&quot;</code>出现，<code>&quot;How&quot;</code>不出现，<code>&quot;are&quot;</code>不出现，<code>&quot;you&quot;</code>出现)，或者<code>[3, 0, 0, 2]</code>，如果你想数出每个单词出现的次数。</li>
<li>你也许想给你的流水线增加超参数，控制是否剥过邮件头、将邮件转换为小写、去除标点符号、将所有 URL 替换成<code>&quot;URL&quot;</code>，将所有数字替换成<code>&quot;NUMBER&quot;</code>，或者甚至提取词干（比如，截断词尾。有现成的 Python 库可以做到这点）。</li>
<li>然后 尝试几个不同的分类器，看看你可否建立一个很棒的垃圾邮件分类器，同时有着高召回率和高准确率。</li>
</ul>
<h3 id="第04章-训练模型"><a href="#第04章-训练模型" class="headerlink" title="第04章 训练模型"></a>第04章 训练模型</h3><h4 id="正态方程"><a href="#正态方程" class="headerlink" title="正态方程"></a><strong>正态方程</strong></h4><p>最小化损失函数 $\hat{\theta} =   (X^T \cdot X)^{-1} \cdot X^T \cdot y $</p>
<p>复杂度：需要计算$X^T\cdot X$ 的逆矩阵，是一个n*n的矩阵，运算复杂度大约在$O(n^{24})$ 到$O(n^{3})$之间。</p>
<p>可以numpy直接求解，也可以使用sklearn：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(X, y)</span><br><span class="line">lin_reg.intercept_, lin_reg.coef_</span><br></pre></td></tr></table></figure>

<p><code>LinearRegression类基于numpy.linalg.lstsq （least squares）</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond=<span class="number">1e-6</span>)</span><br><span class="line">theta_best_svd</span><br></pre></td></tr></table></figure>

<p>#####pseudoinverse (Moore-Penrose inverse)</p>
<p>该函数求解的是伪逆矩阵（pseudoinverse），即广义矩阵。其中最著名的伪逆矩阵为摩尔－彭若斯广义逆 A+（Moore–Penrose pseudoinverse)，常应用于求非一致线性方程组的最小范数最小二乘解（最小二乘法），并使得解的形式变得简单。矩阵的摩尔－彭若斯广义逆在实数域和复数域上都是唯一的，并且可以通过奇异值分解求得。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.linalg.pinv(X_b).dot(y)</span><br></pre></td></tr></table></figure>

<p>满足摩尔-彭若斯条件的矩阵G称为矩阵A的摩尔－彭若斯广义逆矩阵，记作A+：</p>
<p><img src="https://img-blog.csdn.net/20170824103329707?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemVhbGZvcnk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="条件"></p>
<p>从摩尔－彭若斯条件出发，彭若斯推导出了摩尔－彭若斯广义逆的一些性质：<br><img src="https://img-blog.csdn.net/20170824103423352?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemVhbGZvcnk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img"></p>
<p> 参考：<a href="https://blog.csdn.net/zealfory/article/details/77526815" target="_blank" rel="noopener">https://blog.csdn.net/zealfory/article/details/77526815</a></p>
<h4 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h4><p>超参数学习率的值决定了步长的大小。如果学习率太小，必须经过多次迭代，算法才能收敛，这是非常耗时的，如果学习率太大，你可能使算法发散，函数值变得越来越大，永远不可能找到一个好的答案。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-4.PNG" alt="学习率过小"></p>
<center>学习率过小</center>

<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-5.PNG" alt="img"></p>
<center>学习率过大</center>

<p><strong>两个主要挑战</strong></p>
<ol>
<li>收敛到局部最小值</li>
</ol>
<p>当使用梯度下降的时候，应该确保所有的特征有着相近的尺度范围（例如：使用 Scikit Learn 的 <code>StandardScaler</code>类），否则它将需要很长的时间才能够收敛。</p>
<h4 id="batch-GD"><a href="#batch-GD" class="headerlink" title="batch-GD"></a>batch-GD</h4><p>使用梯度下降的过程中，需要计算每一个 $\theta_j$ 下损失函数的梯度，即计算关于$\theta_j$ 的损失函数的偏导数，记为： </p>
<p>$$\frac{\partial}{\partial \theta_j} MSE(\theta)=\frac{2}{m}\sum_{i=1}^{m}({\theta^T\cdot x^{(i)}-y^{(i)})x_j^{}(i)}$$</p>
<p>写成矩阵的形式：</p>
<p>$$\nabla_\theta MSE(\theta)=\left( \begin{array}{c} \frac{\partial}{\partial \theta_0} MSE(\theta)\\frac{\partial}{\partial \theta_1} MSE(\theta)\…\\frac{\partial}{\partial \theta_n} MSE(\theta) \end{array} \right)=\frac {2}{m} X^T\cdot (X\cdot \theta-y)$$</p>
<blockquote>
<p>在这个方程中每一步计算时都包含了整个训练集$X$，这也是为什么这个算法称为<strong>批量梯度下降</strong>：每一次训练过程都使用所有的的训练数据。因此，在大数据集上，其会变得相当的慢。然而，梯度下降的运算规模和特征的数量成正比。训练一个数千数量特征的线性回归模型使用梯度下降要比使用正态方程快的多。</p>
</blockquote>
<p>梯度下降的步长：</p>
<p>$$\theta^{(next step)}=\theta-\eta\nabla_\theta MSE(\theta)$$</p>
<p>$\eta$ 为学习率</p>
<p>为了找到一个好的学习率，可以使用网格搜索，设置一个<strong>迭代次数</strong>。设置一个非常大的迭代次数，但是当梯度向量变得非常小（容差 $\epsilon$ ）的时候，结束迭代。</p>
<blockquote>
<p>收敛速率：</p>
<p>当损失函数是凸函数，且斜率不能突变（就像均方差损失函数那样），则它的批量梯度下降算法固定学习率之后，收敛速率是 $O(\frac{1}{iterations})$。换句话说，如果将容差 $\epsilon$ 缩小 10 倍（这样可以得到一个更精确的结果），算法的迭代次数大约会变成原来的 10 倍。</p>
</blockquote>
<h4 id="stochastic-gradient-descent"><a href="#stochastic-gradient-descent" class="headerlink" title="stochastic gradient descent"></a>stochastic gradient descent</h4><p>批量梯度下降的最要问题是计算每一步的梯度时都需要使用整个训练集，这导致在规模较大的数据集上，其会变得非常的慢。</p>
<p>而随机梯度下降，每一步的梯度计算只随机选取训练集中的一个样本。由于每一次迭代，只需要在内存中有一个实例，算法非常快，这使随机梯度算法可以在大规模训练集上使用。</p>
<p>另一方面，由于其随机性，SGD呈现出更多的不规律性：到达最小值不是平缓的下降，损失函数会忽高忽低，只在大体上呈下降趋势。随着时间的推移，非常的靠近最小值，但不会停止在一个值上，而是一直在这个值附近摆动。因此，算法停止时，最后的参数不是最优值。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-9.PNG" alt="img"></p>
<p>当损失函数很不规则时，随机梯度下降算法能够跳过局部最小值。因此，随机梯度下降在寻找全局最小值上比批量梯度下降表现要好。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-6.PNG" alt="img"></p>
<p>虽然随机性可以很好的跳过局部最优值，但同时它却不能达到最小值。解决这个难题的一个办法是<strong>逐渐降低学习率</strong>。</p>
<p>开始时，走的每一步较大（有助于快速前进同时跳过局部最小值），然后变得越来越小，从而使算法到达全局最小值。，这个过程被称为<strong>模拟退火</strong>。</p>
<p>决定每次迭代的学习率的函数称为<code>learning schedule</code>。 如果学习速度降低得过快，可能会陷入局部最小值，甚至在到达最小值的半路就停止了。 如果学习速度降低得太慢，可能在最小值的附近长时间摆动，同时如果过早停止训练，最终只会出现次优解。</p>
<h4 id="mini-batch-GD"><a href="#mini-batch-GD" class="headerlink" title="mini-batch GD"></a>mini-batch GD</h4><p>在迭代的每一步，小批量梯度下降使用一个随机的小型实例集。与随机梯度相比主要优点在于可以通过矩阵运算的硬件优化得到一个较好的训练表现。</p>
<p>小批量梯度下降在参数空间上的表现比随机梯度下降要好的多，尤其在有大量的小型实例集时。作为结果，小批量梯度下降会比随机梯度更靠近最小值。但是，另一方面，它有可能陷在局部最小值中（在遇到局部最小值问题的情况下，和我们之前看到的线性回归不一样）。 </p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-11.PNG" alt="img"></p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E8%A1%A84-1.PNG" alt="img"></p>
<h4 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h4><p>对每个特征进行加权后作为新的特征，然后训练一个线性模型在这个扩展的特征集。 这种方法称为多项式回归。</p>
<p><code>from sklearn.preprocessing import PolynomialFeatures</code></p>
<p>当存在多个特征时，多项式回归能够找出特征之间的关系（这是普通线性回归模型无法做到的）。 这是因为<code>LinearRegression</code>会自动添加当前阶数下特征的所有组合。例如，如果有两个特征 $a,b$，使用 3 阶（<code>degree=3</code>）的<code>LinearRegression</code>时，不仅有 $a^3, a^2, b^3, b^2$，同时也会有它们的其他组合项 $ab, ab^2, a^2b$</p>
<p><code>PolynomialFeatures(degree=d)</code>把一个包含$n$个特征的数组转换为一个包含 $\frac{(n+d)!}{d!n!}$特征的数组。小心大量特征的组合爆炸！</p>
<h4 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h4><p><strong>如何估计一个模型的泛化能力</strong> </p>
<ol>
<li>使用交叉验证。若模型在训练集上表现良好，通过交叉验证指标却得出其泛化能力很差，模型过拟合。如果在这两方面都表现不好，那么欠拟合。这种方法可以告诉我们模型是太复杂还是太简单了。</li>
<li>观察学习曲线：画出模型在训练集上的表现，同时画出以训练集规模为自变量的训练集函数。为了得到图像，需要在训练集的不同规模子集上进行多次训练。</li>
</ol>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-15.PNG" alt="img"></p>
<center>欠拟合</center>

<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-16.PNG" alt="img"></p>
<center>过拟合</center>

<blockquote>
<p>偏差和方差的权衡</p>
<p>在统计和机器学习领域有个重要的理论：一个模型的<strong>泛化误差</strong>由三个不同误差的和决定：</p>
<ul>
<li>偏差：泛化误差的这部分误差是由于错误的假设决定的。例如实际是一个二次模型，你却假设了一个线性模型。一个高偏差的模型最容易出现欠拟合。</li>
<li>方差：这部分误差是由于模型对训练数据的微小变化较为敏感，一个多自由度的模型更容易有高的方差（例如一个高阶多项式模型），因此会导致模型过拟合。</li>
<li>不可约误差：这部分误差是由于数据本身的噪声决定的。降低这部分误差的唯一方法就是进行数据清洗（例如：修复数据源，修复坏的传感器，识别和剔除异常值）。</li>
</ul>
</blockquote>
<h4 id="线性模型的正则化"><a href="#线性模型的正则化" class="headerlink" title="线性模型的正则化"></a>线性模型的正则化</h4><p>正则化这个模型（即限制它）：模型有越少的自由度，就越难以拟合数据。例如，正则化一个多项式模型，一个简单的方法就是减少多项式的阶数。</p>
<p>对于一个线性模型，正则化的典型实现就是约束模型中参数的权重。</p>
<h5 id="岭回归（Ridge）"><a href="#岭回归（Ridge）" class="headerlink" title="岭回归（Ridge）"></a>岭回归（Ridge）</h5><p>岭回归（也称为 Tikhonov 正则化）是线性回归的正则化版：在损失函数上直接加上一个正则项。这使得学习算法不仅能够拟合数据，而且能够使模型的参数权重尽量的小。注意到这个正则项只有在训练过程中才会被加到损失函数。当得到完成训练的模型后，我们应该使用没有正则化的测量方法去评价模型的表现。</p>
<blockquote>
<p>提示</p>
<p>一般情况下，训练过程使用的损失函数和测试过程使用的评价函数是不一样的。除了正则化，还有一个不同：训练时的损失函数应该在优化过程中易于求导，而在测试过程中，评价函数更应该接近最后的客观表现。一个好的例子：在分类训练中我们使用对数损失（马上我们会讨论它）作为损失函数，但是我们却使用精确率/召回率来作为它的评价函数。</p>
</blockquote>
<p>岭回归损失函数：</p>
<p>$J(\theta)=MSE(\theta)+\alpha \frac{1}{2} \sum_{i=1}^{n}{\theta _i ^2}$</p>
<p>$\theta_0$是没有被正则化的，所以累加从i=1开始，而不是i=0开始。如果定义w作为特征的权重向量（$\theta_1$到$\theta_n$），则正则项可以简写成$\frac{1}{2}(||w||_2)^2$ ，$||\cdot||_2$表示$l_2$范数。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-17.PNG" alt="img"></p>
<p>######封闭方程的解</p>
<p>$$\hat \theta=(X^T\cdot X+\alpha A)^{-1}\cdot X^T\cdot y$$</p>
<p>A是一个除了左上角有一个0的nxn的单位矩阵，表示偏差$\theta_0$不被正则化。</p>
<h6 id="随机梯度下降法求解"><a href="#随机梯度下降法求解" class="headerlink" title="随机梯度下降法求解"></a>随机梯度下降法求解</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sgd_reg = SGDRegressor(penalty=<span class="string">"l2"</span>)</span><br><span class="line"><span class="comment"># penalty参数指的是正则项的惩罚类型。指定“l2”表明你要在损失函数上添加一项：权重向量 l2 范数平方的一半，这就是简单的岭回归。</span></span><br></pre></td></tr></table></figure>

<h5 id="Lasso回归"><a href="#Lasso回归" class="headerlink" title="Lasso回归"></a>Lasso回归</h5><p>Lasso 回归（也称 Least Absolute Shrinkage，或者 Selection Operator Regression）是另一种正则化版的线性回归：就像岭回归那样，它也在损失函数上添加了一个正则化项，但是它使用权重向量的$l_1$ 范数而不是权重向量 $l_2$范数平方的一半。</p>
<p>$J(\theta)=MSE(\theta)+\alpha \sum_{i=1}^{n}{|\theta _i|}$</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-18.PNG" alt="img"></p>
<p>Lasso 回归的一个重要特征是它倾向于完全消除最不重要的特征的权重（即将它们设置为零）。例如，右图中的虚线所示$\alpha=10^{-7}$，曲线看起来像一条二次曲线，而且几乎是线性的，这是因为所有的高阶多项特征都被设置为零。换句话说，Lasso回归自动的进行特征选择同时输出一个稀疏模型（即，具有很少的非零权重）。</p>
<p>Lasso 回归子梯度向量:</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-93eea6b5c197bbc8d7be8b4c14e9f8f3.gif" alt="g(\theta,J)=\nabla_{\theta}MSE(\theta)+ \alpha{\left(\begin{matrix} sign(\theta_1)\\ sign(\theta_2)\\ \vdots \\ sign(\theta_n)\\ \end{matrix}\right)}\ where\ sign(\theta_i)= \begin{cases} -1, &amp;\theta_i&lt;0 \\ 0, &amp;\theta_i=0 \\ +1,&amp;\theta_i&gt;0 \\ \end{cases}"></p>
<h5 id="弹性网络（ElasticNet）"><a href="#弹性网络（ElasticNet）" class="headerlink" title="弹性网络（ElasticNet）"></a>弹性网络（ElasticNet）</h5><p>弹性网络介于 Ridge 回归和 Lasso 回归之间。它的正则项是 Ridge 回归和 Lasso 回归正则项的简单混合，同时你可以控制它们的混合率 <a href="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-4b43b0aee35624cd95b910189b3dc231.gif" target="_blank" rel="noopener"><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-4b43b0aee35624cd95b910189b3dc231.gif" alt="r"></a></p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/tex-e4da079f692fe35778bbdf1fdf120d99.gif" alt="J(\theta)=MSE(\theta)+r\alpha\sum\limits_{i=1}n\left|\theta_i \right|+\frac{1-r}{2}\alpha\sum\limits_{i=1}n\theta_i^2"></p>
<p>#####早起停止法（Early Stopping）</p>
<p>对于迭代学习算法，有一种非常特殊的正则化方法，就像梯度下降在验证错误达到最小值时立即停止训练那样。我们称为早期停止法。</p>
<p><img src="https://img.cntofu.com/book/hands_on_Ml_with_Sklearn_and_TF/images/chapter_4/%E5%9B%BE4-20.PNG" alt="img"></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/sklearn/" rel="tag"># sklearn</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/08/25/%E3%80%8AScikit-Learn%E4%B8%8ETensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97%E3%80%8B-LAPTOP-CSVRUNHI/" rel="prev" title="《Scikit-Learn与TensorFlow机器学习实用指南》-LAPTOP-CSVRUNHI">
      <i class="fa fa-chevron-left"></i> 《Scikit-Learn与TensorFlow机器学习实用指南》-LAPTOP-CSVRUNHI
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/08/25/%E5%A6%82%E4%BD%95%E5%9C%A8Jupyter%20Notebook%E4%B8%AD%E4%BD%BF%E7%94%A8Python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%EF%BC%9F-LAPTOP-CSVRUNHI/" rel="next" title="如何在Jupyter Notebook中使用Python虚拟环境？">
      如何在Jupyter Notebook中使用Python虚拟环境？ <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#《Scikit-Learn与TensorFlow机器学习实用指南》"><span class="nav-number">1.</span> <span class="nav-text">《Scikit-Learn与TensorFlow机器学习实用指南》</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#第01章-机器学习概览"><span class="nav-number">1.1.</span> <span class="nav-text">第01章 机器学习概览</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#问题："><span class="nav-number">1.1.1.</span> <span class="nav-text">问题：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第02章-一个完整的机器学习项目"><span class="nav-number">1.2.</span> <span class="nav-text">第02章 一个完整的机器学习项目</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#特点：检错能力极强，开销小等"><span class="nav-number">1.2.1.</span> <span class="nav-text">特点：检错能力极强，开销小等</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#本质"><span class="nav-number">1.2.2.</span> <span class="nav-text">本质</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CRC-校验的基本过程"><span class="nav-number">1.2.3.</span> <span class="nav-text">CRC 校验的基本过程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第03章-分类"><span class="nav-number">1.3.</span> <span class="nav-text">第03章 分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第04章-训练模型"><span class="nav-number">1.4.</span> <span class="nav-text">第04章 训练模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#正态方程"><span class="nav-number">1.4.1.</span> <span class="nav-text">正态方程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#梯度下降法"><span class="nav-number">1.4.2.</span> <span class="nav-text">梯度下降法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#batch-GD"><span class="nav-number">1.4.3.</span> <span class="nav-text">batch-GD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#stochastic-gradient-descent"><span class="nav-number">1.4.4.</span> <span class="nav-text">stochastic gradient descent</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mini-batch-GD"><span class="nav-number">1.4.5.</span> <span class="nav-text">mini-batch GD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多项式回归"><span class="nav-number">1.4.6.</span> <span class="nav-text">多项式回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#学习曲线"><span class="nav-number">1.4.7.</span> <span class="nav-text">学习曲线</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#线性模型的正则化"><span class="nav-number">1.4.8.</span> <span class="nav-text">线性模型的正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#岭回归（Ridge）"><span class="nav-number">1.4.8.1.</span> <span class="nav-text">岭回归（Ridge）</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#随机梯度下降法求解"><span class="nav-number">1.4.8.1.1.</span> <span class="nav-text">随机梯度下降法求解</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Lasso回归"><span class="nav-number">1.4.8.2.</span> <span class="nav-text">Lasso回归</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#弹性网络（ElasticNet）"><span class="nav-number">1.4.8.3.</span> <span class="nav-text">弹性网络（ElasticNet）</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="QQAI"
      src="/images/header.jpg">
  <p class="site-author-name" itemprop="name">QQAI</p>
  <div class="site-description" itemprop="description">Home is behind, the world ahead</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">QQAI</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.1
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
