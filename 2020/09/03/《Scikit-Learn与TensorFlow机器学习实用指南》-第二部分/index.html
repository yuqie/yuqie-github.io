<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="学习资料参考： 一个完整的机器学习项目.md 原书Github上代码 Oreilly上原书第二版（可以在线阅读） 第一版翻译 简书第一版 简书第二版第二部分 简书《Scikit-Learn、Keras与TensorFlow机器学习实用指南》第一版和第二版对照 练习题答案参考 参考2">
<meta property="og:type" content="article">
<meta property="og:title" content="《Scikit-Learn与TensorFlow机器学习实用指南》-第二部分">
<meta property="og:url" content="http://yoursite.com/2020/09/03/%E3%80%8AScikit-Learn%E4%B8%8ETensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97%E3%80%8B-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/index.html">
<meta property="og:site_name" content="Ringinmay&#39;s Blog">
<meta property="og:description" content="学习资料参考： 一个完整的机器学习项目.md 原书Github上代码 Oreilly上原书第二版（可以在线阅读） 第一版翻译 简书第一版 简书第二版第二部分 简书《Scikit-Learn、Keras与TensorFlow机器学习实用指南》第一版和第二版对照 练习题答案参考 参考2">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-51a591f44c8f7bba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-c40c1380818019d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1113/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-878dec9a6b1e9c09.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-a8b41a11c481fc03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-eb971779e84208ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-cfc40648369f3b02.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-51306abe073c8ea2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-be616eb033cc7b19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-9e017b74d26835cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-cc7f49f651ae6a8a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/951/format/webp">
<meta property="og:image" content="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/assets/mls2_aain01.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-cfc40648369f3b02.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-c252c67afc52e2f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-34956eb953f08cc1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/702/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-8ccaf8b0c543be01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/956/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-2e50453795b314b6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-e996caccf4ed7c10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/936/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-7bdffc790dc8451f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-1248ce61162010fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/761/format/webp">
<meta property="og:image" content="https://math.jianshu.com/math?formula=%5Cwidehat%7BX%7D">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-888f214e6c98e88c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1038/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-69fe44e53b9ea29b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-f75650e5b631e9bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-38590903b6626149.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/932/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-b852a34b26165cad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/282/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-d2b7668bc13b3ead.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-a24cf7849a7f0c1c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1006/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-827f2d812a6f5640.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1136/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-5060d73f5a52760d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-7ac8433cdc7346f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-19249b3d162bbcb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1170/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-b822155fbb4dd3c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1166/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-4d1453d7d971cba7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-c77b37df3aea8d69.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-647e362f4abb081e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-cd0d53808f2cf8a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-e2753af12c9e73a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-86355457e5a7a1c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-1cfddd1d6ac1db56.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1102/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-9968acd895a0095e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1049/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-8607c8748eef3e4f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-fb733f1a729f0406.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1052/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-4030e5fa51363eb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-4590999c8c41bf3e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-ed2580d5b84531fb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-1c5bbecf35d2e8d9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-39ad65a741a0b167.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-4c0d23d3db687219.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-e911c02ef15d5001.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-67bc697752690e26.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-e945414fcaeeed67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-79c6bd0d2b869c73.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-b26a1770e6dc75da.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1046/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-860eda4472257180.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1095/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-22b08969517e84c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-0a727314de2f6f56.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-a333026f0dd537b5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-33df138d7fe796c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1040/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-b3d78efe2539d55c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-93e236002a0fa2e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-da0506216d22820b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1124/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-96e89d75c6e86056.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-97d3ae02870c17ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-95d0229917d60063.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-870922646a65a746.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-b6809b315bb6dba7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-a96113128470474a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/816/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-8103b55a6c0b39cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-9e0614d9745baf00.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/928/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-fd8844d61cc65f10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/986/format/webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-e3e9a45c0fefb30e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="og:image" content="https://math.jianshu.com/math?formula=%5Csqrt%7B2%252Fninputs%7D">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-6c97696a5b56dafd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">
<meta property="article:published_time" content="2020-09-03T10:28:14.000Z">
<meta property="article:modified_time" content="2020-09-16T02:15:51.818Z">
<meta property="article:author" content="QQAI">
<meta property="article:tag" content="sklearn">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://upload-images.jianshu.io/upload_images/7178691-51a591f44c8f7bba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp">

<link rel="canonical" href="http://yoursite.com/2020/09/03/%E3%80%8AScikit-Learn%E4%B8%8ETensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97%E3%80%8B-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>《Scikit-Learn与TensorFlow机器学习实用指南》-第二部分 | Ringinmay's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ringinmay's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Home is behind, the world ahead</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/03/%E3%80%8AScikit-Learn%E4%B8%8ETensorFlow%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E7%94%A8%E6%8C%87%E5%8D%97%E3%80%8B-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.jpg">
      <meta itemprop="name" content="QQAI">
      <meta itemprop="description" content="Home is behind, the world ahead">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ringinmay's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          《Scikit-Learn与TensorFlow机器学习实用指南》-第二部分
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-09-03 18:28:14" itemprop="dateCreated datePublished" datetime="2020-09-03T18:28:14+08:00">2020-09-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-16 10:15:51" itemprop="dateModified" datetime="2020-09-16T10:15:51+08:00">2020-09-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" itemprop="url" rel="index">
                    <span itemprop="name">数据分析</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>学习资料参考：</p>
<p><a href="https://www.cntofu.com/book/27/docs/2.%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE.md" target="_blank" rel="noopener">一个完整的机器学习项目.md</a></p>
<p><a href="https://github.com/ageron/handson-ml2" target="_blank" rel="noopener">原书Github上代码</a></p>
<p><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" target="_blank" rel="noopener">Oreilly上原书第二版（可以在线阅读）</a></p>
<p><a href="https://github.com/apachecn/hands-on-ml-zh/blob/master/docs/1.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88.md" target="_blank" rel="noopener">第一版翻译</a></p>
<p><a href="https://www.jianshu.com/p/3470a6efbe8d" target="_blank" rel="noopener">简书第一版</a></p>
<p><a href="https://www.jianshu.com/p/86626c79814a" target="_blank" rel="noopener">简书第二版第二部分</a></p>
<p><a href="https://www.jianshu.com/p/4a94798f7dcc" target="_blank" rel="noopener">简书《Scikit-Learn、Keras与TensorFlow机器学习实用指南》第一版和第二版对照</a></p>
<p><a href="https://blog.csdn.net/jiaoyangwm/article/details/82387883#%E7%BB%83%E4%B9%A0%E9%A2%987" target="_blank" rel="noopener">练习题答案参考</a> <a href="https://blog.csdn.net/leowinbow/article/details/88581039" target="_blank" rel="noopener">参考2</a></p>
<a id="more"></a>
<p>[TOC]</p>
<h2 id="第10章-使用Keras搭建人工神经网络"><a href="#第10章-使用Keras搭建人工神经网络" class="headerlink" title="第10章 使用Keras搭建人工神经网络"></a>第10章 使用Keras搭建人工神经网络</h2><p>需要安装<a href="https://www.jianshu.com/p/3a76e4f0504a" target="_blank" rel="noopener">Tensorflow</a>和Keras</p>
<p>人工神经网络是受大脑中的生物神经元启发而来的机器学习模型。</p>
<p>人工神经网络是深度学习的核心，它不仅样式多样、功能强大，还具有可伸缩性，这让人工神经网络适宜处理庞大且复杂的机器学习任务，例如对数十亿张图片分类（谷歌图片）、语音识别（苹果Siri）、向数亿用户每天推荐视频（Youtube）、或者通过学习几百围棋世界冠军（DeepMind的AlphaGo）。</p>
<h3 id="神经元的逻辑计算"><a href="#神经元的逻辑计算" class="headerlink" title="神经元的逻辑计算"></a>神经元的逻辑计算</h3><p>1943年神经生理学家Warren McCulloch和数学家Walter Pitts在他们里程碑的论文<a href="https://scholar.google.com/scholar?q=A+Logical+Calculus+of+Ideas+Immanent+in+Nervous+Activity+author%3Amcculloch" target="_blank" rel="noopener">《A Logical Calculus of Ideas Immanent in Nervous Activity》</a> 中介绍了一个简单的生物神经元模型，它后来演化成了人工神经元：一个或多个二元（开或关）输入，一个二元输出。当达到一定的输入量时，神经元就会产生输出。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-51a591f44c8f7bba.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="感知机（单个TLU）"><a href="#感知机（单个TLU）" class="headerlink" title="感知机（单个TLU）"></a>感知机（单个TLU）</h3><p>感知机是最简单的人工神经网络结构之一，由 Frank Rosenblatt 发明于 1957年。</p>
<p>它基于一种稍微不同的人工神经元，阈值逻辑单元（TLU），或称为线性阈值单元（LTU）：输入和输出是数字（而不是二元开/关值），并且每个输入连接都一个权重。TLU计算其输入的加权和（$z = W_1x_1 + W_2x_2 + … + W_nx_n = x^T·W）$，然后将阶跃函数应用于该和，并输出结果：$h_W(x) = step(z)$，其中$z = x^T·W$。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-c40c1380818019d3.png?imageMogr2/auto-orient/strip|imageView2/2/w/1113/format/webp" alt="img"></p>
<h4 id="阶跃函数："><a href="#阶跃函数：" class="headerlink" title="阶跃函数："></a><strong>阶跃函数</strong>：</h4><p>单位阶跃函数（Heaviside step function）:</p>
<script type="math/tex; mode=display">
heaviside(z)=\left \{ \begin{array} {ll} 0& if\ z<0\\1&if \ z\geq 0 \end{array} \right.\\
sgn(z)=\left \{ \begin{array} {ll} 0& if\ z<0\\0 & if\ z =0\\1&if \ z\gt 0 \end{array} \right.</script><p>单一TLU 可用于简单的线性二元分类。它计算输入的线性组合，如果结果超过阈值，它输出正类或者输出负类（就像逻辑回归分类或线性SVM分类）。</p>
<p><strong>感知器只由一层 TLU 组成，每个TLU连接到所有输入</strong>。当一层的神经元连接着前一层的每个神经元时，该层被称为<strong>全连接层，或紧密层</strong>。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-878dec9a6b1e9c09.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>通常再添加一个<strong>偏置特征（$X_0=1$）</strong>：这种偏置特性通常用一种称为偏置神经元的特殊类型的神经元来表示，它总是输出 1。</p>
<p>一个全连接层神经网络的输出：$h_{W,b}(x) = \phi (XW+B)$</p>
<h4 id="Hebb规则"><a href="#Hebb规则" class="headerlink" title="Hebb规则"></a>Hebb规则</h4><p>如何训练感知机：感知器一次被馈送一个训练实例，对于每个实例，它进行预测。对于每一个产生错误预测的输出神经元，修正输入的连接权重，以获得正确的预测。</p>
<script type="math/tex; mode=display">
\omega_{i,j}^{(next \ step)}=\omega_{i,j}+\eta (y_j-\hat y_j)x_i</script><p><strong>每个输出神经元的决策边界是线性的，因此感知器不能学习复杂的模式</strong>（比如 Logistic 回归分类器）。如果训练实例是线性可分的，Rosenblatt 证明该算法将收敛到一个解。这被称为<strong>感知器收敛定理</strong>。</p>
<p><strong>感知机不输出类概率，而是基于硬阈值进行预测。</strong></p>
<h4 id="感知机的局限性"><a href="#感知机的局限性" class="headerlink" title="感知机的局限性"></a>感知机的局限性</h4><ol>
<li>不能解决一些琐碎的问题（例如，异或（XOR）分类问题）（线性分类模型都不能解决异或问题）</li>
</ol>
<p>可以通过堆叠多个感知机消除，由此产生的人工神经网络被称为<strong>多层感知机（MLP）</strong>。特别地，MLP 可以解决 XOR 问题：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-a8b41a11c481fc03.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="多层感知机（MLP）"><a href="#多层感知机（MLP）" class="headerlink" title="多层感知机（MLP）"></a>多层感知机（MLP）</h3><p>MLP 由一个输入层、一个或多个称为隐藏层的 TLU 组成，一个 TLU 层称为输出层（见图 10-7）。靠近输入层的层，通常被称为浅层，靠近输出层的层通常被称为上层。除了输出层，每一层都有一个偏置神经元，并且全连接到下一层。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-eb971779e84208ec.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>信号是从输入到输出单向流动，因此这种架构被称为<strong>前馈神经网络（FNN）</strong></p>
<p>当人工神经网络有多个隐含层时，称为<strong>深度神经网络（DNN）</strong></p>
<h3 id="反向传播（Back-Propagation）"><a href="#反向传播（Back-Propagation）" class="headerlink" title="反向传播（Back Propagation）"></a>反向传播（Back Propagation）</h3><p>一种训练 MLP 的方法，使用了高效梯度计算的梯度下降算法只需要两次网络传播（一次向前，一次向后），就可以算出网络误差的、和每个独立模型参数相关的梯度。</p>
<blockquote>
<ol>
<li>每次处理一个微批次（假如每个批次包含32个实例），用训练集多次训练BP，每次被称为一个周期（epoch）；</li>
<li>每个微批次先进入输入层，输入层再将其发到第一个隐藏层。计算得到该层所有神经元的（微批次的每个实例的）输出。输出接着传到下一层，直到得到输出层的输出。这个过程就是<strong>前向传播</strong>：就像做预测一样，只是保存了每个中间结果，中间结果要用于反向传播；</li>
<li>然后计算输出误差（使用损失函数比较目标值和实际输出值，然后返回误差）；</li>
<li>通过<strong>链式法则</strong>（对多个变量做微分）计算每个输出连接对误差的贡献量；</li>
<li>使用<strong>链式法则</strong>，计算最后一个隐藏层的每个连接对误差的贡献，这个过程不断向后传播，直到到达输入层。</li>
<li>BP算法做一次梯度下降步骤，用刚刚计算的误差梯度调整所有连接权重。</li>
</ol>
</blockquote>
<p>对每个训练实例，BP算法先做一次预测（前向传播），然后计算误差，然后反向通过每一层以测量误差贡献量（反向传播），最后调整所有连接权重以降低误差（梯度下降）。（每个循环：向前，向后，调整参数）</p>
<p><strong>注意：</strong></p>
<blockquote>
<p><strong>要机初始化隐藏层的连接权重</strong>。假如所有的权重和偏置都初始化为0，则在给定一层的所有神经元都是一样的，BP算法对这些神经元的调整也会是一样的。换句话，就算每层有几百个神经元，模型的整体表现就像每层只有一个神经元一样，模型会显得笨笨的。如果权重是随机初始化的，就可以打破对称性，训练出不同的神经元。</p>
<p><strong>自动计算梯度被称为自动微分。</strong>反向传播使用的是<strong>反向模式自微分</strong>。这种方法快而准，当函数有多个变量（连接权重）和多个输出（损失函数）要微分时也能应对。</p>
</blockquote>
<h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>用其他激活函数代替阶跃函数（因为阶跃函数只包含平坦的段，因此没有梯度，而 Logistic函数处处都有一个定义良好的非零导数，允许梯度下降在每步上取得一些进展。）</p>
<ul>
<li><p>sigmoid（Logistic）函数：输出范围0~1</p>
<p>$\sigma(z)=\frac{1}{1+\exp(-z)}$</p>
</li>
</ul>
<ul>
<li><p>双曲正切函数： S形，连续可微，输出范围-1~1</p>
<p>$\tanh (z) = 2σ(2z) – 1$</p>
</li>
<li><p>ReLU 函数：连续，但在<code>z=0</code>处不可微，没有最大输出值，但效果好，计算快速</p>
<p>$ReLU(z) = max(0, z)$</p>
</li>
<li><p>softplus函数：ReLU函数的平滑变体,z是负值时，softplus接近0，z是正值时，softplus接近z</p>
<p>$softplus(z) = log(1 + exp(z))$</p>
</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-cfc40648369f3b02.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong>设置激活函数的原因</strong>：</p>
<p>如果将几个线性变化链式组合起来，得到的还是线性变换。比如，对于 <code>f(x) = 2x + 3</code> 和 <code>g(x) = 5x – 1</code> ，两者组合起来仍是线性变换：<code>f(g(x)) = 2(5x – 1) + 3 = 10x + 1</code>。<strong>如果层之间不具有非线性，则深层网络和单层网络其实是等同的，这样就不能解决复杂问题。</strong>相反的，足够深且有非线性激活函数的DNN（深度神经网络），在理论上可以近似于任意连续函数。</p>
<h3 id="回归MLP"><a href="#回归MLP" class="headerlink" title="回归MLP"></a>回归MLP</h3><p>预测一个单值，就只需要一个输出神经元；一次预测多个值，则每一维度都要有一个神经元。</p>
<p>回归问题可以不用激活函数，如果想限制输出落到一定范围内，可以使用激活函数。</p>
<p><strong>损失函数</strong>：一般使用<strong>均方误差</strong>，但如果训练集有许多异常值，则可以使用<strong>平均绝对误差</strong>。也可以使用<strong>Huber损失函数</strong>，它是前两者的组合。</p>
<blockquote>
<p>提示：当误差小于阈值δ时（一般为1），Huber损失函数是二次的；误差大于阈值时，Huber损失函数是线性的。相比均方误差，线性部分可以让Huber对异常值不那么敏感，二次部分可以让收敛更快，也比均绝对误差更精确。</p>
</blockquote>
<p><strong>回归MLP的典型架构</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-51306abe073c8ea2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="分类MLP"><a href="#分类MLP" class="headerlink" title="分类MLP"></a>分类MLP</h3><p>二元分类问题：需要一个使用Logistic激活的输出神经元：输出一个0和1之间的值，作为正类的估计概率。</p>
<p>多标签二元分类问题：需要为每个正类配一个输出神经元。多个输出概率的和不一定非要等于1。</p>
<p>多分类：softmax函数可以保证，每个估计概率位于0和1之间，并且各个值相加等于1。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-be616eb033cc7b19.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong>损失函数</strong>： 预测概率分布，可以使用交叉商损失函数</p>
<p><strong>分类MLP的典型架构</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9e017b74d26835cf.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="用Keras实现MLP"><a href="#用Keras实现MLP" class="headerlink" title="用Keras实现MLP"></a>用Keras实现MLP</h3><blockquote>
<p>Keras是一个深度学习高级API，可以用它轻松地搭建、训练、评估和运行各种神经网络。是François Chollet开发的，于2015年3月开源。为了进行神经网络计算，必须要有计算后端的支持。目前可选三个流行库：TensorFlow、CNTK和Theano。</p>
<p>TensorFlow捆绑了自身的Keras实现 —— tf.keras，它只支持TensorFlow作为后端，但提供了更多使用的功能：例如，tf.keras支持TensorFlow的Data API，加载数据更轻松，预处理数据更高效。</p>
<p>排在Keras和TensorFlow之后最流行的深度学习库，是Facebook的PyTorch。</p>
</blockquote>
<p><strong>keras中<code>Sequential API</code>可以搭建序列化的神经网络</strong></p>
<p><strong>复杂模型可以通过<code>Functional API</code>搭建</strong></p>
<p>Wide &amp; Deep是一个非序列化的神经网络模型。由Heng-Tze Cheng在2016年在提出。这个模型可以将全部或部分输入与输出层连起来，既可以学到深层模式（使用深度路径）和简单规则（使用短路径）。作为对比，常规MLP会强制所有数据流经所有层，因此数据中的简单模式在多次变换后会被扭曲。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-cc7f49f651ae6a8a.png?imageMogr2/auto-orient/strip|imageView2/2/w/951/format/webp" alt="img"></p>
<p><strong>使用Subclassing API搭建动态模型</strong></p>
<p>Sequential API和Functional API都是声明式的：只有声明创建每个层以及层的连接方式，才能给模型加载数据以进行训练和推断。</p>
<blockquote>
<p>优点：模型可以方便的进行保存、克隆和分享；模型架构得以展示，便于分析；框架可以推断数据形状和类型，便于及时发现错误（加载数据之前就能发现错误）。调试也很容易，因为模型是层的静态图。</p>
<p>缺点：模型是静态的。不适合一些模型包含循环、可变数据形状、条件分支，和其它的动态特点的情况。</p>
</blockquote>
<p>对<code>Model</code>类划分子类，在构造器中创建需要的层，调用<code>call()</code>进行计算，。</p>
<blockquote>
<p>优点是：</p>
<ol>
<li>将层的创建和和使用分割了</li>
</ol>
<p>代价是：</p>
<ol>
<li>模型架构隐藏在<code>call()</code>方法中，所以Keras不能对其检查</li>
<li>不能保存或克隆</li>
<li>当调用<code>summary()</code>时，得到的只是层的列表，没有层的连接信息</li>
<li>Keras不能提前检查数据类型和形状，所以很容易犯错。</li>
</ol>
</blockquote>
<h4 id="保存和恢复模型"><a href="#保存和恢复模型" class="headerlink" title="保存和恢复模型"></a>保存和恢复模型</h4><p>Keras使用HDF5格式保存模型架构（包括每层的超参数）和每层的所有参数值（连接权重和偏置项）。还保存了优化器（包括超参数和状态）。</p>
<p>加载：<code>keras.models.load_model</code> </p>
<blockquote>
<p><strong>注意</strong> </p>
<p>这种加载模型的方法只对Sequential API或Functional API有用，不适用于Subclassing API。对于后者，可以用save_weights()和load_weights()保存参数，其它的就得手动保存恢复了。</p>
</blockquote>
<h4 id="使用调回"><a href="#使用调回" class="headerlink" title="使用调回"></a>使用调回</h4><p>对于大数据集上，训练时间长的情况，不仅要在训练结束时保存模型检查点，在一定时间间隔内也要保存，以免电脑宕机造成损失。</p>
<p><code>fit()</code>方法接受参数<code>callbacks</code>，可以让用户指明一个Keras列表，让Keras在训练开始和结束、每个周期开始和结束、甚至是每个批次的前后调用。例如，<code>ModelCheckpoint</code>可以在每个时间间隔保存检查点，默认是每个周期结束之后</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model.compile(loss=<span class="string">"mse"</span>, optimizer=keras.optimizers.SGD(lr=<span class="number">1e-3</span>))</span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">"my_keras_model.h5"</span>, save_best_only=<span class="literal">True</span>)</span><br><span class="line">history = model.fit(X_train, y_train, epochs=<span class="number">10</span>,</span><br><span class="line">                    validation_data=(X_valid, y_valid),</span><br><span class="line">                    callbacks=[checkpoint_cb])</span><br><span class="line">model = keras.models.load_model(<span class="string">"my_keras_model.h5"</span>) <span class="comment"># rollback to best model</span></span><br><span class="line">mse_test = model.evaluate(X_test, y_test)</span><br></pre></td></tr></table></figure>
<h3 id="使用TensorBoard进行可视化"><a href="#使用TensorBoard进行可视化" class="headerlink" title="使用TensorBoard进行可视化"></a>使用TensorBoard进行可视化</h3><p>要使用TensorBoard，必须修改程序，将要可视化的数据输出为二进制的日志文件event files。每份二进制数据称为摘要summary，TensorBoard服务器会监测日志文件目录，自动加载更新并可视化：这样就能看到实时数据（稍有延迟），比如训练时的学习曲线。通常，将TensorBoard服务器指向根日志目录，程序的日志写入到它的子目录，这样一个TensorBoard服务就能可视化并比较多次运行的数据，而不会将其搞混。</p>
<h3 id="神经网络参数微调"><a href="#神经网络参数微调" class="headerlink" title="神经网络参数微调"></a>神经网络参数微调</h3><h4 id="微调神经网络的超参数"><a href="#微调神经网络的超参数" class="headerlink" title="微调神经网络的超参数"></a>微调神经网络的超参数</h4><ol>
<li>直接试验超参数的组合，看哪一个在验证集（或使用K折交叉验证）的表现最好。</li>
</ol>
<p>例如，可以使用<code>GridSearchCV</code>或<code>RandomizedSearchCV</code>探索超参数空间</p>
<blockquote>
<p>必须将Keras模型包装进模仿Scikit-Learn回归器的对象中。第一步是给定一组超参数，创建一个搭建和编译Keras模型的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)</span><br></pre></td></tr></table></figure>
<p>因为超参数太多，最好使用随机搜索而不是网格搜索</p>
</blockquote>
<ol>
<li><p>其他探索超参数空间的方法：</p>
<p>核心思想：当某块空间的区域表现好时，就多探索这块区域。这些方法可以代替用户做“放大”工作，可以在更短的时间得到更好的结果。</p>
</li>
</ol>
<blockquote>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fhyperopt%2Fhyperopt" target="_blank" rel="noopener">Hyperopt</a><br>一个可以优化各种复杂搜索空间（包括真实值，比如学习率和离散值，比如层数）的库。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fmaxpumperla%2Fhyperas" target="_blank" rel="noopener">Hyperas</a>，<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2FAvsecz%2Fkopt" target="_blank" rel="noopener">kopt</a> 或 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fautonomio%2Ftalos" target="_blank" rel="noopener">Talos</a><br>用来优化Keras模型超参数的库（前两个是基于Hyperopt的）。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fkerastuner" target="_blank" rel="noopener">Keras Tuner</a><br>Google开发的简单易用的Keras超参数优化库，还有可视化和分析功能。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fscikit-optimize.github.io%2F" target="_blank" rel="noopener">Scikit-Optimize (<code>skopt</code>)</a><br>一个通用的优化库。类<code>BayesSearchCV</code>使用类似于<code>GridSearchCV</code>的接口做贝叶斯优化。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2FJasperSnoek%2Fspearmint" target="_blank" rel="noopener">Spearmint</a><br>一个贝叶斯优化库。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fzygmuntz%2Fhyperband" target="_blank" rel="noopener">Hyperband</a><br>一个快速超参数调节库，基于Lisha Li的论文 《Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization》，<a href="https://links.jianshu.com/go?to=https%3A%2F%2Farxiv.org%2Fabs%2F1603.06560" target="_blank" rel="noopener">https://arxiv.org/abs/1603.06560</a>。</p>
<p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Frsteca%2Fsklearn-deap" target="_blank" rel="noopener">Sklearn-Deap</a><br>一个基于进化算法的超参数优化库，接口类似<code>GridSearchCV</code>。</p>
</blockquote>
<p>Google的AutoML套间已经可以在云服务上使用了</p>
<p>用进化算法训练独立的神经网络很成功，已经取代梯度下降了。</p>
<h4 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h4><p>对于许多问题，开始时只用一个隐藏层就能得到不错的结果。只要有足够多的神经元，只有一个隐藏层的MLP就可以对复杂函数建模。但是对于复杂问题，深层网络比浅层网络有更高的参数效率：深层网络可以用指数级别更少的神经元对复杂函数建模，因此对于同样的训练数据量性能更好。</p>
<p>真实世界的数据通常都是有层次化结构的，深层神经网络正式利用了这一点：浅隐藏层对低级结构（比如各种形状的线段和方向），中隐藏层结合这些低级结构对中级结构（方，圆）建模，深隐藏层和输出层结合中级结构对高级结构（比如，脸）建模。</p>
<p><strong>迁移学习</strong>：层级化的结构不仅帮助深度神经网络收敛更快，也提高了对新数据集的泛化能力。例如，如果已经训练好了一个图片人脸识别的模型，现在想训练一个识别发型的神经网络，可以复用第一个网络的浅层。网络不用从多数图片的低级结构开始学起；只要学高级结构（发型）就行了。</p>
<h4 id="每个隐藏层的神经元数"><a href="#每个隐藏层的神经元数" class="headerlink" title="每个隐藏层的神经元数"></a>每个隐藏层的神经元数</h4><p>输入层和输出层的神经元数是由任务确定的输入和输出类型决定的。</p>
<p>对于隐藏层，惯用的方法是模拟金字塔的形状，神经元数逐层递减 —— 底层思想是，许多低级特征可以聚合成少得多的高级特征。然而，这种方法已经被抛弃了，因为所有隐藏层使用同样多的神经元不仅表现更好，要调节的超参数也只变成了一个，而不是每层都有一个。</p>
<p>和层数相同，可以逐步提高神经元的数量，直到发生过拟合为止。<strong>实际中，通常的简便而高效的方法是使用层数和神经元数都超量的模型，然后使用早停和其它正则技术防止过拟合，称这种方法为“弹力裤”</strong>：不浪费时间选择尺寸完美匹配的裤子，而是选择一条大的弹力裤，它能自动收缩到合适的尺寸。通过这种方法，可以避免影响模型的瓶颈层。另一方面，如果某层的神经元太少，就没有足够强的表征能力，保存所有的输入信息（比如，只有两个神经元的的层只能输出2D数据，如果用它处理3D数据，就会丢失信息）。无论模型网络的其它部分如何强大，丢失的信息也找不回来了。</p>
<blockquote>
<p>通常，增加层数比增加每层的神经元的收益更高。</p>
</blockquote>
<h4 id="学习率，批次大小和其它超参数"><a href="#学习率，批次大小和其它超参数" class="headerlink" title="学习率，批次大小和其它超参数"></a>学习率，批次大小和其它超参数</h4><p><strong>学习率</strong>：</p>
<blockquote>
<p>通常最佳学习率是最大学习率的一般左右（最大学习率是指超过一定值，训练算法发生分叉的学习率）。找到最佳学习率的方式之一是从一个极小值开始（比如10-5）训练模型几百次，直到学习率达到一个比较大的值（比如10）。通过每次迭代，将学习率乘以一个常数（例如 exp(log(106)/500，通过500次迭代，从10-5到10 ）。将损失作为学习率的函数画出来（学习率使用log），可以看到损失一开始是下降的。一段时间后，学习率会变得非常高，损失也会升高。最佳学习率要比损失开始升高的点低一点（通常比拐点低10倍）。然后就可以重新初始化模型，用这个学习率开始训练了</p>
</blockquote>
<p><strong>优化器：</strong></p>
<blockquote>
<p>选择一个更好的优化器（并调节超参数）而不是传统的小批量梯度下降优化器</p>
</blockquote>
<p><strong>批次大小：</strong></p>
<blockquote>
<p>批次大小对模型的表现和训练时间非常重要。使用大批次的好处是硬件（比如GPU）可以快速处理，每秒可以处理更多实例。因此，许多人建议批次大小开到GPU内存的最大值。</p>
<p>缺点：在实际中，大批次会导致训练不稳定，特别是在训练开始时，并且不如小批次模型的泛化能力好。</p>
</blockquote>
<p>一种策略是通过学习率热身使用大批次，如果训练不稳定或效果不好，就换成小批次。</p>
<p><strong>激活函数：</strong></p>
<blockquote>
<p>通常来讲，ReLU适用于所有隐藏层。对于输出层，取决于任务。</p>
</blockquote>
<p><strong>迭代次数：</strong></p>
<blockquote>
<p>对于大多数情况，不用调节训练的迭代次数：直接使用早停。</p>
</blockquote>
<h3 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fplayground.tensorflow.org%2F" target="_blank" rel="noopener">TensorFlow Playground</a>是TensorFlow团队推出的一个便利的神经网络模拟器。只需点击几下，就能训练出二元分类器，通过调整架构和超参数，可以从直观上理解神经网络是如何工作的，以及超参数的作用。如下所示：</p>
<p>a. 神经网络学到的模式。点击左上的运行按钮，训练默认的神经网络。注意是如何找到分类任务的最优解的。第一个隐藏层学到了简单模式，第二个隐藏层将简单模式结合为更复杂的模式。通常，层数越多，得到的模式越复杂。</p>
<p>b. 激活函数。用ReLU激活函数代替tanh，再训练一次网络。注意，找到解变得更快了，且是线性的，这归功于ReLU函数的形状。</p>
<p>c. 局部最小值的风险。将网络只设定为只有一个隐藏层，且只有3个神经元。进行多次训练（重置网络权重，点击Reset按钮）。可以看到训练时间变化很大，甚至有时卡在了局部最小值。</p>
<p>d. 神经网络太小的状况。去除一个神经元，只剩下两个。可以看到，即使尝试多次，神经网络现也不能找到最优解。模型的参数太少，对训练集数据欠拟合。</p>
<p>e. 神经网络足够大的状况。将神经元数设为8，再多次训练神经网络。可以看到过程很快且不会卡住。这是一个重要的发现：大神经网络几乎从不会卡在局部最小值，即使卡住了，局部最小值通常也是全局最小值。但是仍然可能在平台期卡住相当长时间。</p>
<p>f. 梯度消失的风险。选择spiral数据集（右下角位于DATA下面的数据集），模型架构变为四个隐藏层，每层八个神经元。可以看到，训练耗时变长，且经常在平台期卡住很长时间。另外，最高层（右边）的神经元比最底层变得快。这个问题被称为“梯度消失”，可以通过更优的权重初始化、更好的优化器（比如AdaGrad或Adam）、或批次正态化（见第11章）解决。</p>
<p>g. 再尝试尝试其它参数。</p>
</li>
<li><p>用原始神经元（像图10-3中的神经元）画ANN，可以计算 A ⊕ B （ ⊕ 表示 XOR操作）。提示：A ⊕ B = (A ∧ ¬ B) ∨ (¬ A ∧ B)或者<em>A</em> ⊕ <em>B</em> = (<em>A</em> ∨ <em>B</em>) ∧ (¬ <em>A</em> ∨ ¬ <em>B</em>)</p>
<blockquote>
<p><img src="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/assets/mls2_aain01.png" alt="mls2 aain01"></p>
</blockquote>
</li>
<li><p>为什么逻辑回归比经典感知机（即使用感知机训练算法训练的单层的阈值逻辑单元）更好？如何调节感知机，使其等同于逻辑回归分类器？</p>
<blockquote>
<p>逻辑回归可以收敛而不要求数据集线性可分，并且给出实例处于不同类别的概率。</p>
<p>但经典感知机只有当数据集是线性可分时才能收敛，并且不能给出概率。</p>
<p>使用逻辑斯蒂函数作为激活函数（如果有多个类别，可以用softmax函数），并使用梯度下降法训练模型，其结果等同于逻辑回归分类器。</p>
</blockquote>
</li>
<li><p>为什么逻辑激活函数对训练MLP的前几层很重要？</p>
<blockquote>
<p>因为逻辑激活函数处处可微，所以可以使用梯度下降</p>
</blockquote>
</li>
<li><p>说出三种流行的激活函数，并画出来。</p>
<blockquote>
<p>sigmoid ReLU:  tanh:</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-cfc40648369f3b02.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
</blockquote>
</li>
<li><p>假设一个MLP的输入层有10个神经元，接下来是有50个人工神经元的的隐藏层，最后是一个有3个人工神经元的输出层。所有的神经元使用ReLU激活函数。回答以下问题：</p>
<ul>
<li>输入矩阵X的形状是什么？</li>
</ul>
<blockquote>
<p>m x 10， m是训练批次的大小</p>
</blockquote>
<ul>
<li>隐藏层的权重矢量Wh和偏置项bh的形状是什么?</li>
</ul>
<blockquote>
<p>权重矢量Wh:10 x 50</p>
<p>偏置项bh: 50 (每一个隐藏层有一个偏置向)</p>
</blockquote>
<ul>
<li>输出层的权重矢量Wo和偏置项bo的形状是什么?</li>
</ul>
<blockquote>
<p>权重矢量Wo:50x  3</p>
<p>偏置项bo: 3</p>
</blockquote>
<ul>
<li>输出矩阵Y的形状是什么？</li>
</ul>
<blockquote>
<p>m x 3</p>
</blockquote>
<ul>
<li>写出用X、Wh、bh、Wo、bo计算矩阵Y的等式。</li>
</ul>
<blockquote>
<p>$Y = ReLU(ReLU(X W_h + b_h) W_o + b_o)$</p>
</blockquote>
</li>
<li><p>如果要将邮件分为垃圾邮件和正常邮件，输出层需要几个神经元？输出层应该使用什么激活函数？如果任务换成MNIST，输出层需要多少神经元，激活函数是什么？再换成第2章中的房价预测，输出层又该怎么变？</p>
<blockquote>
<p>要将邮件分为垃圾邮件和正常邮件，输出层仅仅需要1个神经元，sigmoid激活函数</p>
<p>如果数据集为MNIST，总共有十个类别，输出层需要10个神经元，softmax激活函数</p>
<p>房价预测是回归问题：输出层只需要一个神经元，并且不需要激活函数</p>
</blockquote>
</li>
<li><p>反向传播是什么及其原理？反向传播和逆向autodiff有什么不同？</p>
<blockquote>
<p>反向传播是一种训练 MLP 的方法，使用了高效梯度计算的梯度下降算法只需要两次网络传播（一次向前，一次向后），就可以算出网络误差的、和每个独立模型参数相关的梯度。</p>
<p>反向传播指的是反向传输，计算梯度，梯度下降的整个过程，而反向模式自微分仅仅是反向传播中用来计算梯度的一个手段。</p>
</blockquote>
</li>
<li><p>列出所有简单MLP中需要调节的超参数？如果MLP过拟合训练数据，如何调节超参数？</p>
<blockquote>
<p>隐藏层的数量，每个隐藏层中神经元的数量，激活函数的选择</p>
<p>一般来说ReLU函数对于隐藏层表现很好，输出层的激活函数需要看输出的需求：</p>
<p>二分类：逻辑函数</p>
<p>多分类：softmax</p>
<p>回归不需要激活函数</p>
<p>过拟合可以早停，或者减少隐藏层的数量，减少每层神经元的数量。</p>
</blockquote>
</li>
<li><p>在MNIST数据及上训练一个深度MLP。</p>
<p>使用<code>keras.datasets.mnist.load_data()</code>加载数据，看看能否使准确率超过98%，利用本章介绍的方法（逐步指数级提高学习率，画误差曲线，找到误差升高的点）搜索最佳学习率。保存检查点，使用早停，用TensorBoard画学习曲线的图。</p>
</li>
</ol>
<hr>
<h2 id="第11章-训练深度神经网络"><a href="#第11章-训练深度神经网络" class="headerlink" title="第11章 训练深度神经网络"></a>第11章 训练深度神经网络</h2><h3 id="梯度消失-爆炸问题"><a href="#梯度消失-爆炸问题" class="headerlink" title="梯度消失/爆炸问题"></a>梯度消失/爆炸问题</h3><p>梯度消失问题： 随着算法进展到较低层，梯度往往变得越来越小。 结果，梯度下降更新使得低层连接权重实际上保持不变，并且训练永远不会收敛到最优解。</p>
<p>梯度爆炸问题：梯度可能变得越来越大，许多层得到了非常大的权重更新，算法发散。</p>
<p>2010 年左右，Xavier Glorot 和 Yoshua Bengio 发表的题为<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fproceedings.mlr.press%2Fv9%2Fglorot10a%2Fglorot10a.pdf" target="_blank" rel="noopener">《Understanding the Difficulty of Training Deep Feedforward Neural Networks》</a>的论文发现：使用流行的 sigmoid 激活函数和当时最受欢迎的权重初始化方法的组合，即随机初始化时使用平均值为 0，标准差为 1 的正态分布，每层输出的方差远大于其输入的方差。随着网络前向传播，每层的方差持续增加，直到激活函数在顶层饱和。logistic函数的平均值为 0.5 而不是 0（双曲正切函数的平均值为 0，表现略好于深层网络中的logistic函数），使得情况更坏。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-c252c67afc52e2f9.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="Glorot-和-He-初始化"><a href="#Glorot-和-He-初始化" class="headerlink" title="Glorot 和 He 初始化"></a>Glorot 和 He 初始化</h3><p>理想情况：需要每层输出的方差等于其输入的方差，并且反向传播时，流经一层的前后，梯度的方差也要相同。</p>
<p>实际上：不可能保证两者都是一样的，除非这个层具有相同数量的输入和神经元（这两个数被称为该层的扇入<code>fan-in</code>和扇出<code>fan-out</code>）</p>
<p>Glorot 和 Bengio提出了一个折衷办法：随机初始化连接权重必须如下:</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-34956eb953f08cc1.png?imageMogr2/auto-orient/strip|imageView2/2/w/702/format/webp" alt="img"></p>
<p>其中$fan_{avg} = (fan_{in} + fan_{out}) / 2$</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-8ccaf8b0c543be01.png?imageMogr2/auto-orient/strip|imageView2/2/w/956/format/webp" alt="img"></p>
<p>默认情况下，Keras使用均匀分布的Glorot初始化函数。</p>
<h3 id="非饱和激活函数"><a href="#非饱和激活函数" class="headerlink" title="非饱和激活函数"></a>非饱和激活函数</h3><p>Glorot 和 Bengio 在 2010 年的论文中的一个见解是，消失/爆炸的梯度问题部分是由于激活函数的选择不好造成的。</p>
<p><strong>“ReLU 死区” </strong> 在训练过程中，一些神经元会“死亡”，即它们停止输出 0 以外的任何东西。</p>
<blockquote>
<p>在训练期间，如果神经元的权重得到更新，使得神经元输入的加权和为负，ReLU函数的梯度为0，神经元就只能输出0了。</p>
</blockquote>
<h4 id="ReLU-函数的变体"><a href="#ReLU-函数的变体" class="headerlink" title="ReLU 函数的变体"></a>ReLU 函数的变体</h4><h4 id="leaky-ReLU："><a href="#leaky-ReLU：" class="headerlink" title="leaky ReLU："></a>leaky ReLU：</h4><p> $LeakyReLU_α(z)= max(αz，z)$</p>
<p>超参数<code>α</code>定义了函数“leak”的程度：它是<code>z &lt; 0</code>时函数的斜率，通常设置为 0.01。这个小斜率保证 leaky ReLU 永不死亡；</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-2e50453795b314b6.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="随机化-leaky-ReLU（RReLU）"><a href="#随机化-leaky-ReLU（RReLU）" class="headerlink" title="随机化 leaky ReLU（RReLU）"></a>随机化 leaky ReLU（RReLU）</h4><p>其中<code>α</code>在训练期间在给定范围内随机，并在测试期间固定为平均值。它表现相当好，似乎是一个正则项（减少训练集的过拟合风险）。</p>
<h4 id="参数化的-leaky-ReLU（PReLU）"><a href="#参数化的-leaky-ReLU（PReLU）" class="headerlink" title="参数化的 leaky ReLU（PReLU）"></a>参数化的 leaky ReLU（PReLU）</h4><p><code>α</code>被授权在训练期间参与学习（不是作为超参数，<code>α</code>变成可以像任何其他参数一样被反向传播修改的参数）。PReLU在大型图像数据集上的表现强于 ReLU，但是对于较小的数据集，其具有过度拟合训练集的风险。</p>
<h4 id="指数线性单元（exponential-linear-unit，ELU）"><a href="#指数线性单元（exponential-linear-unit，ELU）" class="headerlink" title="指数线性单元（exponential linear unit，ELU）"></a>指数线性单元（exponential linear unit，ELU）</h4><p><img src="https://upload-images.jianshu.io/upload_images/7178691-e996caccf4ed7c10.png?imageMogr2/auto-orient/strip|imageView2/2/w/936/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-7bdffc790dc8451f.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>ELU 激活函数的主要缺点是计算速度慢于 ReLU 及其变体（由于使用指数函数），但是在训练过程中，这是通过更快的收敛速度来补偿的。</p>
<h4 id="Scaled-ELU（SELU）激活函数"><a href="#Scaled-ELU（SELU）激活函数" class="headerlink" title="Scaled ELU（SELU）激活函数"></a>Scaled ELU（SELU）激活函数</h4><p>ELU的伸缩变体,2017年提出。</p>
<p>只要神经网络中都是紧密层，并且所有隐藏层都是用的SELU激活函数，则这个网络是自归一的：训练过程中，每层输出的平均值是0，标准差是1，这样就解决了梯度消失爆炸问题。对于全紧密层的网络（尤其是很深的），SELU的效果常常优于其他激活函数。</p>
<p>自归一的条件：</p>
<ul>
<li>输入特征必须是标准的（平均值是0，标准差是1）；</li>
<li>每个隐藏层的权重必须是LeCun正态初始化的。在Keras中，要设置<code>kernel_initializer=&quot;lecun_normal&quot;</code>；</li>
<li>网络架构必须是顺序的。如果要在非顺序网络（比如RNN）或有跳连接的网络（跳过层的连接，比如Wide&amp;Deep）中使用SELU，就不能保证是自归一的，所以SELU就不会比其它激活函数更优；</li>
<li>这篇论文只是说如果所有层都是紧密层才保证自归一，但有些研究者发现SELU激活函数也可以提高卷积神经网络的性能。</li>
</ul>
<blockquote>
<p>一般来说 SELU &gt; ELU &gt; leaky ReLU（及其变体）&gt; ReLU &gt; tanh &gt; sigmoid</p>
<ul>
<li>如果网络架构不能保证自归一，则ELU可能比SELU的性能更好（因为SELU在z=0时不是平滑的）。</li>
<li>如果关心运行延迟，则 leaky ReLU 更好。 如果不想多调整另一个超参数，你以使用前面提到的默认的<code>α</code>值（leaky ReLU 为 0.3）</li>
<li>如果神经网络过拟合，则使用RReLU</li>
<li>如果有庞大的训练数据集，则为 PReLU</li>
<li>如果有充足的时间和计算能力，可以使用交叉验证来评估其他激活函数</li>
</ul>
<p>但是，因为ReLU是目前应用最广的激活函数，许多库和硬件加速器都使用了针对ReLU的优化，如果速度是首要的，ReLU可能仍然是首选。</p>
</blockquote>
<h3 id="批归一化（Batch-Normalization）"><a href="#批归一化（Batch-Normalization）" class="headerlink" title="批归一化（Batch Normalization）"></a>批归一化（Batch Normalization）</h3><p>使用 He初始化和 ELU（或任何 ReLU 变体）可以显著减少训练开始阶段的梯度消失/爆炸问题，但不能保证在训练期间问题不会再次出现。</p>
<p>2015年，Sergey Ioffe 和 Christian Szegedy 提出了一种称为<strong>批归一化（Batch Normalization，BN）</strong>的方法来解决梯度消失/爆炸问题。</p>
<p><strong>BN</strong></p>
<blockquote>
<p>在每层的激活函数之前或之后在模型中添加操作。操作就是将输入平均值变为0，方差变为1，然后用两个新参数，一个做缩放，一个做偏移。这个操作可以让模型学习到每层输入值的最佳缩放值和平均值。</p>
<p>一般如果模型第一层使用了BN层，则不用标准化训练集（比如使用<code>StandardScaler</code>）；BN层做了标准化工作（虽然是近似的，每次每次只处理一个批次，但能做缩放和平移）。</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-1248ce61162010fe.png?imageMogr2/auto-orient/strip|imageView2/2/w/761/format/webp" alt="img"></p>
<p>其中，</p>
<ul>
<li>μB是整个小批量B的均值矢量</li>
<li>σB是输入标准差矢量，也是根据整个小批量估算的。</li>
<li>mB是小批量中的实例数量。</li>
<li><img src="https://math.jianshu.com/math?formula=%5Cwidehat%7BX%7D" alt="\widehat{X}">(i)是以为零中心和标准化的实例i的输入矢量。</li>
<li>γ是层的缩放参数的矢量（每个输入一个缩放参数）。</li>
<li>⊗表示元素级别的相乘（每个输入乘以对应的缩放参数）</li>
<li>β是层的偏移参数（偏移量）矢量（每个输入一个偏移参数）</li>
<li>ϵ是一个很小的数字，以避免被零除（通常为<code>10^-5</code>）。 这被称为平滑项（拉布拉斯平滑，Laplace Smoothing）。</li>
<li>z(i) 是BN操作的输出：它是输入的缩放和移位版本。</li>
</ul>
<p>在训练时，BN将输入标准化，然后做了缩放和平移。测试时又如何呢？</p>
<blockquote>
<p>一种解决方法是等到训练结束，用模型再运行一次训练集，算出每个BN层的平均值和标准差。然后用这些数据做预测，而不是批输入的平均值和标准差。</p>
<p>大部分批归一化实现是通过<strong>层输入的平均值和标准差的移动平均值</strong>来计算的。这也是Keras在<code>BatchNormalization</code>中使用的方法。每个批归一化的层都通过指数移动平均学习了四个参数：<code>γ</code>（输出缩放矢量），<code>β</code>（输出偏移矢量），<code>μ</code>（最终输入平均值矢量）和<code>σ</code>（最终输入标准差矢量）。<code>μ</code>和<code>σ</code>都是在训练过程中计算的，但只在训练后使用。</p>
</blockquote>
<p><strong>BN的优点：</strong></p>
<blockquote>
<ul>
<li>改善了试验的所有深度神经网络，极大提高了ImageNet分类的效果。</li>
<li>梯度消失问题大大减少了，可以使用饱和激活函数，如 tanh 甚至逻辑激活函数。</li>
<li>网络对权重初始化也不那么敏感</li>
<li>能够使用更大的学习率，显著加快了学习过程。</li>
<li>批量标准化也像一个正则化项一样，减少了对其他正则化技术的需求</li>
</ul>
</blockquote>
<p><strong>BN的缺点：</strong></p>
<blockquote>
<ul>
<li>增加模型的复杂性</li>
<li>运行时间的损失</li>
</ul>
<p>前一层计算的是<code>XW + b</code>，BN层计算的是<code>γ⊗(XW + b – μ)/σ + β</code>（忽略了分母中的平滑项<code>ε</code>）。如果定义<code>W′ = γ⊗W/σ</code>和<code>b′ = γ⊗(b – μ)/σ + β</code>，公式就能简化为<code>XW′ + b′</code>。因此如果替换前一层的权重和偏置项（<code>W</code>和<code>b</code>）为<code>W&#39;</code>和<code>b&#39;</code></p>
</blockquote>
<h4 id="使用-Keras-实现批归一化"><a href="#使用-Keras-实现批归一化" class="headerlink" title="使用 Keras 实现批归一化"></a>使用 Keras 实现批归一化</h4><p><code>BatchNormalization</code>类，每个BN层添加了四个参数：γ、 β、 μ 和 σ。后两个参数μ 和 σ是移动平均，不受反向传播影响，Keras称其“不可训练”， 模型中有不可训练的参数量。</p>
<p>超参数：</p>
<blockquote>
<p>超参数<code>momentum</code>是<code>BatchNormalization</code>在更新指数移动平均时使用的。给定一个新值<code>v</code>（一个当前批次的输入平均或标准差新矢量），BN层使用下面的等式更新平均v</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-888f214e6c98e88c.png?imageMogr2/auto-orient/strip|imageView2/2/w/1038/format/webp" alt="img"></p>
<p>超参数是<code>axis</code>：它确定了在哪个轴上归一。默认是-1，即归一化最后一个轴（使用其它轴的平均值和标准差）。</p>
</blockquote>
<h3 id="梯度裁剪"><a href="#梯度裁剪" class="headerlink" title="梯度裁剪"></a>梯度裁剪</h3><p>减少梯度爆炸问题的一种常用技术是在反向传播过程中剪切梯度，使它们不超过某个阈值，这种方法称为梯度裁剪。梯度裁剪在循环神经网络（CNN）中用的很多，因为循环神经网络中用BN很麻烦.</p>
<p>范数裁剪</p>
<h3 id="复用预训练层"><a href="#复用预训练层" class="headerlink" title="复用预训练层"></a>复用预训练层</h3><p>通常不会从零开始训练一个非常大的 DNN ，尝试找到一个现有的神经网络来完成与正在尝试解决的任务类似的任务，然后复用这个网络的较低层：这就是所谓的<strong>迁移学习</strong>。这样不仅能大大加快训练速度，还将需要更少的训练数据。</p>
<blockquote>
<p>一般地说，如果输入具有类似的低级层次的特征，则迁移学习将很好地工作。</p>
</blockquote>
<p>先将所有复用的层冻结（即，使其权重不可训练，梯度下降不能修改权重），然后训练模型，看其表现如何。然后将复用的最上一或两层解冻，让反向传播可以调节它们，再查看性能有无提升。训练数据越多，可以解冻的层越多。解冻时减小学习率也有帮助，可以避免破坏微调而得的权重。</p>
<p><strong>迁移学习在深度卷积网络中表现最好，CNN学到的特征更通用（特别是浅层） </strong></p>
<h4 id="无监督预训练"><a href="#无监督预训练" class="headerlink" title="无监督预训练"></a>无监督预训练</h4><p>使用监督模型，比如自编码器或生成式对抗网络。然后可以复用自编码器或GAN的浅层，加上输出层，使用监督学习微调网络（使用标签数据）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-69fe44e53b9ea29b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="在辅助任务上预训练"><a href="#在辅助任务上预训练" class="headerlink" title="在辅助任务上预训练"></a>在辅助任务上预训练</h4><h3 id="更快的优化器"><a href="#更快的优化器" class="headerlink" title="更快的优化器"></a>更快的优化器</h3><p>四种加速训练的方法（并且达到更好性能的方法）：、</p>
<ol>
<li>对连接权重应用良好的初始化策略，</li>
<li>使用良好的激活函数，</li>
<li>使用批归一化</li>
<li>重用预训练网络的部分（使用辅助任务或无监督学习）。 </li>
<li>使用更快的优化器，而不是常规的梯度下降优化器。</li>
</ol>
<h4 id="动量优化"><a href="#动量优化" class="headerlink" title="动量优化"></a>动量优化</h4><p>梯度下降通过直接减去损失函数<code>J(θ)</code>相对于权重<code>θ</code>的梯度（<code>∇θJ(θ)</code>），乘以学习率<code>η</code>来更新权重<code>θ</code>。 $θ ← θ – η∇_θJ(θ)$。不关心早期的梯度是什么。,如果局部梯度很小，则会非常缓慢。</p>
<p>动量优化关心以前的梯度：在每次迭代时，它将动量矢量<code>m</code>（乘以学习率<code>η</code>）与局部梯度相加，并且通过简单地减去该动量矢量来更新权重.</p>
<p>$m← \beta m+\eta\nabla _\theta J(\theta)$</p>
<p>$\theta \leftarrow\ \theta -m$</p>
<p>为了模拟某种摩擦机制，避免动量过大，该算法引入了一个新的超参数<code>β</code>，简称为动量，它必须设置在 0（高摩擦）和 1（无摩擦）之间。 典型的动量值是 0.9。</p>
<blockquote>
<p>由于动量的原因，优化器可能会超调一些，然后再回来，再次超调，并在稳定在最小值之前多次振荡。 这就是为什么在系统中有一点摩擦的原因之一：它消除了这些振荡，从而加速了收敛。</p>
</blockquote>
<h4 id="Nesterov-加速梯度"><a href="#Nesterov-加速梯度" class="headerlink" title="Nesterov 加速梯度"></a>Nesterov 加速梯度</h4><p>Yurii Nesterov 在 1983 年提出的动量优化的一个小变体几乎总是比普通的动量优化更快。</p>
<p><strong>Nesterov 动量优化或 Nesterov 加速梯度（Nesterov Accelerated Gradient，NAG）*</strong>的思想是测量损失函数的梯度不是在局部位置，而是在动量方向稍微靠前。 与普通的动量优化的唯一区别在于梯度是在<code>θ+βm</code>而不是在<code>θ</code>处测量的。</p>
<p>$m← \beta m+\eta\nabla _\theta J(\theta+\beta m)$</p>
<p>$\theta \leftarrow\ \theta -m$</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-f75650e5b631e9bb.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong>NAG 最终比常规的动量优化快得多。  </strong></p>
<h4 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h4><p>AdaGrad 算法通过沿着最陡的维度缩小梯度向量解决细长碗的问题。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-38590903b6626149.png?imageMogr2/auto-orient/strip|imageView2/2/w/932/format/webp" alt="img"></p>
<p>第一步将梯度的平方累加到矢量<code>s</code>中（⊗符号表示元素级别相乘）。 这个向量化形式相当于向量<code>s</code>的每个元素$s_i$计算$si ← s_i + (∂ / ∂ θ_i J(θ))^2$。换一种说法，每个 $s_i$ 累加损失函数对参数$θ_i$的偏导数的平方。 如果损失函数沿着第<code>i</code>维陡峭，则在每次迭代时， si 将变得越来越大。</p>
<p>第二步几乎与梯度下降相同，但有一个很大的不同：梯度矢量按比例(s+ε)^0.5缩小 （⊘符号表示元素分割，<code>ε</code>是避免被零除的平滑项，通常设置为$10^-10$。 这个矢量化的形式相当于所有θi同时计算</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b852a34b26165cad.png?imageMogr2/auto-orient/strip|imageView2/2/w/282/format/webp" alt="img"></p>
<p><strong>优点</strong></p>
<blockquote>
<p>这种算法会降低学习速度，但对于陡峭的维度，其速度要快于具有温和的斜率的维度。 这被称为<strong>自适应学习率</strong>。 有助于将更新的结果更直接地指向全局最优。 并且不需要那么多的去调整学习率超参数<code>η</code>。</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-d2b7668bc13b3ead.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong>缺点：</strong></p>
<blockquote>
<p>对于简单的二次问题，AdaGrad 经常表现良好，但不幸的是，在训练神经网络时，它经常停止得太早。 学习率被缩减得太多，以至于在达到全局最优之前，算法完全停止。</p>
</blockquote>
<h4 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h4><p>AdaGrad 的风险是降速太快，可能无法收敛到全局最优。RMSProp 算法通过仅累积最近迭代（而不是从训练开始以来的所有梯度）的梯度来修正这个问题。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-a24cf7849a7f0c1c.png?imageMogr2/auto-orient/strip|imageView2/2/w/1006/format/webp" alt="img"></p>
<p>衰变率<code>β</code>通常设定为 0.9。 是这个默认值通常运行良好，可能根本不需要调整它。</p>
<p><strong>通常比 AdaGrad ，动量优化和 Nesterov 加速梯度表现更好。 </strong></p>
<h4 id="Adam-和-Nadam-优化"><a href="#Adam-和-Nadam-优化" class="headerlink" title="Adam 和 Nadam 优化"></a>Adam 和 Nadam 优化</h4><p>Adam，代表自适应矩估计，结合了动量优化和 RMSProp 的思想：就像动量优化一样，它追踪过去梯度的指数衰减平均值，就像 RMSProp 一样，它跟踪过去平方梯度的指数衰减平均值。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-827f2d812a6f5640.png?imageMogr2/auto-orient/strip|imageView2/2/w/1136/format/webp" alt="img"></p>
<p>只看步骤 1, 2 和 5，Adam 与动量优化和 RMSProp 的相似性。 唯一的区别是第 1 步计算指数衰减的平均值，而不是指数衰减的和，但除了一个常数因子（衰减平均值只是衰减和的<code>1 - β1</code>倍）之外，它们实际上是等效的。 步骤 3 和步骤 4 是一个技术细节：由于<code>m</code>和<code>s</code>初始化为 0，所以在训练开始时它们会偏向0，所以这两步将在训练开始时帮助提高<code>m</code>和<code>s</code>。</p>
<p><strong>由于 Adam 是一种自适应学习率算法（如 AdaGrad 和 RMSProp），所以对学习率超参数<code>η</code>的调整较少。 可以使用默认值<code>η= 0.001</code>，使 Adam 相对于梯度下降更容易使用。 </strong></p>
<h5 id="Adam还有两种变体"><a href="#Adam还有两种变体" class="headerlink" title="Adam还有两种变体"></a>Adam还有两种变体</h5><p>AdaMax：</p>
<p>Nadam：Nadam优化是Adam优化加上了Nesterov技巧，所以通常比Adam收敛的快一点。</p>
<blockquote>
<p>目前所有讨论的优化方法都是基于一阶偏导（雅可比矩阵）的。</p>
<p>基于二阶导数（海森矩阵，海森矩阵是雅可比矩阵的骗到）的算法很难应用于深度神经网络，因为每个输出有$n^2$个海森矩阵（n是参数个数），每个输出只有n个雅可比矩阵。因为DNN通常有数万个参数，二阶优化器通常超出了内存，就算内存能装下，计算海森矩阵也非常慢。</p>
<p>训练稀疏模型</p>
<p>以上优化算法都会产生紧密模型，大多数参数都是非零的。 如果运行需要一个非常快的模型，或者需要它占用较少的内存，可能需要用一个稀疏模型来代替。</p>
<p>实现这一点的一个方法是像平常一样训练模型，然后丢掉微小的权重（将它们设置为 0）。但这通常不会生成一个稀疏的模型，而且可能使模型性能下降。更好的选择是在训练过程中应用强 ℓ1 正则化，因为它会推动优化器尽可能多地消除权重</p>
</blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-5060d73f5a52760d.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="学习率调整"><a href="#学习率调整" class="headerlink" title="学习率调整"></a>学习率调整</h3><p><img src="https://upload-images.jianshu.io/upload_images/7178691-7ac8433cdc7346f1.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="幂调度"><a href="#幂调度" class="headerlink" title="幂调度:"></a>幂调度:</h4><p>设学习率为迭代次数 t 的函数： $η(t) = η_0 /(1 + t/s)^c$。初始学习率$η_0$， 幂<code>c</code>（通常被设置为 1），步数<code>s</code>是超参数。学习率在每步都会下降，s步后，下降到$η_0 / 2$。再经过s步，下降到$η_0 / 3$，然后是η0 / 4、η0 / 5，以此类推。可以看到，策略是一开始很快，然后越来越慢。幂调度需要调节η0和s（也可能有c）。</p>
<h4 id="指数调度"><a href="#指数调度" class="headerlink" title="指数调度:"></a>指数调度:</h4><p>将学习率设置为迭代次数<code>t</code>的函数：$η(t) = η_0 0.1^{t/s}$。 学习率每步都会下降10倍。幂调度的下降是越来越慢，指数调度保持10倍不变。</p>
<h4 id="预定的分段恒定学习率："><a href="#预定的分段恒定学习率：" class="headerlink" title="预定的分段恒定学习率："></a>预定的分段恒定学习率：</h4><p>先在几个周期内使用固定的学习率（比如5个周期内学习率设置为 η0 = 0.1），然后在另一个周期内设更小的学习率（比如50个周期η1 = 0.001），以此类推。虽然这个解决方案可以很好地工作，但是通常需要弄清楚正确的学习速度顺序以及使用时长。</p>
<h4 id="性能调度："><a href="#性能调度：" class="headerlink" title="性能调度："></a>性能调度：</h4><p>每 N 步测量验证误差（就像提前停止一样），当误差下降时，将学习率降低<code>λ</code>倍。</p>
<h4 id="1循环调度："><a href="#1循环调度：" class="headerlink" title="1循环调度："></a>1循环调度：</h4><p>与其它方法相反，1循环调度（Leslie Smith在2018年提出）一开始在前半个周期将学习率η0 线性增加到η1，然后在后半个周期内再线性下降到η0，最后几个周期学习率下降几个数量级（仍然是线性的）。</p>
<p>用前面的方法找到最优学习率的方法确定η1，η0是η1的十分之一。当使用动量时，先用一个高动量（比如0.95），然后在训练上半段下降（比如线性下降到0.85），然后在训练后半部分上升到最高值（0.95），最后几个周期也用最高值完成。</p>
<h3 id="通过正则化避免过拟合"><a href="#通过正则化避免过拟合" class="headerlink" title="通过正则化避免过拟合"></a>通过正则化避免过拟合</h3><p>最好的正则方法之一：早停。另外，虽然批归一化是用来解决梯度不稳定的，但也可以作为正则器。这一节会介绍其它一些最流行的神经网络正则化技术：ℓ1 和 ℓ2正则、dropout和最大范数正则。</p>
<h4 id="ℓ1-和-ℓ2正则"><a href="#ℓ1-和-ℓ2正则" class="headerlink" title="ℓ1 和 ℓ2正则"></a>ℓ1 和 ℓ2正则</h4><p>使用 ℓ2正则约束一个神经网络的连接权重，或ℓ1正则得到稀疏模型（许多权重为0）。</p>
<h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>由 Geoffrey Hinton 于 2012 年提出，并在 Nitish Srivastava 等人的2014年论文中进一步详细描述，并且已被证明是非常成功的：即使是最先进的神经网络，仅仅通过增加dropout就可以提高1-2％的准确度。</p>
<p>在每个训练步骤中，每个神经元（包括输入神经元，但不包括输出神经元）都有一个暂时“丢弃”的概率<code>p</code>，这意味着在这个训练步骤中它将被完全忽略， 在下一步可能会激活。 超参数<code>p</code>称为丢失率，通常设为 10%到50%之间；循环神经网络之间接近20-30%，在卷积网络中接近40-50%。 训练后，神经元不会再丢失。</p>
<p><strong>如何理解dropout</strong></p>
<p>dropout使得神经元不能与其相邻的神经元在训练时共适应，必须尽可能让自己变得有用，也不能过分依赖一些输入神经元，必须注意每个输入神经元。最终对输入的微小变化会不太敏感。最后，会得到一个更稳定、泛化能力更强的网络。</p>
<p>每个训练步骤都会产生一个独特的神经网络。 由于每个神经元可以存在或不存在，总共有$2^N$个可能的网络（其中 N 是可丢弃神经元的总数）。 这是一个巨大的数字，实际上不可能对同一个神经网络进行两次采样。 一旦运行了 10,000 个训练步骤，基本上已经训练了 10,000 个不同的神经网络（每个神经网络只有一个训练实例）。 这些神经网络显然不是独立的，因为它们共享许多权重，但是它们都是不同的。 由此产生的神经网络可以看作是所有这些较小的神经网络的平均集成。</p>
<p><strong>dropout 似乎减缓了收敛速度，但通常会在调参得当时使模型更好</strong></p>
<h5 id="蒙特卡洛（MC）dropout"><a href="#蒙特卡洛（MC）dropout" class="headerlink" title="蒙特卡洛（MC）dropout"></a>蒙特卡洛（MC）dropout</h5><p>蒙特卡洛样本的数量是一个可以调节的超参数。这个数越高，预测和不准确度的估计越高。但是，如果样本数翻倍，推断时间也要翻倍。另外，样本数超过一定数量，提升就不大了。</p>
<h4 id="最大范数正则化"><a href="#最大范数正则化" class="headerlink" title="最大范数正则化"></a>最大范数正则化</h4><p>对于每个神经元，它约束输入连接的权重<code>w</code>，使得 $∥ w ∥_2 ≤ r$，其中<code>r</code>是最大范数超参数，$∥ · ∥_2$ 是 l2 范数</p>
<p><strong>Keras中默认DNN配置</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-19249b3d162bbcb8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1170/format/webp" alt="img"></p>
<p><strong>如果网络只有紧密层，则可以是自归一化的，可以使用如下配置。</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b822155fbb4dd3c4.png?imageMogr2/auto-orient/strip|imageView2/2/w/1166/format/webp" alt="img"></p>
<h3 id="练习-1"><a href="#练习-1" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>使用 He 初始化随机选择权重，是否可以将所有权重初始化为相同的值？</p>
<blockquote>
<p>不可以，所有的权重需要独立随机的生成。</p>
<p>如果将神经元的权重初始化为相同的值，则不能打破结构的对称性，该情况下，每层的神经元都是等价的，反向传播也是相同的，意味着，在训练过程中，每层神经元权重一直保持相同，效果相当于每层只有一个神经元，而且更慢。很明显这样的神经网络不能收敛到一个很好的结果。</p>
</blockquote>
</li>
<li><p>可以将偏置初始化为 0 吗？</p>
<blockquote>
<p>可以，偏置向的影响并不大。</p>
</blockquote>
</li>
<li><p>说出SELU 激活功能与 ReLU 相比的三个优点。</p>
<blockquote>
<ol>
<li>微分一直不为零，防止出现ReLU 死区（一些神经元死掉，只能输出0，原因是：在训练期间，神经元的权重更新后使得神经元输入的加权和为负，ReLU函数的梯度为0，神经元就只能输出0。）</li>
<li>只要神经网络中都是紧密层，并且所有隐藏层都是用的SELU激活函数，则这个网络是自归一的（不能使用正则化方法）</li>
<li>小于零时不是常数0，而是变化的负值，训练过程中，每层输出的平均值是0，标准差是1，这样就解决了梯度消失爆炸问题。</li>
</ol>
</blockquote>
</li>
<li><p>在哪些情况下，您想要使用以下每个激活函数：SELU，leaky ReLU（及其变体），ReLU，tanh，logistic 以及 softmax？</p>
<blockquote>
<p>通常情况下SELU表现很好。但如果神经网络不能自归一，ELU效果可能会更好</p>
<p>如果需要很快的神经网络，可以使用leaky ReLU</p>
<p>ReLU因为形式简单，仍是目前应用最广的激活函数</p>
<p>​</p>
<p>如果需要输出值在-1~1之间，可以在输出层使用tanh激活函数</p>
<p>如果二分类想要输出概率，可以在输出层使用逻辑斯蒂激活函数</p>
<p>多分类问题输出概率，可以在输出层使用sftmax激活函数。</p>
<p>但tanh，logit和softmax激活函数，一般不用于隐藏层。</p>
</blockquote>
</li>
<li><p>如果将<code>momentum</code>超参数设置得太接近 1（例如，0.99999），会发生什么情况？</p>
<blockquote>
<p>如果SGD optimizer 中，momentum设置为0.99999，则算法会很快，但由于动量的原因，优化器可能会超调一些，然后再回来，再次超调，并在稳定在最小值之前多次振荡。总体来讲，大的动量参数收敛时使用得时间比小的动量参数要长。</p>
</blockquote>
</li>
<li><p>请列举您可以生成稀疏模型的三种方法。</p>
<blockquote>
<ol>
<li>像平常一样训练模型，然后丢掉微小的权重（将它们设置为 0）。</li>
<li>在训练过程中应用强 ℓ1 正则化，它会推动优化器尽可能多地消除权重</li>
<li>使用ensorFlow Model Optimization Toolkit</li>
</ol>
</blockquote>
</li>
<li><p>dropout 是否会减慢训练？ 它是否会减慢推断（即预测新的实例）？MC dropout呢？</p>
<blockquote>
<p>dropout会减慢训练，一般会变慢一倍，但一般不会减慢推断速度（因为dropout只在训练模型时开启）。</p>
<p>MC dropout在推断过程中也会开启，所以会使得预测新实例时，速度稍微变慢。但是MC dropout的问题主要在于：需要跑十次（若干次）预测，会减慢速度。</p>
<p>在CIFAR10图片数据集上训练一个深度神经网络：</p>
</blockquote>
<ol>
<li>建立一个 DNN，有20个隐藏层，每层 100 个神经元，使用 He 初始化和 ELU 激活函数。</li>
<li>使用 Nadam 优化和早停，尝试在 CIFAR10 上进行训练，可以使用<code>keras.datasets.cifar10.load_data()</code>加载数据。数据集包括60000张32x32的图片（50000张训练，10000张测试）有10个类，所以需要10个神经元的softmax输出层。记得每次调整架构或超参数之后，寻找合适的学习率。</li>
<li>现在尝试添加批归一化并比较学习曲线：它是否比以前收敛得更快？ 它是否会产生更好的模型？对训练速度有何影响？</li>
<li>尝试用SELU替换批归一化，做一些调整，确保网络是自归一化的（即，标准化输入特征，使用LeCun正态初始化，确保DNN只含有紧密层）。</li>
<li>使用alpha dropout正则化模型。然后，不训练模型，使用MC Dropout能否提高准确率。</li>
<li>用1循环调度重新训练模型，是否能提高训练速度和准确率。</li>
</ol>
</li>
</ol>
<h2 id="第12章-使用TensorFlow自定义模型并训练"><a href="#第12章-使用TensorFlow自定义模型并训练" class="headerlink" title="第12章 使用TensorFlow自定义模型并训练"></a>第12章 使用TensorFlow自定义模型并训练</h2><p>TensorFlow的高级API —— tf.keras，功能强大，可以搭建各种神经网络架构（回归、分类网络、Wide &amp; Deep 网络、自归一化网络），使用了各种方法，（批归一化、dropout和学习率调度）。但当需要实现<strong>自定义损失函数、自定义标准、层、模型、初始化器、正则器、权重约束时</strong>，就需要学习TensorFlow的低级Python API。</p>
<h3 id="TensorFlow速览"><a href="#TensorFlow速览" class="headerlink" title="TensorFlow速览"></a>TensorFlow速览</h3><p>TensorFlow由谷歌大脑团队开发，是一个强大的数值计算库，特别适合做和微调大规模机器学习（也可以做其它的重型计算）。具有如下功能：</p>
<ul>
<li>TensorFlow的核心与NumPy很像，但TensorFlow支持GPU；</li>
<li>TensorFlow支持（多设备和服务器）分布式计算；</li>
<li>TensorFlow使用了即时JIT编译器对计算速度和内存使用优化。编译器的工作是从Python函数提取出计算图，然后对计算图优化（比如剪切无用的节点），最后高效运行（比如自动并行运行独立任务）；</li>
<li>计算图可以导出为迁移形式，因此可以在一个环境中训练一个TensorFlow模型（比如使用Python或Linux），然后在另一个环境中运行（比如在安卓设备上用Java运行）；</li>
<li>TensorFlow实现了<strong>自动微分</strong> ，并提供了一些高效的优化器，比如RMSProp和NAdam，因此可以很容易最小化各种损失函数。</li>
</ul>
<p>TensorFlow还提供了许多其他功能：tf.keras，数据加载（（tf.data），预处理操作（tf.io），图片处理操作（tf.image），信号处理操作（tf.signal）等。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4d1453d7d971cba7.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>TensorFlow的低级操作都是用高效的C++实现的。许多操作有多个实现，称为<code>核</code>：每个核对应一个具体的设备型号，比如CPU、GPU，甚至TPU（张量处理单元）。GPU通过将任务分成小块，在多个GPU线程中并行运行，可以极大提高提高计算的速度。TPU更快：TPU是自定义的ASIC芯片，专门用来做深度学习运算。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-c77b37df3aea8d69.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>TensorBoard可以用来可视化。TensorFlow Extended（TFX），是谷歌推出的用来生产化的库，包括：数据确认、预处理、模型分析和服务。TensorFlow Hub上可以方便下载和复用预训练好的神经网络。还可以从<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Fmodels%2F" target="_blank" rel="noopener">TensorFlow model garden</a>上获取许多神经网络架构，其中一些是预训练好的。<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.tensorflow.org%2Fresources" target="_blank" rel="noopener">TensorFlow Resources</a> </p>
<h3 id="像NumPy一样使用TensorFlow"><a href="#像NumPy一样使用TensorFlow" class="headerlink" title="像NumPy一样使用TensorFlow"></a>像NumPy一样使用TensorFlow</h3><p>TensorFlow的API是围绕张量（tensor）展开的，从一个操作流动（flow）到另一个操作，所以名字叫做TensorFlow。</p>
<p>张量通常是一个多维数组（就像NumPy的<code>ndarray</code>），但也可以是标量（即简单值，比如42）。</p>
<h4 id="张量和运算"><a href="#张量和运算" class="headerlink" title="张量和运算"></a>张量和运算</h4><p>使用<code>tf.constant()</code>创建张量。就像<code>ndarray</code>一样，<code>tf.Tensor</code>也有形状和数据类型（<code>dtype</code>），索引和NumPy中很像，所有张量运算都可以执行。</p>
<p>可以在tf中找到所有基本的数学运算（<code>tf.add()</code>、<code>tf.multiply()</code>、<code>tf.square()</code>、<code>tf.exp()</code>、<code>tf.sqrt()</code>），以及NumPy中的大部分运算（比如<code>tf.reshape()</code>、<code>tf.squeeze()</code>、<code>tf.tile()</code>）。一些tf中的函数与NumPy中不同，例如，<code>tf.reduce_mean()</code>、<code>tf.reduce_sum()</code>、<code>tf.reduce_max()</code>、<code>tf.math.log()</code>等同于<code>np.mean()</code>、<code>np.sum()</code>、<code>np.max()</code>和<code>np.log()</code>。</p>
<blockquote>
<p>TensorFlow中必须使用<code>tf.transpose(t)</code>，不能像NumPy中那样使用<code>t.T</code>。是因为函数<code>tf.transpose(t)</code>所做的和NumPy的属性<code>T</code>并不完全相同：在TensorFlow中，是使用转置数据的复制来生成张量的，而在NumPy中，<code>t.T</code>是数据的转置视图。</p>
<p><code>tf.reduce_sum()</code>操作之所以这么命名，是因为它的GPU核（即GPU实现）所采用的reduce算法不能保证元素相加的顺序，因为32位的浮点数精度有限，每次调用的结果可能会有细微的不同。<code>tf.reduce_mean()</code>也是这样（<code>tf.reduce_max()</code>结果是确定的）。</p>
</blockquote>
<p>Keras API 有自己的低级API，位于<code>keras.backend</code>，包括：函数<code>square()</code>、<code>exp()</code>、<code>sqrt()</code>。</p>
<h4 id="张量和NumPy"><a href="#张量和NumPy" class="headerlink" title="张量和NumPy"></a>张量和NumPy</h4><p>张量和NumPy融合地非常好：使用NumPy数组可以创建张量，张量也可以创建NumPy数组。可以在NumPy数组上运行TensorFlow运算，也可以在张量上运行NumPy运算：</p>
<p><strong>NumPy默认使用64位精度，TensorFlow默认用32位精度。这是因为32位精度通常对于神经网络就足够了，另外运行地更快，使用的内存更少。因此当用NumPy数组创建张量时，一定要设置<code>dtype=tf.float32</code>。。 </strong></p>
<h4 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h4><p>类型转换对性能的影响非常大，TensorFlow不会自动做任何类型转换：只是如果用不兼容的类型执行了张量运算，TensorFlow就会报异常。<strong>例如，不能用浮点型张量与整数型张量相加，也不能将32位张量与64位张量相加。</strong></p>
<h4 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h4><p><code>tf.Tensor</code>值不能修改，意味着不能使用常规张量实现神经网络的权重，因为权重必须要能被反向传播调整。另外，其它的参数也需要随着时间调整（比如，动量优化器要跟踪过去的梯度）。此时需要的是<code>tf.Variable</code>：</p>
<h4 id="其它数据结构"><a href="#其它数据结构" class="headerlink" title="其它数据结构"></a>其它数据结构</h4><p>稀疏张量（<code>tf.SparseTensor</code>）<br>高效表示含有许多0的张量。<code>tf.sparse</code>包含有对稀疏张量的运算。</p>
<p>张量数组（<code>tf.TensorArray</code>）<br>是张量的列表。有默认固定大小，但也可以做成动态的。列表中的张量必须形状相同，数据类型也相同。</p>
<p>嵌套张量（<code>tf.RaggedTensor</code>）<br>张量列表的静态列表，张量的形状和数据结构相同。<code>tf.ragged</code>包里有嵌套张量的运算。</p>
<p>字符串张量<br>类型是<code>tf.string</code>的常规张量，是字节串而不是Unicode字符串，因此如果你用Unicode字符串（比如，Python3字符串café）创建了一个字符串张量，就会自动被转换为UTF-8（b”caf\xc3\xa9”）。另外，也可以用<code>tf.int32</code>类型的张量表示Unicode字符串，其中每项表示一个Unicode码（比如，<code>[99, 97, 102, 233]</code>）。<code>tf.strings</code>包里有字节串和Unicode字符串的运算，以及二者转换的运算。要注意<code>tf.string</code>是原子性的，也就是说它的长度不出现在张量的形状中，一旦将其转换成了Unicode张量（即，含有Unicode码的<code>tf.int32</code>张量），长度才出现在形状中。</p>
<p>集合<br>表示为常规张量（或稀疏张量）。例如<code>tf.constant([[1, 2], [3, 4]])</code>表示两个集合{1, 2}和{3, 4}。通常，用张量的最后一个轴的矢量表示集合。集合运算可以用<code>tf.sets</code>包。</p>
<p>队列<br>用来在多个步骤之间保存张量。TensorFlow提供了多种队列。先进先出（FIFO）队列FIFOQueue，优先级队列PriorityQueue，随机队列RandomShuffleQueue，通过填充的不同形状的批次项队列PaddingFIFOQueue。这些队列都在<code>tf.queue</code>包中。</p>
<h3 id="自定义模型和训练算法"><a href="#自定义模型和训练算法" class="headerlink" title="自定义模型和训练算法"></a>自定义模型和训练算法</h3><h4 id="自定义损失函数"><a href="#自定义损失函数" class="headerlink" title="自定义损失函数"></a>自定义损失函数</h4><p>均方差可能对大误差惩罚过重，导致模型不准确。</p>
<p>均绝对值误差不会对异常值惩罚过重，但训练可能要比较长的时间才能收敛，训练模型也可能不准确。</p>
<p>Huber损失：小于阈值是二次的，大于阈值是线性的。</p>
<p>目前官方Keras API中没有Huber损失，但tf.keras有（使用类<code>keras.losses.Huber</code>的实例），也可以def函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">huber_fn</span><span class="params">(y_true, y_pred)</span>:</span></span><br><span class="line">    error = y_true - y_pred</span><br><span class="line">    is_small_error = tf.abs(error) &lt; <span class="number">1</span></span><br><span class="line">    squared_loss = tf.square(error) / <span class="number">2</span></span><br><span class="line">    linear_loss  = tf.abs(error) - <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">return</span> tf.where(is_small_error, squared_loss, linear_loss)</span><br></pre></td></tr></table></figure>
<h4 id="保存并加载包含自定义组件的模型"><a href="#保存并加载包含自定义组件的模型" class="headerlink" title="保存并加载包含自定义组件的模型"></a>保存并加载包含自定义组件的模型</h4><p>Keras可以保存函数名，所以可以保存含有自定义损失函数的模型。当加载模型时，需要提供一个字典，这个字典可以将函数名和真正的函数映射起来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = keras.models.load_model(<span class="string">"my_model_with_a_custom_loss.h5"</span>,</span><br><span class="line">                                custom_objects=&#123;<span class="string">"huber_fn"</span>: huber_fn&#125;)</span><br></pre></td></tr></table></figure>
<p>创建可以产生一个可配置的损失函数的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_huber</span><span class="params">(threshold=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">huber_fn</span><span class="params">(y_true, y_pred)</span>:</span></span><br><span class="line">        error = y_true - y_pred</span><br><span class="line">        is_small_error = tf.abs(error) &lt; threshold</span><br><span class="line">        squared_loss = tf.square(error) / <span class="number">2</span></span><br><span class="line">        linear_loss  = threshold * tf.abs(error) - threshold**<span class="number">2</span> / <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> tf.where(is_small_error, squared_loss, linear_loss)</span><br><span class="line">    <span class="keyword">return</span> huber_fn</span><br><span class="line">model.compile(loss=create_huber(<span class="number">2.0</span>), optimizer=<span class="string">"nadam"</span>)</span><br></pre></td></tr></table></figure>
<p>但在保存模型时，<code>threshold</code>不能被保存。在加载模型时（注意，给Keras的函数名是“Huber_fn”，不是创造这个函数的函数名），必须要指定<code>threshold</code>的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = keras.models.load_model(<span class="string">"my_model_with_a_custom_loss_threshold_2.h5"</span>,</span><br><span class="line">                                custom_objects=&#123;<span class="string">"huber_fn"</span>: create_huber(<span class="number">2.0</span>)&#125;)</span><br></pre></td></tr></table></figure>
<p>要解决这个问题，可以创建一个<code>keras.losses.Loss</code>类的子类，然后实现<code>get_config()</code>方法</p>
<blockquote>
<p>Keras API目前只使用子类来定义层、模型、调回和正则器。如果使用子类创建其它组件（比如损失、指标、初始化器或约束），它们不能迁移到其它Keras实现上。</p>
</blockquote>
<h4 id="自定义激活函数、初始化器、正则器和约束"><a href="#自定义激活函数、初始化器、正则器和约束" class="headerlink" title="自定义激活函数、初始化器、正则器和约束"></a>自定义激活函数、初始化器、正则器和约束</h4><p>如果函数有需要连同模型一起保存的超参数，需要对相应的类做子</p>
<h4 id="自定义指标"><a href="#自定义指标" class="headerlink" title="自定义指标"></a>自定义指标</h4><p>损失和指标的概念是不一样的：梯度下降使用损失（比如交叉熵损失）来训练模型，因此损失必须是可微分的（至少是在评估点可微分），梯度不能在所有地方都是0。另外，就算损失比较难解释也没有关系。相反的，指标（比如准确率）是用来评估模型的：指标的解释性一定要好，可以是不可微分的，或者可以在任何地方的梯度都是0。</p>
<p>假设模型在第一个批次做了5个正预测，其中4个是正确的，准确率就是80%。再假设模型在第二个批次做了3次正预测，但没有一个预测对，则准确率是0%。如果对这两个准确率做平均，则平均值是40%。但它不是模型在两个批次上的准确率！事实上，真正值总共有4个，正预测有8个，整体的准确率是50%。</p>
<p><strong>一个批次接一个批次，逐次更新的叫做流式指标（或者静态指标）。</strong></p>
<h4 id="自定义层"><a href="#自定义层" class="headerlink" title="自定义层"></a>自定义层</h4><p>比如，如果模型的层顺序是A、B、C、A、B、C、A、B、C，则完全可以创建一个包含A、B、C的自定义层D，模型就可以简化为D、D、D。</p>
<p>创建一个没有任何权重的自定义层，将其包装进<code>keras.layers.Lambda</code>层。比如，下面的层会对输入做指数运算：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exponential_layer = keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.exp(x))</span><br></pre></td></tr></table></figure>
<p>创建自定义状态层（即，有权重的层），需要创建<code>keras.layers.Layer</code>类的子类。下面的类实现了一个紧密层的简化版本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDense</span><span class="params">(keras.layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, units, activation=None, **kwargs)</span>:</span></span><br><span class="line">        super().__init__(**kwargs)</span><br><span class="line">        self.units = units</span><br><span class="line">        self.activation = keras.activations.get(activation)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self, batch_input_shape)</span>:</span></span><br><span class="line">        self.kernel = self.add_weight(</span><br><span class="line">            name=<span class="string">"kernel"</span>, shape=[batch_input_shape[<span class="number">-1</span>], self.units],</span><br><span class="line">            initializer=<span class="string">"glorot_normal"</span>)</span><br><span class="line">        self.bias = self.add_weight(</span><br><span class="line">            name=<span class="string">"bias"</span>, shape=[self.units], initializer=<span class="string">"zeros"</span>)</span><br><span class="line">        super().build(batch_input_shape) <span class="comment"># must be at the end</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.activation(X @ self.kernel + self.bias)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span><span class="params">(self, batch_input_shape)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.TensorShape(batch_input_shape.as_list()[:<span class="number">-1</span>] + [self.units])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span></span><br><span class="line">        base_config = super().get_config()</span><br><span class="line">        <span class="keyword">return</span> &#123;**base_config, <span class="string">"units"</span>: self.units,</span><br><span class="line">                <span class="string">"activation"</span>: keras.activations.serialize(self.activation)&#125;</span><br></pre></td></tr></table></figure>
<p>要创建一个有多个输入（比如<code>Concatenate</code>）的层，<code>call()</code>方法的参数应该是包含所有输入的元组。相似的，<code>compute_output_shape()</code>方法的参数应该是一个包含每个输入的批次形状的元组。要创建一个有多输出的层，<code>call()</code>方法要返回输出的列表，<code>compute_output_shape()</code>方法要返回批次输出形状的列表（每个输出一个形状）。例如，下面的层有两个输入和三个输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyMultiLayer</span><span class="params">(keras.layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        X1, X2 = X</span><br><span class="line">        <span class="keyword">return</span> [X1 + X2, X1 * X2, X1 / X2]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span><span class="params">(self, batch_input_shape)</span>:</span></span><br><span class="line">        b1, b2 = batch_input_shape</span><br><span class="line">        <span class="keyword">return</span> [b1, b1, b1] <span class="comment"># 可能需要处理广播规则</span></span><br></pre></td></tr></table></figure>
<p>只能使用Functional和Subclassing API，Sequential API不成（只能使用单输入和单输出的层）。</p>
<p>如果层需要在训练和测试时有不同的行为（比如，如果使用<code>Dropout</code> 或 <code>BatchNormalization</code>层），那么必须给<code>call()</code>方法加上<code>training</code>参数，用这个参数确定该做什么。比如，创建一个在训练中（为了正则）添加高斯噪音的层，但不改动训练：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyGaussianNoise</span><span class="params">(keras.layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, stddev, **kwargs)</span>:</span></span><br><span class="line">        super().__init__(**kwargs)</span><br><span class="line">        self.stddev = stddev</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, X, training=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> training:</span><br><span class="line">            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)</span><br><span class="line">            <span class="keyword">return</span> X + noise</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span><span class="params">(self, batch_input_shape)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> batch_input_shape</span><br></pre></td></tr></table></figure>
<h4 id="自定义模型"><a href="#自定义模型" class="headerlink" title="自定义模型"></a>自定义模型</h4><p> 自定义模型案例：包含残差块层，残块层含有跳连接</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-647e362f4abb081e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p><strong><code>Model</code>类是<code>Layer</code>类的子类</strong></p>
<h4 id="基于模型内部的损失和指标"><a href="#基于模型内部的损失和指标" class="headerlink" title="基于模型内部的损失和指标"></a>基于模型内部的损失和指标</h4><p>前面的自定义损失和指标都是基于标签和预测（或者还有样本权重）。有时，需要基于模型的其它部分定义损失，比如隐藏层的权重或激活函数。达到正则的目的，或监督模型的内部。</p>
<p>要基于模型内部自定义损失，需要先做基于这些组件的计算，然后将结果传递给<code>add_loss()</code>方法。</p>
<h4 id="自定义训练循环"><a href="#自定义训练循环" class="headerlink" title="自定义训练循环"></a>自定义训练循环</h4><h5 id="使用自动微分计算梯度"><a href="#使用自动微分计算梯度" class="headerlink" title="使用自动微分计算梯度"></a>使用自动微分计算梯度</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(w1, w2)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">3</span> * w1 ** <span class="number">2</span> + <span class="number">2</span> * w1 * w2</span><br></pre></td></tr></table></figure>
<p>函数对<code>w1</code>的偏导是<code>6 * w1 + 2 * w2</code>，还能算出它对<code>w2</code>的偏导是<code>2 * w1</code>。例如，在点<code>(w1, w2) = (5, 3)</code>，这两个偏导数分别是36和10，在这个点的梯度矢量就是（36, 10）。但对于神经网络来说，函数会复杂得多，可能会有上万个参数，用手算偏导几乎是不可能的任务。一个解决方法是计算每个偏导的大概值，通过调节参数，查看输出的变化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>w1, w2 = <span class="number">5</span>, <span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>eps = <span class="number">1e-6</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(f(w1 + eps, w2) - f(w1, w2)) / eps</span><br><span class="line"><span class="number">36.000003007075065</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>(f(w1, w2 + eps) - f(w1, w2)) / eps</span><br><span class="line"><span class="number">10.000000003174137</span></span><br></pre></td></tr></table></figure>
<p>上述方法很容易实现，但只是大概。并且，需要对每个参数至少要调用一次<code>f()</code>（不是至少两次，因为可以只计算一次<code>f(w1, w2)</code>）。这样，对于大神经网络，就不怎么可控。需要通过TensorFlow实现自动微分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">w1, w2 = tf.Variable(<span class="number">5.</span>), tf.Variable(<span class="number">3.</span>)</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    z = f(w1, w2)</span><br><span class="line"><span class="comment"># 创建了tf.GradientTape记录器，能自动记录变量的每个操作，</span></span><br><span class="line">gradients = tape.gradient(z, [w1, w2])</span><br></pre></td></tr></table></figure>
<p><code>gradient()</code>方法只逆向算了一次，无论有多少个变量，效率很高。</p>
<h4 id="TensorFlow的函数和图"><a href="#TensorFlow的函数和图" class="headerlink" title="TensorFlow的函数和图"></a>TensorFlow的函数和图</h4><p>使用TensorFlow的自动图生成特征：</p>
<p><code>tf.function()</code>在底层分析了<code>cube()</code>函数的计算，然后生成了一个等价的计算图！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cube</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">3</span></span><br><span class="line"></span><br><span class="line">tf_cube = tf.function(cube)</span><br></pre></td></tr></table></figure>
<p>另外，也可以使用<code>tf.function</code>作为装饰器，更常见一些：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tf_cube</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>TensorFlow优化了计算图，删掉了没用的节点，简化了表达式（比如，1 + 2会替换为3）。当优化好的计算图准备好之后，TF函数可以在图中，按合适的顺序高效执行运算（该并行的时候就并行）。作为结果，TF函数比普通的Python函数快的做，特别是在做复杂计算时。大多数时候，根本没必要知道底层到底发生了什么，如果需要对Python函数加速，将其转换为TF函数就行。</p>
<h5 id="自动图和跟踪"><a href="#自动图和跟踪" class="headerlink" title="自动图和跟踪"></a>自动图和跟踪</h5><p>TensorFlow是先分析Python函数源码，得出所有的数据流控制语句，比如for循环，while循环，if条件，还有break、continue、return。这个第一步被称为<strong>自动图（AutoGraph）</strong>。分析完源码之后，自动图中的所有控制流语句都被替换成相应的TensorFlow方法，比如<code>tf.while_loop()</code>（while循环）和<code>tf.cond()</code>（if判断）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-cd0d53808f2cf8a8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>然后，TensorFlow调用这个“升级”方法，但没有向其传递参数，而是传递一个符号张量（symbolic tensor）——没有任何真实值的张量，只有名字、数据类型和形状。</p>
<p>函数会以图模式运行，意味着每个TensorFlow运算会在图中添加一个表示自身的节点，然后输出<code>tensor(s)</code>（与常规模式相对，这被称为动态图执行，或动态模式）。在图模式中，TF运算不做任何计算。最后的图是跟踪中生成的。节点表示运算，箭头表示张量。</p>
<h5 id="TF-函数规则"><a href="#TF-函数规则" class="headerlink" title="TF 函数规则"></a>TF 函数规则</h5><p>大多数时候，将Python函数转换为TF函数是琐碎的：要用<code>@tf.function</code>装饰，或让Keras来负责。但是，也有一些规则：</p>
<blockquote>
<ul>
<li>调用任何外部库，包括NumPy，甚至是标准库，调用只会在跟踪中运行，不会是图的一部分。</li>
<li>可以调用其它Python函数或TF函数，但是它们要遵守相同的规则，因为TensorFlow会在计算图中记录它们的运算。注意，其它函数不需要用<code>@tf.function</code>装饰。</li>
<li>如果函数创建了一个TensorFlow变量（或任意其它静态TensorFlow对象，比如数据集或队列），它必须在第一次被调用时创建TF函数，否则会导致异常。通常，最好在TF函数的外部创建变量（比如在自定义层的<code>build()</code>方法中）。如果你想将一个新值赋值给变量，要确保调用它的<code>assign()</code>方法，而不是使用<code>=</code>。</li>
<li>Python的源码可以被TensorFlow使用。如果源码用不了（比如，如果是在Python shell中定义函数，源码就访问不了，或者部署的是编译文件<code>*.pyc</code>），图的生成就会失败或者缺失功能。</li>
<li>TensorFlow只能捕获迭代张量或数据集的for循环。因此要确保使用<code>for i in tf.range(x)</code>，而不是<code>for i in range(x)</code>，否则循环不能在图中捕获，而是在会在追踪中运行。</li>
<li>出于性能原因，最好使用矢量化的实现方式，而不是使用循环。</li>
</ul>
</blockquote>
<h3 id="练习-2"><a href="#练习-2" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>如何用一句话描述TensorFlow？它的主要特点是什么？能列举出其它流行的深度学习库吗？</p>
<blockquote>
<p>TensorFlow是由谷歌大脑团队开发的一个强大的开源数值计算库，适合做和微调大规模机器学习。</p>
<p>主要特点：</p>
<ul>
<li>TensorFlow的核心与NumPy很像，但TensorFlow支持GPU；</li>
<li>TensorFlow支持（多设备和服务器）分布式计算；</li>
<li>TensorFlow使用了即时JIT编译器对计算速度和内存使用优化。编译器的工作是从Python函数提取出计算图，然后对计算图优化（比如剪切无用的节点），最后高效运行（比如自动并行运行独立任务）；</li>
<li>计算图可以导出为迁移形式，因此可以在一个环境中训练一个TensorFlow模型（比如使用Python或Linux），然后在另一个环境中运行（比如在安卓设备上用Java运行）；</li>
<li>TensorFlow实现了<strong>自动微分</strong> ，并提供了一些高效的优化器，比如RMSProp和NAdam，因此可以很容易最小化各种损失函数。</li>
</ul>
<p>其他流形的深度学习库有：PyTorch（Facebook）Theano，Caffe2，MXNet, Microsoft Cognitive Toolkit</p>
</blockquote>
</li>
<li><p>TensorFlow是NumPy的简单替换吗？二者有什么区别？</p>
<blockquote>
<p>不是</p>
<ul>
<li>TensorFlow和NumPy的函数名并不完全相同，本质是因为函数做得操作不同（NumPy中属性T和TensorFlow中的tf.transpose()）</li>
<li>大部分TF数据结构都是不可变的（除了变量这一类），但Numpy可变</li>
</ul>
</blockquote>
</li>
<li><p><code>tf.range(10)</code>和<code>tf.constant(np.arange(10))</code>能拿到相同的结果吗？</p>
<blockquote>
<p>基本一致</p>
<p>前者32位整数（TensorFlow中默认），后者64位整数（NumPy默认64位）</p>
</blockquote>
</li>
<li><p>列举出除了常规张量之外，TensorFlow的其它六种数据结构？</p>
<blockquote>
<p>稀疏张量，张量数组，嵌套张量，字符串张量，集合和队列</p>
</blockquote>
</li>
<li><p>可以通过函数或创建<code>keras.losses.Loss</code>的子类来自定义损失函数。两种方法各在什么时候使用？</p>
<blockquote>
<p>当自定义损失函数需要超参数时，需要创建<code>keras.losses.Loss</code>的子类</p>
</blockquote>
</li>
<li><p>相似的，自定义指标可以通过定义函数或创建<code>keras.metrics.Metric</code>的子类。两种方法各在什么时候使用？</p>
<blockquote>
<p>当自定义指标需要超参数时，需要创建<code>keras.metrics.Metric</code>的子类</p>
</blockquote>
</li>
<li><p>什么时候应该创建自定义层，而不是自定义模型？</p>
<blockquote>
<p>当需要自定义模型内部组件时，比如重复使用层的时候需要自定义层。</p>
<p>自定义层是<code>Layer</code>类的子类，自定义模型是<code>Model</code>类的子类。</p>
</blockquote>
</li>
<li><p>什么时候需要创建自定义的训练循环？</p>
<blockquote>
<p>在某些特殊情况下，<code>fit()</code>方法可能不够灵活。比如在神经网络模型中对不同的层使用不同的优化器，Wide &amp; Deep论文使用了两个优化器：一个用于宽路线，一个用于深路线。</p>
</blockquote>
</li>
<li><p>自定义Keras组件可以包含任意Python代码吗，或者Python代码需要转换为TF函数吗？</p>
<blockquote>
<p>可以在<code>tf.py_function()</code>运算中包装任意的Python代码，但这么做的话会使性能下降，因为TensorFlow不能做任何图优化。</p>
<p>不一定需要把Python代码转化为TF函数：</p>
<ul>
<li>可以在构建层或者模型的时候设置 <code>dynamic=True</code></li>
<li>或者，在编译的时候设置 <code>run_eagerly=True</code></li>
</ul>
</blockquote>
</li>
<li><p>如果想让一个函数可以转换为TF函数，要遵守设么规则？</p>
<blockquote>
<p>​</p>
</blockquote>
</li>
<li><p>什么时候需要创建一个动态Keras模型？怎么做？为什么不让所有模型都是动态的？</p>
<blockquote>
<ul>
<li>debug的时候可以创建动态Keras模型，因为没有编译，所以没有转换为TF Function，可以使Python Debug，或者想要在模型中包裹任意Python代码时，也可以创建动态Keras模型。</li>
<li>只需要在创建时设置 <code>dynamic=True</code> ，或者在编译时设置<code>run_eagerly=True</code></li>
<li>动态模型，不能使用TensorFlow的图计算（graph feature），训练和预测速度会下降。</li>
</ul>
</blockquote>
</li>
<li><p>实现一个具有层归一化的自定义层（第15章会用到）：</p>
<p>a. <code>build()</code>方法要定义两个可训练权重α 和 β，形状都是<code>input_shape[-1:]</code>，数据类型是<code>tf.float32</code>。α用1初始化，β用0初始化。</p>
<p>b. <code>call()</code>方法要计算每个实例的特征的平均值μ和标准差σ。你可以使用<code>tf.nn.moments(inputs, axes=-1, keepdims=True)</code>，它可以返回平均值μ和方差σ2（计算其平方根得到标准差）。函数返回<code>α⊗(X - μ)/(σ + ε) + β</code>，其中<code>⊗</code>表示元素级别惩罚，<code>ε</code>是平滑项（避免发生除以0，而是除以0.001）。</p>
<p>c. 确保自定义层的输出和<code>keras.layers.LayerNormalization</code>层的输出一致（或非常接近）。</p>
</li>
</ol>
<ol>
<li><p>训练一个自定义训练循环，来处理Fashion MNIST数据集。</p>
<p>a. 展示周期、迭代，每个周期的平均训练损失、平均准确度（每次迭代会更新），还有每个周期结束后的验证集损失和准确度。</p>
<p>b. 深层和浅层使用不同的优化器，不同的学习率。</p>
</li>
</ol>
<h2 id="第13章-使用TensorFlow加载和预处理数据"><a href="#第13章-使用TensorFlow加载和预处理数据" class="headerlink" title="第13章 使用TensorFlow加载和预处理数据"></a>第13章 使用TensorFlow加载和预处理数据</h2><p>介绍Data API，TFRecord格式，以及如何创建自定义预处理层，和使用Keras的预处理层。</p>
<h3 id="Data-API"><a href="#Data-API" class="headerlink" title="Data API"></a>Data API</h3><p><code>tf.data.Dataset.from_tensor_slices()</code>创建一个存储于内存中的数据集</p>
<h4 id="链式转换"><a href="#链式转换" class="headerlink" title="链式转换"></a>链式转换</h4><p><code>dataset.repeat(3).batch(7)</code> </p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e2753af12c9e73a0.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<blockquote>
<p>数据集方法不修改数据集，只是生成新的数据集而已，所以要做新数据集的赋值</p>
</blockquote>
<p><code>dataset.map(lambda x: x * 2)</code> 对于复杂的处理，通常需要多线程来加速：需设置参数<code>num_parallel_calls</code>。注意，传递给<code>map()</code>方法的函数必须是可以转换为TF Function。</p>
<p><code>map()</code>方法是对每个元素做转换的，<code>apply()</code>方法是对数据整体做转换的。</p>
<p>用<code>filter()</code>方法做过滤：<code>dataset.filter(lambda x: x &lt; 10)</code></p>
<p><code>take()</code>方法可以用来查看数据</p>
<h4 id="打散数据"><a href="#打散数据" class="headerlink" title="打散数据"></a>打散数据</h4><p>当训练集中的实例是独立同分布时，梯度下降的效果最好。实现独立同分布的一个简单方法是使用<code>shuffle()</code>方法。</p>
<blockquote>
<p>shuffle()创建一个新数据集，其前面是一个缓存，缓存中是源数据集的开头元素。无论何时取元素，会从缓存中随机取出一个元素，从源数据集中取一个新元素替换。从缓冲器取元素，直到缓存为空。必须要指定缓存的大小，最好大一点，否则随机效果不明显。但不要超出内存大小。如果希望随机的顺序是固定的，可以提供一个随机种子。</p>
</blockquote>
<p>对于大数据集，因为缓存比数据集小太多，随机缓存方法就不能用。解决方法是<strong>将源数据本身打乱</strong>，为了将实例进一步打散，一个常用的方法是<strong>将源数据分成多个文件</strong>，训练时随机顺序读取。但是，相同文件中的实例仍然靠的太近。为了避免这点，可以<strong>同时随机读取多个文件，做交叉</strong>。在最顶层，可以用<code>shuffle()</code>加一个随机缓存。</p>
<h4 id="多行数据交叉"><a href="#多行数据交叉" class="headerlink" title="多行数据交叉"></a>多行数据交叉</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.data.Dataset.list_files(train_filepaths, seed=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<p>默认，<code>list_files()</code>函数返回一个文件路径打散的数据集。也可以设置<code>shuffle=False</code>，文件路径就不打散了。</p>
<p>然后，调用<code>leave()</code>方法，一次读取5个文件，做交叉操作（跳过第一行表头，使用<code>skip()</code>方法，可以设定参数<code>num_parallel_calls</code>为想要的线程数（<code>map()</code>方法也有这个参数），并行读取文件。</p>
<blockquote>
<p>提示：为了交叉得更好，最好让文件有相同的长度，否则长文件的尾部不会交叉。</p>
</blockquote>
<h4 id="预处理数据"><a href="#预处理数据" class="headerlink" title="预处理数据"></a>预处理数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X_mean, X_std = [...] <span class="comment"># mean and scale of each feature in the training set</span></span><br><span class="line">n_inputs = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(line)</span>:</span></span><br><span class="line">  defs = [<span class="number">0.</span>] * n_inputs + [tf.constant([], dtype=tf.float32)]</span><br><span class="line">  fields = tf.io.decode_csv(line, record_defaults=defs)</span><br><span class="line">  x = tf.stack(fields[:<span class="number">-1</span>])</span><br><span class="line">  y = tf.stack(fields[<span class="number">-1</span>:])</span><br><span class="line">  <span class="keyword">return</span> (x - X_mean) / X_std, y</span><br></pre></td></tr></table></figure>
<h4 id="整合"><a href="#整合" class="headerlink" title="整合"></a>整合</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">csv_reader_dataset</span><span class="params">(filepaths, repeat=<span class="number">1</span>, n_readers=<span class="number">5</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                       n_read_threads=None, shuffle_buffer_size=<span class="number">10000</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                       n_parse_threads=<span class="number">5</span>, batch_size=<span class="number">32</span>)</span>:</span></span><br><span class="line">    dataset = tf.data.Dataset.list_files(filepaths)</span><br><span class="line">    dataset = dataset.interleave(</span><br><span class="line">        <span class="keyword">lambda</span> filepath: tf.data.TextLineDataset(filepath).skip(<span class="number">1</span>),</span><br><span class="line">        cycle_length=n_readers, num_parallel_calls=n_read_threads)</span><br><span class="line">    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)</span><br><span class="line">    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)</span><br><span class="line">    <span class="keyword">return</span> dataset.batch(batch_size).prefetch(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="预提取"><a href="#预提取" class="headerlink" title="预提取"></a>预提取</h4><p>通过调用<code>prefetch(1)</code>，创建了一个高效的数据集，总能提前一个批次。换句话说，当训练算法在一个批次上工作时，数据集已经准备好下一个批次了（从硬盘读取数据并做预处理）</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-86355457e5a7a1c2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<blockquote>
<p>提示：如果想买一块GPU显卡的话，它的处理能力和显存都是非常重要的。另一个同样重要的，是显存带宽，即每秒可以进入或流出内存的GB数。</p>
</blockquote>
<p>如果数据集不大，内存放得下，可以使用数据集的<code>cache()</code>方法将数据集存入内存。通常这步是在加载和预处理数据之后，在打散、重复、分批次之前。这样做的话，每个实例只需做一次读取和处理，下一个批次仍能提前准备。</p>
<h3 id="TFRecord格式"><a href="#TFRecord格式" class="headerlink" title="TFRecord格式"></a>TFRecord格式</h3><p>虽然使用CSV文件,常见又简单方便，但不够高效，不支持大或复杂的数据结构（比如图片或音频）。这就是TFRecord要解决的。</p>
<p>TFRecord格式是TensorFlow偏爱的存储大量数据并高效读取的数据。它是非常简单的二进制格式，只包含不同大小的二进制记录的数据（每个记录包括一个长度、一个CRC校验和，校验和用于检查长度是否正确，真是的数据，和一个数据的CRC校验和，用于检查数据是否正确）。</p>
<p>使用<code>tf.io.TFRecordWriter</code>类创建TFRecord文件,使用<code>tf.data.TFRecordDataset</code>来读取一个或多个TFRecord文件</p>
<blockquote>
<p>提示：默认情况下，<code>TFRecordDataset</code>会逐一读取数据，但通过设定<code>num_parallel_reads</code>可以并行读取并交叉数据。另外，也可以使用<code>list_files()</code>和<code>interleave()</code>获得同样的结果。</p>
</blockquote>
<h4 id="压缩TFRecord文件"><a href="#压缩TFRecord文件" class="headerlink" title="压缩TFRecord文件"></a>压缩TFRecord文件</h4><p>可以通过设定<code>options</code>参数，创建压缩的TFRecord文件，当读取压缩TFRecord文件时，需要指定压缩类型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">options = tf.io.TFRecordOptions(compression_type=<span class="string">"GZIP"</span>)</span><br><span class="line"><span class="keyword">with</span> tf.io.TFRecordWriter(<span class="string">"my_compressed.tfrecord"</span>, options) <span class="keyword">as</span> f:</span><br><span class="line">  [...]</span><br><span class="line">dataset = tf.data.TFRecordDataset([<span class="string">"my_compressed.tfrecord"</span>],</span><br><span class="line">                                  compression_type=<span class="string">"GZIP"</span>)</span><br></pre></td></tr></table></figure>
<h4 id="协议缓存"><a href="#协议缓存" class="headerlink" title="协议缓存"></a>协议缓存</h4><p>每条记录可以使用任何二进制格式，TFRecord文件通常包括序列化的协议缓存（也称为protobuf）。这是一种可移植、可扩展的高效二进制格式，是谷歌在2001年开发，并在2008年开源的；协议缓存现在使用广泛，特别是在gRPC，谷歌的远程调用系统中。定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">syntax = <span class="string">"proto3"</span>;</span><br><span class="line">message Person &#123;</span><br><span class="line">  string name = <span class="number">1</span>;</span><br><span class="line">  int32 id = <span class="number">2</span>;</span><br><span class="line">  repeated string email = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当<code>.proto</code>文件中有了一个定义，就可以用协议缓存编译器<code>protoc</code>编译，来生成Python（或其它语言）的访问类。</p>
<h4 id="TensorFlow协议缓存"><a href="#TensorFlow协议缓存" class="headerlink" title="TensorFlow协议缓存"></a>TensorFlow协议缓存</h4><p>TFRecord文件主要使用的协议缓存是<code>tf.train.Example</code>，表示数据集中的一个实例，包括命名特征的列表，每个特征可以是字节串列表、或浮点列表、或整数列表。下面是一个协议缓存的定义：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">syntax = <span class="string">"proto3"</span>;</span><br><span class="line">message BytesList &#123; repeated bytes value = <span class="number">1</span>; &#125;</span><br><span class="line">message FloatList &#123; repeated float value = <span class="number">1</span> [packed = true]; &#125;</span><br><span class="line">message Int64List &#123; repeated int64 value = <span class="number">1</span> [packed = true]; &#125;</span><br><span class="line">message Feature &#123;</span><br><span class="line">    oneof kind &#123;</span><br><span class="line">        BytesList bytes_list = <span class="number">1</span>;</span><br><span class="line">        FloatList float_list = <span class="number">2</span>;</span><br><span class="line">        Int64List int64_list = <span class="number">3</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line">message Features &#123; map&lt;string, Feature&gt; feature = <span class="number">1</span>; &#125;;</span><br><span class="line">message Example &#123; Features features = <span class="number">1</span>; &#125;;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>一般来说，你需要写一个转换脚本，读取当前格式（例如csv），为每个实例创建<code>Example</code>协议缓存，序列化并存储到若干TFRecord文件中，最好再打散。</p>
</blockquote>
<h4 id="加载和解析Example"><a href="#加载和解析Example" class="headerlink" title="加载和解析Example"></a>加载和解析Example</h4><p>要加载序列化的<code>Example</code>协议缓存，需要再次使用<code>tf.data.TFRecordDataset</code>，使用<code>tf.io.parse_single_example()</code>解析每个<code>Example</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">feature_description = &#123;</span><br><span class="line">    <span class="string">"name"</span>: tf.io.FixedLenFeature([], tf.string, default_value=<span class="string">""</span>),</span><br><span class="line">    <span class="string">"id"</span>: tf.io.FixedLenFeature([], tf.int64, default_value=<span class="number">0</span>),</span><br><span class="line">    <span class="string">"emails"</span>: tf.io.VarLenFeature(tf.string),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> serialized_example <span class="keyword">in</span> tf.data.TFRecordDataset([<span class="string">"my_contacts.tfrecord"</span>]):</span><br><span class="line">    parsed_example = tf.io.parse_single_example(serialized_example,</span><br><span class="line">                                                feature_description)</span><br></pre></td></tr></table></figure>
<p>长度固定的特征会像常规张量那样解析，而长度可变的特征会作为稀疏张量解析。可以使用<code>tf.sparse.to_dense()</code>将稀疏张量转变为紧密张量。</p>
<h4 id="使用SequenceExample协议缓存处理嵌套列表"><a href="#使用SequenceExample协议缓存处理嵌套列表" class="headerlink" title="使用SequenceExample协议缓存处理嵌套列表"></a>使用<code>SequenceExample</code>协议缓存处理嵌套列表</h4><p>下面是<code>SequenceExample</code>协议缓存的定义：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">message FeatureList &#123; repeated Feature feature = <span class="number">1</span>; &#125;;</span><br><span class="line">message FeatureLists &#123; map&lt;string, FeatureList&gt; feature_list = <span class="number">1</span>; &#125;;</span><br><span class="line">message SequenceExample &#123;</span><br><span class="line">    Features context = <span class="number">1</span>;</span><br><span class="line">    FeatureLists feature_lists = <span class="number">2</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>须要使用<code>tf.io.parse_single_sequence_example()</code>来解析单个的<code>SequenceExample</code>或用<code>tf.io.parse_sequence_example()</code>解析一个批次。两个函数都是返回一个包含上下文特征（字典）和特征列表（也是字典）的元组。如果特征列表包含大小可变的序列（就像前面的例子），可以将其转化为嵌套张量，使用<code>tf.RaggedTensor.from_sparse()</code></p>
<h3 id="预处理输入特征"><a href="#预处理输入特征" class="headerlink" title="预处理输入特征"></a>预处理输入特征</h3><p>为神经网络准备数据需要将所有特征转变为数值特征，做一些归一化工作等等。</p>
<blockquote>
<ul>
<li>可以在准备数据文件的时候做，使用NumPy、Pandas、Scikit-Learn这样的工作。</li>
<li>可以在用Data API加载数据时，实时预处理数据（比如，使用数据集的<code>map()</code>方法，就像前面的例子）。</li>
<li>可以给模型加一个预处理层。</li>
</ul>
</blockquote>
<p><strong>用Lambda层实现标准化层</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">means = np.mean(X_train, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">stds = np.std(X_train, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">eps = keras.backend.epsilon()</span><br><span class="line">model = keras.models.Sequential([</span><br><span class="line">    keras.layers.Lambda(<span class="keyword">lambda</span> inputs: (inputs - means) / (stds + eps)),</span><br><span class="line">    [...] <span class="comment"># 其它层</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p><strong>独立的自定义层</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Standardization</span><span class="params">(keras.layers.Layer)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">adapt</span><span class="params">(self, data_sample)</span>:</span></span><br><span class="line">        self.means_ = np.mean(data_sample, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        self.stds_ = np.std(data_sample, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())</span><br><span class="line">        </span><br><span class="line">std_layer = Standardization()</span><br><span class="line">std_layer.adapt(data_sample)</span><br></pre></td></tr></table></figure>
<h4 id="使用独热矢量编码类型特征"><a href="#使用独热矢量编码类型特征" class="headerlink" title="使用独热矢量编码类型特征"></a>使用独热矢量编码类型特征</h4><p>创建了查找表，传入初始化器并指明未登录词（oov）桶的数量。如果查找的类型不在词典中，查找表会计算这个类型的哈希，使用哈希分配一个未知的类型给未登录词桶。索引序号接着现有序号，</p>
<p>原因：如果类型数足够大（例如，邮编、城市、词、产品、或用户），数据集也足够大，或者数据集持续变化，这样的话，获取类型的完整列表就不容易了。一个解决方法是根据数据样本定义（而不是整个训练集），为其它不在样本中的类型加上一些未登录词桶。训练中碰到的未知类型越多，要使用的未登录词桶就要越多。事实上，如果未登录词桶的数量不够，就会发生碰撞：不同的类型会出现在同一个桶中，所以神经网络就无法区分了。</p>
<blockquote>
<p>一个重要的原则，如果类型数小于10，可以使用独热编码。如果类型超过50个（使用哈希桶时通常如此），最好使用嵌入。类型数在10和50之间时，最好对两种方法做个试验，看哪个更合适。</p>
</blockquote>
<h4 id="用嵌入编码类型特征"><a href="#用嵌入编码类型特征" class="headerlink" title="用嵌入编码类型特征"></a>用嵌入编码类型特征</h4><p>嵌入是一个可训练的表示类型的紧密矢量。默认时，嵌入是随机初始化的，<code>&quot;NEAR BAY&quot;</code>可能初始化为<code>[0.131, 0.890]</code>，<code>&quot;NEAR OCEAN&quot;</code>可能初始化为<code>[0.631, 0.791]</code>。</p>
<blockquote>
<p>表征的越好，越利于神经网络做出准确的预测，而训练会让嵌入更好的表征类型，这被称为表征学习</p>
</blockquote>
<h5 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h5><p>用神经网络预测给定词附近的词，得到了非常好的词嵌入。例如，同义词有非常相近的词嵌入，语义相近的词，比如法国、西班牙和意大利靠的也很近，词嵌入在嵌入空间的轴上的分布也是有意义的。</p>
<blockquote>
<p>独热编码加紧密层（没有激活函数和偏差项），等价于嵌入层。但是，嵌入层用的计算更少（嵌入矩阵越大，性能差距越明显）。紧密层的权重矩阵扮演的是嵌入矩阵的角色。例如，大小为20的独热矢量和10个单元的紧密层加起来，等价于<code>input_dim=20</code>、<code>output_dim=10</code>的嵌入层。作为结果，嵌入的维度超过后面的层的神经元数是浪费的。</p>
</blockquote>
<h4 id="Keras预处理层"><a href="#Keras预处理层" class="headerlink" title="Keras预处理层"></a>Keras预处理层</h4><p><code>keras.layers.Normalization</code>用来做特征标准化，<code>TextVectorization</code>层用于将文本中的词编码为词典的索引。对于这两个层，都是用数据样本调用它的<code>adapt()</code>方法，然后如常使用。其它的预处理层也是这么使用的。</p>
<p><code>keras.layers.Discretization</code>层，它能将连续数据切成不同的组，将每个组斌吗为独热矢量。例如，可以用它将价格分成是三类，低、中、高，编码为[1, 0, 0]、[0, 1, 0]、[0, 0, 1]。</p>
<p><code>TextVectorization</code>层也有一个选项用于输出词频向量，而不是词索引。例如，如果词典包括三个词，比如<code>[&quot;and&quot;, &quot;basketball&quot;, &quot;more&quot;]</code>，则<code>&quot;more and more&quot;</code>会映射为<code>[1, 0, 2]</code>：<code>&quot;and&quot;</code>出现了一次，<code>&quot;basketball&quot;</code>没有出现，<code>&quot;more&quot;</code>出现了两次。这种词表征称为<strong>词袋 </strong> ，因为它完全失去了词的顺序。</p>
<p>词频向量中应该降低常见词的影响。一个常见的方法是<strong>将词频除以出现该词的文档数的对数</strong>。这种方法称为<strong>词频-逆文档频率（TF-IDF）</strong>。例如，假设<code>&quot;and&quot;</code>、<code>&quot;basketball&quot;</code>、<code>&quot;more&quot;</code>分别出现在了200、10、100个文档中：最终的矢量应该是<code>[1/log(200), 0/log(10), 2/log(100)]</code>，大约是<code>[0.19, 0., 0.43]</code>。<code>TextVectorization</code>层会有TF-IDF的选项。</p>
<h3 id="TF-Transform"><a href="#TF-Transform" class="headerlink" title="TF Transform"></a>TF Transform</h3><p>TensorFlow没有捆绑，需要pip安装</p>
<p>在数据训练前，处理每个实例，而不是在训练中每个周期处理一次实例。</p>
<p>如果数据集小到可以存入内存，可以使用<code>cache()</code>方法。但如果太大，可以<strong>使用Apache Beam或Spark</strong>。它们可以在大数据上做高效的数据预处理，还可以分布进行，使用它们就能在训练前处理所有训练数据了。</p>
<p>TF Transform是<a href="https://links.jianshu.com/go?to=https%3A%2F%2Ftensorflow.org%2Ftfx" target="_blank" rel="noopener">TensorFlow Extended (TFX)</a>的一部分，这是一个端到端的TensorFlow模型生产化平台。</p>
<h3 id="TensorFlow-Datasets（TFDS）项目"><a href="#TensorFlow-Datasets（TFDS）项目" class="headerlink" title="TensorFlow Datasets（TFDS）项目"></a>TensorFlow Datasets（TFDS）项目</h3><p>TensorFlow没有捆绑TFDS，所以需要使用pip安装库<code>tensorflow-datasets</code>。然后调用函数<code>tfds.load()</code>，就能下载数据集了（除非之前下载过），返回的数据是数据集的字典（通常是一个是训练集，一个是测试集）。</p>
<h3 id="练习-3"><a href="#练习-3" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>为什么要使用Data API </p>
<blockquote>
<p>当数据集很大，或者保存在不同文件中是，可以用Data API来读入数据，处理数据</p>
</blockquote>
</li>
<li><p>将大数据分成多个文件有什么好处？</p>
<blockquote>
<p>可以对数据进行打散，交叉（shuffle）</p>
<p>还可以对数据进行分布式计算处理</p>
</blockquote>
</li>
<li><p>训练中，如何断定输入管道是瓶颈？如何处理瓶颈？</p>
<blockquote>
<p>如果GPU没有完全被利用时，可能是输入管道达到了瓶颈。</p>
<p>可以多线程来加速</p>
</blockquote>
</li>
<li><p>可以将任何二进制数据存入TFRecord文件吗，还是只能存序列化的协议缓存？</p>
<blockquote>
<p>可以将任意的二级制数据存入</p>
<p>但通常情况下都是村塾序列化的协议缓存，可以被多平台，多语言利用。</p>
</blockquote>
</li>
<li><p>为什么要将数据转换为Example协议缓存？为什么不使用自己的协议缓存？</p>
<blockquote>
<p>TensorFlow为Example提供了许多操作，可以不需要自己定义format解释（parse）</p>
<p>如果不能满足自己的需求时3，可以自定义协议缓存，然后用protoc编译。</p>
</blockquote>
</li>
<li><p>使用TFRecord时，什么时候要压缩？为什么不系统化的做？</p>
<blockquote>
<p>需要下载或传输数据时可以压缩，这样可以减少数据压缩时间。</p>
</blockquote>
</li>
<li><p>数据预处理可以在写入数据文件时，或在tf.data管道中，或在预处理层中，或使用TF Transform。这几种方法各有什么优缺点？</p>
<blockquote>
<p>| 项目             | 优点                                                         | 缺点                                                         |<br>| ———————— | —————————————————————————————— | —————————————————————————————— |<br>| 在tf.data管道中  | 1. preprocessing logics 和 data augmentation很简单 2. 可以构建管道 | 1. 降低训练过程的速度 2. 每个实例会在每个epoch处理一次，不像在写入文件就处理那样，只需一次。2. 训练好的模型仍然需要处理好的数据 |<br>| 在预处理层中     | 1. 只需要在训练和预测的时候写一次代码。2.                    | 1. 降低训练速度。2. 每个实例会在每个epoch处理一次，3. 默认情况下，数据在GPU上处理（因为数据处理是在模型里），不能CPU处理数据，GPU跑模型 |<br>| 使用TF Transform | 1.  the preprocessed data is materialized, 2. 每个实例只需要处理一次，3. 代码只需写一次. | 使用比较困难                                                 |<br>| 在写入数据文件时 | 1. 训练过程会变得很快， 2. 数据处理之后比较小，节省空间，方便下载  3. 方便检查数据 | 1. 有很多preprocessing logics 2，data augmentation时，需要很大的磁盘空间和时间 3，需要在建模之前处理 |</p>
</blockquote>
</li>
<li><p>说出几种常见的编码类型特征的方法。文本如何编码？</p>
<blockquote>
<ol>
<li>ordinal encoding：每个类比给一个编号，但是编号有距离，而不代表实际的距离</li>
<li>one-hot encoding，独热编码</li>
<li>embeddings，嵌入编码</li>
</ol>
<p>文本：</p>
<ol>
<li>统计单词的频率，使用词袋，一句话有表示单词频次的矢量表示，可以使用TF-IDF方法，即除以log（单词出现的文件的个数）来降低常用单词的分数。</li>
<li>count <em>n</em>-grams，统计连续的n个单词，可以保留上下文关系。</li>
<li>除了对单词编码，还可以对字母或者subword tokens编码。</li>
</ol>
</blockquote>
</li>
<li><p>加载Fashion MNIST数据集；将其分成训练集、验证集和测试集；打散训练集；将每个数据存为多个TFRecord文件。每条记录应该是有两个特征的序列化的Example协议缓存：序列化的图片（使用<code>tf.io.serialize_tensor()</code>序列化每张图片）和标签。然后使用tf.data为每个集合创建一个高效数据集。最后，使用Keras模型训练这些数据集，用预处理层标准化每个特征。让输入管道越高效越好，使用TensorBoard可视化地分析数据。</p>
</li>
<li><p>这道题中，要下载一个数据集，分割它，创建一个tf.data.Dataset，用于高效加载和预处理，然后搭建一个包含嵌入层的二分类模型：</p>
<p>a. 下载<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fimdb" target="_blank" rel="noopener">Large Movie Review Dataset</a>，它包含50000条IMDB的影评。数据分为两个目录，train和test，每个包含12500条正面评价和12500条负面评价。每条评价都存在独立的文本文件中。还有其他文件和文件夹（包括预处理的词袋），但这个练习中用不到。</p>
<p>b. 将测试集分给成验证集（15000）和测试集（10000）。</p>
<p>c. 使用tf.data，为每个集合创建高效数据集。</p>
<p>d.创建一个二分类模型，使用<code>TextVectorization</code>层来预处理每条影评。如果<code>TextVectorization</code>层用不了（或者你想挑战下），则创建自定义的预处理层：使用<code>tf.strings</code>包中的函数，比如<code>lower()</code>来做小写，<code>regex_replace()</code>来替换带有空格的标点，<code>split()</code>来分割词。用查找表输出词索引，<code>adapt()</code>方法中要准备好。</p>
<p>e. 加入嵌入层，计算每条评论的平均嵌入，乘以词数的平方根。这个缩放过的平均嵌入可以传入剩余的模型中。</p>
<p>f. 训练模型，看看准确率能达到多少。尝试优化管道，让训练越快越好。</p>
<p>g. 使用TFDS加载同样的数据集：<code>tfds.load(&quot;imdb_reviews&quot;)</code>。</p>
</li>
</ol>
<h2 id="第14章-使用卷积神经网络实现深度计算机视觉"><a href="#第14章-使用卷积神经网络实现深度计算机视觉" class="headerlink" title="第14章 使用卷积神经网络实现深度计算机视觉"></a>第14章 使用卷积神经网络实现深度计算机视觉</h2><p>CNN没有GPU可能会很慢</p>
<h3 id="视神经结构"><a href="#视神经结构" class="headerlink" title="视神经结构"></a>视神经结构</h3><p>David H. Hubel 和 Torsten Wiesel 在1958年和1959年在猫的身上做了一系列研究，对视神经中枢做了研究（并在1981年荣获了诺贝尔生理学或医学奖）。特别的，他们指出视神经中的许多神经元都有一个<strong>局部感受野（local receptive field）</strong>，也就是说，这些神经元只对有限视觉区域的刺激作反应。</p>
<p>Yann LeCun等人再1998年发表了一篇里程碑式的论文，提出了著名的LeNet-5架构，被银行广泛用来识别手写支票的数字。这个架构中的一些组件，我们已经学过了，比如全连接层、sigmod激活函数，但CNN还引入了两个新组件：卷积层和池化层。</p>
<blockquote>
<p>全连接层的深度神经网络尽管在小图片（比如MNIST）任务上表现不错，但由于参数过多，在大图片任务上表现不佳。举个例子，一张100 × 100像素的图片总共有10000个像素点，如果第一层有1000个神经元（如此少的神经元，已经限制信息的传输量了），那么就会有1000万个连接。这仅仅是第一层的情况。CNN是通过部分连接层和权重共享解决这个问题的。</p>
</blockquote>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积层是CNN最重要的组成部分：第一个卷积层的神经元，不是与图片中的每个像素点都连接，而是只连着局部感受野的像素。同理，第二个卷积层中的每个神经元也只是连着第一层中一个小方形内的神经元。这种架构可以让第一个隐藏层聚焦于小的低级特征，然后在下一层组成大而高级的特征。这种<strong>层级式的结构</strong>在真实世界的图片很常见，这是CNN能在图片识别上取得如此成功的原因之一。</p>
<blockquote>
<p>目前所学过的所有多层神经网络的层，都是由一长串神经元组成的，所以在将图片输入给神经网络之前，必须将图片打平成1D的。在CNN中，每个层都是2D的，更容易将神经元和输入做匹配。</p>
</blockquote>
<p>位于给定层第<code>i</code>行、第<code>j</code>列的神经元，和前一层的第<code>i</code>行到第<code>i + fh – 1</code>行、第<code>j</code>列到第<code>j + fw – 1</code>列的输出相连，fh和fw是感受野的高度和宽度（见图14-3）。为了让卷积层能和前一层有相同的高度和宽度，通常给输入加上0，这被称为<strong>零填充（zero padding）。</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-1cfddd1d6ac1db56.png?imageMogr2/auto-orient/strip|imageView2/2/w/1102/format/webp" alt="img"></p>
<p><strong>间隔感受野，将大输入层和小卷积层连接起来</strong>。可以极大降低模型的计算复杂度。一个感受野到下一个感受野的距离称为<strong>步长</strong>。5 × 7 的输入层（加上零填充），连接着一个3 × 4的层，使用 3 × 3 的感受野，步长是2。位于上层第<code>i</code>行、第<code>j</code>列的神经元，连接着前一层的第<code>i × sh</code>到<code>i × sh + fh – 1</code>行、第<code>j × sw</code>到<code>j × sw + fw – 1</code>列的神经元的输出，sh和sw分别是垂直和水平步长。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9968acd895a0095e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1049/format/webp" alt="img"></p>
<h3 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h3><p>神经元的权重可以表示为感受野大小的图片。例如，图14-5展示了两套可能的权重（称为权重，或卷积核）。第一个是黑色的方形，中央有垂直白线（7 × 7的矩阵，除了中间的竖线都是1，其它地方是0）；使用这个矩阵，神经元只能注意到中间的垂直线（因为其它地方都乘以0了）。第二个过滤器也是黑色的方形，但是中间是水平的白线。使用这个权重的神经元只会注意中间的白色水平线。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-8607c8748eef3e4f.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>一层的全部神经元都用一个过滤器，就能输出一个<strong>特征映射（feature map），特征映射可以高亮图片中最为激活过滤器的区域。</strong></p>
<h3 id="堆叠多个特征映射"><a href="#堆叠多个特征映射" class="headerlink" title="堆叠多个特征映射"></a>堆叠多个特征映射</h3><p> 计算卷积层中给定神经元的输出</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-fb733f1a729f0406.png?imageMogr2/auto-orient/strip|imageView2/2/w/1052/format/webp" alt="img"></p>
<blockquote>
<p>同一特征映射中的所有神经元共享一套参数，极大地减少了模型的参数量。当CNN认识了一个位置的图案，就可以在任何其它位置识别出来。相反的，当常规DNN学会一个图案，只能在特定位置识别出来。</p>
</blockquote>
<h3 id="内存需求"><a href="#内存需求" class="headerlink" title="内存需求"></a>内存需求</h3><p>CNN的另一个问题是卷积层需要很高的内存。特别是在训练时，因为反向传播需要所有前向传播的中间值。</p>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>明白卷积层的原理了，池化层就容易多了。池化层的目的是对输入图片做降采样（即，收缩），以降低计算负载、内存消耗和参数的数量（降低过拟合）。</p>
<p>和卷积层一样，池化层中的每个神经元也是之和前一层的感受野里的有限个神经元相连。和前面一样，必须定义感受野的大小、步长和填充类型。但是，池化神经元没有权重，它所要做的是使用聚合函数，比如最大或平均，对输入做聚合。</p>
<p>除了可以减少计算、内存消耗、参数数量，最大池化层还可以带来对小偏移的不变性</p>
<p>最大池化层的缺点：</p>
<ol>
<li>池化层破坏了信息：即使感受野的核是2 × 2，步长是2，输出在两个方向上都损失了一半，总共损失了75%的信息。</li>
<li>对于某些任务，不变性不可取。比如语义分割（将像素按照对象分类）：如果输入图片向右平移了一个像素，输出也应该向右平移一个降速。此时强调的就是等价：输入发生小变化，则输出也要有对应的小变化。</li>
</ol>
<p><strong>平均池化层</strong>和最大池化层很相似，但计算的是感受野的平均值。平均池化层在过去很流行，但最近人们使用最大池化层更多，因为最大池化层的效果更好。初看很奇怪，因为计算平均值比最大值损失的信息要少。但是从反面看，最大值保留了最强特征，去除了无意义的特征，可以让下一层获得更清楚的信息。另外，最大池化层提供了更强的平移不变性，所需计算也更少。</p>
<p><strong>全局平均池化层</strong>。它计算整个特征映射的平均值（就像是平均池化层的核的大小和输入的空间维度一样）。这意味着，全局平均池化层对于每个实例的每个特征映射，只输出一个值。虽然这么做对信息的破坏性很大，却可以用来做输出层。</p>
<p><strong>深度方向最大池化层：</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4030e5fa51363eb8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="CNN架构"><a href="#CNN架构" class="headerlink" title="CNN架构"></a>CNN架构</h3><p>CNN的典型架构是：几个卷积层叠起来（每个卷积层后面跟着一个ReLU层）+ 池化层+卷积层（+ReLU），+池化层。图片在流经神经网络的过程中，变得越来越小，但得益于卷积层，却变得越来越深（特征映射变多了）。在CNN的顶部，还有一个常规的前馈神经网络，由几个全连接层（+ReLU）组成，最终层输出预测（比如，一个输出类型概率的softmax层）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4590999c8c41bf3e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Flenet5" target="_blank" rel="noopener">LeNet-5</a> 也许是最广为人知的CNN架构。由Yann LeCun在1998年创造出来的，被广泛用于手写字识别（MNIST）。结构如下：</p>
<p><img src="//upload-images.jianshu.io/upload_images/7178691-ed2580d5b84531fb.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F80" target="_blank" rel="noopener">AlexNet CNN 架构</a>是2012 ImageNet ILSVRC冠军：Top-5误差率达到了17%，由Alex Krizhevsky、Ilya Sutskever 和 Geoffrey Hinton发明。AlexNet和LeNet-5很相似，只是更大更深，是首个将卷积层堆叠起来的网络，而不是在每个卷积层上再加一个池化层。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-1c5bbecf35d2e8d9.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<blockquote>
<p>数据增强是通过生成许多训练实例的真实变种，来人为增大训练集。因为可以降低过拟合，成为了一种正则化方法。生成出来的实例越真实越好：最理想的情况，人们无法区分增强图片是原生的还是增强过的。简单的添加白噪声没有用，增强修改要是可以学习的（白噪声不可学习）。</p>
<p>例如，可以轻微偏移、旋转、缩放原生图，再添加到训练集中（见图14-12）。这么做可以使模型对位置、方向和物体在图中的大小，有更高的容忍度。如果想让模型对不同光度有容忍度，可以生成对比度不同的照片。通常，还可以水平翻转图片（文字不成、不对称物体也不成）。通过这些变换，可以极大的增大训练集。</p>
</blockquote>
<p>AlexNet还在C1和C3层的ReLU之后，使用了强大的归一化方法，称为<strong>局部响应归一化（LRN）</strong>：激活最强的神经元抑制了相同位置的相邻特征映射的神经元（这样的竞争性激活也在生物神经元上观察到了）。这么做可以让不同的特征映射专业化，特征范围更广，提升泛化能力。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-39ad65a741a0b167.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F81" target="_blank" rel="noopener">GoogLeNet 架构</a>是Google Research的Christian Szegedy及其同事发明的，是2014年ILSVRC的冠军 ，top-5误差率降低到了7%以内。能取得这么大的进步，很大的原因是它的网络比之前的CNN更深。创始模块（inception module）的子网络让GoogLeNet可以用更高的效率使用参数：实际上，GoogLeNet的参数量比AlexNet小10倍（大约是600万，而不是AlexNet的6000万）。</p>
<p><strong>创始模块的架构</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4c0d23d3db687219.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h3><p>ILSVRC 2014年的亚军是<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F83" target="_blank" rel="noopener">VGGNet</a>，作者是来自牛津大学Visual Geometry Group（VGC）的Karen Simonyan 和 Andrew Zisserman。VGGNet的架构简单而经典，2或3个卷积层和1个池化层，然后又是2或3个卷积层和1个池化层，以此类推（总共达到16或19个卷积层）。最终加上一个有两个隐藏层和输出层的紧密网络。VGGNet只用3 × 3的过滤器，但数量很多。</p>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p>何凯明使用<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F82" target="_blank" rel="noopener"><em>Residual Network</em> (或 <em>ResNet</em>)</a>赢得了ILSVRC 2015的冠军，top-5误差率降低到了3.6%以下。ResNet的使用了极深的卷积网络，共152层（其它的变体有1450或152层）。反映了一个总体趋势：<strong>模型变得越来越深，参数越来越少</strong>。训练这样的深度网络的方法是使用跳连接（也被称为快捷连接）：输入信号添加到更高层的输出上。</p>
<p>残差学习：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e911c02ef15d5001.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="使用预训练模型做迁移学习"><a href="#使用预训练模型做迁移学习" class="headerlink" title="使用预训练模型做迁移学习"></a>使用预训练模型做迁移学习</h3><h3 id="分类和定位"><a href="#分类和定位" class="headerlink" title="分类和定位"></a>分类和定位</h3><p>定位图片中的物体可以表达为一个回归任务：预测物体的范围框，一个常见的方法是预测物体中心的水平和垂直坐标，和其高度和宽度。</p>
<p>MSE作为损失函数来训练模型效果很好，但不是评估模型预测边框的好指标。最常见的指标是交并比（Intersection over Union (IoU)）：预测边框与目标边框的重叠部分，除以两者的并集。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-67bc697752690e26.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h3><p>分类并定位图片中的多个物体的任务被称为目标检测。</p>
<h3 id="全卷积网络（fully-convolutional-network，FCN）"><a href="#全卷积网络（fully-convolutional-network，FCN）" class="headerlink" title="全卷积网络（fully convolutional network，FCN）"></a>全卷积网络（fully convolutional network，FCN）</h3><h3 id="全卷积层"><a href="#全卷积层" class="headerlink" title="全卷积层"></a>全卷积层</h3><p>FCN是Jonathan Long在2015年的一篇<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Ffcn" target="_blank" rel="noopener">论文</a>汇总提出的，用于语义分割（根据所属目标，对图片中的每个像素点进行分类）</p>
<h3 id="只看一次（YOLO）"><a href="#只看一次（YOLO）" class="headerlink" title="只看一次（YOLO）"></a>只看一次（YOLO）</h3><p>只看一次”（You Only Look Once，YOLO）是一个非常流行（非常快且准确）的<strong>目标检测架构</strong>的名字，是Joseph Redmon在2015年的一篇<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fyolo" target="_blank" rel="noopener">论文</a>中提出的，2016年优化为<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fyolo2" target="_blank" rel="noopener">YOLOv2</a>，2018年优化为<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fyolo3" target="_blank" rel="noopener">YOLOv3</a>。速度快到甚至可以在实时视频中运行。</p>
<p>平均精度均值（mean Average Precision，mAP）</p>
<blockquote>
<p>目标检测中非常常见的指标是平均精度均值。</p>
<p>假设当召回率为10%时，分类器的精确率是90%，召回率为20%时，精确率是96%。这里就没有取舍关系：使用召回率为20%的分类器就好，因为此时精确率更高。所以当召回率至少有10%时，需要找到最高精确率，即96%。因此，一个衡量模型性能的方法是计算召回率至少为0%时，计算最大精确率，再计算召回率至少为10%时的最大精确率，再计算召回率至少为20%时的最大精确率，以此类推。最后计算这些最大精确率的平均值，这个指标称为平均精确率（Average Precision (AP)）。当有超过两个类时，可以计算每个类的AP，然后计算平均AP（即，mAP）。</p>
</blockquote>
<p>IOU阈值:</p>
<blockquote>
<p>在目标检测中，还有另外一个复杂度：如果系统检测到了正确的类，但是定位错了，当然不能将其作为正预测。一种方法是定义IOU阈值：例如，只有当IOU超过0.5时，预测才是正确的。相应的mAP表示为mAP@0.5（或mAP@50%，或AP50）。</p>
</blockquote>
<h3 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h3><p>在语义分割中，每个像素根据其所属的目标来进行分类。相同类的不同目标是不做区分的。</p>
<h3 id="练习-4"><a href="#练习-4" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>对于图片分类，CNN相对于全连接DNN的优势是什么？</p>
<blockquote>
<ol>
<li>CNN神经元之间部分连接，参数少</li>
<li>当CNN的核学会识别一个特征后，可以在图像任意位置识别该特征，而DNN只能在特定的位置识别。</li>
<li>DNN将图像数据flatten，每个像素之间的位置关系不能被保持</li>
</ol>
</blockquote>
</li>
<li><p>考虑一个CNN，有3个卷积层，每个都是3 × 3的核，步长为2，零填充。最低的层输出100个特征映射，中间的输出200个特征映射，最上面的输出400个。输入图片是200 × 300像素的RGB图。这个CNN的总参数量是多少？如果使用32位浮点数，做测试需要多少内存？批次是50张图片，训练时的内存消耗是多少？</p>
<blockquote>
<p>第一层：[3x3x3(RGB三通道)+1（偏置向）]*100=2800</p>
<p>第二层：[3x3x100+1]*200=180200</p>
<p>第三层：[3x3x200+1]*400=720400</p>
<p>所以三层共有903400个参数。</p>
<hr>
<p>32位浮点数在内存中占4个字节。假设stride=2</p>
<p>第一层有100个feature map，4x100x100x150=6百万字节（6MB）</p>
<p>同理第二层：4x200x50x75=3MB</p>
<p>第三层：4x400x25x38=1.5MB</p>
<p>但是只需同时保证两层的计算结果，最大为前两层：9MB</p>
<p>参数占用内存：4*903400=3.6MB</p>
<p>共12.6MB</p>
<hr>
<p>反向传播要求保留向前计算的所有结果，每个实例三层-10.5MB，mini-batch=50，需要525MB</p>
<p>50张图片需要：50x4x200x300x3=36MB</p>
<p>参数需要3.6MB</p>
<p>还需要一些内存记录梯度</p>
<p>共需要564.6MB</p>
</blockquote>
</li>
<li><p>如果训练CNN时GPU内存不够，解决该问题的5种方法是什么？</p>
<blockquote>
<ol>
<li>减小batch的大小</li>
<li>使用更大的strider</li>
<li>去掉几层卷积层</li>
<li>使用16位浮点数，而不是32位浮点数</li>
<li>分布式训练，将CNN分布到多台计算机上</li>
</ol>
</blockquote>
</li>
<li><p>为什么使用最大池化层，而不是同样步长的卷积层？</p>
<blockquote>
<p>最大池化层不需要参数，同样不长的卷积层需要参数。</p>
</blockquote>
</li>
<li><p>为什么使用局部响应归一化层？</p>
<blockquote>
<p>LRN:激活最强的神经元抑制了相同位置的相邻特征映射的神经元（这样的竞争性激活也在生物神经元上观察到了）。这么做可以让不同的特征映射专业化，特征范围更广，提升泛化能力。</p>
</blockquote>
</li>
<li><p>AlexNet相对于LeNet-5的创新在哪里？GoogLeNet、ResNet、SENet、Xception的创新又是什么？</p>
<blockquote>
<p>AlexNet箱规与LeNet-5 更大更深，并且将卷积层链接到一起，而不是卷积层+池化层</p>
<p>GoogLeNet：引入创始模块，可以层数更深，而参数更少</p>
<p>ResNet：跳接</p>
<p>SENet： 在原始架构的每个单元（比如创始模块或残差单元）上添加了一个小的神经网络，称为SE块</p>
<p>Xception：使用depthwise separable convolutional layers</p>
</blockquote>
</li>
<li><p>什么是全卷积网络？如何将紧密层转变为卷积层？</p>
<blockquote>
<p>FCN: 完全由卷积层和池化层构成。在目标检测和语义分割领域很有用，因为只需要扫描图片一次。</p>
<p>将紧密层替换为核大小等于层输入大小的卷积层，使用valid padding，激活函数可以不用变。</p>
</blockquote>
<p>语义分割的主要技术难点是什么？</p>
<blockquote>
<p>在流经CNN网络过程中，一些空间信息会消失</p>
</blockquote>
</li>
<li><p>从零搭建你的CNN，并在MNIST上达到尽可能高的准确率。</p>
</li>
<li><p>使用迁移学习来做大图片分类，经过下面步骤：</p>
<p>a. 创建每个类至少有100张图片的训练集。例如，你可以用自己的图片基于地点来分类（沙滩、山、城市，等等），或者使用现成的数据集（比如从TensorFlow Datasets）。</p>
<p>b. 将其分成训练集、验证集、训练集。</p>
<p>c. 搭建输入管道，包括必要的预处理操作，最好加上数据增强。</p>
<p>d. 在这个数据集上，微调预训练模型。</p>
</li>
<li><p>尝试下TensorFlow的<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fstyletuto" target="_blank" rel="noopener">风格迁移教程</a>。用深度学习生成艺术作品很有趣。</p>
</li>
</ol>
<h2 id="第15章-使用RNN和CNN处理序列"><a href="#第15章-使用RNN和CNN处理序列" class="headerlink" title="第15章 使用RNN和CNN处理序列"></a>第15章 使用RNN和CNN处理序列</h2><p>循环神经网络，一类可以预测未来的网络（当然，是到某一点为止）</p>
<p>RNN面对的两大难点：</p>
<ul>
<li>不稳定梯度（换句话说，在第11章中讨论的梯度消失/爆炸），可以使用多种方法缓解，包括循环dropout和循环层归一化。</li>
<li>有限的短期记忆，可以通过LSTM 和 GRU 单元延长。</li>
</ul>
<h3 id="循环神经元和层"><a href="#循环神经元和层" class="headerlink" title="循环神经元和层"></a>循环神经元和层</h3><p>最简单的 RNN，由一个神经元接收输入，产生一个输出，并将输出发送回自己。 在每个时间步<code>t</code>（也称为一个帧），这个循环神经元接收输入x(t)以及它自己的前一时间步长 y(t-1) 的输出。 因为第一个时间步骤没有上一次的输出，所以是0。可以用时间轴来表示这个微小的网络。 这被称为随时间展开网络。</p>
<p> 循环神经网络（左），随时间展开网络（右）</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e945414fcaeeed67.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>一层循环神经元（左），及其随时间展开（右）</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-79c6bd0d2b869c73.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>每个循环神经元有两组权重：一组用于输入x(t)，另一组用于前一时间步长 y(t-1) 的输出。 </p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b26a1770e6dc75da.png?imageMogr2/auto-orient/strip|imageView2/2/w/1046/format/webp" alt="img"></p>
<h3 id="记忆单元"><a href="#记忆单元" class="headerlink" title="记忆单元"></a>记忆单元</h3><p>由于时间<code>t</code>的循环神经元的输出，是由所有先前时间步骤计算出来的的函数，你可以说它有一种记忆形式。神经网络的一部分，保留一些跨越时间步长的状态，称为存储单元（或简称为单元）。单个循环神经元或循环神经元层是非常基本的单元，只能学习短期规律。</p>
<p>一般情况下，时间步<code>t</code>的单元状态，记为 h(t)（<code>h</code>代表“隐藏”），是该时间步的某些输入和前一时间步状态的函数：h(t) = f(h(t–1), x(t))。 其在时间步<code>t</code>的输出，表示为 y(t)，也和前一状态和当前输入的函数有关。 我们已经讨论过的基本单元，输出等于单元状态，但是在更复杂的单元中并不总是如此。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-860eda4472257180.png?imageMogr2/auto-orient/strip|imageView2/2/w/1095/format/webp" alt="img"></p>
<p>序列到序列（左上），序列到矢量（右上），矢量到序列（左下），延迟序列到序列（右下）</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-22b08969517e84c2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<blockquote>
<p>一个序列到矢量的网络，称为编码器，后面跟着一个称为解码器的矢量到序列的网络。 可以用于将句子从一种语言翻译成另一种语言。 给网络输入一种语言的一句话，编码器会把这个句子转换成单一的矢量表征，然后解码器将这个矢量解码成另一种语言的句子。 这种称为<strong>编码器 - 解码器</strong>的两步模型，比用单个序列到序列的 RNN实时地进行翻译要好得多，<strong>因为句子的最后一个单词可以影响翻译的第一句话，所以需要等到听完整个句子才能翻译。</strong></p>
</blockquote>
<h3 id="训练RNN"><a href="#训练RNN" class="headerlink" title="训练RNN"></a>训练RNN</h3><p>训练RNN诀窍是在时间上展开，然后只要使用常规反向传播。 这个策略被称为<strong>时间上的反向传播（BPTT）</strong>。</p>
<h3 id="预测时间序列"><a href="#预测时间序列" class="headerlink" title="预测时间序列"></a>预测时间序列</h3><p>研究网站每小时的活跃用户数，或是所在城市的每日气温，或公司的财务状况，用多种指标做季度衡量。在这些任务中，数据都是一个序列，每步有一个或多个值，被称为<strong>时间序列</strong>。在前两个任务中，每个时间步只有一个值，它们是<strong>单变量时间序列</strong>。在财务状况的任务中，每个时间步有多个值（利润、欠账，等等），所以是<strong>多变量时间序列</strong>。</p>
<ul>
<li>典型的任务是预测未来值，称为“预测”。</li>
<li>另一个任务是填空：预测（或“后测”）过去的缺失值，这被称为“填充”。</li>
</ul>
<blockquote>
<p>当处理时间序列时（和其它类型的时间序列），输入特征通常用3D数组来表示，其形状是 [批次大小, 时间步数, 维度]，对于单变量时间序列，其维度是1，多变量时间序列的维度是其维度数。</p>
</blockquote>
<h3 id="基线模型"><a href="#基线模型" class="headerlink" title="基线模型"></a>基线模型</h3><p>使用RNN之前，最好有基线指标，否则做出来的模型可能比基线模型还糟。例如，最简单的方法，是预测每个序列的最后一个值。这个方法被称为<strong>朴素预测</strong>，有时很难被超越。</p>
<h3 id="实现一个简单地RNN"><a href="#实现一个简单地RNN" class="headerlink" title="实现一个简单地RNN"></a>实现一个简单地RNN</h3><p>不用指定输入序列的长度（和之前的模型不同），因为循环神经网络可以处理任意的时间步（这就是为什么将第一个输入维度设为<code>None</code>）</p>
<blockquote>
<p>趋势和季节性</p>
<p>还有其它预测时间序列的模型，比如权重移动平均模型或自动回归集成移动平均（ARIMA）模型。某些模型需要先移出趋势和季节性。例如，如果要研究网站的活跃用户数，它每月会增长10%，就需要去掉这个趋势。训练好模型之后，在做预测时，你可以将趋势加回来做最终的预测。相似的，如果要预测防晒霜的每月销量，会观察到明显的季节性：每年夏天卖的多。需要将季节性从时间序列去除，比如计算每个时间步和前一年的差值（这个方法被称为差分）。然后，当训练好模型，做预测时，可以将季节性加回来，来得到最终结果。</p>
<p>使用RNN时，一般不需要做这些，但在有些任务中可以提高性能，因为模型不是非要学习这些趋势或季节性。</p>
</blockquote>
<h3 id="深度RNN"><a href="#深度RNN" class="headerlink" title="深度RNN"></a>深度RNN</h3><p>将多个神经元的层堆起来，就形成了深度RNN。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-0a727314de2f6f56.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="处理长序列"><a href="#处理长序列" class="headerlink" title="处理长序列"></a>处理长序列</h3><p>在训练长序列的 RNN 模型时，必须运行许多时间步，展开的RNN变成了一个很深的网络。正如任何深度神经网络一样，它面临<strong>不稳定梯度问题</strong>，使训练无法停止，或训练不稳定。另外，当RNN处理长序列时，<strong>RNN会逐渐忘掉序列的第一个输入</strong>。</p>
<h4 id="应对不稳定梯度"><a href="#应对不稳定梯度" class="headerlink" title="应对不稳定梯度"></a>应对不稳定梯度</h4><p>好的参数初始化方式，更快的优化器，dropoutd都可以应对RNN的梯度不稳定。但是非饱和激活函数（如 ReLU）的帮助不大；事实上，它会导致RNN更加不稳定。</p>
<blockquote>
<p>假设梯度下降更新了权重，可令第一个时间步的输出提高。因为每个时间步使用的权重相同，第二个时间步的输出也会提高，这样就会导致输出爆炸 —— 不饱和激活函数不能阻止这个问题。要降低爆炸风险，可以<strong>使用更小的学习率</strong>，更简单的方法是<strong>使用饱和激活函数</strong>，比如双曲正切函数（所以tanh是默认选项）。</p>
</blockquote>
<p>批归一化也没什么帮助。不能在时间步骤之间使用批归一化，只能在循环层之间使用。</p>
<p><strong>层归一化，由Jimmy Lei Ba等人在2016年提出：跟批归一化很像，但不是在批次维度上做归一化，而是在特征维度上归一化。</strong>这么做的一个优势是可以独立对每个实例，实时计算所需的统计量。训练和测试中的行为是一致的（这点和BN相反），且不需要使用指数移动平均来估计训练集中所有实例的特征统计。和BN一样，层归一化会学习每个输入的比例和偏移参数。<strong>在RNN中，层归一化通常用在输入和隐藏态的线型组合之后。</strong></p>
<h4 id="处理短期记忆问题"><a href="#处理短期记忆问题" class="headerlink" title="处理短期记忆问题"></a>处理短期记忆问题</h4><p>由于数据在RNN中流动时会经历转换，每个时间步都损失了一定信息。一定时间后，第一个输入实际上会在 RNN 的状态中消失。</p>
<p><strong>长短时记忆神经单元 LSTM：</strong></p>
<p>长短时记忆单元在 1997 年<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgoo.gl%2Fj39AGv" target="_blank" rel="noopener">由 Sepp Hochreiter 和 Jürgen Schmidhuber 首次提出</a>，并在接下来的几年内经过 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fgraves" target="_blank" rel="noopener">Alex Graves</a>、<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F94" target="_blank" rel="noopener">Haşim Sak</a>、<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F95" target="_blank" rel="noopener">Wojciech Zaremba</a> 等人的改进，逐渐完善。如果把 LSTM 单元看作一个黑盒，可以将其当做基本单元一样来使用，但 LSTM 单元比基本单元性能更好：收敛更快，能够感知数据的长时依赖。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-a333026f0dd537b5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>可以认为 h(t) 是短期记忆状态，c(t) 是长期记忆状态。</p>
<ul>
<li>输出 g(t)的层是主要层。它的常规任务是分析当前的输入 x(t) 和前一时刻的短时状态 h(t-1)。基本单元中与这种结构一样，直接输出了 h(t)   和 y(t) 。而LSTM 单元中的该层的输出不会直接出去，将最重要的部分保存在长期状态中（其余部分丢掉）。</li>
<li>其它三个全连接层被是门控制器（gate controller）。其采用 Logistic 作为激活函数，输出范围在 0 到 1 之间。可以看到，这三个层的输出提供给了逐元素乘法操作，当输入为 0 时门关闭，输出为 1 时门打开。具体讲：</li>
<li>遗忘门（由 f(t) 控制）决定哪些长期记忆需要被删除；</li>
<li>输入门（由 i(t) 控制） 决定哪部分 g(t) 应该被添加到长时状态中。</li>
<li>输出门（由 o(t) 控制）决定长时状态的哪些部分要读取和输出为 h(t) 和y(t)。</li>
</ul>
<p>LSTM 单元能够学习识别重要输入（输入门的作用），存储进长时状态，并保存必要的时间（遗忘门功能），并在需要时提取出来。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-33df138d7fe796c5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1040/format/webp" alt="img"></p>
<h4 id="LSTM的变体"><a href="#LSTM的变体" class="headerlink" title="LSTM的变体"></a>LSTM的变体</h4><h5 id="窥孔连接"><a href="#窥孔连接" class="headerlink" title="窥孔连接"></a>窥孔连接</h5><p>在基本 LSTM 单元中，门控制器只能观察当前输入 x(t) 和前一时刻的短时状态 h(t-1)。不妨让各个门控制器窥视一下长时状态，获取一些上下文信息。</p>
<p> Felix Gers 和 Jürgen Schmidhuber 在 2000 年提出了一个 LSTM 的变体，带有叫做窥孔连接的额外连接：把前一时刻的长时状态 c(t-1) 输入给遗忘门和输入门，当前时刻的长时状态c(t)输入给输出门。这么做时常可以提高性能，但不一定每次都能有效，也没有清晰的规律显示哪种任务适合添加窥孔连接。</p>
<h5 id="GRU-单元"><a href="#GRU-单元" class="headerlink" title="GRU 单元"></a>GRU 单元</h5><p><img src="https://upload-images.jianshu.io/upload_images/7178691-b3d78efe2539d55c.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>门控循环单元（GRU）由Kyunghyun Cho于2014年提出，引入了编码器-解码器网络。GRU单元是 LSTM 单元的简化版本，能实现同样的性能。简化主要在一下几个方面：</p>
<ul>
<li>长时状态和短时状态合并为一个矢量 h(t)。</li>
<li>用一个门控制器z(t)控制遗忘门和输入门。如果门控制器输出 1，则遗忘门打开（=1），输入门关闭（1 - 1 = 0）。如果输出0，则相反。换句话说，如果当有记忆要存储，那么就必须先在其存储位置删掉该处记忆。这构成了 LSTM 本身的常见变体。</li>
<li>GRU 单元取消了输出门，每个时间步输出全态矢量。但是，增加了一个控制门 r(t) 来控制前一状态的哪些部分呈现给主层g(t)。</li>
</ul>
<h3 id="使用1D卷积层处理序列"><a href="#使用1D卷积层处理序列" class="headerlink" title="使用1D卷积层处理序列"></a>使用1D卷积层处理序列</h3><p>对于音频、长时间序列或长序列，学习长时模式就很困难。应对的方法之一，是使用缩短输入序列，例如使用1D卷积层。</p>
<h3 id="WaveNet"><a href="#WaveNet" class="headerlink" title="WaveNet"></a>WaveNet</h3><p>WaveNet架构将1D卷积层叠起来，每一层膨胀率（如何将每个神经元的输入分开）变为2倍：第一个卷积层一次只观察两个时间步，下一层观察四个时间步（感受野是4个时间步的长度），下一层观察八个时间步，以此类推。用这种方式，底下的层学习短时模式，上面的层学习长时模式。得益于翻倍的膨胀率，这个网络可以非常高效地处理极长的序列。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-93e236002a0fa2e2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="练习-5"><a href="#练习-5" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>你能说出序列到序列RNN 的几个应用吗？序列到矢量的应用？矢量到序列的应用？</p>
<blockquote>
<p>序列到序列RNN：可以预测天气，股票信息。</p>
<p>序列到矢量RNN：判断音乐的流派</p>
<p>矢量到序列RNN：通过几个参数创建一段音乐</p>
</blockquote>
</li>
<li><p>RNN层的输入要有多少维？每一维表示什么？输出呢？</p>
<blockquote>
<p>RNN需要有三维的输入：batch size x time steps x number of input feature</p>
</blockquote>
</li>
<li><p>如果搭建深度序列到序列RNN，哪些RNN层要设置<code>return_sequences=True</code>？序列到矢量RNN又如何？</p>
<blockquote>
<p>深度序列到序列RNN：所有的RNN层都需要设置<code>return_sequences=True</code></p>
<p>sequence-to-vector RNN：除了顶层的所有RNN层都需要设置<code>return_sequences=True</code></p>
</blockquote>
</li>
<li><p>假如有一个每日单变量时间序列，想预测接下来的七天。要使用什么RNN架构？</p>
<blockquote>
<p>序列到矢量RNN：除了顶层都设置 <code>return_sequences=True</code> ，输出层使用七个神经元.</p>
</blockquote>
</li>
<li><p>训练RNN的困难是什么？如何应对？</p>
<blockquote>
<p>梯度不稳定：使用小学习率，梯度裁剪，层归一化，dropout</p>
<p>短期记忆：使用LSTM<code>or</code>GRU层</p>
</blockquote>
</li>
<li><p>画出LSTM单元的架构图？</p>
<blockquote>
<p>​</p>
</blockquote>
</li>
<li><p>为什么在RNN中使用1D卷积层？</p>
<blockquote>
<p>RNN层是串行的，为了预测t时间之后的结果，需要先计算早些时候结果，使得它不能并行计算，</p>
<p>另一方面，一维卷积层不需要之前结果的记忆，可以根据输入中某一窗口的数值计算得到任意时刻的输出。</p>
<p>再者，1D卷积层不是循环的（recurrent），梯度不稳定问题将大大改善</p>
<p>在RNN网络中使用一层或者多层1D卷积层预处理输入数据，可以downsampling，帮助RNN探测到long-term patterns</p>
</blockquote>
</li>
<li><p>哪种神经网络架构可以用来分类视频？</p>
<blockquote>
<p>对于音频、长时间序列或长序列，学习长时模式就很困难。应对的方法之一，使用1D卷积层缩短输入序列.</p>
</blockquote>
</li>
<li><p>为SketchRNN数据集（TensorFlow Datasets中有），训练一个分类模型。</p>
</li>
<li><p>下载<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fbach" target="_blank" rel="noopener">Bach chorales</a>数据集，并解压。它含有382首巴赫作曲的赞美歌。每首的长度是100到640时间步，每个时间步包含4个整数，每个整数对应一个钢琴音符索引（除了0，表示没有音符）。训练一个可以预测下一个时间步（四个音符）的模型，循环、卷积、或混合架构。然后使用这个模型来生成类似巴赫的音乐，每个时间一个音符：可以给模型一首赞美歌的开头，然后让其预测接下来的时间步，然后将输出加到输入上，再让模型继续预测。或者查看<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fcoconet" target="_blank" rel="noopener">Google的 Coconet 模型</a>，它是Google来做巴赫曲子的。</p>
</li>
</ol>
<h2 id="第16章-使用RNN和注意力机制进行自然语言处理"><a href="#第16章-使用RNN和注意力机制进行自然语言处理" class="headerlink" title="第16章 使用RNN和注意力机制进行自然语言处理"></a>第16章 使用RNN和注意力机制进行自然语言处理</h2><h3 id="有状态RNN"><a href="#有状态RNN" class="headerlink" title="有状态RNN"></a>有状态RNN</h3><p>无状态RNN：在每个训练迭代中，模型从全是0的隐藏状态开始训练，然后在每个时间步更新其状态，在最后一个时间步，隐藏态就被丢掉，以后再也不用了。如果让RNN保留这个状态，供下一个训练批次使用如何呢？这么做的话，尽管反向传播只在短序列传播，模型也可以学到长时规律。这被称为有状态RNN。</p>
<h3 id="集束搜索"><a href="#集束搜索" class="headerlink" title="集束搜索"></a>集束搜索</h3><p>它跟踪k个最大概率的句子列表，在每个解码器步骤延长一个词，然后再关注其中k个最大概率的句子。参数k被称为集束宽度。</p>
<h3 id="视觉注意力"><a href="#视觉注意力" class="headerlink" title="视觉注意力"></a>视觉注意力</h3><p>最先用途之一是利用视觉注意力生成图片标题：卷积神经网络首先处理图片，生成一些特征映射，然后用带有注意力机制的解码器RNN来生成标题，每次生成一个词。在每个解码器时间步（每个词），解码器使用注意力模型聚焦于图片的一部分。</p>
<h3 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h3><p>多头注意力基于缩放点积注意力层（Scaled Dot-Product Attention），</p>
<blockquote>
<p>假设编码器分析输入句子“They played chess”，编码器分析出“They”是主语，“played”是动词，然后用词的表征编码这些信息。假设解码器已经翻译了主语，接下来要翻译动词。要这么做的话，它需要从输入句子取动词。这有点像查询字典：编码器创建了字典{“subject”: “They”, “verb”: “played”, …}，解码器想查找键“verb”对应的值是什么。但是，模型没有离散的token来表示键（比如“subject” 或 “verb”）；它只有这些（训练中学到的）信息的矢量化表征所以用来查询的键，不会完美对应前面字典中的键。解决的方法是计算查询词和键的相似度，然后用softmax函数计算概率权重。如果表示动词的键和查询词很相似，则键的权重会接近于1。然后模型可以计算对应值的加权和，如果“verb”键的权重接近1，则加权和会接近于词“played”的表征。</p>
</blockquote>
<p>缩放点积注意力：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-da0506216d22820b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1124/format/webp" alt="img"></p>
<h3 id="练习-6"><a href="#练习-6" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>有状态RNN和无状态RNN相比，优点和缺点是什么？</p>
<blockquote>
<p>无状态RNN只能找到不大于训练窗口长度的pattern</p>
<p>有状态RNN可以找到longer-term patterns，但是有状态RNN中，相邻批次的数据可能是不独立的，identically distributed</p>
</blockquote>
</li>
<li><p>为什么使用编码器-解码器RNN，而不是普通的序列到序列RNN，来做自动翻译？</p>
<blockquote>
<p>单独训练单词，自动翻译的结果不会很好。</p>
<p>普通的序列到序列RNN在读入第一个单词就开始翻译，但是编码器-解码器RNN会读完整个句子再翻译</p>
</blockquote>
</li>
<li><p>如何处理长度可变的输入序列？长度可变的输出序列怎么处理？</p>
<blockquote>
<p>padding the shorter sequences, 使用遮挡忽略padding token，这样每一批次中所有的序列可以由相同的长度。之后tf.keras中嵌套张量可以用来表示长度可变的序列。</p>
<p>如果输出序列的长度可以提前预知（比如和输入的长度相同），可以直接根据长度忽略掉序列长度后的token，计算损失函数；如果输出序列的长度未知，可以输出一个表示序列结束的token</p>
</blockquote>
</li>
<li><p>什么是集束搜索，为什么要用集束搜索？可以用什么工具实现集束搜索？</p>
<blockquote>
<p>beam search: 提高编码器-解码器模型的表现，算法跟踪k个最大概率的句子列表，在每个解码器步骤延长一个词，然后再关注其中k个最大概率的句子，k称为集束宽度。该算法可以并行。</p>
<p>Tensorflow addons可以用来实现集束搜索。</p>
</blockquote>
</li>
<li><p>什么是注意力机制？用处是什么？</p>
<blockquote>
<p>注意力机制最早用于编码器-解码器模型，用于长输入，可以让解码器在每个时间步关注特别的（被编码器编码的）词。</p>
</blockquote>
</li>
<li><p>Transformer架构中最重要的层是什么？它的目的是什么？</p>
</li>
<li><p>什么时候需要使用采样softmax？</p>
</li>
<li><p>Hochreiter 和 Schmidhuber 在关于LSTM的<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F93" target="_blank" rel="noopener">论文</a>中使用了嵌入Reber语法。这是一种人工的语法，用来生成字符串，比如 “BPBTSXXVPSEPE”。查看Jenny Orr对它的<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F108" target="_blank" rel="noopener">介绍</a>。选择一个嵌入Reber语法（比如Jenny Orr的论文中展示的），然后训练一个RNN来判断字符串是否符合语法。你需要先写一个函数来生成训练批次，其中50%符合语法，50%不符合语法。</p>
</li>
<li><p>训练一个编码器-解码器模型，它可以将日期字符串从一个格式变为另一个格式（例如，从“April 22, 2019”变为“2019-04-22”）。</p>
</li>
<li><p>阅读TensorFlow的<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fnmttuto" target="_blank" rel="noopener">《Neural Machine Translation with Attention tutorial》</a>。</p>
</li>
<li><p>使用一个最近的语言模型（比如，BERT），来生成一段更具信服力的莎士比亚文字。</p>
</li>
</ol>
<h2 id="第17章-使用自编码器和GAN做表征学习和生成式学习"><a href="#第17章-使用自编码器和GAN做表征学习和生成式学习" class="headerlink" title="第17章 使用自编码器和GAN做表征学习和生成式学习"></a>第17章 使用自编码器和GAN做表征学习和生成式学习</h2><p>自编码器是能够在无监督（即，训练集是未标记）的情况下学习输入数据的紧密表征（叫做潜在表征或编码）的人工神经网络。这些编码通常具有比输入数据低得多的维度，使得自编码器对降维有用。自编码器还可以作为强大的特征检测器，它们可以用于无监督的深度神经网络预训练。一些自编码器是生成式模型：他们能够随机生成与训练数据非常相似的新数据。</p>
<p>对抗生成网络（GAN）生成的人脸可以非常逼真，甚至让人认为他们是真实存在的人。</p>
<p>自编码器和GAN都是无监督的，都可以学习紧密表征，都可以用作生成模型，有许多相似的应用，但原理非常不同：</p>
<blockquote>
<p>自编码器是通过学习，将输入复制到输出。听起来很简单，但内部结构会使其相当困难。例如，可以限制潜在表征的大小，或者可以给输入添加噪音，训练模型恢复原始输入。这些限制组织自编码器直接将输入复制到输出，可以强迫模型学习数据的高效表征。总而言之，编码是自编码器在一些限制下学习恒等函数的副产品。</p>
<p>GAN包括两个神经网络：一个生成器尝试生成和训练数据相似的数据，一个判别器来区分真实数据和假数据。特别之处在于，生成器和判别器在训练过程中彼此竞争：生成器就像一个制造伪钞的罪犯，而判别器就像警察一样，要把真钱挑出来。对抗训练（训练竞争神经网络），被认为是近几年的一大进展。在2016年，Yann LeCun甚至说GAN是过去10年机器学习领域最有趣的发明。</p>
</blockquote>
<h3 id="自编码器"><a href="#自编码器" class="headerlink" title="自编码器"></a>自编码器</h3><p>自编码器通常具有与多层感知器相同的体系结构，但输出层中的神经元数量必须等于输入数量。由于自编码器试图重构输入，所以输出通常被称为重建，并且损失函数包含重建损失，当重建与输入不同时，重建损失会对模型进行惩罚。由于内部表征具有比输入数据更低的维度（它是 2D 而不是 3D），所以自编码器被认为是不完整的。 不完整的自编码器不能简单地将其输入复制到编码，但它必须找到一种方法来输出其输入的副本。 它被迫学习输入数据中最重要的特征（并删除不重要的特征）。</p>
<p>自编码器不限于紧密网络：还有卷积自编码器和循环自编码器。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-96e89d75c6e86056.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h3 id="栈式自编码器"><a href="#栈式自编码器" class="headerlink" title="栈式自编码器"></a>栈式自编码器</h3><p>自编码器可以有多个隐藏层。 在这种情况下，它们被称为栈式自编码器（或深度自编码器）。栈式自编码器的架构以中央隐藏层（编码层）为中心通常是对称的。 </p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-97d3ae02870c17ac.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="使用栈式自编码器做无监督预训练"><a href="#使用栈式自编码器做无监督预训练" class="headerlink" title="使用栈式自编码器做无监督预训练"></a>使用栈式自编码器做无监督预训练</h4><p>用所有训练数据训练自编码器，然后用编码器层创建新的神经网络</p>
<h4 id="关联权重"><a href="#关联权重" class="headerlink" title="关联权重"></a>关联权重</h4><p>将解码器层的权重与编码器层的权重相关联。 这样减半了模型中的权重数量，加快了训练速度，并限制了过度拟合的风险。</p>
<h4 id="一次训练一个自编码器"><a href="#一次训练一个自编码器" class="headerlink" title="一次训练一个自编码器"></a>一次训练一个自编码器</h4><p>不是一次完成整个栈式自编码器的训练，而是一次训练一个浅自编码器，然后将所有这些自编码器堆叠到一个栈式自编码器（因此名称）中，通常要快得多，</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-95d0229917d60063.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>现在的一大趋势是Geoffrey Hinton等人在2006年发现的，靠这种贪婪层级方法，可以用无监督方式训练神经网络。他们还使用了受限玻尔兹曼机（RBM，见附录E）。但在2007年，Yoshua Bengio发现只用自编码器也可以达到不错的效果。</p>
<h3 id="卷积自编码器"><a href="#卷积自编码器" class="headerlink" title="卷积自编码器"></a>卷积自编码器</h3><p>对于图片任务，卷积神经网络比紧密网络的效果更好。所以如果想用自编码器来处理图片的话（例如，无监督预训练或降维），需要搭建一个卷积自编码器。编码器是一个包含卷积层和池化层的常规CNN。</p>
<h3 id="循环自编码器"><a href="#循环自编码器" class="headerlink" title="循环自编码器"></a>循环自编码器</h3><p>如果想用自编码器处理序列，比如对时间序列或文本无监督学习和降维，则循环神经网络要优于紧密网络。搭建循环自编码器很简单：编码器是一个序列到矢量的RNN，而解码器是矢量到序列的RNN。</p>
<h3 id="学习方法"><a href="#学习方法" class="headerlink" title="学习方法"></a>学习方法</h3><p>为了让自编码学习特征，我们限制了编码层的大小（使它处于不完整的状态）。还可以使用许多其他的限制方法，可以让编码层和输入层一样大，甚至更大，得到一个过完成的自编码器。</p>
<h4 id="降噪自编码"><a href="#降噪自编码" class="headerlink" title="降噪自编码"></a>降噪自编码</h4><p>为其输入添加噪声，对其进行训练以恢复原始的无噪声输入。 噪声可以是添加到输入的纯高斯噪声，或者可以随机关闭输入，就像 dropout。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-870922646a65a746.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<h4 id="稀疏自编码器"><a href="#稀疏自编码器" class="headerlink" title="稀疏自编码器"></a>稀疏自编码器</h4><p>特征提取的另一种约束是稀疏性：通过向损失函数添加适当的项，让自编码器减少编码层中活动神经元的数量。</p>
<p> Kullback-Leibler 散度，具有比均方误差更强的梯度，</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b6809b315bb6dba7.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>给定两个离散的概率分布<code>P</code>和<code>Q</code>，这些分布之间的 KL 散度，记为 DKL(P // Q)</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-a96113128470474a.png?imageMogr2/auto-orient/strip|imageView2/2/w/816/format/webp" alt="img"></p>
<h3 id="变分自编码器（VAE）"><a href="#变分自编码器（VAE）" class="headerlink" title="变分自编码器（VAE）"></a>变分自编码器（VAE）</h3><p>特点：</p>
<ol>
<li>它们是概率自编码器，意味着即使在训练之后，它们的输出部分也是偶然确定的（相对于仅在训练过程中使用随机性的自编码器的去噪）。</li>
<li>它们是生成自编码器，这意味着它们可以生成看起来像从训练集中采样的新实例。</li>
</ol>
<p>与 RBM （受限玻尔兹曼机）非常相似。编码器产生平均编码<code>μ</code>和标准差<code>σ</code>。 然后从平均值<code>μ</code>和标准差<code>σ</code>的高斯分布随机采样实际编码。 之后，解码器正常解码采样的编码。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-8103b55a6c0b39cb.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>损失函数：重建损失+潜在的损失</p>
<p>潜在损失：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9e0614d9745baf00.png?imageMogr2/auto-orient/strip|imageView2/2/w/928/format/webp" alt="img"></p>
<p>n是编码维度，μi 和 σi是编码的第ith个成分的平均值和标准差。矢量u和σ是编码器的输出。</p>
<p>一种常见的变体是训练编码器输出<code>γ= log(σ^2)</code>而不是<code>σ</code>。 这个方法的计算更稳定，且可以加速训练。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-fd8844d61cc65f10.png?imageMogr2/auto-orient/strip|imageView2/2/w/986/format/webp" alt="img"></p>
<h3 id="对抗生成网络（GAN）"><a href="#对抗生成网络（GAN）" class="headerlink" title="对抗生成网络（GAN）"></a>对抗生成网络（GAN）</h3><p>Ian Goodfellow在2014年提出，本质很简单：让神经网络互相竞争，让其在竞争中进步。</p>
<ul>
<li><p>生成器</p>
<p>使用随机分布作为输入（通常为高斯分布），并输出一些数据，比如图片。可以将随机输入作为生成文件的潜在表征（即，编码）。生成器的作用和变分自编码器中的解码器差不多，可以用同样的方式生成图片（只要输入一些高斯噪音，就能输出全新的图片）。但是，生成器的训练过程很不一样。</p>
</li>
</ul>
<ul>
<li><p>判别器</p>
<p>从训练集取出一张图片，判断图片是真是假。</p>
</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-e3e9a45c0fefb30e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>每次训练迭代分成两个阶段：</p>
<ol>
<li><p>第一个阶段，训练判别器。</p>
<p>从训练集取样一批真实图片，数量与假图片相同。假图片的标签设为0，真图片的标签设为1，判别器用这个有标签的批次训练一步，使用二元交叉熵损失。反向传播在这一阶段只优化判别器的权重。</p>
</li>
<li><p>第二个阶段，训练生成器。</p>
<p>首先用生成器产生另一个批次的假图片，再用判别器来判断图片是真是假。这一次不添加真图片，但所有标签都设为1（真）：换句话说，我们想让生成器产生可以让判别器信以为真的图片。判别器的权重在这一步是冷冻的，所以反向传播只影响生成器。</p>
</li>
</ol>
<h4 id="训练GAN的难点"><a href="#训练GAN的难点" class="headerlink" title="训练GAN的难点"></a>训练GAN的难点</h4><p>在训练中，生成器和判别器不断试图超越对方，这是一个零和博弈。随着训练的进行，可能会达成博弈学家称为纳什均衡的状态：每个选手都不改变策略，并认为对方也不会改变策略。不同的初始状态和动力学会导致不同的均衡。</p>
<p>论文作者证明，GAN只能达到一种均衡状态：生成器产生完美的真实图片，同时让判别器来判断（50%为真，50%为假）。</p>
<p>最大的困难是模式坍塌：生成器的输出逐渐变得不那么丰富。为什么会这样？假设生成器产生的鞋子图片比其它类的图片更让人信服，假鞋子图片就会更多的欺骗判别器，就会导致生成更多的鞋子图片。逐渐的，生成器会忘掉如何生成其它类的图片。同时，判别器唯一能看到的就是鞋子图片，所以判别器也会忘掉如何判断其它类的图片。GAN会逐渐在一些类上循环，从而对哪一类都不擅长。</p>
<p>GAN会对超参数特别敏感：微调超参数会特别花费时间。</p>
<h3 id="深度卷积GAN（DCGAN）"><a href="#深度卷积GAN（DCGAN）" class="headerlink" title="深度卷积GAN（DCGAN）"></a>深度卷积GAN（DCGAN）</h3><p>搭建稳定卷积GAN的建议如下：</p>
<ul>
<li>（判别器中）用卷积步长（strided convolutions）、（生成器中）用转置卷积，替换池化层。</li>
<li>生成器和判别器都使用批归一化，除了生成器的输出层和判别器的输入层。</li>
<li>去除深层架构中的全连接隐藏层。</li>
<li>生成器的输出层使用tanh激活，其它层使用ReLU激活。</li>
<li>判别器的所有层使用leaky ReLU激活。</li>
</ul>
<h3 id="条件GAN（CGAN）"><a href="#条件GAN（CGAN）" class="headerlink" title="条件GAN（CGAN）"></a>条件GAN（CGAN）</h3><p>如果将图片的类作为另一个输入，输入给生成器和判别器，它们都能学到每个类的样子，你就可以控制生成器产生图片的类。这被称为条件GAN（CGAN）。</p>
<h3 id="方法：用于提高输出的散度（避免模式坍塌），使训练更稳定："><a href="#方法：用于提高输出的散度（避免模式坍塌），使训练更稳定：" class="headerlink" title="方法：用于提高输出的散度（避免模式坍塌），使训练更稳定："></a>方法：用于提高输出的散度（避免模式坍塌），使训练更稳定：</h3><h4 id="GAN的渐进式变大"><a href="#GAN的渐进式变大" class="headerlink" title="GAN的渐进式变大"></a>GAN的渐进式变大</h4><p>建议在训练时，先从生成小图片开始，然后逐步给生成器和判别器添加卷积层，生成越来越大的图片（4 × 4, 8 × 8, 16 × 16, …, 512 × 512, 1,024 × 1,024）。这个方法和栈式自编码器的贪婪层级训练很像。余下的层添加到生成器的末端和判别器的前端，之前训练好的层仍然可训练。</p>
<h4 id="小批次标准差层"><a href="#小批次标准差层" class="headerlink" title="小批次标准差层"></a>小批次标准差层</h4><p>添加在判别器的靠近末端的位置。对于输入的每个位置，计算批次（<code>S = tf.math.reduce_std(inputs, axis=[0, -1])</code>）中，所有通道所有实例的标准差。接着，这些标准差对所有点做平均，得到一个单值（<code>v = tf.reduce_mean(S)</code>）。最后，给批次中的每个实例添加一个额外的特征映射，填入计算得到的单值（<code>tf.concat([inputs, tf.fill([batch_size, height, width, 1], v)], axis=-1)</code>）。如果生成器产生的图片没有什么偏差，则判别器的特征映射的标准差会特别小。有了这个层，判别器就可以做出判断。可以让生成器产生高散度的输出，降低模式坍塌的风险。</p>
<h4 id="相等的学习率"><a href="#相等的学习率" class="headerlink" title="相等的学习率"></a>相等的学习率</h4><p>使用一个简单的高斯分布（平均值为0，标准差为1）初始化权重，而不使用He初始化。但是，权重在运行时（即，每次执行层）会变小：会除以<img src="https://math.jianshu.com/math?formula=%5Csqrt%7B2%2Fninputs%7D" alt="\sqrt{2/ninputs}">，ninputs是层的输入数。使用这个方法可以显著提升GAN使用RMSProp、Adam和其它适应梯度优化器时的性能。事实上，这些优化器用估计标准差归一化了梯度更新，所以有较大动态范围的参数需要更长时间训练，而较小动态范围的参数可能更新过快，会导致不稳定。通过缩放模型的部分参数，可以保证参数的动态范围在训练过程中一致，可以用相同的速度学习。这样既加速了训练，也做到了稳定。</p>
<h4 id="像素级归一化层"><a href="#像素级归一化层" class="headerlink" title="像素级归一化层"></a>像素级归一化层</h4><p>生成器的每个卷积层之后添加。它能归一化每个激活函数，基于相同图片相同位置的所有激活，而且跨通道（除以平均激活平方的平方根）。在TensorFlow的代码中，这是<code>inputs / tf.sqrt(tf.reduce_mean(tf.square(X), axis=-1, keepdims=True) + 1e-8)</code>（平滑项1e-8用于避免零除）。这种方法可以避免生成器和判别器的过分竞争导致的激活爆炸。</p>
<h3 id="StyleGAN"><a href="#StyleGAN" class="headerlink" title="StyleGAN"></a>StyleGAN</h3><p>Nvidia团队在2018年的一篇<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2Fstylegan" target="_blank" rel="noopener">论文</a>中提出了高性能的高清图片生成架构，StyleGAN。作者在生成器中使用了风格迁移方法，使生成的图片和训练图片在每个层次，都有相同的局部结构，极大提升了图片的质量。判别器和损失函数没有变动，只修改了生成器。StyleGAN包含两个网络</p>
<ol>
<li><p>映射网络</p>
<p>一个八层的MLP，将潜在表征<code>z</code>（即，编码）映射为矢量<code>w</code>。矢量然后传给仿射变换，输出许多矢量。这些矢量在不同级别控制着生成图片的风格，从细粒度纹理（比如，头发颜色）到高级特征（比如，成人或孩子）。总而言之，映射网络将编码变为许多风格矢量。</p>
</li>
<li><p>合成网络</p>
<p>负责生成图片。它有一个固定的学好的输入（这个输入在训练之后是不变的，但在训练中被反向传播更新）。和之前一样，合成网络使用多个卷积核上采样层处理输入，但有两处不同：首先，输入和所有卷积层的输出（在激活函数之前）都添加了噪音。第二，每个噪音层的后面是一个适应实例归一化（AdaIN）层：它独立标准化每个特征映射（减去平均值，除以标准差），然后使用风格矢量确定每个特征映射的缩放和偏移（风格矢量对每个特征映射包含一个缩放和一个偏置项）</p>
</li>
</ol>
<p>StyleGAN使用了一种称为混合正则（或风格混合）的方法，生成图的一定比例使用两个编码来生成。特别的，编码c1 和 c2发送给映射网络，得到两个风格矢量w1 和 w2。然后合成网络使用风格w1生成第一级，用w2生成其余的。级的选取是随机的。这可以防止模型认为临近的级是有关联的，会导致GAN的局部性，每个风格矢量只会影响生成图的有限数量的特性。</p>
<h3 id="练习-7"><a href="#练习-7" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>自编码器主要用来做什么？</p>
<blockquote>
<p>无监督预训练，特征提取，降维，生成模型，异常值检测</p>
</blockquote>
</li>
<li><p>假设你想训练一个分类器，有许多未打标签的训练数据，只有一千多打了标签的数据。如何使用自编码器来解决这个问题？</p>
<blockquote>
<p>用所有的数据训练一个自编码器，然后将编码器部分用作分类器，用有标签的数据训练。如果有标签数据特别少，可能需要先冻结重复使用的几层。</p>
</blockquote>
</li>
<li><p>如果自编码器完美重建了输入，它一定是个好的自编码器吗？如何评估自编码器的表现？</p>
<blockquote>
<p>不一定，如果自编码器非常复杂，重建结果非常好，但是可能不能学到特征，泛化能力不好。</p>
<p>但是反过来，如果重建结果不好，那一定不是一个好的自编码器。</p>
<p>计算重建损失函数来评估自编码器的表现。</p>
</blockquote>
</li>
<li><p>自编码器的欠完成和过完成是什么？超欠完成的风险是什么？过完成的风险是什么？</p>
<blockquote>
<p>欠完成（undercomplete）：coding层比输入和输出层小，重建输入比较困难。</p>
<p>过完成（overcomplete）：coding层比输入和输出层大，仅仅将输入copy到输出，无法学习有用的特征。</p>
</blockquote>
</li>
<li><p>如何将栈式自编码器的权重连起来？这么做的意义是什么？</p>
<blockquote>
<p>将自编码器的编码器和解码器的权重连起来（解码器的权重=编码器权重的转置），减少参数的个数，使得训练收敛更快，减少过拟合的风险。</p>
</blockquote>
</li>
<li><p>什么是生成式模型？可以举出生成式自编码器的例子吗？</p>
<blockquote>
<p>生成模型可以随机生成可以以假乱真的数据实例。</p>
<p>在MNIST上训练的生成模型，可以随机生成手写数字的图像，一般情况下，生成模型的输出分布和训练集上的分布相似。如果想要输出特定类别的输出，可以使用变分编码器。</p>
</blockquote>
</li>
<li><p>GAN是什么？可以用于什么任务？</p>
<blockquote>
<p>GAN（generative adversarial network）生成对抗网络：是一种神经网络模型，有生成器和判别器两个部分。生成器的目的生成和训练集相似的实例，欺骗判别器，而判别器得目的是从生成的实例中分辨哪些是真正的实例。在每一轮训练中，判别器类似于二分类器，而生成器最大化判别器的误差。</p>
<p>GAN可以用于：高级的图像处理任务：上色，超分辨率，将草图生成照片化的图像。</p>
</blockquote>
</li>
<li><p>训练GAN的难点是什么？</p>
<blockquote>
<p>最大的困难是模式坍塌：生成器的输出逐渐变得不那么丰富。</p>
<p>训练不稳定，可能开始表现很好，几次迭代之后开始坍塌或者发散。</p>
<p>GAN会对超参数特别敏感：微调超参数会特别花费时间。</p>
</blockquote>
</li>
<li><p>用去噪音自编码器预训练一个图片分类器。可以使用MNIST，或是更复杂的图片数据集，比如CIFAR10。不管用的是什么数据集，遵循下面的步骤：</p>
<ul>
<li>将数据集分成训练集和测试集。在完整训练集上，训练一个深度去噪音自编码器。</li>
<li>检查图片正确重建了。可视化最激活编码层神经元的图片。</li>
<li>搭建一个分类DNN，使用自编码器的浅层。用训练集中的500张图片来训练。然后判断预训练是否提升了性能？</li>
</ul>
</li>
<li><p>用刚才选择的数据集，训练一个变分自编码器。用它来生成图片。或者，用一个没有标签的数据集，来生成新样本。</p>
</li>
<li><p>训练一个DCGAN来处理选择的数据集，生成新图片。添加经验接力，看看它是否有作用。再将其变为一个条件GAN，可以控制生成的类。</p>
</li>
</ol>
<h2 id="第18章-强化学习"><a href="#第18章-强化学习" class="headerlink" title="第18章 强化学习"></a>第18章 强化学习</h2><p> 2013 年一个革命性的发展：来自英国的研究者发起了Deepmind 项目，这个项目可以学习去玩任何从头开始的 Atari 游戏，在多数游戏中，比人类玩的还好，它仅使用像素作为输入而没有使用游戏规则的任何先验知识。在 2016 年 3 月以他们的系统AlphaGo战胜了世界围棋冠军李世石而告终。DeepMind 在 2014 被谷歌以超过 5 亿美元收购。</p>
<p>原理：将深度学习运用到强化学习领域</p>
<p>策略梯度和深度 Q 网络（DQN），包括讨论马尔可夫决策过程（MDP）。</p>
<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>在强化学习中，智能体在环境（environment）中观察（observation）并且做出决策（action），随后它会得到奖励（reward）。它的目标是去学习如何行动能最大化<strong>期望奖励</strong>。</p>
<h3 id="OpenAI-Gym"><a href="#OpenAI-Gym" class="headerlink" title="OpenAI Gym"></a>OpenAI Gym</h3><p>OpenAI Gym 是一个工具包，它提供各种各样的模拟环境（Atari 游戏，棋盘游戏，2D 和 3D 物理模拟等等）</p>
<h3 id="评价行为：信用分配问题"><a href="#评价行为：信用分配问题" class="headerlink" title="评价行为：信用分配问题"></a>评价行为：信用分配问题</h3><p>在强化学习中，智能体获得的指导的唯一途径是通过奖励，奖励通常是稀疏的和延迟的。例如，如果智能体在 100 个步骤内设法平衡杆，它怎么知道它采取的 100 个行动中的哪一个是好的，哪些是坏的？它所知道的是，在最后一次行动之后，杆子坠落了，但最后一次行动肯定不是负全责的。这被称为信用分配问题：当智能体得到奖励时，很难知道哪些行为应该被信任（或责备）。</p>
<p>基于这个动作后得分的总和来评估这个个动作，通常在每个步骤中应用衰减因子<code>r</code>。</p>
<h3 id="策略搜索"><a href="#策略搜索" class="headerlink" title="策略搜索"></a>策略搜索</h3><p>智能体用于改变行为的算法称为策略。</p>
<ol>
<li>神经网络策略，把观察作为输入，输出要执行的动作。</li>
<li>搜寻策略空间的方法是遗传算法。</li>
<li>另一种方法是使用优化技术，通过评估奖励关于策略参数的梯度，然后通过跟随梯度向更高的奖励（梯度上升）调整这些参数。这种方法被称为<strong>策略梯度（policy gradient, PG）。</strong></li>
</ol>
<p><strong>策略梯度</strong></p>
<ol>
<li>让神经网络策略玩几次游戏，并在每一步计算梯度，这使得智能体更可能选择行为，但不应用这些梯度。</li>
<li>运行几次后，计算每个动作的得分（使用前面段落中描述的方法）。</li>
<li>如果一个动作的分数是正的，这意味着动作是好的，可应用较早计算的梯度，以便将来有更大的的概率选择这个动作。但是，如果分数是负的，这意味着动作是坏的，要应用相反梯度来使得这个动作在将来采取的可能性更低。我们的方法就是简单地将每个梯度向量乘以相应的动作得分。</li>
<li>最后，计算所有得到的梯度向量的平均值，并使用它来执行梯度下降步骤。</li>
</ol>
<h4 id="马尔可夫决策过程"><a href="#马尔可夫决策过程" class="headerlink" title="马尔可夫决策过程"></a>马尔可夫决策过程</h4><p>在二十世纪初，数学家 Andrey Markov 研究了<strong>没有记忆的随机过程，称为马尔可夫链</strong>。这样的过程具有固定数量的状态，并且在每个步骤中随机地从一个状态演化到另一个状态。它从状态<code>S</code>演变为状态<code>S&#39;</code>的概率是固定的，它只依赖于<code>(S, S&#39;)</code>对，而不是依赖于过去的状态（系统没有记忆）。</p>
<p><strong>马尔可夫决策过程</strong>最初是在 20 世纪 50 年代由 Richard Bellman <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F133" target="_blank" rel="noopener">描述</a>的。它们类似于马尔可夫链，但有一个不同：在状态转移的每一步中，一个智能体可以选择几种可能的动作中的一个，并且过渡概率取决于所选择的动作。此外，一些状态过渡返回一些奖励（正或负），智能体的目标是找到一个策略，随着时间的推移将最大限度地提高奖励。</p>
<p>估计任何状态<code>S</code>的最佳状态值的方法，记作<code>V(s)</code>，它是智能体在其采取最佳行为达到状态<code>s</code>后所有衰减未来奖励的总和的平均期望。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-6c97696a5b56dafd.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img"></p>
<p>Bellman 发现了一种非常类似的算法来估计最优状态-动作值（<em>state-action values</em>），通常称为 Q 值。状态行动<code>(S, A)</code>对的最优 Q 值，记为<code>Q*(s, a)</code>，是智能体在到达状态<code>S</code>，然后选择动作<code>A</code>之后平均衰减未来奖励的期望的总和。但是在它看到这个动作的结果之前，假设它在该动作之后的动作是最优的。</p>
<h4 id="时间差分学习"><a href="#时间差分学习" class="headerlink" title="时间差分学习"></a>时间差分学习</h4><p>具有离散动作的强化学习问题通常可以被建模为马尔可夫决策过程，但是智能体最初不知道转移概率是什么（它不知道<code>T(s, a, s′)</code>），并且它不知道奖励会是什么（它不知道<code>R(s, a, s′)</code>）。它必须经历每一个状态和每一次转变并且至少知道一次奖励，并且如果要对转移概率进行合理的估计，就必须经历多次。</p>
<p>时间差分学习（TD 学习）算法与数值迭代算法非常类似，但考虑到智能体仅具有 MDP 的部分知识。</p>
<h4 id="Q-学习"><a href="#Q-学习" class="headerlink" title="Q-学习"></a>Q-学习</h4><p>Q-学习算法是 Q 值迭代算法的改编版本，其适应转移概率和回报在初始未知的情况。</p>
<p>Q-学习被称为离线策略算法，因为正在训练的策略不是正在执行的策略。</p>
<p><strong>缺点：</strong>不能很好地扩展到具有许多状态和动作的大（甚至中等）的 MDP。</p>
<p><strong>解决方案：</strong>找到一个函数Qθ(s,a)，使用可管理数量的参数（根据矢量θ）来近似 Q 值。这被称为<strong>近似 Q 学习。</strong></p>
<p>在2013年， DeepMind 表明使用深度神经网络可以工作得更好，特别是对于复杂的问题。它不需要任何特征工程。用于估计 Q 值的 DNN 被称为深度 Q 网络（DQN），并且使用近似 Q 学习的 DQN 被称为<strong>深度 Q 学习。</strong></p>
<h4 id="深度Q-学习的变体"><a href="#深度Q-学习的变体" class="headerlink" title="深度Q-学习的变体"></a>深度Q-学习的变体</h4><h5 id="固定Q-值目标"><a href="#固定Q-值目标" class="headerlink" title="固定Q-值目标"></a>固定Q-值目标</h5><p>在基本的深度Q-学习算法中，模型不仅做预测还自己设置目标。有点像一只狗追自己的尾巴。反馈循环使得网络不稳定：会发生分叉、摇摆、冻结，等等。要解决问题，DeepMind在2013年的论文中使用了两个DQN，而不是一个：第一个是在线模型，它在每一步进行学习，并移动智能体；另一个是目标模型只定义目标。目标模型只是在线模型的克隆。</p>
<h5 id="双DQN"><a href="#双DQN" class="headerlink" title="双DQN"></a>双DQN</h5><h5 id="优先经验接力"><a href="#优先经验接力" class="headerlink" title="优先经验接力"></a>优先经验接力</h5><h5 id="对决DQN"><a href="#对决DQN" class="headerlink" title="对决DQN"></a>对决DQN</h5><h4 id="探索策略"><a href="#探索策略" class="headerlink" title="探索策略"></a>探索策略</h4><p>只有在探索策略充分探索 MDP 的情况下，Q 学习才能起作用。尽管一个纯粹的随机策略保证最终访问每一个状态和每个转换多次，但可能需要很长的时间这样做。因此，一个更好的选择是使用 ε 贪婪策略：在每个步骤中，它以概率<code>ε</code>随机地或以概率为<code>1-ε</code>贪婪地选择具有最高 Q 值的动作。ε 贪婪策略的优点（与完全随机策略相比）是，它将花费越来越多的时间来探索环境中有趣的部分，因为 Q 值估计越来越好，同时仍花费一些时间访问 MDP 的未知区域。</p>
<h3 id="练习-8"><a href="#练习-8" class="headerlink" title="练习"></a>练习</h3><ol>
<li><p>如何定义强化学习？它与传统的监督和非监督学习有什么不同？</p>
<blockquote>
<p>​</p>
</blockquote>
</li>
<li><p>你能想到什么本章没有提到过的强化学习的应用？环境是什么？智能体是什么？什么是可能的动作，什么是奖励？</p>
<blockquote>
<p>音乐个人化：环境是用户个人化的网络电台。智能体是软件决定下一首播放音乐。可能动作是播放目录下的任一首音乐。如果用户没有切换音乐则获得奖励，如果用户跳过该音乐则负奖励，如果用户离开，或者非常大的负奖励。</p>
</blockquote>
</li>
<li><p>什么是衰减率？如果修改了衰减率那最优策略会变化吗？</p>
<blockquote>
<p>在评估一个动作的时候，强化学习通常会把几步的奖励加起来，给最近的奖励大的权重，之前的奖励小的权重。衰减率就是这个权重的差别。</p>
<p>如果修改了衰减率最优策略肯定会发生变化。</p>
</blockquote>
</li>
<li><p>如何测量强化学习智能体的表现？</p>
<blockquote>
<p>用几步的奖励和来评估强化学习智能体的表现。</p>
</blockquote>
</li>
<li><p>什么是信用分配问题？它怎么出现的？怎么解决？</p>
<blockquote>
<p>产生信用分配问题的原因是不知道之前的动作对当下动作获得奖励的贡献。</p>
<p>使用shorter-term rewards。</p>
</blockquote>
</li>
<li><p>使用接力缓存的目的是什么？</p>
<blockquote>
<p>一个智能体会在环境的某一部分中停留一段时间，所以在这一阶段经历类似。将所有经验存储在接力缓存（或接力记忆）中，每次训练迭代，从中随机采样一个批次。这样可以降低训练批次中的经验相关性，可以极大的提高训练效果。</p>
<p><a href="https://www.zhihu.com/question/52064135" target="_blank" rel="noopener">知乎相关答案</a></p>
</blockquote>
</li>
<li><p>什么是off策略 RL 算法？</p>
<blockquote>
<p>在强化学些中利用动作来探索（exploration 行为策略），之后得到应用的策略中去（exploitation 目标策略）</p>
<p>on-policy的目标策略和行为策略相同，直接利用数据优化策略，但可能学习到局部最优，没有办法很好的同时探索，利用。而off-policy RL将目标策略和行为策略分开，可以在保持探索的同时，更能求到全局最优值。</p>
<p>Q-learning就是一个这样的例子。</p>
</blockquote>
</li>
<li><p>使用策略梯度处理 OpenAI gym 的“LunarLander-v2” 环境。需要安装<code>Box2D</code>依赖（<code>python3 -m pip install gym[box2d]</code>）。</p>
</li>
<li><p>用任何可行的算法，使用TF-Agents训练可以达到人类水平的可以玩SpaceInvaders-v4的智能体。</p>
</li>
<li><p>如果你有大约 100 美元备用，你可以购买 Raspberry Pi 3 再加上一些便宜的机器人组件，在 Pi 上安装 TensorFlow，然后让我们嗨起来~！举个例子，看看 Lukas Biewald 的这个<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fhoml.info%2F2" target="_blank" rel="noopener">有趣的帖子</a>，或者看看 GoPiGo 或 BrickPi。从简单目标开始，比如让机器人转向最亮的角度（如果有光传感器）或最近的物体（如果有声呐传感器），并移动。然后可以使用深度学习：比如，如果机器人有摄像头，可以实现目标检测算法，检测人并向人移动。还可以利用RL算法让智能体自己学习使用马达达到目的。</p>
</li>
</ol>
<h2 id="第19章-规模化训练和部署TensorFlow模型"><a href="#第19章-规模化训练和部署TensorFlow模型" class="headerlink" title="第19章 规模化训练和部署TensorFlow模型"></a>第19章 规模化训练和部署TensorFlow模型</h2><h3 id="练习-9"><a href="#练习-9" class="headerlink" title="练习"></a>练习</h3><ol>
<li>SavedModel包含什么？如何检查内容？</li>
<li>什么时候使用TF Serving？它有什么特点？可以用什么工具部署TF Serving？</li>
<li>如何在多个TF Serving实例上部署模型？</li>
<li>为什么使用gRPC API而不是REST API，查询TF Serving模型？</li>
<li>在移动和嵌入设备上运行，TFLite减小模型的大小有什么方法？</li>
<li>什么是伪量化训练，有什么用？</li>
<li>什么是模型并行和数据并行？为什么推荐后者？</li>
<li>在多台服务器上训练模型时，可以使用什么分布策略？如何进行选择？</li>
<li>训练模型（或任意模型），部署到TF Serving或Google Cloud AI Platform上。写客户端代码，用REST API 或 gRPC API做查询。更新模型，部署新版本。客户端现在查询新版本。回滚到第一个版本。</li>
<li>用一台机器多个GPU、<code>MirroredStrategy</code>策略，训练模型（如果没有GPU，可以使用带有GPU的Colaboratory，创建两个虚拟GPU）。再用<code>CentralStorageStrategy</code>训练一次，比较训练时间。</li>
<li>在Google Cloud AI Platform训练一个小模型，使用黑盒超参数调节。</li>
</ol>
<p>​                                                                                                                                                                                          </p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/sklearn/" rel="tag"># sklearn</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/08/29/Markdown%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D/" rel="prev" title="Markdown文件恢复">
      <i class="fa fa-chevron-left"></i> Markdown文件恢复
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/09/04/hexo-%E5%A6%82%E4%BD%95%E6%94%AF%E6%8C%81%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/" rel="next" title="hexo-如何支持数学公式">
      hexo-如何支持数学公式 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#第10章-使用Keras搭建人工神经网络"><span class="nav-text">第10章 使用Keras搭建人工神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#神经元的逻辑计算"><span class="nav-text">神经元的逻辑计算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#感知机（单个TLU）"><span class="nav-text">感知机（单个TLU）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#阶跃函数："><span class="nav-text">阶跃函数：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hebb规则"><span class="nav-text">Hebb规则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#感知机的局限性"><span class="nav-text">感知机的局限性</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多层感知机（MLP）"><span class="nav-text">多层感知机（MLP）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#反向传播（Back-Propagation）"><span class="nav-text">反向传播（Back Propagation）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#激活函数"><span class="nav-text">激活函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#回归MLP"><span class="nav-text">回归MLP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分类MLP"><span class="nav-text">分类MLP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#用Keras实现MLP"><span class="nav-text">用Keras实现MLP</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#保存和恢复模型"><span class="nav-text">保存和恢复模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用调回"><span class="nav-text">使用调回</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用TensorBoard进行可视化"><span class="nav-text">使用TensorBoard进行可视化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#神经网络参数微调"><span class="nav-text">神经网络参数微调</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#微调神经网络的超参数"><span class="nav-text">微调神经网络的超参数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#隐藏层"><span class="nav-text">隐藏层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#每个隐藏层的神经元数"><span class="nav-text">每个隐藏层的神经元数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#学习率，批次大小和其它超参数"><span class="nav-text">学习率，批次大小和其它超参数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#练习"><span class="nav-text">练习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第11章-训练深度神经网络"><span class="nav-text">第11章 训练深度神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度消失-爆炸问题"><span class="nav-text">梯度消失&#x2F;爆炸问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Glorot-和-He-初始化"><span class="nav-text">Glorot 和 He 初始化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#非饱和激活函数"><span class="nav-text">非饱和激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ReLU-函数的变体"><span class="nav-text">ReLU 函数的变体</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#leaky-ReLU："><span class="nav-text">leaky ReLU：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#随机化-leaky-ReLU（RReLU）"><span class="nav-text">随机化 leaky ReLU（RReLU）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#参数化的-leaky-ReLU（PReLU）"><span class="nav-text">参数化的 leaky ReLU（PReLU）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#指数线性单元（exponential-linear-unit，ELU）"><span class="nav-text">指数线性单元（exponential linear unit，ELU）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Scaled-ELU（SELU）激活函数"><span class="nav-text">Scaled ELU（SELU）激活函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#批归一化（Batch-Normalization）"><span class="nav-text">批归一化（Batch Normalization）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用-Keras-实现批归一化"><span class="nav-text">使用 Keras 实现批归一化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度裁剪"><span class="nav-text">梯度裁剪</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#复用预训练层"><span class="nav-text">复用预训练层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#无监督预训练"><span class="nav-text">无监督预训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#在辅助任务上预训练"><span class="nav-text">在辅助任务上预训练</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#更快的优化器"><span class="nav-text">更快的优化器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#动量优化"><span class="nav-text">动量优化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Nesterov-加速梯度"><span class="nav-text">Nesterov 加速梯度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AdaGrad"><span class="nav-text">AdaGrad</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RMSProp"><span class="nav-text">RMSProp</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Adam-和-Nadam-优化"><span class="nav-text">Adam 和 Nadam 优化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#学习率调整"><span class="nav-text">学习率调整</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#幂调度"><span class="nav-text">幂调度:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#指数调度"><span class="nav-text">指数调度:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#预定的分段恒定学习率："><span class="nav-text">预定的分段恒定学习率：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#性能调度："><span class="nav-text">性能调度：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1循环调度："><span class="nav-text">1循环调度：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#通过正则化避免过拟合"><span class="nav-text">通过正则化避免过拟合</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ℓ1-和-ℓ2正则"><span class="nav-text">ℓ1 和 ℓ2正则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dropout"><span class="nav-text">Dropout</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最大范数正则化"><span class="nav-text">最大范数正则化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#练习-1"><span class="nav-text">练习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第12章-使用TensorFlow自定义模型并训练"><span class="nav-text">第12章 使用TensorFlow自定义模型并训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#TensorFlow速览"><span class="nav-text">TensorFlow速览</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#像NumPy一样使用TensorFlow"><span class="nav-text">像NumPy一样使用TensorFlow</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#张量和运算"><span class="nav-text">张量和运算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#张量和NumPy"><span class="nav-text">张量和NumPy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#类型转换"><span class="nav-text">类型转换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#变量"><span class="nav-text">变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#其它数据结构"><span class="nav-text">其它数据结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自定义模型和训练算法"><span class="nav-text">自定义模型和训练算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义损失函数"><span class="nav-text">自定义损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#保存并加载包含自定义组件的模型"><span class="nav-text">保存并加载包含自定义组件的模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义激活函数、初始化器、正则器和约束"><span class="nav-text">自定义激活函数、初始化器、正则器和约束</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义指标"><span class="nav-text">自定义指标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义层"><span class="nav-text">自定义层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义模型"><span class="nav-text">自定义模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基于模型内部的损失和指标"><span class="nav-text">基于模型内部的损失和指标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义训练循环"><span class="nav-text">自定义训练循环</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TensorFlow的函数和图"><span class="nav-text">TensorFlow的函数和图</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#练习-2"><span class="nav-text">练习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第13章-使用TensorFlow加载和预处理数据"><span class="nav-text">第13章 使用TensorFlow加载和预处理数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-API"><span class="nav-text">Data API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#链式转换"><span class="nav-text">链式转换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#打散数据"><span class="nav-text">打散数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多行数据交叉"><span class="nav-text">多行数据交叉</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#预处理数据"><span class="nav-text">预处理数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#整合"><span class="nav-text">整合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#预提取"><span class="nav-text">预提取</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TFRecord格式"><span class="nav-text">TFRecord格式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#压缩TFRecord文件"><span class="nav-text">压缩TFRecord文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#协议缓存"><span class="nav-text">协议缓存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TensorFlow协议缓存"><span class="nav-text">TensorFlow协议缓存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#加载和解析Example"><span class="nav-text">加载和解析Example</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用SequenceExample协议缓存处理嵌套列表"><span class="nav-text">使用SequenceExample协议缓存处理嵌套列表</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预处理输入特征"><span class="nav-text">预处理输入特征</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用独热矢量编码类型特征"><span class="nav-text">使用独热矢量编码类型特征</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#用嵌入编码类型特征"><span class="nav-text">用嵌入编码类型特征</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Keras预处理层"><span class="nav-text">Keras预处理层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TF-Transform"><span class="nav-text">TF Transform</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TensorFlow-Datasets（TFDS）项目"><span class="nav-text">TensorFlow Datasets（TFDS）项目</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#练习-3"><span class="nav-text">练习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第14章-使用卷积神经网络实现深度计算机视觉"><span class="nav-text">第14章 使用卷积神经网络实现深度计算机视觉</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#视神经结构"><span class="nav-text">视神经结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积层"><span class="nav-text">卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#过滤器"><span class="nav-text">过滤器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#堆叠多个特征映射"><span class="nav-text">堆叠多个特征映射</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内存需求"><span class="nav-text">内存需求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#池化层"><span class="nav-text">池化层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN架构"><span class="nav-text">CNN架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LeNet-5"><span class="nav-text">LeNet-5</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AlexNet"><span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GoogLeNet"><span class="nav-text">GoogLeNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#VGGNet"><span class="nav-text">VGGNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ResNet"><span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用预训练模型做迁移学习"><span class="nav-text">使用预训练模型做迁移学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分类和定位"><span class="nav-text">分类和定位</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#目标检测"><span class="nav-text">目标检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#全卷积网络（fully-convolutional-network，FCN）"><span class="nav-text">全卷积网络（fully convolutional network，FCN）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#全卷积层"><span class="nav-text">全卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#只看一次（YOLO）"><span class="nav-text">只看一次（YOLO）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#语义分割"><span class="nav-text">语义分割</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#练习-4"><span class="nav-text">练习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第15章-使用RNN和CNN处理序列"><span class="nav-text">第15章 使用RNN和CNN处理序列</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#循环神经元和层"><span class="nav-text">循环神经元和层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#记忆单元"><span class="nav-text">记忆单元</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练RNN"><span class="nav-text">训练RNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预测时间序列"><span class="nav-text">预测时间序列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基线模型"><span class="nav-text">基线模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实现一个简单地RNN"><span class="nav-text">实现一个简单地RNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#深度RNN"><span class="nav-text">深度RNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#处理长序列"><span class="nav-text">处理长序列</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#应对不稳定梯度"><span class="nav-text">应对不稳定梯度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#处理短期记忆问题"><span class="nav-text">处理短期记忆问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LSTM的变体"><span class="nav-text">LSTM的变体</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用1D卷积层处理序列"><span class="nav-text">使用1D卷积层处理序列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#WaveNet"><span class="nav-text">WaveNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#练习-5"><span class="nav-text">练习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第16章-使用RNN和注意力机制进行自然语言处理"><span class="nav-text">第16章 使用RNN和注意力机制进行自然语言处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#有状态RNN"><span class="nav-text">有状态RNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#集束搜索"><span class="nav-text">集束搜索</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#视觉注意力"><span class="nav-text">视觉注意力</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多头注意力"><span class="nav-text">多头注意力</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#练习-6"><span class="nav-text">练习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第17章-使用自编码器和GAN做表征学习和生成式学习"><span class="nav-text">第17章 使用自编码器和GAN做表征学习和生成式学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#自编码器"><span class="nav-text">自编码器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#栈式自编码器"><span class="nav-text">栈式自编码器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用栈式自编码器做无监督预训练"><span class="nav-text">使用栈式自编码器做无监督预训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#关联权重"><span class="nav-text">关联权重</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#一次训练一个自编码器"><span class="nav-text">一次训练一个自编码器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积自编码器"><span class="nav-text">卷积自编码器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#循环自编码器"><span class="nav-text">循环自编码器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#学习方法"><span class="nav-text">学习方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#降噪自编码"><span class="nav-text">降噪自编码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#稀疏自编码器"><span class="nav-text">稀疏自编码器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#变分自编码器（VAE）"><span class="nav-text">变分自编码器（VAE）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对抗生成网络（GAN）"><span class="nav-text">对抗生成网络（GAN）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#训练GAN的难点"><span class="nav-text">训练GAN的难点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#深度卷积GAN（DCGAN）"><span class="nav-text">深度卷积GAN（DCGAN）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#条件GAN（CGAN）"><span class="nav-text">条件GAN（CGAN）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#方法：用于提高输出的散度（避免模式坍塌），使训练更稳定："><span class="nav-text">方法：用于提高输出的散度（避免模式坍塌），使训练更稳定：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#GAN的渐进式变大"><span class="nav-text">GAN的渐进式变大</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#小批次标准差层"><span class="nav-text">小批次标准差层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#相等的学习率"><span class="nav-text">相等的学习率</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#像素级归一化层"><span class="nav-text">像素级归一化层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#StyleGAN"><span class="nav-text">StyleGAN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#练习-7"><span class="nav-text">练习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第18章-强化学习"><span class="nav-text">第18章 强化学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概念"><span class="nav-text">概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OpenAI-Gym"><span class="nav-text">OpenAI Gym</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#评价行为：信用分配问题"><span class="nav-text">评价行为：信用分配问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#策略搜索"><span class="nav-text">策略搜索</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#马尔可夫决策过程"><span class="nav-text">马尔可夫决策过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#时间差分学习"><span class="nav-text">时间差分学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Q-学习"><span class="nav-text">Q-学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#深度Q-学习的变体"><span class="nav-text">深度Q-学习的变体</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#探索策略"><span class="nav-text">探索策略</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#练习-8"><span class="nav-text">练习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第19章-规模化训练和部署TensorFlow模型"><span class="nav-text">第19章 规模化训练和部署TensorFlow模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#练习-9"><span class="nav-text">练习</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="QQAI"
      src="/images/header.jpg">
  <p class="site-author-name" itemprop="name">QQAI</p>
  <div class="site-description" itemprop="description">Home is behind, the world ahead</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">28</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">QQAI</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.1
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">
    MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
